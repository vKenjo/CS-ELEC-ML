{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Josh Kenn Viray\n",
    "# 3CSC\n",
    "# Formative 2.1\n",
    "# flake8: noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours Studied  Previous Scores  Extracurricular Activities  Sleep Hours  \\\n",
       "0              7               99                           1            9   \n",
       "1              4               82                           0            4   \n",
       "2              8               51                           1            7   \n",
       "3              5               52                           1            5   \n",
       "4              7               75                           0            8   \n",
       "\n",
       "   Sample Question Papers Practiced  Performance Index  \n",
       "0                                 1                 91  \n",
       "1                                 2                 65  \n",
       "2                                 2                 45  \n",
       "3                                 2                 36  \n",
       "4                                 5                 66  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. Load Data\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "# Load the data \n",
    "df = pd.read_csv('./../Student_Performance.csv')\n",
    "df.head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. Select a unique randomization seed\n",
    "# =============================================================================\n",
    "\n",
    "seed = 39\n",
    "np.random.seed(seed)\n",
    "\n",
    "# let n be the target sample of observations\n",
    "n = 30\n",
    "\n",
    "# let tn be the target sample of observations\n",
    "tn = 30\n",
    "\n",
    "# let i be iterations\n",
    "i = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hours Studied  Previous Scores  Extracurricular Activities  Sleep Hours  \\\n",
       "9229              2               96                           0            9   \n",
       "7476              6               95                           1            8   \n",
       "2702              5               79                           0            8   \n",
       "3941              1               91                           1            5   \n",
       "3540              1               50                           0            4   \n",
       "\n",
       "      Sample Question Papers Practiced  Performance Index  \n",
       "9229                                 6                 74  \n",
       "7476                                 4                 84  \n",
       "2702                                 5                 65  \n",
       "3941                                 0                 63  \n",
       "3540                                 6                 22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. Sample Train Data\n",
    "# =============================================================================\n",
    "\n",
    "features = ['Hours Studied', 'Previous Scores', \n",
    "            'Extracurricular Activities', \n",
    "            'Sample Question Papers Practiced', \n",
    "            'Performance Index']\n",
    "target = 'Performance Index'\n",
    "\n",
    "# Randomly sample 30 observations for training using the seed.\n",
    "train_df = df.sample(n, random_state=seed)\n",
    "\n",
    "# Check that the training sample looks representative\n",
    "print(\"Training Sample:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[features].values\n",
    "y_train = train_df[target].values\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_train_aug = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. Building the Weight Update (Gradient Descent) Function\n",
    "# =============================================================================\n",
    "def gradient_descent(X, y, weights, learning_rate=0.01, iterations=50):\n",
    "    weight_history = []\n",
    "    for i in range(iterations):\n",
    "        # Compute predictions\n",
    "        predictions = X.dot(weights)\n",
    "        \n",
    "        # Compute errors and Mean Squared Error (MSE) loss\n",
    "        errors = predictions - y\n",
    "        loss = np.mean(errors ** 2)\n",
    "        \n",
    "        # Compute gradients (partial derivatives)\n",
    "        gradients = (1 / len(y)) * X.T.dot(errors)\n",
    "        \n",
    "        # Update weights using gradient descent rule\n",
    "        weights = weights - learning_rate * gradients\n",
    "        \n",
    "        # Save current weights in history and print iteration details\n",
    "        weight_history.append(weights.copy())\n",
    "        print(f\"Iteration {i+1}: Weights = {weights}, Loss = {loss:.4f}\")\n",
    "    return weights, weight_history\n",
    "\n",
    "# Initialize weights (one for intercept plus one per feature)\n",
    "initial_weights = np.zeros(X_train_aug.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Weights = [0.55       0.06436373 0.17343832 0.06640459 0.01581193 0.19440508], Loss = 3402.9333\n",
      "Iteration 2: Weights = [1.0945     0.12758948 0.34327526 0.13086307 0.0310865  0.38486599], Loss = 3327.5608\n",
      "Iteration 3: Weights = [1.633555   0.18969909 0.50958688 0.19342136 0.04583804 0.57146517], Loss = 3254.0136\n",
      "Iteration 4: Weights = [2.16721945 0.25071395 0.67244765 0.25412436 0.06008052 0.7542833 ], Loss = 3182.2417\n",
      "Iteration 5: Weights = [2.69554726 0.31065502 0.83193042 0.31301597 0.07382758 0.93339934], Loss = 3112.1966\n",
      "Iteration 6: Weights = [3.21859178 0.36954285 0.98810651 0.37013914 0.08709254 1.1088906 ], Loss = 3043.8312\n",
      "Iteration 7: Weights = [3.73640587 0.42739755 1.14104572 0.42553584 0.0998884  1.28083275], Loss = 2977.1001\n",
      "Iteration 8: Weights = [4.24904181 0.48423885 1.29081636 0.47924711 0.11222784 1.44929985], Loss = 2911.9591\n",
      "Iteration 9: Weights = [4.75655139 0.54008609 1.43748529 0.53131309 0.12412325 1.61436442], Loss = 2848.3655\n",
      "Iteration 10: Weights = [5.25898587 0.59495818 1.58111796 0.58177303 0.1355867  1.77609741], Loss = 2786.2778\n",
      "Iteration 11: Weights = [5.75639602 0.64887371 1.7217784  0.63066528 0.14662999 1.9345683 ], Loss = 2725.6560\n",
      "Iteration 12: Weights = [6.24883206 0.70185085 1.8595293  0.67802737 0.15726464 2.08984509], Loss = 2666.4610\n",
      "Iteration 13: Weights = [6.73634374 0.75390743 1.99443202 0.72389598 0.16750186 2.24199434], Loss = 2608.6552\n",
      "Iteration 14: Weights = [7.2189803  0.80506091 2.1265466  0.76830696 0.17735263 2.39108121], Loss = 2552.2020\n",
      "Iteration 15: Weights = [7.69679049 0.85532841 2.25593182 0.81129538 0.18682763 2.53716949], Loss = 2497.0659\n",
      "Iteration 16: Weights = [8.16982259 0.90472671 2.3826452  0.85289552 0.1959373  2.6803216 ], Loss = 2443.2124\n",
      "Iteration 17: Weights = [8.63812436 0.95327224 2.50674303 0.89314089 0.20469182 2.82059867], Loss = 2390.6083\n",
      "Iteration 18: Weights = [9.10174312 1.00098111 2.62828042 0.93206426 0.21310113 2.95806051], Loss = 2339.2210\n",
      "Iteration 19: Weights = [9.56072569 1.04786912 2.74731129 0.96969766 0.22117491 3.09276569], Loss = 2289.0193\n",
      "Iteration 20: Weights = [10.01511843  1.09395174  2.86388845  1.00607242  0.22892263  3.22477153], Loss = 2239.9726\n",
      "Iteration 21: Weights = [10.46496725  1.13924414  2.97806354  1.04121914  0.2363535   3.35413416], Loss = 2192.0512\n",
      "Iteration 22: Weights = [10.91031758  1.18376117  3.08988713  1.07516776  0.24347652  3.48090849], Loss = 2145.2266\n",
      "Iteration 23: Weights = [11.3512144   1.22751742  3.19940872  1.10794754  0.25030048  3.6051483 ], Loss = 2099.4707\n",
      "Iteration 24: Weights = [11.78770226  1.27052716  3.30667674  1.13958709  0.25683393  3.72690624], Loss = 2054.7566\n",
      "Iteration 25: Weights = [12.21982523  1.31280437  3.41173861  1.17011436  0.26308523  3.84623381], Loss = 2011.0579\n",
      "Iteration 26: Weights = [12.64762698  1.35436279  3.51464073  1.19955669  0.26906253  3.96318148], Loss = 1968.3491\n",
      "Iteration 27: Weights = [13.07115071  1.39521585  3.61542851  1.2279408   0.27477376  4.0777986 ], Loss = 1926.6054\n",
      "Iteration 28: Weights = [13.4904392   1.43537673  3.71414642  1.25529281  0.28022668  4.19013352], Loss = 1885.8027\n",
      "Iteration 29: Weights = [13.90553481  1.47485835  3.81083795  1.28163826  0.28542884  4.30023355], Loss = 1845.9176\n",
      "Iteration 30: Weights = [14.31647946  1.51367338  3.90554569  1.3070021   0.29038762  4.40814501], Loss = 1806.9275\n",
      "Iteration 31: Weights = [14.72331467  1.55183421  3.99831133  1.33140872  0.29511019  4.51391325], Loss = 1768.8100\n",
      "Iteration 32: Weights = [15.12608152  1.58935301  4.08917566  1.35488198  0.29960357  4.61758264], Loss = 1731.5439\n",
      "Iteration 33: Weights = [15.52482071  1.62624171  4.17817861  1.37744518  0.30387459  4.71919663], Loss = 1695.1082\n",
      "Iteration 34: Weights = [15.9195725   1.662512    4.26535927  1.39912109  0.30792991  4.81879778], Loss = 1659.4827\n",
      "Iteration 35: Weights = [16.31037678  1.69817534  4.35075588  1.41993199  0.31177602  4.91642771], Loss = 1624.6475\n",
      "Iteration 36: Weights = [16.69727301  1.73324295  4.43440588  1.43989965  0.31541926  5.01212718], Loss = 1590.5836\n",
      "Iteration 37: Weights = [17.08030028  1.76772585  4.51634593  1.45904532  0.31886579  5.10593611], Loss = 1557.2722\n",
      "Iteration 38: Weights = [17.45949727  1.80163483  4.59661189  1.47738979  0.32212164  5.19789356], Loss = 1524.6953\n",
      "Iteration 39: Weights = [17.8349023   1.83498047  4.67523886  1.49495339  0.32519266  5.28803776], Loss = 1492.8351\n",
      "Iteration 40: Weights = [18.20655328  1.86777315  4.75226122  1.51175598  0.32808459  5.37640616], Loss = 1461.6745\n",
      "Iteration 41: Weights = [18.57448775  1.90002303  4.82771259  1.52781694  0.33080297  5.4630354 ], Loss = 1431.1967\n",
      "Iteration 42: Weights = [18.93874287  1.93174008  4.90162589  1.54315526  0.33335326  5.54796137], Loss = 1401.3857\n",
      "Iteration 43: Weights = [19.29935544  1.96293408  4.97403335  1.55778946  0.33574073  5.63121919], Loss = 1372.2254\n",
      "Iteration 44: Weights = [19.65636189  1.99361461  5.0449665   1.57173766  0.33797054  5.71284324], Loss = 1343.7006\n",
      "Iteration 45: Weights = [20.00979827  2.02379107  5.11445622  1.58501754  0.34004773  5.79286718], Loss = 1315.7961\n",
      "Iteration 46: Weights = [20.35970028  2.05347266  5.18253272  1.59764642  0.34197718  5.87132397], Loss = 1288.4976\n",
      "Iteration 47: Weights = [20.70610328  2.08266841  5.24922557  1.60964118  0.34376366  5.94824588], Loss = 1261.7906\n",
      "Iteration 48: Weights = [21.04904225  2.11138719  5.31456372  1.62101834  0.34541182  6.02366448], Loss = 1235.6615\n",
      "Iteration 49: Weights = [21.38855183  2.13963766  5.37857551  1.63179404  0.34692619  6.0976107 ], Loss = 1210.0967\n",
      "Iteration 50: Weights = [21.72466631  2.16742835  5.44128867  1.64198404  0.34831118  6.1701148 ], Loss = 1185.0831\n",
      "Iteration 51: Weights = [22.05741964  2.19476759  5.50273034  1.65160375  0.34957108  6.24120642], Loss = 1160.6080\n",
      "Iteration 52: Weights = [22.38684545  2.22166358  5.5629271   1.66066822  0.35071007  6.31091458], Loss = 1136.6589\n",
      "Iteration 53: Weights = [22.71297699  2.24812432  5.62190495  1.66919215  0.35173224  6.37926767], Loss = 1113.2237\n",
      "Iteration 54: Weights = [23.03584722  2.2741577   5.67968935  1.67718993  0.35264154  6.44629351], Loss = 1090.2905\n",
      "Iteration 55: Weights = [23.35548875  2.29977143  5.73630521  1.68467558  0.35344185  6.51201932], Loss = 1067.8479\n",
      "Iteration 56: Weights = [23.67193386  2.32497307  5.79177694  1.69166281  0.35413692  6.57647175], Loss = 1045.8846\n",
      "Iteration 57: Weights = [23.98521453  2.34977004  5.84612839  1.69816503  0.35473041  6.6396769 ], Loss = 1024.3897\n",
      "Iteration 58: Weights = [24.29536238  2.37416962  5.89938294  1.70419533  0.3552259   6.70166031], Loss = 1003.3526\n",
      "Iteration 59: Weights = [24.60240876  2.39817893  5.95156346  1.70976649  0.35562686  6.76244699], Loss = 982.7628\n",
      "Iteration 60: Weights = [24.90638467  2.42180498  6.00269234  1.71489101  0.35593665  6.82206143], Loss = 962.6103\n",
      "Iteration 61: Weights = [25.20732082  2.44505462  6.05279149  1.71958108  0.35615858  6.8805276 ], Loss = 942.8851\n",
      "Iteration 62: Weights = [25.50524761  2.46793459  6.10188237  1.72384863  0.35629585  6.93786897], Loss = 923.5777\n",
      "Iteration 63: Weights = [25.80019514  2.49045147  6.14998596  1.72770529  0.35635156  6.99410853], Loss = 904.6786\n",
      "Iteration 64: Weights = [26.09219319  2.51261175  6.19712283  1.73116244  0.35632875  7.04926877], Loss = 886.1787\n",
      "Iteration 65: Weights = [26.38127125  2.53442176  6.2433131   1.73423118  0.35623037  7.10337171], Loss = 868.0691\n",
      "Iteration 66: Weights = [26.66745854  2.55588774  6.28857645  1.73692237  0.35605929  7.15643893], Loss = 850.3411\n",
      "Iteration 67: Weights = [26.95078396  2.57701578  6.33293216  1.7392466   0.3558183   7.20849154], Loss = 832.9860\n",
      "Iteration 68: Weights = [27.23127612  2.59781188  6.3763991   1.74121421  0.35551012  7.25955021], Loss = 815.9958\n",
      "Iteration 69: Weights = [27.50896336  2.6182819   6.41899573  1.74283532  0.35513738  7.30963518], Loss = 799.3623\n",
      "Iteration 70: Weights = [27.78387372  2.63843161  6.46074015  1.74411978  0.35470267  7.35876627], Loss = 783.0775\n",
      "Iteration 71: Weights = [28.05603498  2.65826665  6.50165004  1.74507725  0.35420846  7.40696288], Loss = 767.1338\n",
      "Iteration 72: Weights = [28.32547463  2.67779257  6.54174272  1.74571712  0.3536572   7.454244  ], Loss = 751.5237\n",
      "Iteration 73: Weights = [28.59221989  2.6970148   6.58103516  1.7460486   0.35305125  7.50062825], Loss = 736.2398\n",
      "Iteration 74: Weights = [28.85629769  2.71593867  6.61954395  1.74608065  0.3523929   7.54613382], Loss = 721.2750\n",
      "Iteration 75: Weights = [29.11773471  2.73456942  6.65728534  1.74582204  0.35168438  7.59077856], Loss = 706.6223\n",
      "Iteration 76: Weights = [29.37655737  2.75291217  6.69427523  1.74528132  0.35092786  7.63457992], Loss = 692.2749\n",
      "Iteration 77: Weights = [29.63279179  2.77097195  6.7305292   1.74446685  0.35012545  7.67755499], Loss = 678.2261\n",
      "Iteration 78: Weights = [29.88646387  2.78875371  6.76606248  1.74338678  0.3492792   7.71972051], Loss = 664.4693\n",
      "Iteration 79: Weights = [30.13759924  2.80626228  6.80088999  1.74204907  0.3483911   7.76109288], Loss = 650.9984\n",
      "Iteration 80: Weights = [30.38622324  2.82350242  6.83502634  1.74046149  0.34746308  7.80168813], Loss = 637.8070\n",
      "Iteration 81: Weights = [30.63236101  2.84047878  6.86848581  1.73863164  0.34649702  7.84152198], Loss = 624.8890\n",
      "Iteration 82: Weights = [30.8760374   2.85719595  6.90128241  1.73656692  0.34549475  7.88060981], Loss = 612.2387\n",
      "Iteration 83: Weights = [31.11727703  2.8736584   6.93342983  1.73427456  0.34445803  7.9189667 ], Loss = 599.8501\n",
      "Iteration 84: Weights = [31.35610426  2.88987054  6.96494148  1.73176162  0.34338858  7.95660738], Loss = 587.7178\n",
      "Iteration 85: Weights = [31.59254321  2.90583668  6.99583049  1.72903499  0.34228809  7.9935463 ], Loss = 575.8360\n",
      "Iteration 86: Weights = [31.82661778  2.92156106  7.02610971  1.72610138  0.34115816  8.0297976 ], Loss = 564.1996\n",
      "Iteration 87: Weights = [32.0583516   2.93704785  7.05579171  1.72296737  0.34000037  8.06537513], Loss = 552.8031\n",
      "Iteration 88: Weights = [32.28776809  2.95230111  7.08488881  1.71963935  0.33881625  8.10029246], Loss = 541.6416\n",
      "Iteration 89: Weights = [32.51489041  2.96732485  7.11341307  1.71612358  0.33760728  8.13456285], Loss = 530.7098\n",
      "Iteration 90: Weights = [32.7397415   2.982123    7.14137627  1.71242615  0.3363749   8.16819931], Loss = 520.0030\n",
      "Iteration 91: Weights = [32.96234409  2.99669941  7.16878999  1.70855302  0.33512049  8.20121457], Loss = 509.5163\n",
      "Iteration 92: Weights = [33.18272065  3.01105785  7.19566552  1.70450998  0.33384543  8.23362109], Loss = 499.2451\n",
      "Iteration 93: Weights = [33.40089344  3.02520205  7.22201393  1.70030271  0.332551    8.2654311 ], Loss = 489.1848\n",
      "Iteration 94: Weights = [33.61688451  3.03913564  7.24784606  1.69593674  0.33123849  8.29665652], Loss = 479.3309\n",
      "Iteration 95: Weights = [33.83071566  3.05286219  7.27317253  1.69141745  0.32990914  8.32730909], Loss = 469.6789\n",
      "Iteration 96: Weights = [34.0424085   3.06638521  7.29800371  1.68675011  0.32856412  8.35740025], Loss = 460.2248\n",
      "Iteration 97: Weights = [34.25198442  3.07970814  7.32234977  1.68193984  0.3272046   8.38694123], Loss = 450.9642\n",
      "Iteration 98: Weights = [34.45946458  3.09283436  7.34622067  1.67699167  0.32583171  8.41594302], Loss = 441.8931\n",
      "Iteration 99: Weights = [34.66486993  3.10576717  7.36962615  1.67191046  0.32444652  8.4444164 ], Loss = 433.0074\n",
      "Iteration 100: Weights = [34.86822123  3.11850985  7.39257574  1.66670098  0.32305009  8.47237189], Loss = 424.3033\n",
      "Iteration 101: Weights = [35.06953902  3.13106556  7.4150788   1.66136788  0.32164344  8.49981983], Loss = 415.7770\n",
      "Iteration 102: Weights = [35.26884363  3.14343746  7.43714445  1.65591569  0.32022756  8.52677031], Loss = 407.4247\n",
      "Iteration 103: Weights = [35.46615519  3.15562861  7.45878165  1.65034882  0.31880339  8.55323325], Loss = 399.2428\n",
      "Iteration 104: Weights = [35.66149364  3.16764203  7.47999917  1.64467159  0.31737186  8.57921833], Loss = 391.2277\n",
      "Iteration 105: Weights = [35.8548787   3.17948068  7.50080557  1.63888818  0.31593386  8.60473505], Loss = 383.3758\n",
      "Iteration 106: Weights = [36.04632992  3.19114747  7.52120927  1.63300271  0.31449026  8.62979271], Loss = 375.6839\n",
      "Iteration 107: Weights = [36.23586662  3.20264526  7.54121847  1.62701916  0.31304189  8.65440042], Loss = 368.1485\n",
      "Iteration 108: Weights = [36.42350795  3.21397685  7.56084122  1.62094142  0.31158956  8.67856708], Loss = 360.7664\n",
      "Iteration 109: Weights = [36.60927287  3.22514498  7.58008542  1.61477329  0.31013405  8.70230144], Loss = 353.5344\n",
      "Iteration 110: Weights = [36.79318014  3.23615236  7.59895877  1.60851847  0.30867612  8.72561204], Loss = 346.4493\n",
      "Iteration 111: Weights = [36.97524834  3.24700164  7.61746882  1.60218056  0.30721648  8.74850727], Loss = 339.5081\n",
      "Iteration 112: Weights = [37.15549586  3.25769542  7.63562297  1.59576308  0.30575584  8.77099533], Loss = 332.7078\n",
      "Iteration 113: Weights = [37.3339409   3.26823625  7.65342846  1.58926945  0.30429488  8.79308424], Loss = 326.0455\n",
      "Iteration 114: Weights = [37.51060149  3.27862664  7.67089238  1.58270301  0.30283426  8.81478189], Loss = 319.5184\n",
      "Iteration 115: Weights = [37.68549548  3.28886906  7.68802166  1.57606701  0.30137461  8.83609597], Loss = 313.1235\n",
      "Iteration 116: Weights = [37.85864052  3.29896592  7.70482311  1.56936462  0.29991653  8.85703404], Loss = 306.8582\n",
      "Iteration 117: Weights = [38.03005412  3.30891959  7.72130336  1.56259893  0.29846061  8.87760348], Loss = 300.7198\n",
      "Iteration 118: Weights = [38.19975357  3.3187324   7.73746894  1.55577294  0.29700741  8.89781154], Loss = 294.7057\n",
      "Iteration 119: Weights = [38.36775604  3.32840664  7.75332622  1.54888957  0.29555749  8.91766531], Loss = 288.8133\n",
      "Iteration 120: Weights = [38.53407848  3.33794456  7.76888144  1.5419517   0.29411136  8.93717173], Loss = 283.0401\n",
      "Iteration 121: Weights = [38.69873769  3.34734837  7.78414071  1.53496209  0.29266953  8.9563376 ], Loss = 277.3836\n",
      "Iteration 122: Weights = [38.86175032  3.35662022  7.79911002  1.52792345  0.29123249  8.9751696 ], Loss = 271.8415\n",
      "Iteration 123: Weights = [39.02313281  3.36576225  7.81379523  1.52083841  0.2898007   8.99367424], Loss = 266.4113\n",
      "Iteration 124: Weights = [39.18290148  3.37477655  7.82820207  1.51370954  0.2883746   9.01185792], Loss = 261.0908\n",
      "Iteration 125: Weights = [39.34107247  3.38366516  7.84233617  1.50653934  0.28695464  9.0297269 ], Loss = 255.8777\n",
      "Iteration 126: Weights = [39.49766175  3.3924301   7.85620301  1.49933025  0.28554122  9.04728731], Loss = 250.7698\n",
      "Iteration 127: Weights = [39.65268513  3.40107335  7.86980798  1.49208462  0.28413474  9.06454516], Loss = 245.7650\n",
      "Iteration 128: Weights = [39.80615828  3.40959685  7.88315637  1.48480476  0.28273558  9.08150633], Loss = 240.8611\n",
      "Iteration 129: Weights = [39.95809669  3.4180025   7.89625331  1.47749292  0.28134411  9.09817659], Loss = 236.0560\n",
      "Iteration 130: Weights = [40.10851573  3.42629219  7.90910389  1.47015127  0.27996067  9.11456157], Loss = 231.3478\n",
      "Iteration 131: Weights = [40.25743057  3.43446775  7.92171303  1.46278195  0.2785856   9.13066682], Loss = 226.7345\n",
      "Iteration 132: Weights = [40.40485626  3.44253099  7.93408559  1.45538701  0.27721922  9.14649775], Loss = 222.2141\n",
      "Iteration 133: Weights = [40.5508077   3.45048368  7.94622631  1.44796846  0.27586183  9.16205966], Loss = 217.7847\n",
      "Iteration 134: Weights = [40.69529962  3.45832757  7.95813984  1.44052826  0.27451373  9.17735775], Loss = 213.4444\n",
      "Iteration 135: Weights = [40.83834663  3.46606438  7.96983073  1.43306831  0.27317519  9.19239711], Loss = 209.1915\n",
      "Iteration 136: Weights = [40.97996316  3.47369578  7.98130343  1.42559046  0.27184649  9.20718274], Loss = 205.0242\n",
      "Iteration 137: Weights = [41.12016353  3.48122342  7.9925623   1.4180965   0.27052786  9.22171952], Loss = 200.9406\n",
      "Iteration 138: Weights = [41.25896189  3.48864894  8.00361161  1.41058818  0.26921956  9.23601223], Loss = 196.9392\n",
      "Iteration 139: Weights = [41.39637228  3.49597392  8.01445555  1.40306721  0.26792181  9.25006556], Loss = 193.0182\n",
      "Iteration 140: Weights = [41.53240855  3.50319993  8.02509821  1.39553522  0.26663484  9.26388411], Loss = 189.1760\n",
      "Iteration 141: Weights = [41.66708447  3.51032852  8.0355436   1.38799383  0.26535883  9.27747237], Loss = 185.4109\n",
      "Iteration 142: Weights = [41.80041362  3.51736119  8.04579565  1.3804446   0.264094    9.29083476], Loss = 181.7215\n",
      "Iteration 143: Weights = [41.93240949  3.52429943  8.0558582   1.37288903  0.26284052  9.30397559], Loss = 178.1062\n",
      "Iteration 144: Weights = [42.06308539  3.53114469  8.06573502  1.3653286   0.26159856  9.3168991 ], Loss = 174.5634\n",
      "Iteration 145: Weights = [42.19245454  3.53789843  8.07542979  1.35776474  0.2603683   9.32960943], Loss = 171.0917\n",
      "Iteration 146: Weights = [42.32052999  3.54456203  8.08494613  1.35019883  0.25914989  9.34211064], Loss = 167.6897\n",
      "Iteration 147: Weights = [42.44732469  3.5511369   8.09428756  1.34263223  0.25794346  9.35440672], Loss = 164.3559\n",
      "Iteration 148: Weights = [42.57285145  3.55762438  8.10345757  1.33506623  0.25674917  9.36650155], Loss = 161.0890\n",
      "Iteration 149: Weights = [42.69712293  3.56402582  8.11245952  1.32750211  0.25556713  9.37839896], Loss = 157.8876\n",
      "Iteration 150: Weights = [42.8201517   3.57034253  8.12129675  1.31994111  0.25439746  9.39010269], Loss = 154.7504\n",
      "Iteration 151: Weights = [42.94195018  3.5765758   8.12997251  1.3123844   0.25324027  9.4016164 ], Loss = 151.6760\n",
      "Iteration 152: Weights = [43.06253068  3.5827269   8.13848997  1.30483316  0.25209566  9.41294369], Loss = 148.6632\n",
      "Iteration 153: Weights = [43.18190538  3.58879708  8.14685227  1.2972885   0.25096374  9.42408809], Loss = 145.7108\n",
      "Iteration 154: Weights = [43.30008632  3.59478755  8.15506244  1.28975152  0.24984457  9.43505302], Loss = 142.8176\n",
      "Iteration 155: Weights = [43.41708546  3.60069954  8.1631235   1.28222327  0.24873826  9.44584189], Loss = 139.9823\n",
      "Iteration 156: Weights = [43.5329146   3.60653421  8.17103835  1.27470478  0.24764485  9.45645798], Loss = 137.2037\n",
      "Iteration 157: Weights = [43.64758546  3.61229274  8.17880987  1.26719704  0.24656443  9.46690456], Loss = 134.4808\n",
      "Iteration 158: Weights = [43.7611096   3.61797626  8.18644088  1.25970101  0.24549705  9.4771848 ], Loss = 131.8123\n",
      "Iteration 159: Weights = [43.87349851  3.6235859   8.19393412  1.25221762  0.24444276  9.48730181], Loss = 129.1973\n",
      "Iteration 160: Weights = [43.98476352  3.62912277  8.20129228  1.24474777  0.2434016   9.49725865], Loss = 126.6346\n",
      "Iteration 161: Weights = [44.09491589  3.63458795  8.20851801  1.23729234  0.24237362  9.5070583 ], Loss = 124.1231\n",
      "Iteration 162: Weights = [44.20396673  3.63998251  8.21561389  1.22985216  0.24135885  9.51670371], Loss = 121.6619\n",
      "Iteration 163: Weights = [44.31192706  3.6453075   8.22258245  1.22242806  0.24035732  9.52619773], Loss = 119.2499\n",
      "Iteration 164: Weights = [44.41880779  3.65056395  8.22942617  1.21502083  0.23936904  9.53554318], Loss = 116.8861\n",
      "Iteration 165: Weights = [44.52461971  3.65575286  8.23614748  1.20763123  0.23839405  9.54474282], Loss = 114.5695\n",
      "Iteration 166: Weights = [44.62937352  3.66087525  8.24274876  1.20026     0.23743234  9.55379936], Loss = 112.2993\n",
      "Iteration 167: Weights = [44.73307978  3.66593209  8.24923234  1.19290785  0.23648393  9.56271545], Loss = 110.0744\n",
      "Iteration 168: Weights = [44.83574898  3.67092435  8.2556005   1.18557548  0.23554882  9.57149367], Loss = 107.8940\n",
      "Iteration 169: Weights = [44.93739149  3.67585296  8.26185547  1.17826355  0.234627    9.58013657], Loss = 105.7572\n",
      "Iteration 170: Weights = [45.03801758  3.68071887  8.26799944  1.17097269  0.23371848  9.58864665], Loss = 103.6630\n",
      "Iteration 171: Weights = [45.1376374   3.68552299  8.27403456  1.16370354  0.23282323  9.59702635], Loss = 101.6107\n",
      "Iteration 172: Weights = [45.23626103  3.69026622  8.27996292  1.15645669  0.23194124  9.60527806], Loss = 99.5993\n",
      "Iteration 173: Weights = [45.33389842  3.69494944  8.28578659  1.14923272  0.2310725   9.61340413], Loss = 97.6281\n",
      "Iteration 174: Weights = [45.43055943  3.69957353  8.29150758  1.14203219  0.23021698  9.62140686], Loss = 95.6963\n",
      "Iteration 175: Weights = [45.52625384  3.70413934  8.29712786  1.13485562  0.22937465  9.62928851], Loss = 93.8030\n",
      "Iteration 176: Weights = [45.6209913   3.70864772  8.30264936  1.12770354  0.22854548  9.63705128], Loss = 91.9475\n",
      "Iteration 177: Weights = [45.71478139  3.71309949  8.30807398  1.12057644  0.22772944  9.64469734], Loss = 90.1291\n",
      "Iteration 178: Weights = [45.80763357  3.71749546  8.31340358  1.11347481  0.2269265   9.65222881], Loss = 88.3469\n",
      "Iteration 179: Weights = [45.89955724  3.72183644  8.31863997  1.10639909  0.2261366   9.65964778], Loss = 86.6003\n",
      "Iteration 180: Weights = [45.99056167  3.72612322  8.32378493  1.09934973  0.22535971  9.66695628], Loss = 84.8885\n",
      "Iteration 181: Weights = [46.08065605  3.73035657  8.32884021  1.09232716  0.22459578  9.67415631], Loss = 83.2109\n",
      "Iteration 182: Weights = [46.16984949  3.73453725  8.33380751  1.08533178  0.22384476  9.68124984], Loss = 81.5667\n",
      "Iteration 183: Weights = [46.25815099  3.73866602  8.3386885   1.07836398  0.22310659  9.68823878], Loss = 79.9554\n",
      "Iteration 184: Weights = [46.34556948  3.7427436   8.34348483  1.07142414  0.22238123  9.69512501], Loss = 78.3761\n",
      "Iteration 185: Weights = [46.43211379  3.74677073  8.34819811  1.06451261  0.22166862  9.70191039], Loss = 76.8284\n",
      "Iteration 186: Weights = [46.51779265  3.75074812  8.35282989  1.05762974  0.22096869  9.70859672], Loss = 75.3115\n",
      "Iteration 187: Weights = [46.60261472  3.75467647  8.35738174  1.05077585  0.22028139  9.71518577], Loss = 73.8248\n",
      "Iteration 188: Weights = [46.68658858  3.75855647  8.36185515  1.04395126  0.21960664  9.72167929], Loss = 72.3678\n",
      "Iteration 189: Weights = [46.76972269  3.7623888   8.36625161  1.03715626  0.21894438  9.72807898], Loss = 70.9398\n",
      "Iteration 190: Weights = [46.85202546  3.76617413  8.37057256  1.03039115  0.21829455  9.73438651], Loss = 69.5403\n",
      "Iteration 191: Weights = [46.93350521  3.76991311  8.37481943  1.02365619  0.21765707  9.74060352], Loss = 68.1686\n",
      "Iteration 192: Weights = [47.01417016  3.77360639  8.3789936   1.01695164  0.21703187  9.74673162], Loss = 66.8243\n",
      "Iteration 193: Weights = [47.09402846  3.77725462  8.38309645  1.01027775  0.21641888  9.75277237], Loss = 65.5068\n",
      "Iteration 194: Weights = [47.17308817  3.78085841  8.38712929  1.00363475  0.21581802  9.75872734], Loss = 64.2155\n",
      "Iteration 195: Weights = [47.25135729  3.78441838  8.39109346  0.99702286  0.21522921  9.76459802], Loss = 62.9499\n",
      "Iteration 196: Weights = [47.32884372  3.78793514  8.39499021  0.99044229  0.21465237  9.7703859 ], Loss = 61.7096\n",
      "Iteration 197: Weights = [47.40555528  3.79140928  8.39882082  0.98389324  0.21408742  9.77609245], Loss = 60.4939\n",
      "Iteration 198: Weights = [47.48149973  3.79484139  8.40258651  0.97737589  0.21353429  9.78171908], Loss = 59.3025\n",
      "Iteration 199: Weights = [47.55668473  3.79823205  8.40628849  0.97089042  0.21299288  9.7872672 ], Loss = 58.1348\n",
      "Iteration 200: Weights = [47.63111788  3.80158183  8.40992794  0.964437    0.21246312  9.79273818], Loss = 56.9903\n",
      "Iteration 201: Weights = [47.7048067   3.80489129  8.41350602  0.95801577  0.21194491  9.79813337], Loss = 55.8686\n",
      "Iteration 202: Weights = [47.77775864  3.80816097  8.41702386  0.95162689  0.21143818  9.80345407], Loss = 54.7693\n",
      "Iteration 203: Weights = [47.84998105  3.81139143  8.42048257  0.94527049  0.21094282  9.8087016 ], Loss = 53.6918\n",
      "Iteration 204: Weights = [47.92148124  3.81458318  8.42388325  0.93894669  0.21045877  9.81387722], Loss = 52.6358\n",
      "Iteration 205: Weights = [47.99226643  3.81773677  8.42722696  0.93265561  0.20998591  9.81898216], Loss = 51.6008\n",
      "Iteration 206: Weights = [48.06234376  3.8208527   8.43051475  0.92639735  0.20952417  9.82401766], Loss = 50.5863\n",
      "Iteration 207: Weights = [48.13172033  3.82393148  8.43374764  0.92017202  0.20907345  9.82898491], Loss = 49.5921\n",
      "Iteration 208: Weights = [48.20040312  3.82697362  8.43692664  0.9139797   0.20863365  9.83388508], Loss = 48.6177\n",
      "Iteration 209: Weights = [48.26839909  3.8299796   8.44005274  0.90782047  0.2082047   9.83871932], Loss = 47.6626\n",
      "Iteration 210: Weights = [48.3357151   3.83294991  8.44312689  0.90169442  0.20778649  9.84348877], Loss = 46.7266\n",
      "Iteration 211: Weights = [48.40235795  3.83588504  8.44615004  0.89560159  0.20737893  9.84819453], Loss = 45.8092\n",
      "Iteration 212: Weights = [48.46833437  3.83878545  8.44912312  0.88954206  0.20698192  9.85283769], Loss = 44.9100\n",
      "Iteration 213: Weights = [48.53365103  3.8416516   8.45204704  0.88351586  0.20659537  9.85741931], Loss = 44.0287\n",
      "Iteration 214: Weights = [48.59831452  3.84448394  8.4549227   0.87752305  0.20621918  9.86194043], Loss = 43.1649\n",
      "Iteration 215: Weights = [48.66233137  3.84728294  8.45775095  0.87156366  0.20585326  9.86640209], Loss = 42.3184\n",
      "Iteration 216: Weights = [48.72570806  3.85004902  8.46053266  0.86563771  0.20549751  9.87080529], Loss = 41.4886\n",
      "Iteration 217: Weights = [48.78845098  3.85278263  8.46326866  0.85974524  0.20515184  9.87515101], Loss = 40.6754\n",
      "Iteration 218: Weights = [48.85056647  3.8554842   8.46595978  0.85388626  0.20481614  9.87944022], Loss = 39.8783\n",
      "Iteration 219: Weights = [48.9120608   3.85815413  8.46860682  0.84806077  0.20449032  9.88367387], Loss = 39.0971\n",
      "Iteration 220: Weights = [48.97294019  3.86079286  8.47121058  0.84226879  0.20417429  9.8878529 ], Loss = 38.3314\n",
      "Iteration 221: Weights = [49.03321079  3.86340079  8.47377181  0.8365103   0.20386794  9.89197821], Loss = 37.5809\n",
      "Iteration 222: Weights = [49.09287868  3.86597831  8.47629129  0.83078531  0.20357117  9.8960507 ], Loss = 36.8454\n",
      "Iteration 223: Weights = [49.1519499   3.86852584  8.47876976  0.82509379  0.20328389  9.90007125], Loss = 36.1245\n",
      "Iteration 224: Weights = [49.2104304   3.87104376  8.48120795  0.81943574  0.20300601  9.90404073], Loss = 35.4179\n",
      "Iteration 225: Weights = [49.26832609  3.87353245  8.48360656  0.81381112  0.20273741  9.90795997], Loss = 34.7253\n",
      "Iteration 226: Weights = [49.32564283  3.87599229  8.4859663   0.80821991  0.20247801  9.91182982], Loss = 34.0466\n",
      "Iteration 227: Weights = [49.38238641  3.87842366  8.48828786  0.80266207  0.20222771  9.91565108], Loss = 33.3813\n",
      "Iteration 228: Weights = [49.43856254  3.88082692  8.49057191  0.79713757  0.20198641  9.91942455], Loss = 32.7292\n",
      "Iteration 229: Weights = [49.49417692  3.88320244  8.49281911  0.79164637  0.201754    9.92315102], Loss = 32.0901\n",
      "Iteration 230: Weights = [49.54923515  3.88555057  8.49503011  0.7861884   0.2015304   9.92683126], Loss = 31.4637\n",
      "Iteration 231: Weights = [49.60374279  3.88787167  8.49720554  0.78076364  0.2013155   9.93046602], Loss = 30.8497\n",
      "Iteration 232: Weights = [49.65770537  3.89016607  8.49934602  0.77537201  0.20110921  9.93405605], Loss = 30.2480\n",
      "Iteration 233: Weights = [49.71112831  3.89243413  8.50145216  0.77001346  0.20091143  9.93760207], Loss = 29.6582\n",
      "Iteration 234: Weights = [49.76401703  3.89467617  8.50352456  0.76468792  0.20072207  9.94110479], Loss = 29.0801\n",
      "Iteration 235: Weights = [49.81637686  3.89689253  8.50556381  0.75939533  0.20054101  9.94456492], Loss = 28.5135\n",
      "Iteration 236: Weights = [49.86821309  3.89908354  8.50757048  0.75413562  0.20036818  9.94798314], Loss = 27.9582\n",
      "Iteration 237: Weights = [49.91953096  3.90124951  8.50954514  0.74890871  0.20020347  9.95136013], Loss = 27.4139\n",
      "Iteration 238: Weights = [49.97033565  3.90339076  8.51148833  0.74371451  0.20004679  9.95469655], Loss = 26.8804\n",
      "Iteration 239: Weights = [50.02063229  3.9055076   8.5134006   0.73855296  0.19989804  9.95799305], Loss = 26.3575\n",
      "Iteration 240: Weights = [50.07042597  3.90760035  8.51528248  0.73342397  0.19975712  9.96125027], Loss = 25.8449\n",
      "Iteration 241: Weights = [50.11972171  3.9096693   8.51713449  0.72832745  0.19962395  9.96446883], Loss = 25.3426\n",
      "Iteration 242: Weights = [50.16852449  3.91171475  8.51895715  0.7232633   0.19949842  9.96764935], Loss = 24.8503\n",
      "Iteration 243: Weights = [50.21683925  3.91373699  8.52075094  0.71823143  0.19938044  9.97079243], Loss = 24.3677\n",
      "Iteration 244: Weights = [50.26467086  3.91573632  8.52251637  0.71323176  0.19926992  9.97389867], Loss = 23.8947\n",
      "Iteration 245: Weights = [50.31202415  3.91771302  8.52425392  0.70826417  0.19916676  9.97696864], Loss = 23.4311\n",
      "Iteration 246: Weights = [50.35890391  3.91966737  8.52596406  0.70332857  0.19907087  9.98000292], Loss = 22.9767\n",
      "Iteration 247: Weights = [50.40531487  3.92159965  8.52764725  0.69842485  0.19898216  9.98300207], Loss = 22.5313\n",
      "Iteration 248: Weights = [50.45126172  3.92351014  8.52930394  0.6935529   0.19890054  9.98596663], Loss = 22.0948\n",
      "Iteration 249: Weights = [50.4967491   3.92539909  8.53093459  0.68871263  0.19882591  9.98889715], Loss = 21.6669\n",
      "Iteration 250: Weights = [50.54178161  3.92726678  8.53253963  0.68390391  0.19875818  9.99179416], Loss = 21.2475\n",
      "Iteration 251: Weights = [50.58636379  3.92911348  8.53411949  0.67912663  0.19869726  9.99465817], Loss = 20.8365\n",
      "Iteration 252: Weights = [50.63050016  3.93093942  8.53567459  0.67438067  0.19864307  9.99748971], Loss = 20.4336\n",
      "Iteration 253: Weights = [50.67419516  3.93274488  8.53720534  0.66966593  0.1985955  10.00028926], Loss = 20.0387\n",
      "Iteration 254: Weights = [50.7174532   3.9345301   8.53871215  0.66498228  0.19855448 10.00305733], Loss = 19.6517\n",
      "Iteration 255: Weights = [50.76027867  3.93629533  8.54019541  0.6603296   0.19851991 10.00579439], Loss = 19.2723\n",
      "Iteration 256: Weights = [50.80267589  3.93804081  8.54165552  0.65570776  0.19849171 10.00850093], Loss = 18.9005\n",
      "Iteration 257: Weights = [50.84464913  3.93976678  8.54309285  0.65111665  0.19846978 10.01117741], Loss = 18.5360\n",
      "Iteration 258: Weights = [50.88620264  3.94147348  8.54450779  0.64655613  0.19845405 10.01382428], Loss = 18.1788\n",
      "Iteration 259: Weights = [50.92734061  3.94316114  8.54590069  0.64202608  0.19844442 10.01644201], Loss = 17.8287\n",
      "Iteration 260: Weights = [50.9680672   3.94482999  8.54727193  0.63752637  0.1984408  10.01903102], Loss = 17.4855\n",
      "Iteration 261: Weights = [51.00838653  3.94648026  8.54862185  0.63305686  0.19844312 10.02159176], Loss = 17.1492\n",
      "Iteration 262: Weights = [51.04830267  3.94811218  8.5499508   0.62861744  0.19845129 10.02412464], Loss = 16.8195\n",
      "Iteration 263: Weights = [51.08781964  3.94972595  8.55125913  0.62420796  0.19846522 10.0266301 ], Loss = 16.4963\n",
      "Iteration 264: Weights = [51.12694144  3.95132181  8.55254716  0.61982829  0.19848483 10.02910854], Loss = 16.1796\n",
      "Iteration 265: Weights = [51.16567203  3.95289996  8.55381523  0.61547829  0.19851004 10.03156036], Loss = 15.8691\n",
      "Iteration 266: Weights = [51.20401531  3.95446061  8.55506365  0.61115783  0.19854076 10.03398597], Loss = 15.5648\n",
      "Iteration 267: Weights = [51.24197515  3.95600398  8.55629275  0.60686678  0.19857692 10.03638574], Loss = 15.2666\n",
      "Iteration 268: Weights = [51.2795554   3.95753027  8.55750283  0.60260498  0.19861843 10.03876008], Loss = 14.9742\n",
      "Iteration 269: Weights = [51.31675985  3.95903969  8.5586942   0.59837231  0.1986652  10.04110934], Loss = 14.6877\n",
      "Iteration 270: Weights = [51.35359225  3.96053242  8.55986716  0.59416861  0.19871717 10.0434339 ], Loss = 14.4068\n",
      "Iteration 271: Weights = [51.39005633  3.96200867  8.561022    0.58999376  0.19877425 10.04573413], Loss = 14.1316\n",
      "Iteration 272: Weights = [51.42615576  3.96346864  8.562159    0.58584761  0.19883637 10.04801038], Loss = 13.8617\n",
      "Iteration 273: Weights = [51.46189421  3.96491251  8.56327846  0.58173001  0.19890344 10.050263  ], Loss = 13.5973\n",
      "Iteration 274: Weights = [51.49727526  3.96634048  8.56438064  0.57764083  0.19897539 10.05249234], Loss = 13.3380\n",
      "Iteration 275: Weights = [51.53230251  3.96775273  8.56546582  0.57357991  0.19905214 10.05469873], Loss = 13.0840\n",
      "Iteration 276: Weights = [51.56697949  3.96914945  8.56653426  0.56954712  0.19913361 10.05688251], Loss = 12.8349\n",
      "Iteration 277: Weights = [51.60130969  3.97053081  8.56758624  0.5655423   0.19921974 10.05904401], Loss = 12.5908\n",
      "Iteration 278: Weights = [51.6352966   3.971897    8.568622    0.56156532  0.19931044 10.06118354], Loss = 12.3516\n",
      "Iteration 279: Weights = [51.66894363  3.97324819  8.5696418   0.55761603  0.19940564 10.06330142], Loss = 12.1170\n",
      "Iteration 280: Weights = [51.70225419  3.97458455  8.57064588  0.55369428  0.19950527 10.06539797], Loss = 11.8872\n",
      "Iteration 281: Weights = [51.73523165  3.97590627  8.57163449  0.54979992  0.19960925 10.06747348], Loss = 11.6619\n",
      "Iteration 282: Weights = [51.76787933  3.97721351  8.57260787  0.5459328   0.19971751 10.06952826], Loss = 11.4410\n",
      "Iteration 283: Weights = [51.80020054  3.97850643  8.57356625  0.54209278  0.19982999 10.0715626 ], Loss = 11.2246\n",
      "Iteration 284: Weights = [51.83219854  3.9797852   8.57450987  0.53827972  0.19994661 10.07357679], Loss = 11.0124\n",
      "Iteration 285: Weights = [51.86387655  3.98104998  8.57543894  0.53449345  0.20006729 10.07557112], Loss = 10.8044\n",
      "Iteration 286: Weights = [51.89523779  3.98230094  8.57635369  0.53073384  0.20019198 10.07754586], Loss = 10.6006\n",
      "Iteration 287: Weights = [51.92628541  3.98353823  8.57725435  0.52700073  0.2003206  10.07950129], Loss = 10.4008\n",
      "Iteration 288: Weights = [51.95702255  3.98476201  8.57814111  0.52329398  0.20045308 10.08143769], Loss = 10.2050\n",
      "Iteration 289: Weights = [51.98745233  3.98597244  8.5790142   0.51961344  0.20058936 10.08335531], Loss = 10.0130\n",
      "Iteration 290: Weights = [52.0175778   3.98716966  8.57987382  0.51595895  0.20072936 10.08525442], Loss = 9.8249\n",
      "Iteration 291: Weights = [52.04740203  3.98835382  8.58072017  0.51233038  0.20087303 10.08713527], Loss = 9.6405\n",
      "Iteration 292: Weights = [52.07692801  3.98952508  8.58155345  0.50872756  0.2010203  10.08899812], Loss = 9.4597\n",
      "Iteration 293: Weights = [52.10615873  3.99068358  8.58237386  0.50515035  0.2011711  10.09084322], Loss = 9.2825\n",
      "Iteration 294: Weights = [52.13509714  3.99182947  8.58318159  0.50159861  0.20132536 10.09267081], Loss = 9.1089\n",
      "Iteration 295: Weights = [52.16374617  3.99296288  8.58397683  0.49807217  0.20148303 10.09448113], Loss = 8.9386\n",
      "Iteration 296: Weights = [52.19210871  3.99408397  8.58475975  0.4945709   0.20164404 10.09627442], Loss = 8.7718\n",
      "Iteration 297: Weights = [52.22018762  3.99519286  8.58553056  0.49109465  0.20180833 10.0980509 ], Loss = 8.6082\n",
      "Iteration 298: Weights = [52.24798574  3.99628969  8.58628941  0.48764326  0.20197583 10.09981081], Loss = 8.4479\n",
      "Iteration 299: Weights = [52.27550588  3.99737461  8.5870365   0.48421658  0.20214649 10.10155438], Loss = 8.2908\n",
      "Iteration 300: Weights = [52.30275083  3.99844773  8.58777198  0.48081448  0.20232025 10.10328182], Loss = 8.1368\n",
      "Iteration 301: Weights = [52.32972332  3.99950921  8.58849604  0.47743679  0.20249704 10.10499335], Loss = 7.9858\n",
      "Iteration 302: Weights = [52.35642608  4.00055915  8.58920883  0.47408338  0.2026768  10.10668918], Loss = 7.8379\n",
      "Iteration 303: Weights = [52.38286182  4.0015977   8.58991052  0.47075409  0.20285949 10.10836953], Loss = 7.6928\n",
      "Iteration 304: Weights = [52.40903321  4.00262498  8.59060128  0.46744877  0.20304503 10.1100346 ], Loss = 7.5507\n",
      "Iteration 305: Weights = [52.43494287  4.00364112  8.59128125  0.46416729  0.20323337 10.11168459], Loss = 7.4113\n",
      "Iteration 306: Weights = [52.46059344  4.00464623  8.5919506   0.46090948  0.20342446 10.11331971], Loss = 7.2748\n",
      "Iteration 307: Weights = [52.48598751  4.00564045  8.59260948  0.45767521  0.20361824 10.11494016], Loss = 7.1409\n",
      "Iteration 308: Weights = [52.51112764  4.00662388  8.59325803  0.45446433  0.20381466 10.11654611], Loss = 7.0097\n",
      "Iteration 309: Weights = [52.53601636  4.00759666  8.59389641  0.45127668  0.20401365 10.11813778], Loss = 6.8810\n",
      "Iteration 310: Weights = [52.5606562   4.00855889  8.59452475  0.44811214  0.20421517 10.11971533], Loss = 6.7550\n",
      "Iteration 311: Weights = [52.58504963  4.00951069  8.5951432   0.44497054  0.20441915 10.12127897], Loss = 6.6314\n",
      "Iteration 312: Weights = [52.60919914  4.01045218  8.59575191  0.44185175  0.20462556 10.12282887], Loss = 6.5102\n",
      "Iteration 313: Weights = [52.63310715  4.01138348  8.596351    0.43875561  0.20483433 10.1243652 ], Loss = 6.3915\n",
      "Iteration 314: Weights = [52.65677607  4.01230468  8.59694061  0.435682    0.20504542 10.12588815], Loss = 6.2751\n",
      "Iteration 315: Weights = [52.68020831  4.0132159   8.59752088  0.43263075  0.20525876 10.12739789], Loss = 6.1611\n",
      "Iteration 316: Weights = [52.70340623  4.01411726  8.59809194  0.42960173  0.20547432 10.12889458], Loss = 6.0492\n",
      "Iteration 317: Weights = [52.72637217  4.01500885  8.5986539   0.4265948   0.20569204 10.1303784 ], Loss = 5.9396\n",
      "Iteration 318: Weights = [52.74910845  4.01589079  8.59920691  0.42360981  0.20591188 10.13184951], Loss = 5.8322\n",
      "Iteration 319: Weights = [52.77161736  4.01676317  8.59975108  0.42064661  0.20613377 10.13330807], Loss = 5.7269\n",
      "Iteration 320: Weights = [52.79390119  4.01762611  8.60028653  0.41770508  0.20635769 10.13475425], Loss = 5.6237\n",
      "Iteration 321: Weights = [52.81596218  4.0184797   8.60081339  0.41478506  0.20658356 10.13618819], Loss = 5.5225\n",
      "Iteration 322: Weights = [52.83780255  4.01932404  8.60133177  0.41188641  0.20681136 10.13761006], Loss = 5.4234\n",
      "Iteration 323: Weights = [52.85942453  4.02015924  8.60184179  0.409009    0.20704104 10.13902001], Loss = 5.3261\n",
      "Iteration 324: Weights = [52.88083028  4.02098539  8.60234356  0.40615269  0.20727253 10.14041818], Loss = 5.2309\n",
      "Iteration 325: Weights = [52.90202198  4.02180259  8.6028372   0.40331733  0.20750582 10.14180473], Loss = 5.1375\n",
      "Iteration 326: Weights = [52.92300176  4.02261093  8.60332281  0.40050279  0.20774083 10.1431798 ], Loss = 5.0459\n",
      "Iteration 327: Weights = [52.94377174  4.02341052  8.6038005   0.39770893  0.20797755 10.14454353], Loss = 4.9562\n",
      "Iteration 328: Weights = [52.96433403  4.02420144  8.60427038  0.39493561  0.20821591 10.14589607], Loss = 4.8682\n",
      "Iteration 329: Weights = [52.98469069  4.02498378  8.60473255  0.39218269  0.20845587 10.14723755], Loss = 4.7820\n",
      "Iteration 330: Weights = [53.00484378  4.02575764  8.60518711  0.38945004  0.2086974  10.14856811], Loss = 4.6975\n",
      "Iteration 331: Weights = [53.02479534  4.02652311  8.60563418  0.38673752  0.20894045 10.14988788], Loss = 4.6147\n",
      "Iteration 332: Weights = [53.04454739  4.02728028  8.60607384  0.384045    0.20918497 10.151197  ], Loss = 4.5335\n",
      "Iteration 333: Weights = [53.06410191  4.02802923  8.60650619  0.38137234  0.20943094 10.1524956 ], Loss = 4.4539\n",
      "Iteration 334: Weights = [53.08346089  4.02877005  8.60693134  0.37871941  0.2096783  10.15378381], Loss = 4.3759\n",
      "Iteration 335: Weights = [53.10262629  4.02950283  8.60734937  0.37608606  0.20992702 10.15506174], Loss = 4.2994\n",
      "Iteration 336: Weights = [53.12160002  4.03022765  8.60776038  0.37347218  0.21017705 10.15632954], Loss = 4.2245\n",
      "Iteration 337: Weights = [53.14038402  4.03094459  8.60816446  0.37087763  0.21042836 10.15758732], Loss = 4.1510\n",
      "Iteration 338: Weights = [53.15898018  4.03165375  8.6085617   0.36830227  0.21068092 10.15883519], Loss = 4.0790\n",
      "Iteration 339: Weights = [53.17739038  4.03235519  8.60895219  0.36574598  0.21093467 10.16007329], Loss = 4.0084\n",
      "Iteration 340: Weights = [53.19561648  4.03304901  8.60933601  0.36320862  0.21118959 10.16130173], Loss = 3.9392\n",
      "Iteration 341: Weights = [53.21366031  4.03373528  8.60971326  0.36069006  0.21144563 10.16252062], Loss = 3.8713\n",
      "Iteration 342: Weights = [53.23152371  4.03441407  8.61008402  0.35819018  0.21170276 10.16373008], Loss = 3.8049\n",
      "Iteration 343: Weights = [53.24920847  4.03508548  8.61044836  0.35570884  0.21196095 10.16493022], Loss = 3.7397\n",
      "Iteration 344: Weights = [53.26671639  4.03574957  8.61080638  0.35324592  0.21222016 10.16612115], Loss = 3.6758\n",
      "Iteration 345: Weights = [53.28404922  4.03640642  8.61115815  0.35080129  0.21248035 10.16730298], Loss = 3.6132\n",
      "Iteration 346: Weights = [53.30120873  4.0370561   8.61150376  0.34837483  0.21274148 10.16847582], Loss = 3.5518\n",
      "Iteration 347: Weights = [53.31819664  4.0376987   8.61184327  0.3459664   0.21300354 10.16963977], Loss = 3.4916\n",
      "Iteration 348: Weights = [53.33501468  4.03833428  8.61217677  0.34357588  0.21326647 10.17079494], Loss = 3.4327\n",
      "Iteration 349: Weights = [53.35166453  4.03896292  8.61250433  0.34120314  0.21353025 10.17194143], Loss = 3.3749\n",
      "Iteration 350: Weights = [53.36814789  4.03958468  8.61282603  0.33884807  0.21379484 10.17307934], Loss = 3.3182\n",
      "Iteration 351: Weights = [53.38446641  4.04019964  8.61314195  0.33651054  0.21406022 10.17420877], Loss = 3.2627\n",
      "Iteration 352: Weights = [53.40062174  4.04080788  8.61345214  0.33419042  0.21432634 10.17532982], Loss = 3.2082\n",
      "Iteration 353: Weights = [53.41661552  4.04140945  8.61375668  0.3318876   0.21459319 10.17644259], Loss = 3.1548\n",
      "Iteration 354: Weights = [53.43244937  4.04200442  8.61405566  0.32960195  0.21486072 10.17754717], Loss = 3.1025\n",
      "Iteration 355: Weights = [53.44812488  4.04259287  8.61434912  0.32733335  0.2151289  10.17864366], Loss = 3.0513\n",
      "Iteration 356: Weights = [53.46364363  4.04317486  8.61463714  0.32508167  0.21539772 10.17973215], Loss = 3.0010\n",
      "Iteration 357: Weights = [53.47900719  4.04375046  8.61491979  0.32284681  0.21566713 10.18081272], Loss = 2.9517\n",
      "Iteration 358: Weights = [53.49421712  4.04431973  8.61519713  0.32062864  0.21593711 10.18188548], Loss = 2.9034\n",
      "Iteration 359: Weights = [53.50927495  4.04488274  8.61546923  0.31842705  0.21620763 10.18295052], Loss = 2.8561\n",
      "Iteration 360: Weights = [53.5241822   4.04543954  8.61573615  0.3162419   0.21647865 10.18400791], Loss = 2.8097\n",
      "Iteration 361: Weights = [53.53894038  4.04599021  8.61599795  0.3140731   0.21675016 10.18505774], Loss = 2.7642\n",
      "Iteration 362: Weights = [53.55355097  4.04653481  8.6162547   0.31192052  0.21702213 10.1861001 ], Loss = 2.7196\n",
      "Iteration 363: Weights = [53.56801546  4.04707339  8.61650646  0.30978404  0.21729452 10.18713508], Loss = 2.6759\n",
      "Iteration 364: Weights = [53.58233531  4.04760602  8.61675328  0.30766356  0.21756731 10.18816276], Loss = 2.6331\n",
      "Iteration 365: Weights = [53.59651196  4.04813276  8.61699523  0.30555896  0.21784048 10.18918321], Loss = 2.5911\n",
      "Iteration 366: Weights = [53.61054684  4.04865366  8.61723236  0.30347011  0.21811399 10.19019653], Loss = 2.5499\n",
      "Iteration 367: Weights = [53.62444137  4.04916879  8.61746473  0.30139692  0.21838782 10.19120278], Loss = 2.5095\n",
      "Iteration 368: Weights = [53.63819695  4.04967821  8.6176924   0.29933927  0.21866195 10.19220205], Loss = 2.4700\n",
      "Iteration 369: Weights = [53.65181498  4.05018196  8.61791543  0.29729704  0.21893636 10.19319442], Loss = 2.4312\n",
      "Iteration 370: Weights = [53.66529683  4.05068012  8.61813386  0.29527012  0.21921101 10.19417996], Loss = 2.3932\n",
      "Iteration 371: Weights = [53.67864387  4.05117273  8.61834775  0.29325842  0.21948588 10.19515874], Loss = 2.3559\n",
      "Iteration 372: Weights = [53.69185743  4.05165985  8.61855716  0.29126181  0.21976096 10.19613085], Loss = 2.3194\n",
      "Iteration 373: Weights = [53.70493885  4.05214154  8.61876214  0.28928018  0.22003621 10.19709635], Loss = 2.2836\n",
      "Iteration 374: Weights = [53.71788946  4.05261784  8.61896273  0.28731343  0.22031161 10.19805532], Loss = 2.2485\n",
      "Iteration 375: Weights = [53.73071057  4.05308882  8.619159    0.28536146  0.22058714 10.19900782], Loss = 2.2141\n",
      "Iteration 376: Weights = [53.74340346  4.05355452  8.61935098  0.28342414  0.22086278 10.19995393], Loss = 2.1804\n",
      "Iteration 377: Weights = [53.75596943  4.054015    8.61953874  0.28150139  0.22113851 10.20089372], Loss = 2.1474\n",
      "Iteration 378: Weights = [53.76840974  4.05447032  8.61972231  0.27959308  0.22141429 10.20182726], Loss = 2.1150\n",
      "Iteration 379: Weights = [53.78072564  4.05492051  8.61990175  0.27769912  0.22169013 10.20275461], Loss = 2.0832\n",
      "Iteration 380: Weights = [53.79291838  4.05536563  8.62007711  0.2758194   0.22196598 10.20367584], Loss = 2.0521\n",
      "Iteration 381: Weights = [53.8049892   4.05580574  8.62024842  0.27395383  0.22224184 10.20459101], Loss = 2.0216\n",
      "Iteration 382: Weights = [53.81693931  4.05624088  8.62041574  0.27210228  0.22251767 10.2055002 ], Loss = 1.9916\n",
      "Iteration 383: Weights = [53.82876991  4.0566711   8.62057912  0.27026467  0.22279347 10.20640346], Loss = 1.9623\n",
      "Iteration 384: Weights = [53.84048221  4.05709645  8.62073859  0.26844089  0.22306921 10.20730086], Loss = 1.9336\n",
      "Iteration 385: Weights = [53.85207739  4.05751698  8.6208942   0.26663084  0.22334487 10.20819246], Loss = 1.9054\n",
      "Iteration 386: Weights = [53.86355662  4.05793273  8.62104599  0.26483442  0.22362043 10.20907832], Loss = 1.8778\n",
      "Iteration 387: Weights = [53.87492105  4.05834376  8.62119402  0.26305153  0.22389588 10.2099585 ], Loss = 1.8507\n",
      "Iteration 388: Weights = [53.88617184  4.0587501   8.62133831  0.26128207  0.22417119 10.21083307], Loss = 1.8242\n",
      "Iteration 389: Weights = [53.89731012  4.0591518   8.62147891  0.25952594  0.22444635 10.21170208], Loss = 1.7981\n",
      "Iteration 390: Weights = [53.90833702  4.05954892  8.62161587  0.25778305  0.22472134 10.21256559], Loss = 1.7726\n",
      "Iteration 391: Weights = [53.91925365  4.05994148  8.62174921  0.25605329  0.22499615 10.21342365], Loss = 1.7476\n",
      "Iteration 392: Weights = [53.93006111  4.06032955  8.62187899  0.25433658  0.22527075 10.21427633], Loss = 1.7231\n",
      "Iteration 393: Weights = [53.9407605   4.06071316  8.62200524  0.2526328   0.22554512 10.21512369], Loss = 1.6991\n",
      "Iteration 394: Weights = [53.9513529   4.06109235  8.62212801  0.25094188  0.22581926 10.21596577], Loss = 1.6755\n",
      "Iteration 395: Weights = [53.96183937  4.06146717  8.62224732  0.24926371  0.22609314 10.21680263], Loss = 1.6525\n",
      "Iteration 396: Weights = [53.97222098  4.06183766  8.62236322  0.2475982   0.22636676 10.21763432], Loss = 1.6298\n",
      "Iteration 397: Weights = [53.98249877  4.06220387  8.62247574  0.24594526  0.22664009 10.21846091], Loss = 1.6077\n",
      "Iteration 398: Weights = [53.99267378  4.06256583  8.62258492  0.24430479  0.22691311 10.21928244], Loss = 1.5859\n",
      "Iteration 399: Weights = [54.00274704  4.06292358  8.6226908   0.2426767   0.22718582 10.22009896], Loss = 1.5646\n",
      "Iteration 400: Weights = [54.01271957  4.06327717  8.62279342  0.24106091  0.2274582  10.22091052], Loss = 1.5437\n",
      "Iteration 401: Weights = [54.02259237  4.06362664  8.6228928   0.23945731  0.22773023 10.22171719], Loss = 1.5232\n",
      "Iteration 402: Weights = [54.03236645  4.06397202  8.62298899  0.23786582  0.2280019  10.22251899], Loss = 1.5031\n",
      "Iteration 403: Weights = [54.04204279  4.06431336  8.62308201  0.23628634  0.22827319 10.223316  ], Loss = 1.4834\n",
      "Iteration 404: Weights = [54.05162236  4.06465069  8.6231719   0.2347188   0.2285441  10.22410824], Loss = 1.4641\n",
      "Iteration 405: Weights = [54.06110613  4.06498405  8.6232587   0.2331631   0.2288146  10.22489578], Loss = 1.4452\n",
      "Iteration 406: Weights = [54.07049507  4.06531348  8.62334244  0.23161915  0.22908469 10.22567867], Loss = 1.4267\n",
      "Iteration 407: Weights = [54.07979012  4.06563903  8.62342315  0.23008687  0.22935435 10.22645693], Loss = 1.4085\n",
      "Iteration 408: Weights = [54.08899222  4.06596071  8.62350086  0.22856617  0.22962356 10.22723064], Loss = 1.3907\n",
      "Iteration 409: Weights = [54.0981023   4.06627858  8.62357561  0.22705696  0.22989233 10.22799982], Loss = 1.3732\n",
      "Iteration 410: Weights = [54.10712128  4.06659267  8.62364742  0.22555916  0.23016062 10.22876453], Loss = 1.3561\n",
      "Iteration 411: Weights = [54.11605006  4.06690301  8.62371633  0.22407268  0.23042844 10.22952481], Loss = 1.3393\n",
      "Iteration 412: Weights = [54.12488956  4.06720964  8.62378237  0.22259743  0.23069576 10.2302807 ], Loss = 1.3229\n",
      "Iteration 413: Weights = [54.13364067  4.0675126   8.62384556  0.22113335  0.23096259 10.23103225], Loss = 1.3067\n",
      "Iteration 414: Weights = [54.14230426  4.06781192  8.62390594  0.21968033  0.2312289  10.2317795 ], Loss = 1.2909\n",
      "Iteration 415: Weights = [54.15088122  4.06810763  8.62396354  0.2182383   0.23149468 10.2325225 ], Loss = 1.2754\n",
      "Iteration 416: Weights = [54.15937241  4.06839978  8.62401838  0.21680717  0.23175993 10.23326128], Loss = 1.2602\n",
      "Iteration 417: Weights = [54.16777868  4.06868838  8.6240705   0.21538688  0.23202463 10.2339959 ], Loss = 1.2453\n",
      "Iteration 418: Weights = [54.17610089  4.06897348  8.62411992  0.21397732  0.23228877 10.23472638], Loss = 1.2307\n",
      "Iteration 419: Weights = [54.18433989  4.06925512  8.62416667  0.21257843  0.23255235 10.23545277], Loss = 1.2164\n",
      "Iteration 420: Weights = [54.19249649  4.06953331  8.62421078  0.21119012  0.23281535 10.23617511], Loss = 1.2024\n",
      "Iteration 421: Weights = [54.20057152  4.0698081   8.62425227  0.20981231  0.23307776 10.23689345], Loss = 1.1886\n",
      "Iteration 422: Weights = [54.20856581  4.07007952  8.62429118  0.20844493  0.23333957 10.23760781], Loss = 1.1751\n",
      "Iteration 423: Weights = [54.21648015  4.07034759  8.62432752  0.2070879   0.23360078 10.23831824], Loss = 1.1619\n",
      "Iteration 424: Weights = [54.22431535  4.07061235  8.62436133  0.20574114  0.23386137 10.23902478], Loss = 1.1489\n",
      "Iteration 425: Weights = [54.23207219  4.07087384  8.62439263  0.20440457  0.23412133 10.23972746], Loss = 1.1362\n",
      "Iteration 426: Weights = [54.23975147  4.07113208  8.62442144  0.20307812  0.23438066 10.24042632], Loss = 1.1238\n",
      "Iteration 427: Weights = [54.24735396  4.0713871   8.6244478   0.20176171  0.23463935 10.24112141], Loss = 1.1116\n",
      "Iteration 428: Weights = [54.25488042  4.07163893  8.62447172  0.20045526  0.23489738 10.24181275], Loss = 1.0996\n",
      "Iteration 429: Weights = [54.26233161  4.0718876   8.62449324  0.1991587   0.23515476 10.24250038], Loss = 1.0879\n",
      "Iteration 430: Weights = [54.2697083   4.07213315  8.62451236  0.19787196  0.23541147 10.24318434], Loss = 1.0764\n",
      "Iteration 431: Weights = [54.27701121  4.07237559  8.62452913  0.19659496  0.2356675  10.24386466], Loss = 1.0651\n",
      "Iteration 432: Weights = [54.2842411   4.07261497  8.62454356  0.19532762  0.23592284 10.24454138], Loss = 1.0540\n",
      "Iteration 433: Weights = [54.29139869  4.0728513   8.62455568  0.19406989  0.2361775  10.24521454], Loss = 1.0432\n",
      "Iteration 434: Weights = [54.2984847   4.07308462  8.6245655   0.19282167  0.23643146 10.24588416], Loss = 1.0326\n",
      "Iteration 435: Weights = [54.30549986  4.07331495  8.62457306  0.19158291  0.23668471 10.24655028], Loss = 1.0222\n",
      "Iteration 436: Weights = [54.31244486  4.07354233  8.62457837  0.19035353  0.23693725 10.24721294], Loss = 1.0119\n",
      "Iteration 437: Weights = [54.31932041  4.07376678  8.62458146  0.18913346  0.23718906 10.24787216], Loss = 1.0019\n",
      "Iteration 438: Weights = [54.32612721  4.07398832  8.62458235  0.18792263  0.23744016 10.24852798], Loss = 0.9921\n",
      "Iteration 439: Weights = [54.33286593  4.07420699  8.62458106  0.18672097  0.23769051 10.24918044], Loss = 0.9825\n",
      "Iteration 440: Weights = [54.33953727  4.0744228   8.62457761  0.18552841  0.23794013 10.24982956], Loss = 0.9731\n",
      "Iteration 441: Weights = [54.3461419   4.07463579  8.62457202  0.18434488  0.238189   10.25047537], Loss = 0.9638\n",
      "Iteration 442: Weights = [54.35268048  4.07484599  8.62456432  0.18317031  0.23843712 10.25111791], Loss = 0.9548\n",
      "Iteration 443: Weights = [54.35915368  4.07505341  8.62455453  0.18200465  0.23868449 10.25175721], Loss = 0.9459\n",
      "Iteration 444: Weights = [54.36556214  4.07525809  8.62454266  0.18084781  0.23893109 10.2523933 ], Loss = 0.9372\n",
      "Iteration 445: Weights = [54.37190652  4.07546005  8.62452874  0.17969973  0.23917691 10.2530262 ], Loss = 0.9286\n",
      "Iteration 446: Weights = [54.37818745  4.07565931  8.62451278  0.17856035  0.23942197 10.25365595], Loss = 0.9203\n",
      "Iteration 447: Weights = [54.38440558  4.07585589  8.62449481  0.1774296   0.23966624 10.25428259], Loss = 0.9120\n",
      "Iteration 448: Weights = [54.39056152  4.07604984  8.62447485  0.17630741  0.23990973 10.25490612], Loss = 0.9040\n",
      "Iteration 449: Weights = [54.39665591  4.07624116  8.62445291  0.17519373  0.24015243 10.2555266 ], Loss = 0.8961\n",
      "Iteration 450: Weights = [54.40268935  4.07642988  8.62442901  0.17408848  0.24039433 10.25614403], Loss = 0.8884\n",
      "Iteration 451: Weights = [54.40866246  4.07661602  8.62440318  0.1729916   0.24063544 10.25675847], Loss = 0.8808\n",
      "Iteration 452: Weights = [54.41457583  4.07679962  8.62437543  0.17190304  0.24087573 10.25736992], Loss = 0.8734\n",
      "Iteration 453: Weights = [54.42043007  4.07698068  8.62434578  0.17082272  0.24111522 10.25797842], Loss = 0.8661\n",
      "Iteration 454: Weights = [54.42622577  4.07715924  8.62431425  0.16975058  0.2413539  10.25858399], Loss = 0.8589\n",
      "Iteration 455: Weights = [54.43196351  4.07733532  8.62428086  0.16868656  0.24159176 10.25918667], Loss = 0.8519\n",
      "Iteration 456: Weights = [54.43764388  4.07750894  8.62424561  0.16763061  0.24182879 10.25978647], Loss = 0.8451\n",
      "Iteration 457: Weights = [54.44326744  4.07768012  8.62420855  0.16658265  0.24206501 10.26038343], Loss = 0.8383\n",
      "Iteration 458: Weights = [54.44883477  4.07784889  8.62416967  0.16554263  0.24230039 10.26097758], Loss = 0.8317\n",
      "Iteration 459: Weights = [54.45434642  4.07801526  8.62412899  0.16451049  0.24253494 10.26156893], Loss = 0.8253\n",
      "Iteration 460: Weights = [54.45980295  4.07817926  8.62408655  0.16348617  0.24276865 10.26215751], Loss = 0.8189\n",
      "Iteration 461: Weights = [54.46520493  4.07834092  8.62404234  0.1624696   0.24300152 10.26274336], Loss = 0.8127\n",
      "Iteration 462: Weights = [54.47055288  4.07850024  8.62399639  0.16146074  0.24323355 10.26332648], Loss = 0.8066\n",
      "Iteration 463: Weights = [54.47584735  4.07865725  8.62394871  0.16045952  0.24346473 10.26390692], Loss = 0.8006\n",
      "Iteration 464: Weights = [54.48108887  4.07881198  8.62389933  0.15946588  0.24369506 10.26448469], Loss = 0.7947\n",
      "Iteration 465: Weights = [54.48627798  4.07896444  8.62384825  0.15847977  0.24392454 10.26505981], Loss = 0.7890\n",
      "Iteration 466: Weights = [54.49141521  4.07911466  8.62379549  0.15750113  0.24415316 10.26563232], Loss = 0.7834\n",
      "Iteration 467: Weights = [54.49650105  4.07926265  8.62374107  0.1565299   0.24438093 10.26620223], Loss = 0.7778\n",
      "Iteration 468: Weights = [54.50153604  4.07940843  8.623685    0.15556602  0.24460783 10.26676957], Loss = 0.7724\n",
      "Iteration 469: Weights = [54.50652068  4.07955203  8.62362731  0.15460945  0.24483387 10.26733437], Loss = 0.7671\n",
      "Iteration 470: Weights = [54.51145548  4.07969346  8.623568    0.15366012  0.24505905 10.26789663], Loss = 0.7619\n",
      "Iteration 471: Weights = [54.51634092  4.07983274  8.62350708  0.15271798  0.24528335 10.2684564 ], Loss = 0.7568\n",
      "Iteration 472: Weights = [54.52117751  4.0799699   8.62344458  0.15178298  0.24550679 10.26901369], Loss = 0.7518\n",
      "Iteration 473: Weights = [54.52596574  4.08010495  8.62338051  0.15085506  0.24572935 10.26956851], Loss = 0.7469\n",
      "Iteration 474: Weights = [54.53070608  4.08023791  8.62331489  0.14993416  0.24595104 10.27012091], Loss = 0.7421\n",
      "Iteration 475: Weights = [54.53539902  4.08036879  8.62324772  0.14902024  0.24617185 10.27067089], Loss = 0.7374\n",
      "Iteration 476: Weights = [54.54004503  4.08049763  8.62317903  0.14811324  0.24639178 10.27121848], Loss = 0.7328\n",
      "Iteration 477: Weights = [54.54464458  4.08062443  8.62310882  0.1472131   0.24661084 10.27176369], Loss = 0.7282\n",
      "Iteration 478: Weights = [54.54919813  4.08074921  8.62303711  0.14631979  0.24682901 10.27230656], Loss = 0.7238\n",
      "Iteration 479: Weights = [54.55370615  4.080872    8.62296392  0.14543323  0.24704629 10.2728471 ], Loss = 0.7194\n",
      "Iteration 480: Weights = [54.55816909  4.0809928   8.62288926  0.14455339  0.2472627  10.27338534], Loss = 0.7151\n",
      "Iteration 481: Weights = [54.5625874   4.08111165  8.62281313  0.14368021  0.24747821 10.27392128], Loss = 0.7110\n",
      "Iteration 482: Weights = [54.56696152  4.08122854  8.62273557  0.14281364  0.24769284 10.27445496], Loss = 0.7068\n",
      "Iteration 483: Weights = [54.57129191  4.08134351  8.62265657  0.14195364  0.24790659 10.2749864 ], Loss = 0.7028\n",
      "Iteration 484: Weights = [54.57557899  4.08145657  8.62257615  0.14110014  0.24811944 10.2755156 ], Loss = 0.6989\n",
      "Iteration 485: Weights = [54.5798232   4.08156774  8.62249433  0.1402531   0.2483314  10.2760426 ], Loss = 0.6950\n",
      "Iteration 486: Weights = [54.58402497  4.08167702  8.62241111  0.13941248  0.24854247 10.27656742], Loss = 0.6912\n",
      "Iteration 487: Weights = [54.58818472  4.08178445  8.62232652  0.13857822  0.24875264 10.27709006], Loss = 0.6875\n",
      "Iteration 488: Weights = [54.59230287  4.08189003  8.62224056  0.13775027  0.24896193 10.27761056], Loss = 0.6838\n",
      "Iteration 489: Weights = [54.59637984  4.08199378  8.62215324  0.13692859  0.24917032 10.27812893], Loss = 0.6803\n",
      "Iteration 490: Weights = [54.60041604  4.08209572  8.62206458  0.13611313  0.24937781 10.27864518], Loss = 0.6767\n",
      "Iteration 491: Weights = [54.60441188  4.08219587  8.62197459  0.13530384  0.24958441 10.27915935], Loss = 0.6733\n",
      "Iteration 492: Weights = [54.60836776  4.08229424  8.62188328  0.13450067  0.24979012 10.27967144], Loss = 0.6699\n",
      "Iteration 493: Weights = [54.61228409  4.08239084  8.62179067  0.13370359  0.24999492 10.28018147], Loss = 0.6666\n",
      "Iteration 494: Weights = [54.61616125  4.08248569  8.62169676  0.13291253  0.25019884 10.28068947], Loss = 0.6634\n",
      "Iteration 495: Weights = [54.61999963  4.08257881  8.62160157  0.13212746  0.25040185 10.28119544], Loss = 0.6602\n",
      "Iteration 496: Weights = [54.62379964  4.08267021  8.62150511  0.13134833  0.25060397 10.28169942], Loss = 0.6571\n",
      "Iteration 497: Weights = [54.62756164  4.0827599   8.62140738  0.13057509  0.25080519 10.2822014 ], Loss = 0.6540\n",
      "Iteration 498: Weights = [54.63128602  4.08284791  8.62130841  0.12980771  0.25100552 10.28270143], Loss = 0.6510\n",
      "Iteration 499: Weights = [54.63497316  4.08293425  8.62120821  0.12904613  0.25120495 10.2831995 ], Loss = 0.6481\n",
      "Iteration 500: Weights = [54.63862343  4.08301892  8.62110677  0.12829031  0.25140348 10.28369563], Loss = 0.6452\n",
      "Iteration 501: Weights = [54.6422372   4.08310195  8.62100412  0.1275402   0.25160112 10.28418986], Loss = 0.6424\n",
      "Iteration 502: Weights = [54.64581483  4.08318335  8.62090027  0.12679578  0.25179786 10.28468218], Loss = 0.6396\n",
      "Iteration 503: Weights = [54.64935668  4.08326314  8.62079523  0.12605698  0.2519937  10.28517261], Loss = 0.6369\n",
      "Iteration 504: Weights = [54.65286311  4.08334132  8.620689    0.12532377  0.25218865 10.28566119], Loss = 0.6342\n",
      "Iteration 505: Weights = [54.65633448  4.08341792  8.6205816   0.1245961   0.2523827  10.28614791], Loss = 0.6316\n",
      "Iteration 506: Weights = [54.65977114  4.08349294  8.62047303  0.12387394  0.25257586 10.28663279], Loss = 0.6291\n",
      "Iteration 507: Weights = [54.66317342  4.0835664   8.62036332  0.12315724  0.25276813 10.28711586], Loss = 0.6266\n",
      "Iteration 508: Weights = [54.66654169  4.08363832  8.62025247  0.12244595  0.2529595  10.28759712], Loss = 0.6241\n",
      "Iteration 509: Weights = [54.66987627  4.0837087   8.62014048  0.12174005  0.25314998 10.28807659], Loss = 0.6217\n",
      "Iteration 510: Weights = [54.67317751  4.08377756  8.62002738  0.12103948  0.25333956 10.2885543 ], Loss = 0.6193\n",
      "Iteration 511: Weights = [54.67644574  4.08384491  8.61991316  0.1203442   0.25352825 10.28903024], Loss = 0.6170\n",
      "Iteration 512: Weights = [54.67968128  4.08391077  8.61979784  0.11965419  0.25371606 10.28950444], Loss = 0.6147\n",
      "Iteration 513: Weights = [54.68288446  4.08397515  8.61968143  0.11896939  0.25390297 10.28997692], Loss = 0.6125\n",
      "Iteration 514: Weights = [54.68605562  4.08403807  8.61956394  0.11828976  0.254089   10.29044768], Loss = 0.6103\n",
      "Iteration 515: Weights = [54.68919506  4.08409952  8.61944538  0.11761527  0.25427413 10.29091675], Loss = 0.6081\n",
      "Iteration 516: Weights = [54.69230311  4.08415954  8.61932576  0.11694588  0.25445838 10.29138413], Loss = 0.6060\n",
      "Iteration 517: Weights = [54.69538008  4.08421812  8.61920508  0.11628155  0.25464175 10.29184985], Loss = 0.6040\n",
      "Iteration 518: Weights = [54.69842628  4.08427529  8.61908336  0.11562223  0.25482423 10.29231391], Loss = 0.6019\n",
      "Iteration 519: Weights = [54.70144202  4.08433104  8.6189606   0.1149679   0.25500582 10.29277633], Loss = 0.5999\n",
      "Iteration 520: Weights = [54.7044276   4.08438541  8.61883682  0.11431851  0.25518653 10.29323712], Loss = 0.5980\n",
      "Iteration 521: Weights = [54.70738332  4.0844384   8.61871202  0.11367403  0.25536637 10.2936963 ], Loss = 0.5961\n",
      "Iteration 522: Weights = [54.71030949  4.08449001  8.61858621  0.11303442  0.25554532 10.29415389], Loss = 0.5942\n",
      "Iteration 523: Weights = [54.71320639  4.08454027  8.61845941  0.11239963  0.25572339 10.29460988], Loss = 0.5924\n",
      "Iteration 524: Weights = [54.71607433  4.08458918  8.61833162  0.11176964  0.25590059 10.29506431], Loss = 0.5906\n",
      "Iteration 525: Weights = [54.71891359  4.08463675  8.61820284  0.11114441  0.25607691 10.29551718], Loss = 0.5888\n",
      "Iteration 526: Weights = [54.72172445  4.08468301  8.61807309  0.11052391  0.25625235 10.2959685 ], Loss = 0.5871\n",
      "Iteration 527: Weights = [54.72450721  4.08472795  8.61794238  0.10990808  0.25642693 10.29641829], Loss = 0.5854\n",
      "Iteration 528: Weights = [54.72726213  4.08477158  8.61781071  0.10929691  0.25660063 10.29686656], Loss = 0.5837\n",
      "Iteration 529: Weights = [54.72998951  4.08481393  8.61767809  0.10869035  0.25677346 10.29731332], Loss = 0.5821\n",
      "Iteration 530: Weights = [54.73268962  4.08485501  8.61754454  0.10808838  0.25694542 10.2977586 ], Loss = 0.5805\n",
      "Iteration 531: Weights = [54.73536272  4.08489481  8.61741005  0.10749094  0.25711652 10.29820239], Loss = 0.5789\n",
      "Iteration 532: Weights = [54.73800909  4.08493336  8.61727464  0.10689802  0.25728675 10.29864471], Loss = 0.5774\n",
      "Iteration 533: Weights = [54.740629    4.08497066  8.61713832  0.10630957  0.25745612 10.29908558], Loss = 0.5758\n",
      "Iteration 534: Weights = [54.74322271  4.08500672  8.61700109  0.10572556  0.25762463 10.299525  ], Loss = 0.5744\n",
      "Iteration 535: Weights = [54.74579049  4.08504156  8.61686296  0.10514596  0.25779228 10.29996299], Loss = 0.5729\n",
      "Iteration 536: Weights = [54.74833258  4.08507519  8.61672394  0.10457074  0.25795907 10.30039956], Loss = 0.5715\n",
      "Iteration 537: Weights = [54.75084926  4.08510761  8.61658403  0.10399985  0.25812501 10.30083473], Loss = 0.5701\n",
      "Iteration 538: Weights = [54.75334076  4.08513884  8.61644325  0.10343327  0.25829009 10.3012685 ], Loss = 0.5687\n",
      "Iteration 539: Weights = [54.75580736  4.08516888  8.6163016   0.10287097  0.25845432 10.30170088], Loss = 0.5674\n",
      "Iteration 540: Weights = [54.75824928  4.08519775  8.61615909  0.10231291  0.2586177  10.30213189], Loss = 0.5660\n",
      "Iteration 541: Weights = [54.76066679  4.08522546  8.61601573  0.10175906  0.25878023 10.30256154], Loss = 0.5647\n",
      "Iteration 542: Weights = [54.76306012  4.08525201  8.61587152  0.10120938  0.25894191 10.30298985], Loss = 0.5635\n",
      "Iteration 543: Weights = [54.76542952  4.08527742  8.61572648  0.10066385  0.25910275 10.30341681], Loss = 0.5622\n",
      "Iteration 544: Weights = [54.76777523  4.08530169  8.6155806   0.10012244  0.25926275 10.30384244], Loss = 0.5610\n",
      "Iteration 545: Weights = [54.77009747  4.08532484  8.6154339   0.09958511  0.25942191 10.30426676], Loss = 0.5598\n",
      "Iteration 546: Weights = [54.7723965   4.08534687  8.61528638  0.09905183  0.25958023 10.30468978], Loss = 0.5586\n",
      "Iteration 547: Weights = [54.77467253  4.0853678   8.61513805  0.09852257  0.25973771 10.3051115 ], Loss = 0.5575\n",
      "Iteration 548: Weights = [54.77692581  4.08538763  8.61498891  0.0979973   0.25989437 10.30553194], Loss = 0.5563\n",
      "Iteration 549: Weights = [54.77915655  4.08540637  8.61483898  0.09747599  0.26005019 10.3059511 ], Loss = 0.5552\n",
      "Iteration 550: Weights = [54.78136498  4.08542404  8.61468827  0.09695861  0.26020518 10.306369  ], Loss = 0.5541\n",
      "Iteration 551: Weights = [54.78355133  4.08544063  8.61453676  0.09644513  0.26035934 10.30678565], Loss = 0.5531\n",
      "Iteration 552: Weights = [54.78571582  4.08545617  8.61438449  0.09593552  0.26051268 10.30720106], Loss = 0.5520\n",
      "Iteration 553: Weights = [54.78785866  4.08547065  8.61423144  0.09542975  0.2606652  10.30761524], Loss = 0.5510\n",
      "Iteration 554: Weights = [54.78998008  4.08548409  8.61407763  0.09492779  0.26081689 10.3080282 ], Loss = 0.5500\n",
      "Iteration 555: Weights = [54.79208028  4.0854965   8.61392307  0.09442962  0.26096777 10.30843995], Loss = 0.5490\n",
      "Iteration 556: Weights = [54.79415947  4.08550789  8.61376776  0.0939352   0.26111784 10.30885049], Loss = 0.5480\n",
      "Iteration 557: Weights = [54.79621788  4.08551825  8.6136117   0.0934445   0.26126709 10.30925985], Loss = 0.5471\n",
      "Iteration 558: Weights = [54.7982557   4.08552761  8.6134549   0.0929575   0.26141553 10.30966802], Loss = 0.5461\n",
      "Iteration 559: Weights = [54.80027314  4.08553597  8.61329738  0.09247416  0.26156316 10.31007503], Loss = 0.5452\n",
      "Iteration 560: Weights = [54.80227041  4.08554334  8.61313913  0.09199447  0.26170999 10.31048087], Loss = 0.5443\n",
      "Iteration 561: Weights = [54.80424771  4.08554973  8.61298016  0.09151839  0.26185601 10.31088556], Loss = 0.5434\n",
      "Iteration 562: Weights = [54.80620523  4.08555514  8.61282049  0.09104589  0.26200123 10.31128911], Loss = 0.5426\n",
      "Iteration 563: Weights = [54.80814318  4.08555958  8.6126601   0.09057695  0.26214566 10.31169152], Loss = 0.5417\n",
      "Iteration 564: Weights = [54.81006175  4.08556307  8.61249902  0.09011155  0.26228928 10.31209281], Loss = 0.5409\n",
      "Iteration 565: Weights = [54.81196113  4.08556561  8.61233724  0.08964964  0.26243212 10.31249299], Loss = 0.5401\n",
      "Iteration 566: Weights = [54.81384152  4.0855672   8.61217477  0.08919122  0.26257416 10.31289206], Loss = 0.5393\n",
      "Iteration 567: Weights = [54.8157031   4.08556786  8.61201162  0.08873624  0.26271542 10.31329004], Loss = 0.5385\n",
      "Iteration 568: Weights = [54.81754607  4.0855676   8.6118478   0.08828469  0.26285588 10.31368692], Loss = 0.5377\n",
      "Iteration 569: Weights = [54.81937061  4.08556641  8.6116833   0.08783654  0.26299557 10.31408273], Loss = 0.5370\n",
      "Iteration 570: Weights = [54.8211769   4.08556432  8.61151814  0.08739175  0.26313448 10.31447747], Loss = 0.5362\n",
      "Iteration 571: Weights = [54.82296513  4.08556132  8.61135232  0.08695032  0.2632726  10.31487115], Loss = 0.5355\n",
      "Iteration 572: Weights = [54.82473548  4.08555742  8.61118585  0.08651221  0.26340995 10.31526378], Loss = 0.5348\n",
      "Iteration 573: Weights = [54.82648813  4.08555264  8.61101873  0.08607739  0.26354653 10.31565537], Loss = 0.5341\n",
      "Iteration 574: Weights = [54.82822325  4.08554697  8.61085096  0.08564584  0.26368234 10.31604591], Loss = 0.5334\n",
      "Iteration 575: Weights = [54.82994101  4.08554043  8.61068256  0.08521754  0.26381738 10.31643544], Loss = 0.5327\n",
      "Iteration 576: Weights = [54.8316416   4.08553302  8.61051353  0.08479246  0.26395166 10.31682394], Loss = 0.5320\n",
      "Iteration 577: Weights = [54.83332519  4.08552476  8.61034387  0.08437058  0.26408518 10.31721144], Loss = 0.5314\n",
      "Iteration 578: Weights = [54.83499194  4.08551564  8.61017359  0.08395187  0.26421793 10.31759793], Loss = 0.5308\n",
      "Iteration 579: Weights = [54.83664202  4.08550567  8.61000269  0.08353631  0.26434993 10.31798343], Loss = 0.5301\n",
      "Iteration 580: Weights = [54.8382756   4.08549487  8.60983119  0.08312387  0.26448117 10.31836795], Loss = 0.5295\n",
      "Iteration 581: Weights = [54.83989284  4.08548323  8.60965907  0.08271453  0.26461166 10.31875148], Loss = 0.5289\n",
      "Iteration 582: Weights = [54.84149391  4.08547077  8.60948636  0.08230827  0.26474141 10.31913405], Loss = 0.5283\n",
      "Iteration 583: Weights = [54.84307897  4.0854575   8.60931305  0.08190506  0.26487041 10.31951566], Loss = 0.5277\n",
      "Iteration 584: Weights = [54.84464818  4.08544341  8.60913915  0.08150489  0.26499866 10.31989631], Loss = 0.5272\n",
      "Iteration 585: Weights = [54.8462017   4.08542852  8.60896467  0.08110772  0.26512618 10.32027602], Loss = 0.5266\n",
      "Iteration 586: Weights = [54.84773969  4.08541283  8.60878961  0.08071353  0.26525295 10.32065479], Loss = 0.5261\n",
      "Iteration 587: Weights = [54.84926229  4.08539635  8.60861397  0.08032231  0.26537899 10.32103263], Loss = 0.5255\n",
      "Iteration 588: Weights = [54.85076967  4.08537908  8.60843776  0.07993402  0.2655043  10.32140954], Loss = 0.5250\n",
      "Iteration 589: Weights = [54.85226197  4.08536103  8.60826098  0.07954866  0.26562888 10.32178554], Loss = 0.5245\n",
      "Iteration 590: Weights = [54.85373935  4.08534222  8.60808364  0.07916618  0.26575274 10.32216064], Loss = 0.5240\n",
      "Iteration 591: Weights = [54.85520196  4.08532264  8.60790575  0.07878658  0.26587587 10.32253483], Loss = 0.5235\n",
      "Iteration 592: Weights = [54.85664994  4.0853023   8.6077273   0.07840983  0.26599828 10.32290813], Loss = 0.5230\n",
      "Iteration 593: Weights = [54.85808344  4.0852812   8.60754831  0.07803591  0.26611997 10.32328054], Loss = 0.5225\n",
      "Iteration 594: Weights = [54.8595026   4.08525936  8.60736878  0.0776648   0.26624094 10.32365207], Loss = 0.5220\n",
      "Iteration 595: Weights = [54.86090758  4.08523678  8.6071887   0.07729647  0.2663612  10.32402273], Loss = 0.5215\n",
      "Iteration 596: Weights = [54.8622985   4.08521347  8.6070081   0.07693091  0.26648076 10.32439253], Loss = 0.5211\n",
      "Iteration 597: Weights = [54.86367552  4.08518942  8.60682696  0.0765681   0.2665996  10.32476146], Loss = 0.5206\n",
      "Iteration 598: Weights = [54.86503876  4.08516466  8.6066453   0.076208    0.26671774 10.32512955], Loss = 0.5202\n",
      "Iteration 599: Weights = [54.86638837  4.08513917  8.60646312  0.07585061  0.26683518 10.32549679], Loss = 0.5198\n",
      "Iteration 600: Weights = [54.86772449  4.08511298  8.60628043  0.0754959   0.26695192 10.32586319], Loss = 0.5193\n",
      "Iteration 601: Weights = [54.86904724  4.08508608  8.60609722  0.07514385  0.26706797 10.32622877], Loss = 0.5189\n",
      "Iteration 602: Weights = [54.87035677  4.08505848  8.60591351  0.07479444  0.26718332 10.32659352], Loss = 0.5185\n",
      "Iteration 603: Weights = [54.8716532   4.08503019  8.60572929  0.07444766  0.26729799 10.32695745], Loss = 0.5181\n",
      "Iteration 604: Weights = [54.87293667  4.08500121  8.60554458  0.07410347  0.26741196 10.32732057], Loss = 0.5177\n",
      "Iteration 605: Weights = [54.87420731  4.08497155  8.60535937  0.07376187  0.26752525 10.32768289], Loss = 0.5173\n",
      "Iteration 606: Weights = [54.87546523  4.08494121  8.60517367  0.07342283  0.26763786 10.32804441], Loss = 0.5170\n",
      "Iteration 607: Weights = [54.87671058  4.0849102   8.60498748  0.07308633  0.26774979 10.32840513], Loss = 0.5166\n",
      "Iteration 608: Weights = [54.87794347  4.08487853  8.60480082  0.07275236  0.26786105 10.32876508], Loss = 0.5162\n",
      "Iteration 609: Weights = [54.87916404  4.08484619  8.60461367  0.07242089  0.26797163 10.32912424], Loss = 0.5159\n",
      "Iteration 610: Weights = [54.8803724   4.0848132   8.60442605  0.0720919   0.26808154 10.32948263], Loss = 0.5155\n",
      "Iteration 611: Weights = [54.88156867  4.08477956  8.60423796  0.07176538  0.26819079 10.32984025], Loss = 0.5152\n",
      "Iteration 612: Weights = [54.88275299  4.08474528  8.6040494   0.07144131  0.26829937 10.33019712], Loss = 0.5148\n",
      "Iteration 613: Weights = [54.88392546  4.08471036  8.60386038  0.07111966  0.26840729 10.33055323], Loss = 0.5145\n",
      "Iteration 614: Weights = [54.8850862   4.0846748   8.60367091  0.07080043  0.26851455 10.33090859], Loss = 0.5141\n",
      "Iteration 615: Weights = [54.88623534  4.08463861  8.60348098  0.07048359  0.26862115 10.33126321], Loss = 0.5138\n",
      "Iteration 616: Weights = [54.88737299  4.0846018   8.60329059  0.07016912  0.2687271  10.33161709], Loss = 0.5135\n",
      "Iteration 617: Weights = [54.88849926  4.08456438  8.60309976  0.06985701  0.26883241 10.33197024], Loss = 0.5132\n",
      "Iteration 618: Weights = [54.88961427  4.08452634  8.60290849  0.06954724  0.26893706 10.33232267], Loss = 0.5129\n",
      "Iteration 619: Weights = [54.89071812  4.08448769  8.60271678  0.06923979  0.26904107 10.33267438], Loss = 0.5126\n",
      "Iteration 620: Weights = [54.89181094  4.08444843  8.60252463  0.06893464  0.26914444 10.33302537], Loss = 0.5123\n",
      "Iteration 621: Weights = [54.89289283  4.08440858  8.60233205  0.06863178  0.26924717 10.33337566], Loss = 0.5120\n",
      "Iteration 622: Weights = [54.8939639   4.08436814  8.60213904  0.06833118  0.26934926 10.33372525], Loss = 0.5117\n",
      "Iteration 623: Weights = [54.89502427  4.0843271   8.60194561  0.06803283  0.26945072 10.33407414], Loss = 0.5114\n",
      "Iteration 624: Weights = [54.89607402  4.08428548  8.60175175  0.06773672  0.26955155 10.33442234], Loss = 0.5112\n",
      "Iteration 625: Weights = [54.89711328  4.08424328  8.60155747  0.06744283  0.26965175 10.33476985], Loss = 0.5109\n",
      "Iteration 626: Weights = [54.89814215  4.08420051  8.60136279  0.06715113  0.26975133 10.33511668], Loss = 0.5106\n",
      "Iteration 627: Weights = [54.89916073  4.08415716  8.60116769  0.06686162  0.26985028 10.33546284], Loss = 0.5104\n",
      "Iteration 628: Weights = [54.90016912  4.08411325  8.60097218  0.06657428  0.26994862 10.33580833], Loss = 0.5101\n",
      "Iteration 629: Weights = [54.90116743  4.08406878  8.60077627  0.06628908  0.27004634 10.33615316], Loss = 0.5098\n",
      "Iteration 630: Weights = [54.90215576  4.08402376  8.60057995  0.06600602  0.27014345 10.33649733], Loss = 0.5096\n",
      "Iteration 631: Weights = [54.9031342   4.08397818  8.60038324  0.06572508  0.27023995 10.33684084], Loss = 0.5094\n",
      "Iteration 632: Weights = [54.90410286  4.08393205  8.60018614  0.06544624  0.27033584 10.33718371], Loss = 0.5091\n",
      "Iteration 633: Weights = [54.90506183  4.08388538  8.59998864  0.06516948  0.27043112 10.33752593], Loss = 0.5089\n",
      "Iteration 634: Weights = [54.90601121  4.08383817  8.59979076  0.06489479  0.2705258  10.33786752], Loss = 0.5086\n",
      "Iteration 635: Weights = [54.9069511   4.08379042  8.59959249  0.06462216  0.27061989 10.33820847], Loss = 0.5084\n",
      "Iteration 636: Weights = [54.90788159  4.08374215  8.59939384  0.06435157  0.27071337 10.3385488 ], Loss = 0.5082\n",
      "Iteration 637: Weights = [54.90880277  4.08369335  8.59919481  0.064083    0.27080627 10.3388885 ], Loss = 0.5080\n",
      "Iteration 638: Weights = [54.90971474  4.08364403  8.59899541  0.06381644  0.27089857 10.33922758], Loss = 0.5078\n",
      "Iteration 639: Weights = [54.91061759  4.08359419  8.59879563  0.06355187  0.27099028 10.33956605], Loss = 0.5075\n",
      "Iteration 640: Weights = [54.91151142  4.08354383  8.59859549  0.06328928  0.27108141 10.33990392], Loss = 0.5073\n",
      "Iteration 641: Weights = [54.9123963   4.08349297  8.59839498  0.06302865  0.27117196 10.34024118], Loss = 0.5071\n",
      "Iteration 642: Weights = [54.91327234  4.0834416   8.59819411  0.06276997  0.27126193 10.34057784], Loss = 0.5069\n",
      "Iteration 643: Weights = [54.91413962  4.08338974  8.59799287  0.06251323  0.27135132 10.3409139 ], Loss = 0.5067\n",
      "Iteration 644: Weights = [54.91499822  4.08333737  8.59779129  0.0622584   0.27144013 10.34124938], Loss = 0.5065\n",
      "Iteration 645: Weights = [54.91584824  4.08328451  8.59758934  0.06200547  0.27152838 10.34158427], Loss = 0.5063\n",
      "Iteration 646: Weights = [54.91668976  4.08323116  8.59738705  0.06175444  0.27161605 10.34191858], Loss = 0.5062\n",
      "Iteration 647: Weights = [54.91752286  4.08317733  8.59718441  0.06150528  0.27170316 10.34225232], Loss = 0.5060\n",
      "Iteration 648: Weights = [54.91834763  4.08312301  8.59698142  0.06125798  0.27178971 10.34258549], Loss = 0.5058\n",
      "Iteration 649: Weights = [54.91916415  4.08306822  8.59677809  0.06101252  0.27187569 10.34291809], Loss = 0.5056\n",
      "Iteration 650: Weights = [54.91997251  4.08301295  8.59657442  0.06076891  0.27196112 10.34325012], Loss = 0.5054\n",
      "Iteration 651: Weights = [54.92077279  4.08295721  8.59637042  0.06052711  0.272046   10.3435816 ], Loss = 0.5053\n",
      "Iteration 652: Weights = [54.92156506  4.08290101  8.59616608  0.06028711  0.27213032 10.34391253], Loss = 0.5051\n",
      "Iteration 653: Weights = [54.92234941  4.08284434  8.59596141  0.06004891  0.27221409 10.3442429 ], Loss = 0.5049\n",
      "Iteration 654: Weights = [54.92312592  4.08278722  8.59575641  0.05981248  0.27229731 10.34457274], Loss = 0.5047\n",
      "Iteration 655: Weights = [54.92389466  4.08272964  8.59555109  0.05957782  0.27237999 10.34490203], Loss = 0.5046\n",
      "Iteration 656: Weights = [54.92465571  4.08267161  8.59534544  0.05934491  0.27246213 10.34523078], Loss = 0.5044\n",
      "Iteration 657: Weights = [54.92540915  4.08261313  8.59513948  0.05911374  0.27254373 10.34555901], Loss = 0.5043\n",
      "Iteration 658: Weights = [54.92615506  4.08255421  8.59493319  0.05888429  0.2726248  10.3458867 ], Loss = 0.5041\n",
      "Iteration 659: Weights = [54.92689351  4.08249484  8.5947266   0.05865656  0.27270533 10.34621387], Loss = 0.5040\n",
      "Iteration 660: Weights = [54.92762458  4.08243504  8.59451968  0.05843052  0.27278533 10.34654053], Loss = 0.5038\n",
      "Iteration 661: Weights = [54.92834833  4.0823748   8.59431246  0.05820618  0.2728648  10.34686666], Loss = 0.5037\n",
      "Iteration 662: Weights = [54.92906485  4.08231414  8.59410494  0.0579835   0.27294375 10.34719229], Loss = 0.5035\n",
      "Iteration 663: Weights = [54.9297742   4.08225304  8.5938971   0.05776248  0.27302217 10.34751741], Loss = 0.5034\n",
      "Iteration 664: Weights = [54.93047646  4.08219152  8.59368897  0.05754312  0.27310008 10.34784202], Loss = 0.5032\n",
      "Iteration 665: Weights = [54.93117169  4.08212959  8.59348054  0.05732538  0.27317747 10.34816614], Loss = 0.5031\n",
      "Iteration 666: Weights = [54.93185997  4.08206723  8.59327181  0.05710928  0.27325434 10.34848975], Loss = 0.5029\n",
      "Iteration 667: Weights = [54.93254137  4.08200446  8.59306278  0.05689478  0.2733307  10.34881288], Loss = 0.5028\n",
      "Iteration 668: Weights = [54.93321596  4.08194128  8.59285346  0.05668188  0.27340655 10.34913552], Loss = 0.5027\n",
      "Iteration 669: Weights = [54.9338838   4.0818777   8.59264386  0.05647057  0.27348189 10.34945767], Loss = 0.5025\n",
      "Iteration 670: Weights = [54.93454496  4.08181371  8.59243396  0.05626083  0.27355673 10.34977935], Loss = 0.5024\n",
      "Iteration 671: Weights = [54.93519951  4.08174932  8.59222378  0.05605266  0.27363107 10.35010055], Loss = 0.5023\n",
      "Iteration 672: Weights = [54.93584752  4.08168453  8.59201332  0.05584603  0.2737049  10.35042127], Loss = 0.5022\n",
      "Iteration 673: Weights = [54.93648904  4.08161935  8.59180258  0.05564095  0.27377824 10.35074153], Loss = 0.5020\n",
      "Iteration 674: Weights = [54.93712415  4.08155378  8.59159156  0.05543739  0.27385109 10.35106131], Loss = 0.5019\n",
      "Iteration 675: Weights = [54.93775291  4.08148781  8.59138026  0.05523535  0.27392345 10.35138064], Loss = 0.5018\n",
      "Iteration 676: Weights = [54.93837538  4.08142147  8.59116869  0.05503482  0.27399531 10.35169951], Loss = 0.5017\n",
      "Iteration 677: Weights = [5.49389916e+01 4.08135474e+00 8.59095685e+00 5.48357784e-02\n",
      " 2.74066693e-01 1.03520179e+01], Loss = 0.5016\n",
      "Iteration 678: Weights = [5.49396017e+01 4.08128763e+00 8.59074474e+00 5.46382189e-02\n",
      " 2.74137589e-01 1.03523359e+01], Loss = 0.5015\n",
      "Iteration 679: Weights = [5.49402057e+01 4.08122015e+00 8.59053237e+00 5.44421304e-02\n",
      " 2.74208004e-01 1.03526534e+01], Loss = 0.5013\n",
      "Iteration 680: Weights = [5.49408036e+01 4.08115229e+00 8.59031973e+00 5.42475017e-02\n",
      " 2.74277940e-01 1.03529705e+01], Loss = 0.5012\n",
      "Iteration 681: Weights = [5.49413956e+01 4.08108406e+00 8.59010682e+00 5.40543219e-02\n",
      " 2.74347400e-01 1.03532871e+01], Loss = 0.5011\n",
      "Iteration 682: Weights = [5.49419816e+01 4.08101547e+00 8.58989366e+00 5.38625799e-02\n",
      " 2.74416386e-01 1.03536033e+01], Loss = 0.5010\n",
      "Iteration 683: Weights = [5.49425618e+01 4.08094651e+00 8.58968024e+00 5.36722649e-02\n",
      " 2.74484901e-01 1.03539190e+01], Loss = 0.5009\n",
      "Iteration 684: Weights = [5.49431362e+01 4.08087719e+00 8.58946656e+00 5.34833662e-02\n",
      " 2.74552946e-01 1.03542344e+01], Loss = 0.5008\n",
      "Iteration 685: Weights = [5.49437048e+01 4.08080751e+00 8.58925263e+00 5.32958730e-02\n",
      " 2.74620526e-01 1.03545493e+01], Loss = 0.5007\n",
      "Iteration 686: Weights = [5.49442678e+01 4.08073748e+00 8.58903845e+00 5.31097748e-02\n",
      " 2.74687641e-01 1.03548637e+01], Loss = 0.5006\n",
      "Iteration 687: Weights = [5.49448251e+01 4.08066709e+00 8.58882402e+00 5.29250611e-02\n",
      " 2.74754296e-01 1.03551778e+01], Loss = 0.5005\n",
      "Iteration 688: Weights = [5.49453769e+01 4.08059635e+00 8.58860934e+00 5.27417213e-02\n",
      " 2.74820491e-01 1.03554914e+01], Loss = 0.5004\n",
      "Iteration 689: Weights = [5.49459231e+01 4.08052527e+00 8.58839442e+00 5.25597452e-02\n",
      " 2.74886230e-01 1.03558047e+01], Loss = 0.5003\n",
      "Iteration 690: Weights = [5.49464639e+01 4.08045384e+00 8.58817925e+00 5.23791224e-02\n",
      " 2.74951514e-01 1.03561175e+01], Loss = 0.5002\n",
      "Iteration 691: Weights = [5.49469992e+01 4.08038207e+00 8.58796385e+00 5.21998428e-02\n",
      " 2.75016347e-01 1.03564299e+01], Loss = 0.5001\n",
      "Iteration 692: Weights = [5.49475292e+01 4.08030995e+00 8.58774820e+00 5.20218962e-02\n",
      " 2.75080731e-01 1.03567419e+01], Loss = 0.5000\n",
      "Iteration 693: Weights = [5.49480539e+01 4.08023751e+00 8.58753231e+00 5.18452725e-02\n",
      " 2.75144668e-01 1.03570535e+01], Loss = 0.4999\n",
      "Iteration 694: Weights = [5.49485734e+01 4.08016473e+00 8.58731619e+00 5.16699619e-02\n",
      " 2.75208161e-01 1.03573646e+01], Loss = 0.4998\n",
      "Iteration 695: Weights = [5.49490877e+01 4.08009161e+00 8.58709984e+00 5.14959543e-02\n",
      " 2.75271211e-01 1.03576755e+01], Loss = 0.4997\n",
      "Iteration 696: Weights = [5.49495968e+01 4.08001817e+00 8.58688325e+00 5.13232400e-02\n",
      " 2.75333822e-01 1.03579859e+01], Loss = 0.4996\n",
      "Iteration 697: Weights = [5.49501008e+01 4.07994440e+00 8.58666644e+00 5.11518093e-02\n",
      " 2.75395996e-01 1.03582959e+01], Loss = 0.4996\n",
      "Iteration 698: Weights = [5.49505998e+01 4.07987031e+00 8.58644940e+00 5.09816524e-02\n",
      " 2.75457735e-01 1.03586055e+01], Loss = 0.4995\n",
      "Iteration 699: Weights = [5.49510938e+01 4.07979590e+00 8.58623213e+00 5.08127597e-02\n",
      " 2.75519042e-01 1.03589148e+01], Loss = 0.4994\n",
      "Iteration 700: Weights = [5.49515829e+01 4.07972117e+00 8.58601464e+00 5.06451217e-02\n",
      " 2.75579918e-01 1.03592236e+01], Loss = 0.4993\n",
      "Iteration 701: Weights = [5.49520671e+01 4.07964612e+00 8.58579692e+00 5.04787291e-02\n",
      " 2.75640366e-01 1.03595321e+01], Loss = 0.4992\n",
      "Iteration 702: Weights = [5.49525464e+01 4.07957076e+00 8.58557899e+00 5.03135723e-02\n",
      " 2.75700390e-01 1.03598402e+01], Loss = 0.4991\n",
      "Iteration 703: Weights = [5.49530209e+01 4.07949509e+00 8.58536083e+00 5.01496421e-02\n",
      " 2.75759989e-01 1.03601480e+01], Loss = 0.4991\n",
      "Iteration 704: Weights = [5.49534907e+01 4.07941911e+00 8.58514246e+00 4.99869292e-02\n",
      " 2.75819169e-01 1.03604553e+01], Loss = 0.4990\n",
      "Iteration 705: Weights = [5.49539558e+01 4.07934282e+00 8.58492388e+00 4.98254245e-02\n",
      " 2.75877929e-01 1.03607623e+01], Loss = 0.4989\n",
      "Iteration 706: Weights = [5.49544162e+01 4.07926623e+00 8.58470508e+00 4.96651188e-02\n",
      " 2.75936273e-01 1.03610690e+01], Loss = 0.4988\n",
      "Iteration 707: Weights = [5.49548721e+01 4.07918933e+00 8.58448607e+00 4.95060032e-02\n",
      " 2.75994204e-01 1.03613753e+01], Loss = 0.4987\n",
      "Iteration 708: Weights = [5.49553234e+01 4.07911214e+00 8.58426686e+00 4.93480687e-02\n",
      " 2.76051723e-01 1.03616812e+01], Loss = 0.4987\n",
      "Iteration 709: Weights = [5.49557701e+01 4.07903465e+00 8.58404743e+00 4.91913063e-02\n",
      " 2.76108832e-01 1.03619868e+01], Loss = 0.4986\n",
      "Iteration 710: Weights = [5.49562124e+01 4.07895687e+00 8.58382780e+00 4.90357074e-02\n",
      " 2.76165534e-01 1.03622920e+01], Loss = 0.4985\n",
      "Iteration 711: Weights = [5.49566503e+01 4.07887880e+00 8.58360796e+00 4.88812630e-02\n",
      " 2.76221832e-01 1.03625968e+01], Loss = 0.4984\n",
      "Iteration 712: Weights = [5.49570838e+01 4.07880043e+00 8.58338792e+00 4.87279645e-02\n",
      " 2.76277727e-01 1.03629014e+01], Loss = 0.4984\n",
      "Iteration 713: Weights = [5.49575130e+01 4.07872178e+00 8.58316768e+00 4.85758033e-02\n",
      " 2.76333221e-01 1.03632055e+01], Loss = 0.4983\n",
      "Iteration 714: Weights = [5.49579378e+01 4.07864284e+00 8.58294724e+00 4.84247709e-02\n",
      " 2.76388318e-01 1.03635094e+01], Loss = 0.4982\n",
      "Iteration 715: Weights = [5.49583585e+01 4.07856362e+00 8.58272661e+00 4.82748586e-02\n",
      " 2.76443018e-01 1.03638129e+01], Loss = 0.4981\n",
      "Iteration 716: Weights = [5.49587749e+01 4.07848412e+00 8.58250577e+00 4.81260582e-02\n",
      " 2.76497325e-01 1.03641160e+01], Loss = 0.4981\n",
      "Iteration 717: Weights = [5.49591871e+01 4.07840434e+00 8.58228475e+00 4.79783612e-02\n",
      " 2.76551240e-01 1.03644189e+01], Loss = 0.4980\n",
      "Iteration 718: Weights = [5.49595953e+01 4.07832428e+00 8.58206353e+00 4.78317593e-02\n",
      " 2.76604766e-01 1.03647213e+01], Loss = 0.4979\n",
      "Iteration 719: Weights = [5.49599993e+01 4.07824394e+00 8.58184212e+00 4.76862444e-02\n",
      " 2.76657905e-01 1.03650235e+01], Loss = 0.4979\n",
      "Iteration 720: Weights = [5.49603993e+01 4.07816334e+00 8.58162052e+00 4.75418081e-02\n",
      " 2.76710658e-01 1.03653253e+01], Loss = 0.4978\n",
      "Iteration 721: Weights = [5.49607953e+01 4.07808247e+00 8.58139873e+00 4.73984425e-02\n",
      " 2.76763029e-01 1.03656269e+01], Loss = 0.4977\n",
      "Iteration 722: Weights = [5.49611874e+01 4.07800132e+00 8.58117675e+00 4.72561394e-02\n",
      " 2.76815020e-01 1.03659280e+01], Loss = 0.4977\n",
      "Iteration 723: Weights = [5.49615755e+01 4.07791991e+00 8.58095459e+00 4.71148909e-02\n",
      " 2.76866632e-01 1.03662289e+01], Loss = 0.4976\n",
      "Iteration 724: Weights = [5.49619597e+01 4.07783824e+00 8.58073225e+00 4.69746890e-02\n",
      " 2.76917867e-01 1.03665295e+01], Loss = 0.4975\n",
      "Iteration 725: Weights = [5.49623401e+01 4.07775631e+00 8.58050972e+00 4.68355258e-02\n",
      " 2.76968728e-01 1.03668297e+01], Loss = 0.4975\n",
      "Iteration 726: Weights = [5.49627167e+01 4.07767411e+00 8.58028702e+00 4.66973937e-02\n",
      " 2.77019217e-01 1.03671296e+01], Loss = 0.4974\n",
      "Iteration 727: Weights = [5.49630896e+01 4.07759166e+00 8.58006413e+00 4.65602847e-02\n",
      " 2.77069337e-01 1.03674293e+01], Loss = 0.4974\n",
      "Iteration 728: Weights = [5.49634587e+01 4.07750895e+00 8.57984107e+00 4.64241912e-02\n",
      " 2.77119088e-01 1.03677286e+01], Loss = 0.4973\n",
      "Iteration 729: Weights = [5.49638241e+01 4.07742599e+00 8.57961783e+00 4.62891056e-02\n",
      " 2.77168473e-01 1.03680276e+01], Loss = 0.4972\n",
      "Iteration 730: Weights = [5.49641858e+01 4.07734278e+00 8.57939442e+00 4.61550203e-02\n",
      " 2.77217495e-01 1.03683263e+01], Loss = 0.4972\n",
      "Iteration 731: Weights = [5.49645440e+01 4.07725931e+00 8.57917083e+00 4.60219278e-02\n",
      " 2.77266155e-01 1.03686247e+01], Loss = 0.4971\n",
      "Iteration 732: Weights = [5.49648985e+01 4.07717560e+00 8.57894708e+00 4.58898206e-02\n",
      " 2.77314455e-01 1.03689228e+01], Loss = 0.4971\n",
      "Iteration 733: Weights = [5.49652496e+01 4.07709164e+00 8.57872315e+00 4.57586914e-02\n",
      " 2.77362398e-01 1.03692206e+01], Loss = 0.4970\n",
      "Iteration 734: Weights = [5.49655971e+01 4.07700744e+00 8.57849905e+00 4.56285327e-02\n",
      " 2.77409986e-01 1.03695181e+01], Loss = 0.4969\n",
      "Iteration 735: Weights = [5.49659411e+01 4.07692300e+00 8.57827479e+00 4.54993372e-02\n",
      " 2.77457220e-01 1.03698153e+01], Loss = 0.4969\n",
      "Iteration 736: Weights = [5.49662817e+01 4.07683831e+00 8.57805036e+00 4.53710979e-02\n",
      " 2.77504102e-01 1.03701123e+01], Loss = 0.4968\n",
      "Iteration 737: Weights = [5.49666189e+01 4.07675339e+00 8.57782577e+00 4.52438074e-02\n",
      " 2.77550635e-01 1.03704089e+01], Loss = 0.4968\n",
      "Iteration 738: Weights = [5.49669527e+01 4.07666823e+00 8.57760101e+00 4.51174586e-02\n",
      " 2.77596821e-01 1.03707053e+01], Loss = 0.4967\n",
      "Iteration 739: Weights = [5.49672831e+01 4.07658284e+00 8.57737609e+00 4.49920445e-02\n",
      " 2.77642662e-01 1.03710014e+01], Loss = 0.4967\n",
      "Iteration 740: Weights = [5.49676103e+01 4.07649721e+00 8.57715101e+00 4.48675580e-02\n",
      " 2.77688159e-01 1.03712972e+01], Loss = 0.4966\n",
      "Iteration 741: Weights = [5.49679342e+01 4.07641135e+00 8.57692577e+00 4.47439922e-02\n",
      " 2.77733314e-01 1.03715927e+01], Loss = 0.4966\n",
      "Iteration 742: Weights = [5.49682549e+01 4.07632526e+00 8.57670038e+00 4.46213402e-02\n",
      " 2.77778130e-01 1.03718880e+01], Loss = 0.4965\n",
      "Iteration 743: Weights = [5.49685723e+01 4.07623895e+00 8.57647483e+00 4.44995951e-02\n",
      " 2.77822609e-01 1.03721829e+01], Loss = 0.4965\n",
      "Iteration 744: Weights = [5.49688866e+01 4.07615241e+00 8.57624912e+00 4.43787501e-02\n",
      " 2.77866752e-01 1.03724776e+01], Loss = 0.4964\n",
      "Iteration 745: Weights = [5.49691977e+01 4.07606564e+00 8.57602326e+00 4.42587984e-02\n",
      " 2.77910562e-01 1.03727721e+01], Loss = 0.4963\n",
      "Iteration 746: Weights = [5.49695058e+01 4.07597865e+00 8.57579724e+00 4.41397333e-02\n",
      " 2.77954040e-01 1.03730662e+01], Loss = 0.4963\n",
      "Iteration 747: Weights = [5.49698107e+01 4.07589145e+00 8.57557108e+00 4.40215482e-02\n",
      " 2.77997188e-01 1.03733601e+01], Loss = 0.4962\n",
      "Iteration 748: Weights = [5.49701126e+01 4.07580402e+00 8.57534476e+00 4.39042366e-02\n",
      " 2.78040008e-01 1.03736538e+01], Loss = 0.4962\n",
      "Iteration 749: Weights = [5.49704115e+01 4.07571637e+00 8.57511830e+00 4.37877917e-02\n",
      " 2.78082503e-01 1.03739471e+01], Loss = 0.4961\n",
      "Iteration 750: Weights = [5.49707074e+01 4.07562852e+00 8.57489168e+00 4.36722071e-02\n",
      " 2.78124673e-01 1.03742402e+01], Loss = 0.4961\n",
      "Iteration 751: Weights = [5.49710003e+01 4.07554044e+00 8.57466493e+00 4.35574764e-02\n",
      " 2.78166522e-01 1.03745331e+01], Loss = 0.4960\n",
      "Iteration 752: Weights = [5.49712903e+01 4.07545216e+00 8.57443802e+00 4.34435932e-02\n",
      " 2.78208050e-01 1.03748257e+01], Loss = 0.4960\n",
      "Iteration 753: Weights = [5.49715774e+01 4.07536366e+00 8.57421097e+00 4.33305510e-02\n",
      " 2.78249260e-01 1.03751180e+01], Loss = 0.4959\n",
      "Iteration 754: Weights = [5.49718616e+01 4.07527495e+00 8.57398378e+00 4.32183437e-02\n",
      " 2.78290154e-01 1.03754101e+01], Loss = 0.4959\n",
      "Iteration 755: Weights = [5.49721430e+01 4.07518604e+00 8.57375645e+00 4.31069649e-02\n",
      " 2.78330733e-01 1.03757020e+01], Loss = 0.4958\n",
      "Iteration 756: Weights = [5.49724216e+01 4.07509692e+00 8.57352898e+00 4.29964084e-02\n",
      " 2.78370999e-01 1.03759936e+01], Loss = 0.4958\n",
      "Iteration 757: Weights = [5.49726973e+01 4.07500760e+00 8.57330137e+00 4.28866680e-02\n",
      " 2.78410954e-01 1.03762849e+01], Loss = 0.4958\n",
      "Iteration 758: Weights = [5.49729704e+01 4.07491807e+00 8.57307362e+00 4.27777377e-02\n",
      " 2.78450601e-01 1.03765760e+01], Loss = 0.4957\n",
      "Iteration 759: Weights = [5.49732407e+01 4.07482835e+00 8.57284573e+00 4.26696113e-02\n",
      " 2.78489940e-01 1.03768669e+01], Loss = 0.4957\n",
      "Iteration 760: Weights = [5.49735083e+01 4.07473842e+00 8.57261771e+00 4.25622829e-02\n",
      " 2.78528973e-01 1.03771575e+01], Loss = 0.4956\n",
      "Iteration 761: Weights = [5.49737732e+01 4.07464830e+00 8.57238955e+00 4.24557464e-02\n",
      " 2.78567703e-01 1.03774479e+01], Loss = 0.4956\n",
      "Iteration 762: Weights = [5.49740354e+01 4.07455798e+00 8.57216126e+00 4.23499959e-02\n",
      " 2.78606131e-01 1.03777380e+01], Loss = 0.4955\n",
      "Iteration 763: Weights = [5.49742951e+01 4.07446747e+00 8.57193284e+00 4.22450255e-02\n",
      " 2.78644259e-01 1.03780279e+01], Loss = 0.4955\n",
      "Iteration 764: Weights = [5.49745521e+01 4.07437676e+00 8.57170428e+00 4.21408294e-02\n",
      " 2.78682089e-01 1.03783176e+01], Loss = 0.4954\n",
      "Iteration 765: Weights = [5.49748066e+01 4.07428586e+00 8.57147560e+00 4.20374017e-02\n",
      " 2.78719622e-01 1.03786070e+01], Loss = 0.4954\n",
      "Iteration 766: Weights = [5.49750585e+01 4.07419477e+00 8.57124679e+00 4.19347368e-02\n",
      " 2.78756861e-01 1.03788962e+01], Loss = 0.4953\n",
      "Iteration 767: Weights = [5.49753080e+01 4.07410349e+00 8.57101784e+00 4.18328289e-02\n",
      " 2.78793807e-01 1.03791852e+01], Loss = 0.4953\n",
      "Iteration 768: Weights = [5.49755549e+01 4.07401202e+00 8.57078878e+00 4.17316722e-02\n",
      " 2.78830461e-01 1.03794740e+01], Loss = 0.4953\n",
      "Iteration 769: Weights = [5.49757993e+01 4.07392037e+00 8.57055958e+00 4.16312613e-02\n",
      " 2.78866826e-01 1.03797625e+01], Loss = 0.4952\n",
      "Iteration 770: Weights = [5.49760413e+01 4.07382853e+00 8.57033026e+00 4.15315905e-02\n",
      " 2.78902903e-01 1.03800508e+01], Loss = 0.4952\n",
      "Iteration 771: Weights = [5.49762809e+01 4.07373651e+00 8.57010082e+00 4.14326542e-02\n",
      " 2.78938694e-01 1.03803389e+01], Loss = 0.4951\n",
      "Iteration 772: Weights = [5.49765181e+01 4.07364431e+00 8.56987125e+00 4.13344470e-02\n",
      " 2.78974201e-01 1.03806267e+01], Loss = 0.4951\n",
      "Iteration 773: Weights = [5.49767529e+01 4.07355193e+00 8.56964157e+00 4.12369634e-02\n",
      " 2.79009425e-01 1.03809144e+01], Loss = 0.4950\n",
      "Iteration 774: Weights = [5.49769854e+01 4.07345936e+00 8.56941176e+00 4.11401980e-02\n",
      " 2.79044368e-01 1.03812018e+01], Loss = 0.4950\n",
      "Iteration 775: Weights = [5.49772156e+01 4.07336663e+00 8.56918183e+00 4.10441454e-02\n",
      " 2.79079031e-01 1.03814890e+01], Loss = 0.4950\n",
      "Iteration 776: Weights = [5.49774434e+01 4.07327371e+00 8.56895179e+00 4.09488003e-02\n",
      " 2.79113418e-01 1.03817760e+01], Loss = 0.4949\n",
      "Iteration 777: Weights = [5.49776690e+01 4.07318062e+00 8.56872162e+00 4.08541573e-02\n",
      " 2.79147528e-01 1.03820628e+01], Loss = 0.4949\n",
      "Iteration 778: Weights = [5.49778923e+01 4.07308736e+00 8.56849134e+00 4.07602112e-02\n",
      " 2.79181364e-01 1.03823494e+01], Loss = 0.4948\n",
      "Iteration 779: Weights = [5.49781134e+01 4.07299392e+00 8.56826094e+00 4.06669568e-02\n",
      " 2.79214927e-01 1.03826357e+01], Loss = 0.4948\n",
      "Iteration 780: Weights = [5.49783322e+01 4.07290031e+00 8.56803043e+00 4.05743890e-02\n",
      " 2.79248220e-01 1.03829219e+01], Loss = 0.4948\n",
      "Iteration 781: Weights = [5.49785489e+01 4.07280654e+00 8.56779981e+00 4.04825025e-02\n",
      " 2.79281243e-01 1.03832078e+01], Loss = 0.4947\n",
      "Iteration 782: Weights = [5.49787634e+01 4.07271259e+00 8.56756907e+00 4.03912923e-02\n",
      " 2.79313998e-01 1.03834936e+01], Loss = 0.4947\n",
      "Iteration 783: Weights = [5.49789758e+01 4.07261848e+00 8.56733822e+00 4.03007533e-02\n",
      " 2.79346487e-01 1.03837791e+01], Loss = 0.4946\n",
      "Iteration 784: Weights = [5.49791860e+01 4.07252421e+00 8.56710726e+00 4.02108805e-02\n",
      " 2.79378712e-01 1.03840645e+01], Loss = 0.4946\n",
      "Iteration 785: Weights = [5.49793942e+01 4.07242976e+00 8.56687619e+00 4.01216689e-02\n",
      " 2.79410674e-01 1.03843496e+01], Loss = 0.4946\n",
      "Iteration 786: Weights = [5.49796002e+01 4.07233516e+00 8.56664501e+00 4.00331136e-02\n",
      " 2.79442375e-01 1.03846346e+01], Loss = 0.4945\n",
      "Iteration 787: Weights = [5.49798042e+01 4.07224039e+00 8.56641372e+00 3.99452096e-02\n",
      " 2.79473815e-01 1.03849193e+01], Loss = 0.4945\n",
      "Iteration 788: Weights = [5.49800062e+01 4.07214547e+00 8.56618233e+00 3.98579521e-02\n",
      " 2.79504998e-01 1.03852039e+01], Loss = 0.4944\n",
      "Iteration 789: Weights = [5.49802061e+01 4.07205038e+00 8.56595083e+00 3.97713363e-02\n",
      " 2.79535924e-01 1.03854882e+01], Loss = 0.4944\n",
      "Iteration 790: Weights = [5.49804040e+01 4.07195514e+00 8.56571922e+00 3.96853573e-02\n",
      " 2.79566596e-01 1.03857724e+01], Loss = 0.4944\n",
      "Iteration 791: Weights = [5.49806000e+01 4.07185974e+00 8.56548751e+00 3.96000104e-02\n",
      " 2.79597013e-01 1.03860563e+01], Loss = 0.4943\n",
      "Iteration 792: Weights = [5.49807940e+01 4.07176418e+00 8.56525569e+00 3.95152908e-02\n",
      " 2.79627179e-01 1.03863401e+01], Loss = 0.4943\n",
      "Iteration 793: Weights = [5.49809861e+01 4.07166847e+00 8.56502378e+00 3.94311939e-02\n",
      " 2.79657094e-01 1.03866237e+01], Loss = 0.4943\n",
      "Iteration 794: Weights = [5.49811762e+01 4.07157260e+00 8.56479176e+00 3.93477150e-02\n",
      " 2.79686761e-01 1.03869071e+01], Loss = 0.4942\n",
      "Iteration 795: Weights = [5.49813644e+01 4.07147659e+00 8.56455964e+00 3.92648495e-02\n",
      " 2.79716180e-01 1.03871904e+01], Loss = 0.4942\n",
      "Iteration 796: Weights = [5.49815508e+01 4.07138042e+00 8.56432742e+00 3.91825928e-02\n",
      " 2.79745354e-01 1.03874734e+01], Loss = 0.4941\n",
      "Iteration 797: Weights = [5.49817353e+01 4.07128410e+00 8.56409510e+00 3.91009404e-02\n",
      " 2.79774283e-01 1.03877562e+01], Loss = 0.4941\n",
      "Iteration 798: Weights = [5.49819179e+01 4.07118763e+00 8.56386268e+00 3.90198876e-02\n",
      " 2.79802969e-01 1.03880389e+01], Loss = 0.4941\n",
      "Iteration 799: Weights = [5.49820988e+01 4.07109102e+00 8.56363016e+00 3.89394302e-02\n",
      " 2.79831414e-01 1.03883214e+01], Loss = 0.4940\n",
      "Iteration 800: Weights = [5.49822778e+01 4.07099426e+00 8.56339755e+00 3.88595635e-02\n",
      " 2.79859619e-01 1.03886037e+01], Loss = 0.4940\n",
      "Iteration 801: Weights = [5.49824550e+01 4.07089735e+00 8.56316484e+00 3.87802832e-02\n",
      " 2.79887586e-01 1.03888859e+01], Loss = 0.4940\n",
      "Iteration 802: Weights = [5.49826304e+01 4.07080030e+00 8.56293203e+00 3.87015849e-02\n",
      " 2.79915316e-01 1.03891678e+01], Loss = 0.4939\n",
      "Iteration 803: Weights = [5.49828041e+01 4.07070311e+00 8.56269913e+00 3.86234643e-02\n",
      " 2.79942810e-01 1.03894496e+01], Loss = 0.4939\n",
      "Iteration 804: Weights = [5.49829761e+01 4.07060578e+00 8.56246614e+00 3.85459170e-02\n",
      " 2.79970070e-01 1.03897312e+01], Loss = 0.4938\n",
      "Iteration 805: Weights = [5.49831463e+01 4.07050830e+00 8.56223306e+00 3.84689387e-02\n",
      " 2.79997098e-01 1.03900126e+01], Loss = 0.4938\n",
      "Iteration 806: Weights = [5.49833149e+01 4.07041069e+00 8.56199988e+00 3.83925253e-02\n",
      " 2.80023894e-01 1.03902939e+01], Loss = 0.4938\n",
      "Iteration 807: Weights = [5.49834817e+01 4.07031293e+00 8.56176661e+00 3.83166724e-02\n",
      " 2.80050461e-01 1.03905750e+01], Loss = 0.4937\n",
      "Iteration 808: Weights = [5.49836469e+01 4.07021504e+00 8.56153325e+00 3.82413760e-02\n",
      " 2.80076800e-01 1.03908559e+01], Loss = 0.4937\n",
      "Iteration 809: Weights = [5.49838104e+01 4.07011701e+00 8.56129980e+00 3.81666318e-02\n",
      " 2.80102912e-01 1.03911367e+01], Loss = 0.4937\n",
      "Iteration 810: Weights = [5.49839723e+01 4.07001885e+00 8.56106626e+00 3.80924357e-02\n",
      " 2.80128798e-01 1.03914173e+01], Loss = 0.4936\n",
      "Iteration 811: Weights = [5.49841326e+01 4.06992055e+00 8.56083264e+00 3.80187836e-02\n",
      " 2.80154460e-01 1.03916977e+01], Loss = 0.4936\n",
      "Iteration 812: Weights = [5.49842913e+01 4.06982212e+00 8.56059892e+00 3.79456715e-02\n",
      " 2.80179899e-01 1.03919780e+01], Loss = 0.4936\n",
      "Iteration 813: Weights = [5.49844484e+01 4.06972355e+00 8.56036512e+00 3.78730953e-02\n",
      " 2.80205117e-01 1.03922581e+01], Loss = 0.4935\n",
      "Iteration 814: Weights = [5.49846039e+01 4.06962486e+00 8.56013124e+00 3.78010510e-02\n",
      " 2.80230115e-01 1.03925380e+01], Loss = 0.4935\n",
      "Iteration 815: Weights = [5.49847578e+01 4.06952603e+00 8.55989726e+00 3.77295347e-02\n",
      " 2.80254895e-01 1.03928178e+01], Loss = 0.4935\n",
      "Iteration 816: Weights = [5.49849103e+01 4.06942708e+00 8.55966321e+00 3.76585424e-02\n",
      " 2.80279457e-01 1.03930974e+01], Loss = 0.4934\n",
      "Iteration 817: Weights = [5.49850612e+01 4.06932799e+00 8.55942907e+00 3.75880703e-02\n",
      " 2.80303804e-01 1.03933769e+01], Loss = 0.4934\n",
      "Iteration 818: Weights = [5.49852106e+01 4.06922878e+00 8.55919485e+00 3.75181143e-02\n",
      " 2.80327936e-01 1.03936562e+01], Loss = 0.4934\n",
      "Iteration 819: Weights = [5.49853584e+01 4.06912944e+00 8.55896054e+00 3.74486707e-02\n",
      " 2.80351854e-01 1.03939354e+01], Loss = 0.4933\n",
      "Iteration 820: Weights = [5.49855049e+01 4.06902998e+00 8.55872615e+00 3.73797356e-02\n",
      " 2.80375561e-01 1.03942143e+01], Loss = 0.4933\n",
      "Iteration 821: Weights = [5.49856498e+01 4.06893039e+00 8.55849169e+00 3.73113053e-02\n",
      " 2.80399057e-01 1.03944932e+01], Loss = 0.4933\n",
      "Iteration 822: Weights = [5.49857933e+01 4.06883068e+00 8.55825714e+00 3.72433760e-02\n",
      " 2.80422344e-01 1.03947719e+01], Loss = 0.4932\n",
      "Iteration 823: Weights = [5.49859354e+01 4.06873085e+00 8.55802251e+00 3.71759440e-02\n",
      " 2.80445423e-01 1.03950504e+01], Loss = 0.4932\n",
      "Iteration 824: Weights = [5.49860760e+01 4.06863089e+00 8.55778780e+00 3.71090054e-02\n",
      " 2.80468296e-01 1.03953288e+01], Loss = 0.4932\n",
      "Iteration 825: Weights = [5.49862153e+01 4.06853082e+00 8.55755302e+00 3.70425567e-02\n",
      " 2.80490963e-01 1.03956071e+01], Loss = 0.4931\n",
      "Iteration 826: Weights = [5.49863531e+01 4.06843062e+00 8.55731816e+00 3.69765943e-02\n",
      " 2.80513426e-01 1.03958851e+01], Loss = 0.4931\n",
      "Iteration 827: Weights = [5.49864896e+01 4.06833030e+00 8.55708322e+00 3.69111143e-02\n",
      " 2.80535686e-01 1.03961631e+01], Loss = 0.4931\n",
      "Iteration 828: Weights = [5.49866247e+01 4.06822987e+00 8.55684820e+00 3.68461134e-02\n",
      " 2.80557745e-01 1.03964409e+01], Loss = 0.4930\n",
      "Iteration 829: Weights = [5.49867584e+01 4.06812932e+00 8.55661311e+00 3.67815879e-02\n",
      " 2.80579603e-01 1.03967185e+01], Loss = 0.4930\n",
      "Iteration 830: Weights = [5.49868909e+01 4.06802865e+00 8.55637794e+00 3.67175342e-02\n",
      " 2.80601263e-01 1.03969961e+01], Loss = 0.4930\n",
      "Iteration 831: Weights = [5.49870220e+01 4.06792787e+00 8.55614270e+00 3.66539488e-02\n",
      " 2.80622724e-01 1.03972734e+01], Loss = 0.4929\n",
      "Iteration 832: Weights = [5.49871517e+01 4.06782698e+00 8.55590739e+00 3.65908283e-02\n",
      " 2.80643989e-01 1.03975507e+01], Loss = 0.4929\n",
      "Iteration 833: Weights = [5.49872802e+01 4.06772597e+00 8.55567200e+00 3.65281692e-02\n",
      " 2.80665059e-01 1.03978277e+01], Loss = 0.4929\n",
      "Iteration 834: Weights = [5.49874074e+01 4.06762485e+00 8.55543654e+00 3.64659680e-02\n",
      " 2.80685935e-01 1.03981047e+01], Loss = 0.4928\n",
      "Iteration 835: Weights = [5.49875333e+01 4.06752361e+00 8.55520101e+00 3.64042213e-02\n",
      " 2.80706618e-01 1.03983815e+01], Loss = 0.4928\n",
      "Iteration 836: Weights = [5.49876580e+01 4.06742227e+00 8.55496541e+00 3.63429258e-02\n",
      " 2.80727110e-01 1.03986582e+01], Loss = 0.4928\n",
      "Iteration 837: Weights = [5.49877814e+01 4.06732081e+00 8.55472974e+00 3.62820780e-02\n",
      " 2.80747411e-01 1.03989347e+01], Loss = 0.4927\n",
      "Iteration 838: Weights = [5.49879036e+01 4.06721925e+00 8.55449400e+00 3.62216747e-02\n",
      " 2.80767522e-01 1.03992111e+01], Loss = 0.4927\n",
      "Iteration 839: Weights = [5.49880246e+01 4.06711757e+00 8.55425818e+00 3.61617125e-02\n",
      " 2.80787446e-01 1.03994874e+01], Loss = 0.4927\n",
      "Iteration 840: Weights = [5.49881443e+01 4.06701579e+00 8.55402230e+00 3.61021882e-02\n",
      " 2.80807183e-01 1.03997635e+01], Loss = 0.4926\n",
      "Iteration 841: Weights = [5.49882629e+01 4.06691391e+00 8.55378635e+00 3.60430984e-02\n",
      " 2.80826735e-01 1.04000395e+01], Loss = 0.4926\n",
      "Iteration 842: Weights = [5.49883803e+01 4.06681191e+00 8.55355034e+00 3.59844399e-02\n",
      " 2.80846102e-01 1.04003154e+01], Loss = 0.4926\n",
      "Iteration 843: Weights = [5.49884965e+01 4.06670982e+00 8.55331426e+00 3.59262096e-02\n",
      " 2.80865285e-01 1.04005911e+01], Loss = 0.4925\n",
      "Iteration 844: Weights = [5.49886115e+01 4.06660761e+00 8.55307811e+00 3.58684042e-02\n",
      " 2.80884287e-01 1.04008667e+01], Loss = 0.4925\n",
      "Iteration 845: Weights = [5.49887254e+01 4.06650531e+00 8.55284189e+00 3.58110205e-02\n",
      " 2.80903107e-01 1.04011422e+01], Loss = 0.4925\n",
      "Iteration 846: Weights = [5.49888381e+01 4.06640290e+00 8.55260561e+00 3.57540555e-02\n",
      " 2.80921748e-01 1.04014175e+01], Loss = 0.4924\n",
      "Iteration 847: Weights = [5.49889497e+01 4.06630039e+00 8.55236926e+00 3.56975060e-02\n",
      " 2.80940210e-01 1.04016928e+01], Loss = 0.4924\n",
      "Iteration 848: Weights = [5.49890602e+01 4.06619778e+00 8.55213286e+00 3.56413689e-02\n",
      " 2.80958494e-01 1.04019679e+01], Loss = 0.4924\n",
      "Iteration 849: Weights = [5.49891696e+01 4.06609507e+00 8.55189638e+00 3.55856411e-02\n",
      " 2.80976602e-01 1.04022428e+01], Loss = 0.4923\n",
      "Iteration 850: Weights = [5.49892779e+01 4.06599225e+00 8.55165985e+00 3.55303197e-02\n",
      " 2.80994534e-01 1.04025177e+01], Loss = 0.4923\n",
      "Iteration 851: Weights = [5.49893852e+01 4.06588934e+00 8.55142325e+00 3.54754015e-02\n",
      " 2.81012293e-01 1.04027924e+01], Loss = 0.4923\n",
      "Iteration 852: Weights = [5.49894913e+01 4.06578634e+00 8.55118659e+00 3.54208835e-02\n",
      " 2.81029878e-01 1.04030670e+01], Loss = 0.4922\n",
      "Iteration 853: Weights = [5.49895964e+01 4.06568323e+00 8.55094987e+00 3.53667629e-02\n",
      " 2.81047291e-01 1.04033415e+01], Loss = 0.4922\n",
      "Iteration 854: Weights = [5.49897004e+01 4.06558003e+00 8.55071308e+00 3.53130365e-02\n",
      " 2.81064534e-01 1.04036158e+01], Loss = 0.4922\n",
      "Iteration 855: Weights = [5.49898034e+01 4.06547673e+00 8.55047624e+00 3.52597016e-02\n",
      " 2.81081606e-01 1.04038901e+01], Loss = 0.4922\n",
      "Iteration 856: Weights = [5.49899054e+01 4.06537334e+00 8.55023934e+00 3.52067551e-02\n",
      " 2.81098510e-01 1.04041642e+01], Loss = 0.4921\n",
      "Iteration 857: Weights = [5.49900063e+01 4.06526985e+00 8.55000238e+00 3.51541942e-02\n",
      " 2.81115246e-01 1.04044382e+01], Loss = 0.4921\n",
      "Iteration 858: Weights = [5.49901063e+01 4.06516627e+00 8.54976536e+00 3.51020160e-02\n",
      " 2.81131816e-01 1.04047121e+01], Loss = 0.4921\n",
      "Iteration 859: Weights = [5.49902052e+01 4.06506259e+00 8.54952828e+00 3.50502177e-02\n",
      " 2.81148220e-01 1.04049858e+01], Loss = 0.4920\n",
      "Iteration 860: Weights = [5.49903032e+01 4.06495883e+00 8.54929114e+00 3.49987964e-02\n",
      " 2.81164460e-01 1.04052595e+01], Loss = 0.4920\n",
      "Iteration 861: Weights = [5.49904001e+01 4.06485497e+00 8.54905395e+00 3.49477493e-02\n",
      " 2.81180536e-01 1.04055330e+01], Loss = 0.4920\n",
      "Iteration 862: Weights = [5.49904961e+01 4.06475102e+00 8.54881670e+00 3.48970737e-02\n",
      " 2.81196450e-01 1.04058065e+01], Loss = 0.4919\n",
      "Iteration 863: Weights = [5.49905912e+01 4.06464698e+00 8.54857940e+00 3.48467668e-02\n",
      " 2.81212203e-01 1.04060798e+01], Loss = 0.4919\n",
      "Iteration 864: Weights = [5.49906853e+01 4.06454285e+00 8.54834203e+00 3.47968258e-02\n",
      " 2.81227795e-01 1.04063530e+01], Loss = 0.4919\n",
      "Iteration 865: Weights = [5.49907784e+01 4.06443864e+00 8.54810462e+00 3.47472480e-02\n",
      " 2.81243228e-01 1.04066260e+01], Loss = 0.4918\n",
      "Iteration 866: Weights = [5.49908706e+01 4.06433433e+00 8.54786714e+00 3.46980307e-02\n",
      " 2.81258503e-01 1.04068990e+01], Loss = 0.4918\n",
      "Iteration 867: Weights = [5.49909619e+01 4.06422994e+00 8.54762962e+00 3.46491713e-02\n",
      " 2.81273620e-01 1.04071719e+01], Loss = 0.4918\n",
      "Iteration 868: Weights = [5.49910523e+01 4.06412546e+00 8.54739204e+00 3.46006671e-02\n",
      " 2.81288582e-01 1.04074446e+01], Loss = 0.4918\n",
      "Iteration 869: Weights = [5.49911418e+01 4.06402090e+00 8.54715441e+00 3.45525153e-02\n",
      " 2.81303388e-01 1.04077173e+01], Loss = 0.4917\n",
      "Iteration 870: Weights = [5.49912304e+01 4.06391625e+00 8.54691672e+00 3.45047135e-02\n",
      " 2.81318040e-01 1.04079898e+01], Loss = 0.4917\n",
      "Iteration 871: Weights = [5.49913181e+01 4.06381151e+00 8.54667898e+00 3.44572590e-02\n",
      " 2.81332538e-01 1.04082622e+01], Loss = 0.4917\n",
      "Iteration 872: Weights = [5.49914049e+01 4.06370669e+00 8.54644119e+00 3.44101492e-02\n",
      " 2.81346885e-01 1.04085346e+01], Loss = 0.4916\n",
      "Iteration 873: Weights = [5.49914908e+01 4.06360179e+00 8.54620335e+00 3.43633815e-02\n",
      " 2.81361080e-01 1.04088068e+01], Loss = 0.4916\n",
      "Iteration 874: Weights = [5.49915759e+01 4.06349680e+00 8.54596546e+00 3.43169535e-02\n",
      " 2.81375125e-01 1.04090789e+01], Loss = 0.4916\n",
      "Iteration 875: Weights = [5.49916602e+01 4.06339174e+00 8.54572752e+00 3.42708625e-02\n",
      " 2.81389021e-01 1.04093509e+01], Loss = 0.4915\n",
      "Iteration 876: Weights = [5.49917436e+01 4.06328659e+00 8.54548952e+00 3.42251062e-02\n",
      " 2.81402768e-01 1.04096228e+01], Loss = 0.4915\n",
      "Iteration 877: Weights = [5.49918261e+01 4.06318136e+00 8.54525148e+00 3.41796819e-02\n",
      " 2.81416368e-01 1.04098946e+01], Loss = 0.4915\n",
      "Iteration 878: Weights = [5.49919079e+01 4.06307605e+00 8.54501339e+00 3.41345873e-02\n",
      " 2.81429821e-01 1.04101663e+01], Loss = 0.4915\n",
      "Iteration 879: Weights = [5.49919888e+01 4.06297066e+00 8.54477525e+00 3.40898198e-02\n",
      " 2.81443129e-01 1.04104379e+01], Loss = 0.4914\n",
      "Iteration 880: Weights = [5.49920689e+01 4.06286519e+00 8.54453706e+00 3.40453771e-02\n",
      " 2.81456293e-01 1.04107094e+01], Loss = 0.4914\n",
      "Iteration 881: Weights = [5.49921482e+01 4.06275964e+00 8.54429883e+00 3.40012567e-02\n",
      " 2.81469312e-01 1.04109808e+01], Loss = 0.4914\n",
      "Iteration 882: Weights = [5.49922267e+01 4.06265402e+00 8.54406054e+00 3.39574562e-02\n",
      " 2.81482190e-01 1.04112521e+01], Loss = 0.4913\n",
      "Iteration 883: Weights = [5.49923045e+01 4.06254832e+00 8.54382221e+00 3.39139733e-02\n",
      " 2.81494925e-01 1.04115233e+01], Loss = 0.4913\n",
      "Iteration 884: Weights = [5.49923814e+01 4.06244254e+00 8.54358383e+00 3.38708056e-02\n",
      " 2.81507519e-01 1.04117944e+01], Loss = 0.4913\n",
      "Iteration 885: Weights = [5.49924576e+01 4.06233668e+00 8.54334541e+00 3.38279508e-02\n",
      " 2.81519974e-01 1.04120655e+01], Loss = 0.4912\n",
      "Iteration 886: Weights = [5.49925330e+01 4.06223075e+00 8.54310694e+00 3.37854065e-02\n",
      " 2.81532289e-01 1.04123364e+01], Loss = 0.4912\n",
      "Iteration 887: Weights = [5.49926077e+01 4.06212475e+00 8.54286843e+00 3.37431704e-02\n",
      " 2.81544467e-01 1.04126072e+01], Loss = 0.4912\n",
      "Iteration 888: Weights = [5.49926816e+01 4.06201867e+00 8.54262987e+00 3.37012402e-02\n",
      " 2.81556507e-01 1.04128779e+01], Loss = 0.4912\n",
      "Iteration 889: Weights = [5.49927548e+01 4.06191252e+00 8.54239126e+00 3.36596137e-02\n",
      " 2.81568411e-01 1.04131485e+01], Loss = 0.4911\n",
      "Iteration 890: Weights = [5.49928272e+01 4.06180629e+00 8.54215262e+00 3.36182886e-02\n",
      " 2.81580179e-01 1.04134191e+01], Loss = 0.4911\n",
      "Iteration 891: Weights = [5.49928990e+01 4.06169999e+00 8.54191393e+00 3.35772627e-02\n",
      " 2.81591813e-01 1.04136895e+01], Loss = 0.4911\n",
      "Iteration 892: Weights = [5.49929700e+01 4.06159362e+00 8.54167519e+00 3.35365337e-02\n",
      " 2.81603313e-01 1.04139599e+01], Loss = 0.4910\n",
      "Iteration 893: Weights = [5.49930403e+01 4.06148718e+00 8.54143641e+00 3.34960995e-02\n",
      " 2.81614680e-01 1.04142301e+01], Loss = 0.4910\n",
      "Iteration 894: Weights = [5.49931099e+01 4.06138067e+00 8.54119759e+00 3.34559578e-02\n",
      " 2.81625915e-01 1.04145003e+01], Loss = 0.4910\n",
      "Iteration 895: Weights = [5.49931788e+01 4.06127408e+00 8.54095873e+00 3.34161065e-02\n",
      " 2.81637020e-01 1.04147704e+01], Loss = 0.4909\n",
      "Iteration 896: Weights = [5.49932470e+01 4.06116743e+00 8.54071982e+00 3.33765434e-02\n",
      " 2.81647993e-01 1.04150403e+01], Loss = 0.4909\n",
      "Iteration 897: Weights = [5.49933145e+01 4.06106071e+00 8.54048088e+00 3.33372664e-02\n",
      " 2.81658838e-01 1.04153102e+01], Loss = 0.4909\n",
      "Iteration 898: Weights = [5.49933814e+01 4.06095392e+00 8.54024189e+00 3.32982733e-02\n",
      " 2.81669554e-01 1.04155800e+01], Loss = 0.4909\n",
      "Iteration 899: Weights = [5.49934476e+01 4.06084706e+00 8.54000286e+00 3.32595621e-02\n",
      " 2.81680142e-01 1.04158498e+01], Loss = 0.4908\n",
      "Iteration 900: Weights = [5.49935131e+01 4.06074013e+00 8.53976380e+00 3.32211307e-02\n",
      " 2.81690603e-01 1.04161194e+01], Loss = 0.4908\n",
      "Iteration 901: Weights = [5.49935780e+01 4.06063314e+00 8.53952469e+00 3.31829769e-02\n",
      " 2.81700939e-01 1.04163890e+01], Loss = 0.4908\n",
      "Iteration 902: Weights = [5.49936422e+01 4.06052608e+00 8.53928554e+00 3.31450988e-02\n",
      " 2.81711149e-01 1.04166584e+01], Loss = 0.4907\n",
      "Iteration 903: Weights = [5.49937058e+01 4.06041895e+00 8.53904636e+00 3.31074942e-02\n",
      " 2.81721234e-01 1.04169278e+01], Loss = 0.4907\n",
      "Iteration 904: Weights = [5.49937687e+01 4.06031176e+00 8.53880713e+00 3.30701612e-02\n",
      " 2.81731196e-01 1.04171971e+01], Loss = 0.4907\n",
      "Iteration 905: Weights = [5.49938310e+01 4.06020450e+00 8.53856787e+00 3.30330977e-02\n",
      " 2.81741036e-01 1.04174663e+01], Loss = 0.4906\n",
      "Iteration 906: Weights = [5.49938927e+01 4.06009718e+00 8.53832857e+00 3.29963017e-02\n",
      " 2.81750753e-01 1.04177354e+01], Loss = 0.4906\n",
      "Iteration 907: Weights = [5.49939538e+01 4.05998979e+00 8.53808923e+00 3.29597712e-02\n",
      " 2.81760349e-01 1.04180044e+01], Loss = 0.4906\n",
      "Iteration 908: Weights = [5.49940142e+01 4.05988234e+00 8.53784985e+00 3.29235044e-02\n",
      " 2.81769825e-01 1.04182734e+01], Loss = 0.4906\n",
      "Iteration 909: Weights = [5.49940741e+01 4.05977483e+00 8.53761044e+00 3.28874991e-02\n",
      " 2.81779181e-01 1.04185423e+01], Loss = 0.4905\n",
      "Iteration 910: Weights = [5.49941334e+01 4.05966725e+00 8.53737099e+00 3.28517536e-02\n",
      " 2.81788418e-01 1.04188111e+01], Loss = 0.4905\n",
      "Iteration 911: Weights = [5.49941920e+01 4.05955961e+00 8.53713150e+00 3.28162657e-02\n",
      " 2.81797537e-01 1.04190798e+01], Loss = 0.4905\n",
      "Iteration 912: Weights = [5.49942501e+01 4.05945191e+00 8.53689198e+00 3.27810338e-02\n",
      " 2.81806539e-01 1.04193484e+01], Loss = 0.4904\n",
      "Iteration 913: Weights = [5.49943076e+01 4.05934415e+00 8.53665242e+00 3.27460557e-02\n",
      " 2.81815424e-01 1.04196170e+01], Loss = 0.4904\n",
      "Iteration 914: Weights = [5.49943645e+01 4.05923633e+00 8.53641282e+00 3.27113297e-02\n",
      " 2.81824194e-01 1.04198854e+01], Loss = 0.4904\n",
      "Iteration 915: Weights = [5.49944209e+01 4.05912845e+00 8.53617319e+00 3.26768539e-02\n",
      " 2.81832848e-01 1.04201538e+01], Loss = 0.4904\n",
      "Iteration 916: Weights = [5.49944767e+01 4.05902051e+00 8.53593353e+00 3.26426264e-02\n",
      " 2.81841389e-01 1.04204221e+01], Loss = 0.4903\n",
      "Iteration 917: Weights = [5.49945319e+01 4.05891251e+00 8.53569383e+00 3.26086454e-02\n",
      " 2.81849816e-01 1.04206904e+01], Loss = 0.4903\n",
      "Iteration 918: Weights = [5.49945866e+01 4.05880445e+00 8.53545410e+00 3.25749091e-02\n",
      " 2.81858130e-01 1.04209585e+01], Loss = 0.4903\n",
      "Iteration 919: Weights = [5.49946407e+01 4.05869633e+00 8.53521434e+00 3.25414156e-02\n",
      " 2.81866332e-01 1.04212266e+01], Loss = 0.4902\n",
      "Iteration 920: Weights = [5.49946943e+01 4.05858815e+00 8.53497454e+00 3.25081632e-02\n",
      " 2.81874423e-01 1.04214946e+01], Loss = 0.4902\n",
      "Iteration 921: Weights = [5.49947474e+01 4.05847992e+00 8.53473470e+00 3.24751500e-02\n",
      " 2.81882404e-01 1.04217626e+01], Loss = 0.4902\n",
      "Iteration 922: Weights = [5.49947999e+01 4.05837163e+00 8.53449484e+00 3.24423743e-02\n",
      " 2.81890275e-01 1.04220304e+01], Loss = 0.4902\n",
      "Iteration 923: Weights = [5.49948519e+01 4.05826328e+00 8.53425494e+00 3.24098344e-02\n",
      " 2.81898036e-01 1.04222982e+01], Loss = 0.4901\n",
      "Iteration 924: Weights = [5.49949034e+01 4.05815488e+00 8.53401501e+00 3.23775284e-02\n",
      " 2.81905690e-01 1.04225659e+01], Loss = 0.4901\n",
      "Iteration 925: Weights = [5.49949543e+01 4.05804642e+00 8.53377505e+00 3.23454546e-02\n",
      " 2.81913235e-01 1.04228335e+01], Loss = 0.4901\n",
      "Iteration 926: Weights = [5.49950048e+01 4.05793791e+00 8.53353506e+00 3.23136114e-02\n",
      " 2.81920674e-01 1.04231011e+01], Loss = 0.4900\n",
      "Iteration 927: Weights = [5.49950548e+01 4.05782934e+00 8.53329503e+00 3.22819969e-02\n",
      " 2.81928007e-01 1.04233686e+01], Loss = 0.4900\n",
      "Iteration 928: Weights = [5.49951042e+01 4.05772071e+00 8.53305498e+00 3.22506096e-02\n",
      " 2.81935234e-01 1.04236360e+01], Loss = 0.4900\n",
      "Iteration 929: Weights = [5.49951532e+01 4.05761204e+00 8.53281489e+00 3.22194478e-02\n",
      " 2.81942356e-01 1.04239034e+01], Loss = 0.4900\n",
      "Iteration 930: Weights = [5.49952016e+01 4.05750330e+00 8.53257477e+00 3.21885097e-02\n",
      " 2.81949374e-01 1.04241706e+01], Loss = 0.4899\n",
      "Iteration 931: Weights = [5.49952496e+01 4.05739452e+00 8.53233463e+00 3.21577936e-02\n",
      " 2.81956289e-01 1.04244378e+01], Loss = 0.4899\n",
      "Iteration 932: Weights = [5.49952971e+01 4.05728568e+00 8.53209445e+00 3.21272981e-02\n",
      " 2.81963101e-01 1.04247050e+01], Loss = 0.4899\n",
      "Iteration 933: Weights = [5.49953441e+01 4.05717679e+00 8.53185424e+00 3.20970214e-02\n",
      " 2.81969811e-01 1.04249720e+01], Loss = 0.4898\n",
      "Iteration 934: Weights = [5.49953907e+01 4.05706785e+00 8.53161401e+00 3.20669618e-02\n",
      " 2.81976419e-01 1.04252390e+01], Loss = 0.4898\n",
      "Iteration 935: Weights = [5.49954368e+01 4.05695886e+00 8.53137374e+00 3.20371179e-02\n",
      " 2.81982927e-01 1.04255060e+01], Loss = 0.4898\n",
      "Iteration 936: Weights = [5.49954824e+01 4.05684982e+00 8.53113345e+00 3.20074880e-02\n",
      " 2.81989335e-01 1.04257728e+01], Loss = 0.4897\n",
      "Iteration 937: Weights = [5.49955276e+01 4.05674072e+00 8.53089313e+00 3.19780705e-02\n",
      " 2.81995643e-01 1.04260396e+01], Loss = 0.4897\n",
      "Iteration 938: Weights = [5.49955723e+01 4.05663158e+00 8.53065278e+00 3.19488638e-02\n",
      " 2.82001853e-01 1.04263063e+01], Loss = 0.4897\n",
      "Iteration 939: Weights = [5.49956166e+01 4.05652238e+00 8.53041240e+00 3.19198664e-02\n",
      " 2.82007965e-01 1.04265730e+01], Loss = 0.4897\n",
      "Iteration 940: Weights = [5.49956604e+01 4.05641314e+00 8.53017200e+00 3.18910767e-02\n",
      " 2.82013979e-01 1.04268396e+01], Loss = 0.4896\n",
      "Iteration 941: Weights = [5.49957038e+01 4.05630384e+00 8.52993157e+00 3.18624932e-02\n",
      " 2.82019896e-01 1.04271061e+01], Loss = 0.4896\n",
      "Iteration 942: Weights = [5.49957468e+01 4.05619450e+00 8.52969111e+00 3.18341144e-02\n",
      " 2.82025718e-01 1.04273726e+01], Loss = 0.4896\n",
      "Iteration 943: Weights = [5.49957893e+01 4.05608511e+00 8.52945062e+00 3.18059387e-02\n",
      " 2.82031443e-01 1.04276390e+01], Loss = 0.4895\n",
      "Iteration 944: Weights = [5.49958314e+01 4.05597567e+00 8.52921011e+00 3.17779646e-02\n",
      " 2.82037074e-01 1.04279053e+01], Loss = 0.4895\n",
      "Iteration 945: Weights = [5.49958731e+01 4.05586618e+00 8.52896957e+00 3.17501907e-02\n",
      " 2.82042611e-01 1.04281716e+01], Loss = 0.4895\n",
      "Iteration 946: Weights = [5.49959144e+01 4.05575665e+00 8.52872900e+00 3.17226155e-02\n",
      " 2.82048054e-01 1.04284378e+01], Loss = 0.4895\n",
      "Iteration 947: Weights = [5.49959552e+01 4.05564707e+00 8.52848841e+00 3.16952375e-02\n",
      " 2.82053404e-01 1.04287039e+01], Loss = 0.4894\n",
      "Iteration 948: Weights = [5.49959957e+01 4.05553744e+00 8.52824780e+00 3.16680551e-02\n",
      " 2.82058662e-01 1.04289700e+01], Loss = 0.4894\n",
      "Iteration 949: Weights = [5.49960357e+01 4.05542777e+00 8.52800716e+00 3.16410671e-02\n",
      " 2.82063828e-01 1.04292360e+01], Loss = 0.4894\n",
      "Iteration 950: Weights = [5.49960754e+01 4.05531805e+00 8.52776649e+00 3.16142720e-02\n",
      " 2.82068903e-01 1.04295019e+01], Loss = 0.4893\n",
      "Iteration 951: Weights = [5.49961146e+01 4.05520828e+00 8.52752580e+00 3.15876682e-02\n",
      " 2.82073888e-01 1.04297678e+01], Loss = 0.4893\n",
      "Iteration 952: Weights = [5.49961535e+01 4.05509847e+00 8.52728508e+00 3.15612545e-02\n",
      " 2.82078782e-01 1.04300336e+01], Loss = 0.4893\n",
      "Iteration 953: Weights = [5.49961919e+01 4.05498862e+00 8.52704434e+00 3.15350293e-02\n",
      " 2.82083587e-01 1.04302994e+01], Loss = 0.4893\n",
      "Iteration 954: Weights = [5.49962300e+01 4.05487872e+00 8.52680358e+00 3.15089914e-02\n",
      " 2.82088304e-01 1.04305651e+01], Loss = 0.4892\n",
      "Iteration 955: Weights = [5.49962677e+01 4.05476878e+00 8.52656279e+00 3.14831392e-02\n",
      " 2.82092932e-01 1.04308308e+01], Loss = 0.4892\n",
      "Iteration 956: Weights = [5.49963050e+01 4.05465879e+00 8.52632198e+00 3.14574715e-02\n",
      " 2.82097473e-01 1.04310963e+01], Loss = 0.4892\n",
      "Iteration 957: Weights = [5.49963420e+01 4.05454876e+00 8.52608114e+00 3.14319869e-02\n",
      " 2.82101927e-01 1.04313619e+01], Loss = 0.4891\n",
      "Iteration 958: Weights = [5.49963786e+01 4.05443869e+00 8.52584029e+00 3.14066840e-02\n",
      " 2.82106294e-01 1.04316273e+01], Loss = 0.4891\n",
      "Iteration 959: Weights = [5.49964148e+01 4.05432857e+00 8.52559941e+00 3.13815615e-02\n",
      " 2.82110576e-01 1.04318927e+01], Loss = 0.4891\n",
      "Iteration 960: Weights = [5.49964506e+01 4.05421841e+00 8.52535850e+00 3.13566180e-02\n",
      " 2.82114772e-01 1.04321581e+01], Loss = 0.4891\n",
      "Iteration 961: Weights = [5.49964861e+01 4.05410821e+00 8.52511758e+00 3.13318522e-02\n",
      " 2.82118884e-01 1.04324234e+01], Loss = 0.4890\n",
      "Iteration 962: Weights = [5.49965213e+01 4.05399797e+00 8.52487663e+00 3.13072629e-02\n",
      " 2.82122912e-01 1.04326886e+01], Loss = 0.4890\n",
      "Iteration 963: Weights = [5.49965561e+01 4.05388769e+00 8.52463566e+00 3.12828486e-02\n",
      " 2.82126856e-01 1.04329538e+01], Loss = 0.4890\n",
      "Iteration 964: Weights = [5.49965905e+01 4.05377737e+00 8.52439467e+00 3.12586082e-02\n",
      " 2.82130717e-01 1.04332189e+01], Loss = 0.4889\n",
      "Iteration 965: Weights = [5.49966246e+01 4.05366700e+00 8.52415366e+00 3.12345402e-02\n",
      " 2.82134496e-01 1.04334840e+01], Loss = 0.4889\n",
      "Iteration 966: Weights = [5.49966584e+01 4.05355660e+00 8.52391262e+00 3.12106435e-02\n",
      " 2.82138193e-01 1.04337490e+01], Loss = 0.4889\n",
      "Iteration 967: Weights = [5.49966918e+01 4.05344615e+00 8.52367157e+00 3.11869168e-02\n",
      " 2.82141809e-01 1.04340139e+01], Loss = 0.4889\n",
      "Iteration 968: Weights = [5.49967249e+01 4.05333567e+00 8.52343049e+00 3.11633588e-02\n",
      " 2.82145344e-01 1.04342788e+01], Loss = 0.4888\n",
      "Iteration 969: Weights = [5.49967576e+01 4.05322514e+00 8.52318940e+00 3.11399682e-02\n",
      " 2.82148799e-01 1.04345437e+01], Loss = 0.4888\n",
      "Iteration 970: Weights = [5.49967900e+01 4.05311458e+00 8.52294828e+00 3.11167439e-02\n",
      " 2.82152174e-01 1.04348085e+01], Loss = 0.4888\n",
      "Iteration 971: Weights = [5.49968221e+01 4.05300398e+00 8.52270714e+00 3.10936846e-02\n",
      " 2.82155469e-01 1.04350732e+01], Loss = 0.4887\n",
      "Iteration 972: Weights = [5.49968539e+01 4.05289334e+00 8.52246598e+00 3.10707891e-02\n",
      " 2.82158687e-01 1.04353379e+01], Loss = 0.4887\n",
      "Iteration 973: Weights = [5.49968854e+01 4.05278266e+00 8.52222481e+00 3.10480561e-02\n",
      " 2.82161826e-01 1.04356025e+01], Loss = 0.4887\n",
      "Iteration 974: Weights = [5.49969165e+01 4.05267194e+00 8.52198361e+00 3.10254845e-02\n",
      " 2.82164888e-01 1.04358671e+01], Loss = 0.4887\n",
      "Iteration 975: Weights = [5.49969473e+01 4.05256119e+00 8.52174240e+00 3.10030731e-02\n",
      " 2.82167872e-01 1.04361316e+01], Loss = 0.4886\n",
      "Iteration 976: Weights = [5.49969779e+01 4.05245039e+00 8.52150116e+00 3.09808207e-02\n",
      " 2.82170780e-01 1.04363961e+01], Loss = 0.4886\n",
      "Iteration 977: Weights = [5.49970081e+01 4.05233957e+00 8.52125991e+00 3.09587261e-02\n",
      " 2.82173612e-01 1.04366605e+01], Loss = 0.4886\n",
      "Iteration 978: Weights = [5.49970380e+01 4.05222870e+00 8.52101863e+00 3.09367881e-02\n",
      " 2.82176369e-01 1.04369249e+01], Loss = 0.4886\n",
      "Iteration 979: Weights = [5.49970676e+01 4.05211780e+00 8.52077734e+00 3.09150056e-02\n",
      " 2.82179050e-01 1.04371892e+01], Loss = 0.4885\n",
      "Iteration 980: Weights = [5.49970970e+01 4.05200686e+00 8.52053603e+00 3.08933775e-02\n",
      " 2.82181658e-01 1.04374534e+01], Loss = 0.4885\n",
      "Iteration 981: Weights = [5.49971260e+01 4.05189589e+00 8.52029471e+00 3.08719026e-02\n",
      " 2.82184191e-01 1.04377177e+01], Loss = 0.4885\n",
      "Iteration 982: Weights = [5.49971547e+01 4.05178488e+00 8.52005336e+00 3.08505797e-02\n",
      " 2.82186650e-01 1.04379818e+01], Loss = 0.4884\n",
      "Iteration 983: Weights = [5.49971832e+01 4.05167383e+00 8.51981200e+00 3.08294078e-02\n",
      " 2.82189037e-01 1.04382459e+01], Loss = 0.4884\n",
      "Iteration 984: Weights = [5.49972113e+01 4.05156275e+00 8.51957062e+00 3.08083857e-02\n",
      " 2.82191351e-01 1.04385100e+01], Loss = 0.4884\n",
      "Iteration 985: Weights = [5.49972392e+01 4.05145164e+00 8.51932922e+00 3.07875124e-02\n",
      " 2.82193593e-01 1.04387740e+01], Loss = 0.4884\n",
      "Iteration 986: Weights = [5.49972668e+01 4.05134049e+00 8.51908780e+00 3.07667867e-02\n",
      " 2.82195764e-01 1.04390380e+01], Loss = 0.4883\n",
      "Iteration 987: Weights = [5.49972942e+01 4.05122931e+00 8.51884637e+00 3.07462075e-02\n",
      " 2.82197864e-01 1.04393019e+01], Loss = 0.4883\n",
      "Iteration 988: Weights = [5.49973212e+01 4.05111809e+00 8.51860492e+00 3.07257737e-02\n",
      " 2.82199893e-01 1.04395657e+01], Loss = 0.4883\n",
      "Iteration 989: Weights = [5.49973480e+01 4.05100684e+00 8.51836345e+00 3.07054843e-02\n",
      " 2.82201852e-01 1.04398296e+01], Loss = 0.4882\n",
      "Iteration 990: Weights = [5.49973745e+01 4.05089556e+00 8.51812197e+00 3.06853383e-02\n",
      " 2.82203741e-01 1.04400933e+01], Loss = 0.4882\n",
      "Iteration 991: Weights = [5.49974008e+01 4.05078424e+00 8.51788047e+00 3.06653345e-02\n",
      " 2.82205562e-01 1.04403571e+01], Loss = 0.4882\n",
      "Iteration 992: Weights = [5.49974268e+01 4.05067289e+00 8.51763896e+00 3.06454718e-02\n",
      " 2.82207313e-01 1.04406207e+01], Loss = 0.4882\n",
      "Iteration 993: Weights = [5.49974525e+01 4.05056151e+00 8.51739743e+00 3.06257494e-02\n",
      " 2.82208997e-01 1.04408844e+01], Loss = 0.4881\n",
      "Iteration 994: Weights = [5.49974780e+01 4.05045010e+00 8.51715588e+00 3.06061660e-02\n",
      " 2.82210612e-01 1.04411479e+01], Loss = 0.4881\n",
      "Iteration 995: Weights = [5.49975032e+01 4.05033865e+00 8.51691432e+00 3.05867208e-02\n",
      " 2.82212161e-01 1.04414115e+01], Loss = 0.4881\n",
      "Iteration 996: Weights = [5.49975282e+01 4.05022717e+00 8.51667274e+00 3.05674126e-02\n",
      " 2.82213642e-01 1.04416750e+01], Loss = 0.4880\n",
      "Iteration 997: Weights = [5.49975529e+01 4.05011567e+00 8.51643115e+00 3.05482405e-02\n",
      " 2.82215057e-01 1.04419384e+01], Loss = 0.4880\n",
      "Iteration 998: Weights = [5.49975774e+01 4.05000412e+00 8.51618954e+00 3.05292035e-02\n",
      " 2.82216407e-01 1.04422018e+01], Loss = 0.4880\n",
      "Iteration 999: Weights = [5.49976016e+01 4.04989255e+00 8.51594792e+00 3.05103005e-02\n",
      " 2.82217690e-01 1.04424652e+01], Loss = 0.4880\n",
      "Iteration 1000: Weights = [5.49976256e+01 4.04978095e+00 8.51570628e+00 3.04915306e-02\n",
      " 2.82218909e-01 1.04427285e+01], Loss = 0.4879\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. Displaying Weights per Iteration\n",
    "# =============================================================================\n",
    "# Run gradient descent\n",
    "final_weights, weight_history = gradient_descent(X_train_aug, y_train, \n",
    "                                                 initial_weights,\n",
    "                                                 learning_rate=0.01, \n",
    "                                                 iterations=i) # sameple is 30 given n = 30 as per instructions\n",
    "                                                  # please check the last cell for all iterations n = 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.49976256e+01 4.04978095e+00 8.51570628e+00 3.04915306e-02\n",
      " 2.82218909e-01 1.04427285e+01]\n"
     ]
    }
   ],
   "source": [
    "print(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. Plot the Value of Weights per Iteration\n",
    "# =============================================================================\n",
    "\n",
    "# Convert weight_history list to a NumPy array for plotting\n",
    "weight_history = np.array(weight_history)  # shape: (iterations, number_of_weights)\n",
    "\n",
    "weight_names = ['bias'] + features\n",
    "\n",
    "# Create a 3x2 grid of subplots\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
    "axs = axs.flatten()  # Flatten the grid for easy indexing\n",
    "\n",
    "# Plot the evolution of each weight over iterations\n",
    "for j in range(weight_history.shape[1]):\n",
    "    axs[j].plot(range(1, len(weight_history) + 1), weight_history[:, j],\n",
    "                marker='o', linestyle='-')\n",
    "    axs[j].set_xlabel('Iteration')\n",
    "    axs[j].set_ylabel(weight_names[j])\n",
    "    axs[j].set_title(f'Weight Update for {weight_names[j]}')\n",
    "    axs[j].grid(True)\n",
    "\n",
    "# Hide any unused subplots (if any)\n",
    "for k in range(weight_history.shape[1], len(axs)):\n",
    "    axs[k].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Regression Model:\n",
      "y = 54.9976 + 4.0498*Hours Studied + 8.5157*Previous Scores + 0.0305*Extracurricular Activities + 0.2822*Sample Question Papers Practiced + 10.4427*Performance Index\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. Build a Function for the Final Regression Model\n",
    "# =============================================================================\n",
    "# The equation will be in the form: y = intercept + coef1*G1 + coef2*G2\n",
    "# reminder that final_weights carry the values of each feature vector\n",
    "equation = f\"{final_weights[0]:.4f}\"  # Start with the intercept\n",
    "for idx, feature in enumerate(features, start=1):\n",
    "    coef = final_weights[idx]\n",
    "    if coef >= 0:\n",
    "        equation += f\" + {coef:.4f}*{feature}\"\n",
    "    else:\n",
    "        equation += f\" - {abs(coef):.4f}*{feature}\"\n",
    "        \n",
    "print(\"Final Regression Model:\")\n",
    "print(\"y =\", equation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7422</th>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hours Studied  Previous Scores  Extracurricular Activities  Sleep Hours  \\\n",
       "8177              1               59                           1            7   \n",
       "7422              4               54                           0            5   \n",
       "4534              6               47                           0            9   \n",
       "9191              7               86                           1            5   \n",
       "9777              5               47                           0            9   \n",
       "\n",
       "      Sample Question Papers Practiced  Performance Index  \n",
       "8177                                 4                 31  \n",
       "7422                                 4                 35  \n",
       "4534                                 8                 37  \n",
       "9191                                 4                 74  \n",
       "9777                                 4                 36  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. Sampling Test Data\n",
    "# =============================================================================\n",
    "\n",
    "# Remove training observations from the original dataframe\n",
    "remaining_df = df.drop(train_df.index)\n",
    "\n",
    "# Randomly sample 30 test observations (use a different seed to avoid overlap)\n",
    "test_df = remaining_df.sample(tn, random_state=seed+1)\n",
    "\n",
    "\n",
    "print(\"Test Sample:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[features].values\n",
    "y_test = test_df[target].values\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_aug = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]\n",
    "\n",
    "X_test_aug = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Test Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([31.4449866 , 35.46770833, 36.51692585, 76.16988095, 34.09177912,\n",
       "       56.47473539, 85.70177335, 24.99837364, 29.92118358, 61.06363455,\n",
       "       75.58746893, 21.26761264, 66.92697627, 23.95521862, 75.37436888,\n",
       "       39.01438334, 16.77523228, 41.47485526, 48.51205842, 61.40946557,\n",
       "       85.76321558, 35.34803322, 40.65407118, 61.97601054, 52.48525816,\n",
       "       41.09764777, 48.39628816, 39.23765548, 53.15519541, 27.86925461])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9. Use the Regression Function for Prediction\n",
    "# =============================================================================\n",
    "\n",
    "# Predict using the final weights for all test observations\n",
    "predictions = X_test_aug.dot(final_weights)\n",
    "\n",
    "# Show a few predictions alongside actual values\n",
    "predictions = X_test_aug.dot(final_weights)\n",
    "print(\"Predictions on Test Set:\")\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 1.0078\n",
      "Root Mean Squared Error on Test Set: 1.0039\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 10. Calculate for Errors\n",
    "# =============================================================================\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error on Test Set: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Weights = [0.55       0.06436373 0.17343832 0.06640459 0.01581193 0.19440508], Loss = 3402.9333\n",
      "Iteration 2: Weights = [1.0945     0.12758948 0.34327526 0.13086307 0.0310865  0.38486599], Loss = 3327.5608\n",
      "Iteration 3: Weights = [1.633555   0.18969909 0.50958688 0.19342136 0.04583804 0.57146517], Loss = 3254.0136\n",
      "Iteration 4: Weights = [2.16721945 0.25071395 0.67244765 0.25412436 0.06008052 0.7542833 ], Loss = 3182.2417\n",
      "Iteration 5: Weights = [2.69554726 0.31065502 0.83193042 0.31301597 0.07382758 0.93339934], Loss = 3112.1966\n",
      "Iteration 6: Weights = [3.21859178 0.36954285 0.98810651 0.37013914 0.08709254 1.1088906 ], Loss = 3043.8312\n",
      "Iteration 7: Weights = [3.73640587 0.42739755 1.14104572 0.42553584 0.0998884  1.28083275], Loss = 2977.1001\n",
      "Iteration 8: Weights = [4.24904181 0.48423885 1.29081636 0.47924711 0.11222784 1.44929985], Loss = 2911.9591\n",
      "Iteration 9: Weights = [4.75655139 0.54008609 1.43748529 0.53131309 0.12412325 1.61436442], Loss = 2848.3655\n",
      "Iteration 10: Weights = [5.25898587 0.59495818 1.58111796 0.58177303 0.1355867  1.77609741], Loss = 2786.2778\n",
      "Iteration 11: Weights = [5.75639602 0.64887371 1.7217784  0.63066528 0.14662999 1.9345683 ], Loss = 2725.6560\n",
      "Iteration 12: Weights = [6.24883206 0.70185085 1.8595293  0.67802737 0.15726464 2.08984509], Loss = 2666.4610\n",
      "Iteration 13: Weights = [6.73634374 0.75390743 1.99443202 0.72389598 0.16750186 2.24199434], Loss = 2608.6552\n",
      "Iteration 14: Weights = [7.2189803  0.80506091 2.1265466  0.76830696 0.17735263 2.39108121], Loss = 2552.2020\n",
      "Iteration 15: Weights = [7.69679049 0.85532841 2.25593182 0.81129538 0.18682763 2.53716949], Loss = 2497.0659\n",
      "Iteration 16: Weights = [8.16982259 0.90472671 2.3826452  0.85289552 0.1959373  2.6803216 ], Loss = 2443.2124\n",
      "Iteration 17: Weights = [8.63812436 0.95327224 2.50674303 0.89314089 0.20469182 2.82059867], Loss = 2390.6083\n",
      "Iteration 18: Weights = [9.10174312 1.00098111 2.62828042 0.93206426 0.21310113 2.95806051], Loss = 2339.2210\n",
      "Iteration 19: Weights = [9.56072569 1.04786912 2.74731129 0.96969766 0.22117491 3.09276569], Loss = 2289.0193\n",
      "Iteration 20: Weights = [10.01511843  1.09395174  2.86388845  1.00607242  0.22892263  3.22477153], Loss = 2239.9726\n",
      "Iteration 21: Weights = [10.46496725  1.13924414  2.97806354  1.04121914  0.2363535   3.35413416], Loss = 2192.0512\n",
      "Iteration 22: Weights = [10.91031758  1.18376117  3.08988713  1.07516776  0.24347652  3.48090849], Loss = 2145.2266\n",
      "Iteration 23: Weights = [11.3512144   1.22751742  3.19940872  1.10794754  0.25030048  3.6051483 ], Loss = 2099.4707\n",
      "Iteration 24: Weights = [11.78770226  1.27052716  3.30667674  1.13958709  0.25683393  3.72690624], Loss = 2054.7566\n",
      "Iteration 25: Weights = [12.21982523  1.31280437  3.41173861  1.17011436  0.26308523  3.84623381], Loss = 2011.0579\n",
      "Iteration 26: Weights = [12.64762698  1.35436279  3.51464073  1.19955669  0.26906253  3.96318148], Loss = 1968.3491\n",
      "Iteration 27: Weights = [13.07115071  1.39521585  3.61542851  1.2279408   0.27477376  4.0777986 ], Loss = 1926.6054\n",
      "Iteration 28: Weights = [13.4904392   1.43537673  3.71414642  1.25529281  0.28022668  4.19013352], Loss = 1885.8027\n",
      "Iteration 29: Weights = [13.90553481  1.47485835  3.81083795  1.28163826  0.28542884  4.30023355], Loss = 1845.9176\n",
      "Iteration 30: Weights = [14.31647946  1.51367338  3.90554569  1.3070021   0.29038762  4.40814501], Loss = 1806.9275\n",
      "Iteration 31: Weights = [14.72331467  1.55183421  3.99831133  1.33140872  0.29511019  4.51391325], Loss = 1768.8100\n",
      "Iteration 32: Weights = [15.12608152  1.58935301  4.08917566  1.35488198  0.29960357  4.61758264], Loss = 1731.5439\n",
      "Iteration 33: Weights = [15.52482071  1.62624171  4.17817861  1.37744518  0.30387459  4.71919663], Loss = 1695.1082\n",
      "Iteration 34: Weights = [15.9195725   1.662512    4.26535927  1.39912109  0.30792991  4.81879778], Loss = 1659.4827\n",
      "Iteration 35: Weights = [16.31037678  1.69817534  4.35075588  1.41993199  0.31177602  4.91642771], Loss = 1624.6475\n",
      "Iteration 36: Weights = [16.69727301  1.73324295  4.43440588  1.43989965  0.31541926  5.01212718], Loss = 1590.5836\n",
      "Iteration 37: Weights = [17.08030028  1.76772585  4.51634593  1.45904532  0.31886579  5.10593611], Loss = 1557.2722\n",
      "Iteration 38: Weights = [17.45949727  1.80163483  4.59661189  1.47738979  0.32212164  5.19789356], Loss = 1524.6953\n",
      "Iteration 39: Weights = [17.8349023   1.83498047  4.67523886  1.49495339  0.32519266  5.28803776], Loss = 1492.8351\n",
      "Iteration 40: Weights = [18.20655328  1.86777315  4.75226122  1.51175598  0.32808459  5.37640616], Loss = 1461.6745\n",
      "Iteration 41: Weights = [18.57448775  1.90002303  4.82771259  1.52781694  0.33080297  5.4630354 ], Loss = 1431.1967\n",
      "Iteration 42: Weights = [18.93874287  1.93174008  4.90162589  1.54315526  0.33335326  5.54796137], Loss = 1401.3857\n",
      "Iteration 43: Weights = [19.29935544  1.96293408  4.97403335  1.55778946  0.33574073  5.63121919], Loss = 1372.2254\n",
      "Iteration 44: Weights = [19.65636189  1.99361461  5.0449665   1.57173766  0.33797054  5.71284324], Loss = 1343.7006\n",
      "Iteration 45: Weights = [20.00979827  2.02379107  5.11445622  1.58501754  0.34004773  5.79286718], Loss = 1315.7961\n",
      "Iteration 46: Weights = [20.35970028  2.05347266  5.18253272  1.59764642  0.34197718  5.87132397], Loss = 1288.4976\n",
      "Iteration 47: Weights = [20.70610328  2.08266841  5.24922557  1.60964118  0.34376366  5.94824588], Loss = 1261.7906\n",
      "Iteration 48: Weights = [21.04904225  2.11138719  5.31456372  1.62101834  0.34541182  6.02366448], Loss = 1235.6615\n",
      "Iteration 49: Weights = [21.38855183  2.13963766  5.37857551  1.63179404  0.34692619  6.0976107 ], Loss = 1210.0967\n",
      "Iteration 50: Weights = [21.72466631  2.16742835  5.44128867  1.64198404  0.34831118  6.1701148 ], Loss = 1185.0831\n",
      "Iteration 51: Weights = [22.05741964  2.19476759  5.50273034  1.65160375  0.34957108  6.24120642], Loss = 1160.6080\n",
      "Iteration 52: Weights = [22.38684545  2.22166358  5.5629271   1.66066822  0.35071007  6.31091458], Loss = 1136.6589\n",
      "Iteration 53: Weights = [22.71297699  2.24812432  5.62190495  1.66919215  0.35173224  6.37926767], Loss = 1113.2237\n",
      "Iteration 54: Weights = [23.03584722  2.2741577   5.67968935  1.67718993  0.35264154  6.44629351], Loss = 1090.2905\n",
      "Iteration 55: Weights = [23.35548875  2.29977143  5.73630521  1.68467558  0.35344185  6.51201932], Loss = 1067.8479\n",
      "Iteration 56: Weights = [23.67193386  2.32497307  5.79177694  1.69166281  0.35413692  6.57647175], Loss = 1045.8846\n",
      "Iteration 57: Weights = [23.98521453  2.34977004  5.84612839  1.69816503  0.35473041  6.6396769 ], Loss = 1024.3897\n",
      "Iteration 58: Weights = [24.29536238  2.37416962  5.89938294  1.70419533  0.3552259   6.70166031], Loss = 1003.3526\n",
      "Iteration 59: Weights = [24.60240876  2.39817893  5.95156346  1.70976649  0.35562686  6.76244699], Loss = 982.7628\n",
      "Iteration 60: Weights = [24.90638467  2.42180498  6.00269234  1.71489101  0.35593665  6.82206143], Loss = 962.6103\n",
      "Iteration 61: Weights = [25.20732082  2.44505462  6.05279149  1.71958108  0.35615858  6.8805276 ], Loss = 942.8851\n",
      "Iteration 62: Weights = [25.50524761  2.46793459  6.10188237  1.72384863  0.35629585  6.93786897], Loss = 923.5777\n",
      "Iteration 63: Weights = [25.80019514  2.49045147  6.14998596  1.72770529  0.35635156  6.99410853], Loss = 904.6786\n",
      "Iteration 64: Weights = [26.09219319  2.51261175  6.19712283  1.73116244  0.35632875  7.04926877], Loss = 886.1787\n",
      "Iteration 65: Weights = [26.38127125  2.53442176  6.2433131   1.73423118  0.35623037  7.10337171], Loss = 868.0691\n",
      "Iteration 66: Weights = [26.66745854  2.55588774  6.28857645  1.73692237  0.35605929  7.15643893], Loss = 850.3411\n",
      "Iteration 67: Weights = [26.95078396  2.57701578  6.33293216  1.7392466   0.3558183   7.20849154], Loss = 832.9860\n",
      "Iteration 68: Weights = [27.23127612  2.59781188  6.3763991   1.74121421  0.35551012  7.25955021], Loss = 815.9958\n",
      "Iteration 69: Weights = [27.50896336  2.6182819   6.41899573  1.74283532  0.35513738  7.30963518], Loss = 799.3623\n",
      "Iteration 70: Weights = [27.78387372  2.63843161  6.46074015  1.74411978  0.35470267  7.35876627], Loss = 783.0775\n",
      "Iteration 71: Weights = [28.05603498  2.65826665  6.50165004  1.74507725  0.35420846  7.40696288], Loss = 767.1338\n",
      "Iteration 72: Weights = [28.32547463  2.67779257  6.54174272  1.74571712  0.3536572   7.454244  ], Loss = 751.5237\n",
      "Iteration 73: Weights = [28.59221989  2.6970148   6.58103516  1.7460486   0.35305125  7.50062825], Loss = 736.2398\n",
      "Iteration 74: Weights = [28.85629769  2.71593867  6.61954395  1.74608065  0.3523929   7.54613382], Loss = 721.2750\n",
      "Iteration 75: Weights = [29.11773471  2.73456942  6.65728534  1.74582204  0.35168438  7.59077856], Loss = 706.6223\n",
      "Iteration 76: Weights = [29.37655737  2.75291217  6.69427523  1.74528132  0.35092786  7.63457992], Loss = 692.2749\n",
      "Iteration 77: Weights = [29.63279179  2.77097195  6.7305292   1.74446685  0.35012545  7.67755499], Loss = 678.2261\n",
      "Iteration 78: Weights = [29.88646387  2.78875371  6.76606248  1.74338678  0.3492792   7.71972051], Loss = 664.4693\n",
      "Iteration 79: Weights = [30.13759924  2.80626228  6.80088999  1.74204907  0.3483911   7.76109288], Loss = 650.9984\n",
      "Iteration 80: Weights = [30.38622324  2.82350242  6.83502634  1.74046149  0.34746308  7.80168813], Loss = 637.8070\n",
      "Iteration 81: Weights = [30.63236101  2.84047878  6.86848581  1.73863164  0.34649702  7.84152198], Loss = 624.8890\n",
      "Iteration 82: Weights = [30.8760374   2.85719595  6.90128241  1.73656692  0.34549475  7.88060981], Loss = 612.2387\n",
      "Iteration 83: Weights = [31.11727703  2.8736584   6.93342983  1.73427456  0.34445803  7.9189667 ], Loss = 599.8501\n",
      "Iteration 84: Weights = [31.35610426  2.88987054  6.96494148  1.73176162  0.34338858  7.95660738], Loss = 587.7178\n",
      "Iteration 85: Weights = [31.59254321  2.90583668  6.99583049  1.72903499  0.34228809  7.9935463 ], Loss = 575.8360\n",
      "Iteration 86: Weights = [31.82661778  2.92156106  7.02610971  1.72610138  0.34115816  8.0297976 ], Loss = 564.1996\n",
      "Iteration 87: Weights = [32.0583516   2.93704785  7.05579171  1.72296737  0.34000037  8.06537513], Loss = 552.8031\n",
      "Iteration 88: Weights = [32.28776809  2.95230111  7.08488881  1.71963935  0.33881625  8.10029246], Loss = 541.6416\n",
      "Iteration 89: Weights = [32.51489041  2.96732485  7.11341307  1.71612358  0.33760728  8.13456285], Loss = 530.7098\n",
      "Iteration 90: Weights = [32.7397415   2.982123    7.14137627  1.71242615  0.3363749   8.16819931], Loss = 520.0030\n",
      "Iteration 91: Weights = [32.96234409  2.99669941  7.16878999  1.70855302  0.33512049  8.20121457], Loss = 509.5163\n",
      "Iteration 92: Weights = [33.18272065  3.01105785  7.19566552  1.70450998  0.33384543  8.23362109], Loss = 499.2451\n",
      "Iteration 93: Weights = [33.40089344  3.02520205  7.22201393  1.70030271  0.332551    8.2654311 ], Loss = 489.1848\n",
      "Iteration 94: Weights = [33.61688451  3.03913564  7.24784606  1.69593674  0.33123849  8.29665652], Loss = 479.3309\n",
      "Iteration 95: Weights = [33.83071566  3.05286219  7.27317253  1.69141745  0.32990914  8.32730909], Loss = 469.6789\n",
      "Iteration 96: Weights = [34.0424085   3.06638521  7.29800371  1.68675011  0.32856412  8.35740025], Loss = 460.2248\n",
      "Iteration 97: Weights = [34.25198442  3.07970814  7.32234977  1.68193984  0.3272046   8.38694123], Loss = 450.9642\n",
      "Iteration 98: Weights = [34.45946458  3.09283436  7.34622067  1.67699167  0.32583171  8.41594302], Loss = 441.8931\n",
      "Iteration 99: Weights = [34.66486993  3.10576717  7.36962615  1.67191046  0.32444652  8.4444164 ], Loss = 433.0074\n",
      "Iteration 100: Weights = [34.86822123  3.11850985  7.39257574  1.66670098  0.32305009  8.47237189], Loss = 424.3033\n",
      "Iteration 101: Weights = [35.06953902  3.13106556  7.4150788   1.66136788  0.32164344  8.49981983], Loss = 415.7770\n",
      "Iteration 102: Weights = [35.26884363  3.14343746  7.43714445  1.65591569  0.32022756  8.52677031], Loss = 407.4247\n",
      "Iteration 103: Weights = [35.46615519  3.15562861  7.45878165  1.65034882  0.31880339  8.55323325], Loss = 399.2428\n",
      "Iteration 104: Weights = [35.66149364  3.16764203  7.47999917  1.64467159  0.31737186  8.57921833], Loss = 391.2277\n",
      "Iteration 105: Weights = [35.8548787   3.17948068  7.50080557  1.63888818  0.31593386  8.60473505], Loss = 383.3758\n",
      "Iteration 106: Weights = [36.04632992  3.19114747  7.52120927  1.63300271  0.31449026  8.62979271], Loss = 375.6839\n",
      "Iteration 107: Weights = [36.23586662  3.20264526  7.54121847  1.62701916  0.31304189  8.65440042], Loss = 368.1485\n",
      "Iteration 108: Weights = [36.42350795  3.21397685  7.56084122  1.62094142  0.31158956  8.67856708], Loss = 360.7664\n",
      "Iteration 109: Weights = [36.60927287  3.22514498  7.58008542  1.61477329  0.31013405  8.70230144], Loss = 353.5344\n",
      "Iteration 110: Weights = [36.79318014  3.23615236  7.59895877  1.60851847  0.30867612  8.72561204], Loss = 346.4493\n",
      "Iteration 111: Weights = [36.97524834  3.24700164  7.61746882  1.60218056  0.30721648  8.74850727], Loss = 339.5081\n",
      "Iteration 112: Weights = [37.15549586  3.25769542  7.63562297  1.59576308  0.30575584  8.77099533], Loss = 332.7078\n",
      "Iteration 113: Weights = [37.3339409   3.26823625  7.65342846  1.58926945  0.30429488  8.79308424], Loss = 326.0455\n",
      "Iteration 114: Weights = [37.51060149  3.27862664  7.67089238  1.58270301  0.30283426  8.81478189], Loss = 319.5184\n",
      "Iteration 115: Weights = [37.68549548  3.28886906  7.68802166  1.57606701  0.30137461  8.83609597], Loss = 313.1235\n",
      "Iteration 116: Weights = [37.85864052  3.29896592  7.70482311  1.56936462  0.29991653  8.85703404], Loss = 306.8582\n",
      "Iteration 117: Weights = [38.03005412  3.30891959  7.72130336  1.56259893  0.29846061  8.87760348], Loss = 300.7198\n",
      "Iteration 118: Weights = [38.19975357  3.3187324   7.73746894  1.55577294  0.29700741  8.89781154], Loss = 294.7057\n",
      "Iteration 119: Weights = [38.36775604  3.32840664  7.75332622  1.54888957  0.29555749  8.91766531], Loss = 288.8133\n",
      "Iteration 120: Weights = [38.53407848  3.33794456  7.76888144  1.5419517   0.29411136  8.93717173], Loss = 283.0401\n",
      "Iteration 121: Weights = [38.69873769  3.34734837  7.78414071  1.53496209  0.29266953  8.9563376 ], Loss = 277.3836\n",
      "Iteration 122: Weights = [38.86175032  3.35662022  7.79911002  1.52792345  0.29123249  8.9751696 ], Loss = 271.8415\n",
      "Iteration 123: Weights = [39.02313281  3.36576225  7.81379523  1.52083841  0.2898007   8.99367424], Loss = 266.4113\n",
      "Iteration 124: Weights = [39.18290148  3.37477655  7.82820207  1.51370954  0.2883746   9.01185792], Loss = 261.0908\n",
      "Iteration 125: Weights = [39.34107247  3.38366516  7.84233617  1.50653934  0.28695464  9.0297269 ], Loss = 255.8777\n",
      "Iteration 126: Weights = [39.49766175  3.3924301   7.85620301  1.49933025  0.28554122  9.04728731], Loss = 250.7698\n",
      "Iteration 127: Weights = [39.65268513  3.40107335  7.86980798  1.49208462  0.28413474  9.06454516], Loss = 245.7650\n",
      "Iteration 128: Weights = [39.80615828  3.40959685  7.88315637  1.48480476  0.28273558  9.08150633], Loss = 240.8611\n",
      "Iteration 129: Weights = [39.95809669  3.4180025   7.89625331  1.47749292  0.28134411  9.09817659], Loss = 236.0560\n",
      "Iteration 130: Weights = [40.10851573  3.42629219  7.90910389  1.47015127  0.27996067  9.11456157], Loss = 231.3478\n",
      "Iteration 131: Weights = [40.25743057  3.43446775  7.92171303  1.46278195  0.2785856   9.13066682], Loss = 226.7345\n",
      "Iteration 132: Weights = [40.40485626  3.44253099  7.93408559  1.45538701  0.27721922  9.14649775], Loss = 222.2141\n",
      "Iteration 133: Weights = [40.5508077   3.45048368  7.94622631  1.44796846  0.27586183  9.16205966], Loss = 217.7847\n",
      "Iteration 134: Weights = [40.69529962  3.45832757  7.95813984  1.44052826  0.27451373  9.17735775], Loss = 213.4444\n",
      "Iteration 135: Weights = [40.83834663  3.46606438  7.96983073  1.43306831  0.27317519  9.19239711], Loss = 209.1915\n",
      "Iteration 136: Weights = [40.97996316  3.47369578  7.98130343  1.42559046  0.27184649  9.20718274], Loss = 205.0242\n",
      "Iteration 137: Weights = [41.12016353  3.48122342  7.9925623   1.4180965   0.27052786  9.22171952], Loss = 200.9406\n",
      "Iteration 138: Weights = [41.25896189  3.48864894  8.00361161  1.41058818  0.26921956  9.23601223], Loss = 196.9392\n",
      "Iteration 139: Weights = [41.39637228  3.49597392  8.01445555  1.40306721  0.26792181  9.25006556], Loss = 193.0182\n",
      "Iteration 140: Weights = [41.53240855  3.50319993  8.02509821  1.39553522  0.26663484  9.26388411], Loss = 189.1760\n",
      "Iteration 141: Weights = [41.66708447  3.51032852  8.0355436   1.38799383  0.26535883  9.27747237], Loss = 185.4109\n",
      "Iteration 142: Weights = [41.80041362  3.51736119  8.04579565  1.3804446   0.264094    9.29083476], Loss = 181.7215\n",
      "Iteration 143: Weights = [41.93240949  3.52429943  8.0558582   1.37288903  0.26284052  9.30397559], Loss = 178.1062\n",
      "Iteration 144: Weights = [42.06308539  3.53114469  8.06573502  1.3653286   0.26159856  9.3168991 ], Loss = 174.5634\n",
      "Iteration 145: Weights = [42.19245454  3.53789843  8.07542979  1.35776474  0.2603683   9.32960943], Loss = 171.0917\n",
      "Iteration 146: Weights = [42.32052999  3.54456203  8.08494613  1.35019883  0.25914989  9.34211064], Loss = 167.6897\n",
      "Iteration 147: Weights = [42.44732469  3.5511369   8.09428756  1.34263223  0.25794346  9.35440672], Loss = 164.3559\n",
      "Iteration 148: Weights = [42.57285145  3.55762438  8.10345757  1.33506623  0.25674917  9.36650155], Loss = 161.0890\n",
      "Iteration 149: Weights = [42.69712293  3.56402582  8.11245952  1.32750211  0.25556713  9.37839896], Loss = 157.8876\n",
      "Iteration 150: Weights = [42.8201517   3.57034253  8.12129675  1.31994111  0.25439746  9.39010269], Loss = 154.7504\n",
      "Iteration 151: Weights = [42.94195018  3.5765758   8.12997251  1.3123844   0.25324027  9.4016164 ], Loss = 151.6760\n",
      "Iteration 152: Weights = [43.06253068  3.5827269   8.13848997  1.30483316  0.25209566  9.41294369], Loss = 148.6632\n",
      "Iteration 153: Weights = [43.18190538  3.58879708  8.14685227  1.2972885   0.25096374  9.42408809], Loss = 145.7108\n",
      "Iteration 154: Weights = [43.30008632  3.59478755  8.15506244  1.28975152  0.24984457  9.43505302], Loss = 142.8176\n",
      "Iteration 155: Weights = [43.41708546  3.60069954  8.1631235   1.28222327  0.24873826  9.44584189], Loss = 139.9823\n",
      "Iteration 156: Weights = [43.5329146   3.60653421  8.17103835  1.27470478  0.24764485  9.45645798], Loss = 137.2037\n",
      "Iteration 157: Weights = [43.64758546  3.61229274  8.17880987  1.26719704  0.24656443  9.46690456], Loss = 134.4808\n",
      "Iteration 158: Weights = [43.7611096   3.61797626  8.18644088  1.25970101  0.24549705  9.4771848 ], Loss = 131.8123\n",
      "Iteration 159: Weights = [43.87349851  3.6235859   8.19393412  1.25221762  0.24444276  9.48730181], Loss = 129.1973\n",
      "Iteration 160: Weights = [43.98476352  3.62912277  8.20129228  1.24474777  0.2434016   9.49725865], Loss = 126.6346\n",
      "Iteration 161: Weights = [44.09491589  3.63458795  8.20851801  1.23729234  0.24237362  9.5070583 ], Loss = 124.1231\n",
      "Iteration 162: Weights = [44.20396673  3.63998251  8.21561389  1.22985216  0.24135885  9.51670371], Loss = 121.6619\n",
      "Iteration 163: Weights = [44.31192706  3.6453075   8.22258245  1.22242806  0.24035732  9.52619773], Loss = 119.2499\n",
      "Iteration 164: Weights = [44.41880779  3.65056395  8.22942617  1.21502083  0.23936904  9.53554318], Loss = 116.8861\n",
      "Iteration 165: Weights = [44.52461971  3.65575286  8.23614748  1.20763123  0.23839405  9.54474282], Loss = 114.5695\n",
      "Iteration 166: Weights = [44.62937352  3.66087525  8.24274876  1.20026     0.23743234  9.55379936], Loss = 112.2993\n",
      "Iteration 167: Weights = [44.73307978  3.66593209  8.24923234  1.19290785  0.23648393  9.56271545], Loss = 110.0744\n",
      "Iteration 168: Weights = [44.83574898  3.67092435  8.2556005   1.18557548  0.23554882  9.57149367], Loss = 107.8940\n",
      "Iteration 169: Weights = [44.93739149  3.67585296  8.26185547  1.17826355  0.234627    9.58013657], Loss = 105.7572\n",
      "Iteration 170: Weights = [45.03801758  3.68071887  8.26799944  1.17097269  0.23371848  9.58864665], Loss = 103.6630\n",
      "Iteration 171: Weights = [45.1376374   3.68552299  8.27403456  1.16370354  0.23282323  9.59702635], Loss = 101.6107\n",
      "Iteration 172: Weights = [45.23626103  3.69026622  8.27996292  1.15645669  0.23194124  9.60527806], Loss = 99.5993\n",
      "Iteration 173: Weights = [45.33389842  3.69494944  8.28578659  1.14923272  0.2310725   9.61340413], Loss = 97.6281\n",
      "Iteration 174: Weights = [45.43055943  3.69957353  8.29150758  1.14203219  0.23021698  9.62140686], Loss = 95.6963\n",
      "Iteration 175: Weights = [45.52625384  3.70413934  8.29712786  1.13485562  0.22937465  9.62928851], Loss = 93.8030\n",
      "Iteration 176: Weights = [45.6209913   3.70864772  8.30264936  1.12770354  0.22854548  9.63705128], Loss = 91.9475\n",
      "Iteration 177: Weights = [45.71478139  3.71309949  8.30807398  1.12057644  0.22772944  9.64469734], Loss = 90.1291\n",
      "Iteration 178: Weights = [45.80763357  3.71749546  8.31340358  1.11347481  0.2269265   9.65222881], Loss = 88.3469\n",
      "Iteration 179: Weights = [45.89955724  3.72183644  8.31863997  1.10639909  0.2261366   9.65964778], Loss = 86.6003\n",
      "Iteration 180: Weights = [45.99056167  3.72612322  8.32378493  1.09934973  0.22535971  9.66695628], Loss = 84.8885\n",
      "Iteration 181: Weights = [46.08065605  3.73035657  8.32884021  1.09232716  0.22459578  9.67415631], Loss = 83.2109\n",
      "Iteration 182: Weights = [46.16984949  3.73453725  8.33380751  1.08533178  0.22384476  9.68124984], Loss = 81.5667\n",
      "Iteration 183: Weights = [46.25815099  3.73866602  8.3386885   1.07836398  0.22310659  9.68823878], Loss = 79.9554\n",
      "Iteration 184: Weights = [46.34556948  3.7427436   8.34348483  1.07142414  0.22238123  9.69512501], Loss = 78.3761\n",
      "Iteration 185: Weights = [46.43211379  3.74677073  8.34819811  1.06451261  0.22166862  9.70191039], Loss = 76.8284\n",
      "Iteration 186: Weights = [46.51779265  3.75074812  8.35282989  1.05762974  0.22096869  9.70859672], Loss = 75.3115\n",
      "Iteration 187: Weights = [46.60261472  3.75467647  8.35738174  1.05077585  0.22028139  9.71518577], Loss = 73.8248\n",
      "Iteration 188: Weights = [46.68658858  3.75855647  8.36185515  1.04395126  0.21960664  9.72167929], Loss = 72.3678\n",
      "Iteration 189: Weights = [46.76972269  3.7623888   8.36625161  1.03715626  0.21894438  9.72807898], Loss = 70.9398\n",
      "Iteration 190: Weights = [46.85202546  3.76617413  8.37057256  1.03039115  0.21829455  9.73438651], Loss = 69.5403\n",
      "Iteration 191: Weights = [46.93350521  3.76991311  8.37481943  1.02365619  0.21765707  9.74060352], Loss = 68.1686\n",
      "Iteration 192: Weights = [47.01417016  3.77360639  8.3789936   1.01695164  0.21703187  9.74673162], Loss = 66.8243\n",
      "Iteration 193: Weights = [47.09402846  3.77725462  8.38309645  1.01027775  0.21641888  9.75277237], Loss = 65.5068\n",
      "Iteration 194: Weights = [47.17308817  3.78085841  8.38712929  1.00363475  0.21581802  9.75872734], Loss = 64.2155\n",
      "Iteration 195: Weights = [47.25135729  3.78441838  8.39109346  0.99702286  0.21522921  9.76459802], Loss = 62.9499\n",
      "Iteration 196: Weights = [47.32884372  3.78793514  8.39499021  0.99044229  0.21465237  9.7703859 ], Loss = 61.7096\n",
      "Iteration 197: Weights = [47.40555528  3.79140928  8.39882082  0.98389324  0.21408742  9.77609245], Loss = 60.4939\n",
      "Iteration 198: Weights = [47.48149973  3.79484139  8.40258651  0.97737589  0.21353429  9.78171908], Loss = 59.3025\n",
      "Iteration 199: Weights = [47.55668473  3.79823205  8.40628849  0.97089042  0.21299288  9.7872672 ], Loss = 58.1348\n",
      "Iteration 200: Weights = [47.63111788  3.80158183  8.40992794  0.964437    0.21246312  9.79273818], Loss = 56.9903\n",
      "Iteration 201: Weights = [47.7048067   3.80489129  8.41350602  0.95801577  0.21194491  9.79813337], Loss = 55.8686\n",
      "Iteration 202: Weights = [47.77775864  3.80816097  8.41702386  0.95162689  0.21143818  9.80345407], Loss = 54.7693\n",
      "Iteration 203: Weights = [47.84998105  3.81139143  8.42048257  0.94527049  0.21094282  9.8087016 ], Loss = 53.6918\n",
      "Iteration 204: Weights = [47.92148124  3.81458318  8.42388325  0.93894669  0.21045877  9.81387722], Loss = 52.6358\n",
      "Iteration 205: Weights = [47.99226643  3.81773677  8.42722696  0.93265561  0.20998591  9.81898216], Loss = 51.6008\n",
      "Iteration 206: Weights = [48.06234376  3.8208527   8.43051475  0.92639735  0.20952417  9.82401766], Loss = 50.5863\n",
      "Iteration 207: Weights = [48.13172033  3.82393148  8.43374764  0.92017202  0.20907345  9.82898491], Loss = 49.5921\n",
      "Iteration 208: Weights = [48.20040312  3.82697362  8.43692664  0.9139797   0.20863365  9.83388508], Loss = 48.6177\n",
      "Iteration 209: Weights = [48.26839909  3.8299796   8.44005274  0.90782047  0.2082047   9.83871932], Loss = 47.6626\n",
      "Iteration 210: Weights = [48.3357151   3.83294991  8.44312689  0.90169442  0.20778649  9.84348877], Loss = 46.7266\n",
      "Iteration 211: Weights = [48.40235795  3.83588504  8.44615004  0.89560159  0.20737893  9.84819453], Loss = 45.8092\n",
      "Iteration 212: Weights = [48.46833437  3.83878545  8.44912312  0.88954206  0.20698192  9.85283769], Loss = 44.9100\n",
      "Iteration 213: Weights = [48.53365103  3.8416516   8.45204704  0.88351586  0.20659537  9.85741931], Loss = 44.0287\n",
      "Iteration 214: Weights = [48.59831452  3.84448394  8.4549227   0.87752305  0.20621918  9.86194043], Loss = 43.1649\n",
      "Iteration 215: Weights = [48.66233137  3.84728294  8.45775095  0.87156366  0.20585326  9.86640209], Loss = 42.3184\n",
      "Iteration 216: Weights = [48.72570806  3.85004902  8.46053266  0.86563771  0.20549751  9.87080529], Loss = 41.4886\n",
      "Iteration 217: Weights = [48.78845098  3.85278263  8.46326866  0.85974524  0.20515184  9.87515101], Loss = 40.6754\n",
      "Iteration 218: Weights = [48.85056647  3.8554842   8.46595978  0.85388626  0.20481614  9.87944022], Loss = 39.8783\n",
      "Iteration 219: Weights = [48.9120608   3.85815413  8.46860682  0.84806077  0.20449032  9.88367387], Loss = 39.0971\n",
      "Iteration 220: Weights = [48.97294019  3.86079286  8.47121058  0.84226879  0.20417429  9.8878529 ], Loss = 38.3314\n",
      "Iteration 221: Weights = [49.03321079  3.86340079  8.47377181  0.8365103   0.20386794  9.89197821], Loss = 37.5809\n",
      "Iteration 222: Weights = [49.09287868  3.86597831  8.47629129  0.83078531  0.20357117  9.8960507 ], Loss = 36.8454\n",
      "Iteration 223: Weights = [49.1519499   3.86852584  8.47876976  0.82509379  0.20328389  9.90007125], Loss = 36.1245\n",
      "Iteration 224: Weights = [49.2104304   3.87104376  8.48120795  0.81943574  0.20300601  9.90404073], Loss = 35.4179\n",
      "Iteration 225: Weights = [49.26832609  3.87353245  8.48360656  0.81381112  0.20273741  9.90795997], Loss = 34.7253\n",
      "Iteration 226: Weights = [49.32564283  3.87599229  8.4859663   0.80821991  0.20247801  9.91182982], Loss = 34.0466\n",
      "Iteration 227: Weights = [49.38238641  3.87842366  8.48828786  0.80266207  0.20222771  9.91565108], Loss = 33.3813\n",
      "Iteration 228: Weights = [49.43856254  3.88082692  8.49057191  0.79713757  0.20198641  9.91942455], Loss = 32.7292\n",
      "Iteration 229: Weights = [49.49417692  3.88320244  8.49281911  0.79164637  0.201754    9.92315102], Loss = 32.0901\n",
      "Iteration 230: Weights = [49.54923515  3.88555057  8.49503011  0.7861884   0.2015304   9.92683126], Loss = 31.4637\n",
      "Iteration 231: Weights = [49.60374279  3.88787167  8.49720554  0.78076364  0.2013155   9.93046602], Loss = 30.8497\n",
      "Iteration 232: Weights = [49.65770537  3.89016607  8.49934602  0.77537201  0.20110921  9.93405605], Loss = 30.2480\n",
      "Iteration 233: Weights = [49.71112831  3.89243413  8.50145216  0.77001346  0.20091143  9.93760207], Loss = 29.6582\n",
      "Iteration 234: Weights = [49.76401703  3.89467617  8.50352456  0.76468792  0.20072207  9.94110479], Loss = 29.0801\n",
      "Iteration 235: Weights = [49.81637686  3.89689253  8.50556381  0.75939533  0.20054101  9.94456492], Loss = 28.5135\n",
      "Iteration 236: Weights = [49.86821309  3.89908354  8.50757048  0.75413562  0.20036818  9.94798314], Loss = 27.9582\n",
      "Iteration 237: Weights = [49.91953096  3.90124951  8.50954514  0.74890871  0.20020347  9.95136013], Loss = 27.4139\n",
      "Iteration 238: Weights = [49.97033565  3.90339076  8.51148833  0.74371451  0.20004679  9.95469655], Loss = 26.8804\n",
      "Iteration 239: Weights = [50.02063229  3.9055076   8.5134006   0.73855296  0.19989804  9.95799305], Loss = 26.3575\n",
      "Iteration 240: Weights = [50.07042597  3.90760035  8.51528248  0.73342397  0.19975712  9.96125027], Loss = 25.8449\n",
      "Iteration 241: Weights = [50.11972171  3.9096693   8.51713449  0.72832745  0.19962395  9.96446883], Loss = 25.3426\n",
      "Iteration 242: Weights = [50.16852449  3.91171475  8.51895715  0.7232633   0.19949842  9.96764935], Loss = 24.8503\n",
      "Iteration 243: Weights = [50.21683925  3.91373699  8.52075094  0.71823143  0.19938044  9.97079243], Loss = 24.3677\n",
      "Iteration 244: Weights = [50.26467086  3.91573632  8.52251637  0.71323176  0.19926992  9.97389867], Loss = 23.8947\n",
      "Iteration 245: Weights = [50.31202415  3.91771302  8.52425392  0.70826417  0.19916676  9.97696864], Loss = 23.4311\n",
      "Iteration 246: Weights = [50.35890391  3.91966737  8.52596406  0.70332857  0.19907087  9.98000292], Loss = 22.9767\n",
      "Iteration 247: Weights = [50.40531487  3.92159965  8.52764725  0.69842485  0.19898216  9.98300207], Loss = 22.5313\n",
      "Iteration 248: Weights = [50.45126172  3.92351014  8.52930394  0.6935529   0.19890054  9.98596663], Loss = 22.0948\n",
      "Iteration 249: Weights = [50.4967491   3.92539909  8.53093459  0.68871263  0.19882591  9.98889715], Loss = 21.6669\n",
      "Iteration 250: Weights = [50.54178161  3.92726678  8.53253963  0.68390391  0.19875818  9.99179416], Loss = 21.2475\n",
      "Iteration 251: Weights = [50.58636379  3.92911348  8.53411949  0.67912663  0.19869726  9.99465817], Loss = 20.8365\n",
      "Iteration 252: Weights = [50.63050016  3.93093942  8.53567459  0.67438067  0.19864307  9.99748971], Loss = 20.4336\n",
      "Iteration 253: Weights = [50.67419516  3.93274488  8.53720534  0.66966593  0.1985955  10.00028926], Loss = 20.0387\n",
      "Iteration 254: Weights = [50.7174532   3.9345301   8.53871215  0.66498228  0.19855448 10.00305733], Loss = 19.6517\n",
      "Iteration 255: Weights = [50.76027867  3.93629533  8.54019541  0.6603296   0.19851991 10.00579439], Loss = 19.2723\n",
      "Iteration 256: Weights = [50.80267589  3.93804081  8.54165552  0.65570776  0.19849171 10.00850093], Loss = 18.9005\n",
      "Iteration 257: Weights = [50.84464913  3.93976678  8.54309285  0.65111665  0.19846978 10.01117741], Loss = 18.5360\n",
      "Iteration 258: Weights = [50.88620264  3.94147348  8.54450779  0.64655613  0.19845405 10.01382428], Loss = 18.1788\n",
      "Iteration 259: Weights = [50.92734061  3.94316114  8.54590069  0.64202608  0.19844442 10.01644201], Loss = 17.8287\n",
      "Iteration 260: Weights = [50.9680672   3.94482999  8.54727193  0.63752637  0.1984408  10.01903102], Loss = 17.4855\n",
      "Iteration 261: Weights = [51.00838653  3.94648026  8.54862185  0.63305686  0.19844312 10.02159176], Loss = 17.1492\n",
      "Iteration 262: Weights = [51.04830267  3.94811218  8.5499508   0.62861744  0.19845129 10.02412464], Loss = 16.8195\n",
      "Iteration 263: Weights = [51.08781964  3.94972595  8.55125913  0.62420796  0.19846522 10.0266301 ], Loss = 16.4963\n",
      "Iteration 264: Weights = [51.12694144  3.95132181  8.55254716  0.61982829  0.19848483 10.02910854], Loss = 16.1796\n",
      "Iteration 265: Weights = [51.16567203  3.95289996  8.55381523  0.61547829  0.19851004 10.03156036], Loss = 15.8691\n",
      "Iteration 266: Weights = [51.20401531  3.95446061  8.55506365  0.61115783  0.19854076 10.03398597], Loss = 15.5648\n",
      "Iteration 267: Weights = [51.24197515  3.95600398  8.55629275  0.60686678  0.19857692 10.03638574], Loss = 15.2666\n",
      "Iteration 268: Weights = [51.2795554   3.95753027  8.55750283  0.60260498  0.19861843 10.03876008], Loss = 14.9742\n",
      "Iteration 269: Weights = [51.31675985  3.95903969  8.5586942   0.59837231  0.1986652  10.04110934], Loss = 14.6877\n",
      "Iteration 270: Weights = [51.35359225  3.96053242  8.55986716  0.59416861  0.19871717 10.0434339 ], Loss = 14.4068\n",
      "Iteration 271: Weights = [51.39005633  3.96200867  8.561022    0.58999376  0.19877425 10.04573413], Loss = 14.1316\n",
      "Iteration 272: Weights = [51.42615576  3.96346864  8.562159    0.58584761  0.19883637 10.04801038], Loss = 13.8617\n",
      "Iteration 273: Weights = [51.46189421  3.96491251  8.56327846  0.58173001  0.19890344 10.050263  ], Loss = 13.5973\n",
      "Iteration 274: Weights = [51.49727526  3.96634048  8.56438064  0.57764083  0.19897539 10.05249234], Loss = 13.3380\n",
      "Iteration 275: Weights = [51.53230251  3.96775273  8.56546582  0.57357991  0.19905214 10.05469873], Loss = 13.0840\n",
      "Iteration 276: Weights = [51.56697949  3.96914945  8.56653426  0.56954712  0.19913361 10.05688251], Loss = 12.8349\n",
      "Iteration 277: Weights = [51.60130969  3.97053081  8.56758624  0.5655423   0.19921974 10.05904401], Loss = 12.5908\n",
      "Iteration 278: Weights = [51.6352966   3.971897    8.568622    0.56156532  0.19931044 10.06118354], Loss = 12.3516\n",
      "Iteration 279: Weights = [51.66894363  3.97324819  8.5696418   0.55761603  0.19940564 10.06330142], Loss = 12.1170\n",
      "Iteration 280: Weights = [51.70225419  3.97458455  8.57064588  0.55369428  0.19950527 10.06539797], Loss = 11.8872\n",
      "Iteration 281: Weights = [51.73523165  3.97590627  8.57163449  0.54979992  0.19960925 10.06747348], Loss = 11.6619\n",
      "Iteration 282: Weights = [51.76787933  3.97721351  8.57260787  0.5459328   0.19971751 10.06952826], Loss = 11.4410\n",
      "Iteration 283: Weights = [51.80020054  3.97850643  8.57356625  0.54209278  0.19982999 10.0715626 ], Loss = 11.2246\n",
      "Iteration 284: Weights = [51.83219854  3.9797852   8.57450987  0.53827972  0.19994661 10.07357679], Loss = 11.0124\n",
      "Iteration 285: Weights = [51.86387655  3.98104998  8.57543894  0.53449345  0.20006729 10.07557112], Loss = 10.8044\n",
      "Iteration 286: Weights = [51.89523779  3.98230094  8.57635369  0.53073384  0.20019198 10.07754586], Loss = 10.6006\n",
      "Iteration 287: Weights = [51.92628541  3.98353823  8.57725435  0.52700073  0.2003206  10.07950129], Loss = 10.4008\n",
      "Iteration 288: Weights = [51.95702255  3.98476201  8.57814111  0.52329398  0.20045308 10.08143769], Loss = 10.2050\n",
      "Iteration 289: Weights = [51.98745233  3.98597244  8.5790142   0.51961344  0.20058936 10.08335531], Loss = 10.0130\n",
      "Iteration 290: Weights = [52.0175778   3.98716966  8.57987382  0.51595895  0.20072936 10.08525442], Loss = 9.8249\n",
      "Iteration 291: Weights = [52.04740203  3.98835382  8.58072017  0.51233038  0.20087303 10.08713527], Loss = 9.6405\n",
      "Iteration 292: Weights = [52.07692801  3.98952508  8.58155345  0.50872756  0.2010203  10.08899812], Loss = 9.4597\n",
      "Iteration 293: Weights = [52.10615873  3.99068358  8.58237386  0.50515035  0.2011711  10.09084322], Loss = 9.2825\n",
      "Iteration 294: Weights = [52.13509714  3.99182947  8.58318159  0.50159861  0.20132536 10.09267081], Loss = 9.1089\n",
      "Iteration 295: Weights = [52.16374617  3.99296288  8.58397683  0.49807217  0.20148303 10.09448113], Loss = 8.9386\n",
      "Iteration 296: Weights = [52.19210871  3.99408397  8.58475975  0.4945709   0.20164404 10.09627442], Loss = 8.7718\n",
      "Iteration 297: Weights = [52.22018762  3.99519286  8.58553056  0.49109465  0.20180833 10.0980509 ], Loss = 8.6082\n",
      "Iteration 298: Weights = [52.24798574  3.99628969  8.58628941  0.48764326  0.20197583 10.09981081], Loss = 8.4479\n",
      "Iteration 299: Weights = [52.27550588  3.99737461  8.5870365   0.48421658  0.20214649 10.10155438], Loss = 8.2908\n",
      "Iteration 300: Weights = [52.30275083  3.99844773  8.58777198  0.48081448  0.20232025 10.10328182], Loss = 8.1368\n",
      "Iteration 301: Weights = [52.32972332  3.99950921  8.58849604  0.47743679  0.20249704 10.10499335], Loss = 7.9858\n",
      "Iteration 302: Weights = [52.35642608  4.00055915  8.58920883  0.47408338  0.2026768  10.10668918], Loss = 7.8379\n",
      "Iteration 303: Weights = [52.38286182  4.0015977   8.58991052  0.47075409  0.20285949 10.10836953], Loss = 7.6928\n",
      "Iteration 304: Weights = [52.40903321  4.00262498  8.59060128  0.46744877  0.20304503 10.1100346 ], Loss = 7.5507\n",
      "Iteration 305: Weights = [52.43494287  4.00364112  8.59128125  0.46416729  0.20323337 10.11168459], Loss = 7.4113\n",
      "Iteration 306: Weights = [52.46059344  4.00464623  8.5919506   0.46090948  0.20342446 10.11331971], Loss = 7.2748\n",
      "Iteration 307: Weights = [52.48598751  4.00564045  8.59260948  0.45767521  0.20361824 10.11494016], Loss = 7.1409\n",
      "Iteration 308: Weights = [52.51112764  4.00662388  8.59325803  0.45446433  0.20381466 10.11654611], Loss = 7.0097\n",
      "Iteration 309: Weights = [52.53601636  4.00759666  8.59389641  0.45127668  0.20401365 10.11813778], Loss = 6.8810\n",
      "Iteration 310: Weights = [52.5606562   4.00855889  8.59452475  0.44811214  0.20421517 10.11971533], Loss = 6.7550\n",
      "Iteration 311: Weights = [52.58504963  4.00951069  8.5951432   0.44497054  0.20441915 10.12127897], Loss = 6.6314\n",
      "Iteration 312: Weights = [52.60919914  4.01045218  8.59575191  0.44185175  0.20462556 10.12282887], Loss = 6.5102\n",
      "Iteration 313: Weights = [52.63310715  4.01138348  8.596351    0.43875561  0.20483433 10.1243652 ], Loss = 6.3915\n",
      "Iteration 314: Weights = [52.65677607  4.01230468  8.59694061  0.435682    0.20504542 10.12588815], Loss = 6.2751\n",
      "Iteration 315: Weights = [52.68020831  4.0132159   8.59752088  0.43263075  0.20525876 10.12739789], Loss = 6.1611\n",
      "Iteration 316: Weights = [52.70340623  4.01411726  8.59809194  0.42960173  0.20547432 10.12889458], Loss = 6.0492\n",
      "Iteration 317: Weights = [52.72637217  4.01500885  8.5986539   0.4265948   0.20569204 10.1303784 ], Loss = 5.9396\n",
      "Iteration 318: Weights = [52.74910845  4.01589079  8.59920691  0.42360981  0.20591188 10.13184951], Loss = 5.8322\n",
      "Iteration 319: Weights = [52.77161736  4.01676317  8.59975108  0.42064661  0.20613377 10.13330807], Loss = 5.7269\n",
      "Iteration 320: Weights = [52.79390119  4.01762611  8.60028653  0.41770508  0.20635769 10.13475425], Loss = 5.6237\n",
      "Iteration 321: Weights = [52.81596218  4.0184797   8.60081339  0.41478506  0.20658356 10.13618819], Loss = 5.5225\n",
      "Iteration 322: Weights = [52.83780255  4.01932404  8.60133177  0.41188641  0.20681136 10.13761006], Loss = 5.4234\n",
      "Iteration 323: Weights = [52.85942453  4.02015924  8.60184179  0.409009    0.20704104 10.13902001], Loss = 5.3261\n",
      "Iteration 324: Weights = [52.88083028  4.02098539  8.60234356  0.40615269  0.20727253 10.14041818], Loss = 5.2309\n",
      "Iteration 325: Weights = [52.90202198  4.02180259  8.6028372   0.40331733  0.20750582 10.14180473], Loss = 5.1375\n",
      "Iteration 326: Weights = [52.92300176  4.02261093  8.60332281  0.40050279  0.20774083 10.1431798 ], Loss = 5.0459\n",
      "Iteration 327: Weights = [52.94377174  4.02341052  8.6038005   0.39770893  0.20797755 10.14454353], Loss = 4.9562\n",
      "Iteration 328: Weights = [52.96433403  4.02420144  8.60427038  0.39493561  0.20821591 10.14589607], Loss = 4.8682\n",
      "Iteration 329: Weights = [52.98469069  4.02498378  8.60473255  0.39218269  0.20845587 10.14723755], Loss = 4.7820\n",
      "Iteration 330: Weights = [53.00484378  4.02575764  8.60518711  0.38945004  0.2086974  10.14856811], Loss = 4.6975\n",
      "Iteration 331: Weights = [53.02479534  4.02652311  8.60563418  0.38673752  0.20894045 10.14988788], Loss = 4.6147\n",
      "Iteration 332: Weights = [53.04454739  4.02728028  8.60607384  0.384045    0.20918497 10.151197  ], Loss = 4.5335\n",
      "Iteration 333: Weights = [53.06410191  4.02802923  8.60650619  0.38137234  0.20943094 10.1524956 ], Loss = 4.4539\n",
      "Iteration 334: Weights = [53.08346089  4.02877005  8.60693134  0.37871941  0.2096783  10.15378381], Loss = 4.3759\n",
      "Iteration 335: Weights = [53.10262629  4.02950283  8.60734937  0.37608606  0.20992702 10.15506174], Loss = 4.2994\n",
      "Iteration 336: Weights = [53.12160002  4.03022765  8.60776038  0.37347218  0.21017705 10.15632954], Loss = 4.2245\n",
      "Iteration 337: Weights = [53.14038402  4.03094459  8.60816446  0.37087763  0.21042836 10.15758732], Loss = 4.1510\n",
      "Iteration 338: Weights = [53.15898018  4.03165375  8.6085617   0.36830227  0.21068092 10.15883519], Loss = 4.0790\n",
      "Iteration 339: Weights = [53.17739038  4.03235519  8.60895219  0.36574598  0.21093467 10.16007329], Loss = 4.0084\n",
      "Iteration 340: Weights = [53.19561648  4.03304901  8.60933601  0.36320862  0.21118959 10.16130173], Loss = 3.9392\n",
      "Iteration 341: Weights = [53.21366031  4.03373528  8.60971326  0.36069006  0.21144563 10.16252062], Loss = 3.8713\n",
      "Iteration 342: Weights = [53.23152371  4.03441407  8.61008402  0.35819018  0.21170276 10.16373008], Loss = 3.8049\n",
      "Iteration 343: Weights = [53.24920847  4.03508548  8.61044836  0.35570884  0.21196095 10.16493022], Loss = 3.7397\n",
      "Iteration 344: Weights = [53.26671639  4.03574957  8.61080638  0.35324592  0.21222016 10.16612115], Loss = 3.6758\n",
      "Iteration 345: Weights = [53.28404922  4.03640642  8.61115815  0.35080129  0.21248035 10.16730298], Loss = 3.6132\n",
      "Iteration 346: Weights = [53.30120873  4.0370561   8.61150376  0.34837483  0.21274148 10.16847582], Loss = 3.5518\n",
      "Iteration 347: Weights = [53.31819664  4.0376987   8.61184327  0.3459664   0.21300354 10.16963977], Loss = 3.4916\n",
      "Iteration 348: Weights = [53.33501468  4.03833428  8.61217677  0.34357588  0.21326647 10.17079494], Loss = 3.4327\n",
      "Iteration 349: Weights = [53.35166453  4.03896292  8.61250433  0.34120314  0.21353025 10.17194143], Loss = 3.3749\n",
      "Iteration 350: Weights = [53.36814789  4.03958468  8.61282603  0.33884807  0.21379484 10.17307934], Loss = 3.3182\n",
      "Iteration 351: Weights = [53.38446641  4.04019964  8.61314195  0.33651054  0.21406022 10.17420877], Loss = 3.2627\n",
      "Iteration 352: Weights = [53.40062174  4.04080788  8.61345214  0.33419042  0.21432634 10.17532982], Loss = 3.2082\n",
      "Iteration 353: Weights = [53.41661552  4.04140945  8.61375668  0.3318876   0.21459319 10.17644259], Loss = 3.1548\n",
      "Iteration 354: Weights = [53.43244937  4.04200442  8.61405566  0.32960195  0.21486072 10.17754717], Loss = 3.1025\n",
      "Iteration 355: Weights = [53.44812488  4.04259287  8.61434912  0.32733335  0.2151289  10.17864366], Loss = 3.0513\n",
      "Iteration 356: Weights = [53.46364363  4.04317486  8.61463714  0.32508167  0.21539772 10.17973215], Loss = 3.0010\n",
      "Iteration 357: Weights = [53.47900719  4.04375046  8.61491979  0.32284681  0.21566713 10.18081272], Loss = 2.9517\n",
      "Iteration 358: Weights = [53.49421712  4.04431973  8.61519713  0.32062864  0.21593711 10.18188548], Loss = 2.9034\n",
      "Iteration 359: Weights = [53.50927495  4.04488274  8.61546923  0.31842705  0.21620763 10.18295052], Loss = 2.8561\n",
      "Iteration 360: Weights = [53.5241822   4.04543954  8.61573615  0.3162419   0.21647865 10.18400791], Loss = 2.8097\n",
      "Iteration 361: Weights = [53.53894038  4.04599021  8.61599795  0.3140731   0.21675016 10.18505774], Loss = 2.7642\n",
      "Iteration 362: Weights = [53.55355097  4.04653481  8.6162547   0.31192052  0.21702213 10.1861001 ], Loss = 2.7196\n",
      "Iteration 363: Weights = [53.56801546  4.04707339  8.61650646  0.30978404  0.21729452 10.18713508], Loss = 2.6759\n",
      "Iteration 364: Weights = [53.58233531  4.04760602  8.61675328  0.30766356  0.21756731 10.18816276], Loss = 2.6331\n",
      "Iteration 365: Weights = [53.59651196  4.04813276  8.61699523  0.30555896  0.21784048 10.18918321], Loss = 2.5911\n",
      "Iteration 366: Weights = [53.61054684  4.04865366  8.61723236  0.30347011  0.21811399 10.19019653], Loss = 2.5499\n",
      "Iteration 367: Weights = [53.62444137  4.04916879  8.61746473  0.30139692  0.21838782 10.19120278], Loss = 2.5095\n",
      "Iteration 368: Weights = [53.63819695  4.04967821  8.6176924   0.29933927  0.21866195 10.19220205], Loss = 2.4700\n",
      "Iteration 369: Weights = [53.65181498  4.05018196  8.61791543  0.29729704  0.21893636 10.19319442], Loss = 2.4312\n",
      "Iteration 370: Weights = [53.66529683  4.05068012  8.61813386  0.29527012  0.21921101 10.19417996], Loss = 2.3932\n",
      "Iteration 371: Weights = [53.67864387  4.05117273  8.61834775  0.29325842  0.21948588 10.19515874], Loss = 2.3559\n",
      "Iteration 372: Weights = [53.69185743  4.05165985  8.61855716  0.29126181  0.21976096 10.19613085], Loss = 2.3194\n",
      "Iteration 373: Weights = [53.70493885  4.05214154  8.61876214  0.28928018  0.22003621 10.19709635], Loss = 2.2836\n",
      "Iteration 374: Weights = [53.71788946  4.05261784  8.61896273  0.28731343  0.22031161 10.19805532], Loss = 2.2485\n",
      "Iteration 375: Weights = [53.73071057  4.05308882  8.619159    0.28536146  0.22058714 10.19900782], Loss = 2.2141\n",
      "Iteration 376: Weights = [53.74340346  4.05355452  8.61935098  0.28342414  0.22086278 10.19995393], Loss = 2.1804\n",
      "Iteration 377: Weights = [53.75596943  4.054015    8.61953874  0.28150139  0.22113851 10.20089372], Loss = 2.1474\n",
      "Iteration 378: Weights = [53.76840974  4.05447032  8.61972231  0.27959308  0.22141429 10.20182726], Loss = 2.1150\n",
      "Iteration 379: Weights = [53.78072564  4.05492051  8.61990175  0.27769912  0.22169013 10.20275461], Loss = 2.0832\n",
      "Iteration 380: Weights = [53.79291838  4.05536563  8.62007711  0.2758194   0.22196598 10.20367584], Loss = 2.0521\n",
      "Iteration 381: Weights = [53.8049892   4.05580574  8.62024842  0.27395383  0.22224184 10.20459101], Loss = 2.0216\n",
      "Iteration 382: Weights = [53.81693931  4.05624088  8.62041574  0.27210228  0.22251767 10.2055002 ], Loss = 1.9916\n",
      "Iteration 383: Weights = [53.82876991  4.0566711   8.62057912  0.27026467  0.22279347 10.20640346], Loss = 1.9623\n",
      "Iteration 384: Weights = [53.84048221  4.05709645  8.62073859  0.26844089  0.22306921 10.20730086], Loss = 1.9336\n",
      "Iteration 385: Weights = [53.85207739  4.05751698  8.6208942   0.26663084  0.22334487 10.20819246], Loss = 1.9054\n",
      "Iteration 386: Weights = [53.86355662  4.05793273  8.62104599  0.26483442  0.22362043 10.20907832], Loss = 1.8778\n",
      "Iteration 387: Weights = [53.87492105  4.05834376  8.62119402  0.26305153  0.22389588 10.2099585 ], Loss = 1.8507\n",
      "Iteration 388: Weights = [53.88617184  4.0587501   8.62133831  0.26128207  0.22417119 10.21083307], Loss = 1.8242\n",
      "Iteration 389: Weights = [53.89731012  4.0591518   8.62147891  0.25952594  0.22444635 10.21170208], Loss = 1.7981\n",
      "Iteration 390: Weights = [53.90833702  4.05954892  8.62161587  0.25778305  0.22472134 10.21256559], Loss = 1.7726\n",
      "Iteration 391: Weights = [53.91925365  4.05994148  8.62174921  0.25605329  0.22499615 10.21342365], Loss = 1.7476\n",
      "Iteration 392: Weights = [53.93006111  4.06032955  8.62187899  0.25433658  0.22527075 10.21427633], Loss = 1.7231\n",
      "Iteration 393: Weights = [53.9407605   4.06071316  8.62200524  0.2526328   0.22554512 10.21512369], Loss = 1.6991\n",
      "Iteration 394: Weights = [53.9513529   4.06109235  8.62212801  0.25094188  0.22581926 10.21596577], Loss = 1.6755\n",
      "Iteration 395: Weights = [53.96183937  4.06146717  8.62224732  0.24926371  0.22609314 10.21680263], Loss = 1.6525\n",
      "Iteration 396: Weights = [53.97222098  4.06183766  8.62236322  0.2475982   0.22636676 10.21763432], Loss = 1.6298\n",
      "Iteration 397: Weights = [53.98249877  4.06220387  8.62247574  0.24594526  0.22664009 10.21846091], Loss = 1.6077\n",
      "Iteration 398: Weights = [53.99267378  4.06256583  8.62258492  0.24430479  0.22691311 10.21928244], Loss = 1.5859\n",
      "Iteration 399: Weights = [54.00274704  4.06292358  8.6226908   0.2426767   0.22718582 10.22009896], Loss = 1.5646\n",
      "Iteration 400: Weights = [54.01271957  4.06327717  8.62279342  0.24106091  0.2274582  10.22091052], Loss = 1.5437\n",
      "Iteration 401: Weights = [54.02259237  4.06362664  8.6228928   0.23945731  0.22773023 10.22171719], Loss = 1.5232\n",
      "Iteration 402: Weights = [54.03236645  4.06397202  8.62298899  0.23786582  0.2280019  10.22251899], Loss = 1.5031\n",
      "Iteration 403: Weights = [54.04204279  4.06431336  8.62308201  0.23628634  0.22827319 10.223316  ], Loss = 1.4834\n",
      "Iteration 404: Weights = [54.05162236  4.06465069  8.6231719   0.2347188   0.2285441  10.22410824], Loss = 1.4641\n",
      "Iteration 405: Weights = [54.06110613  4.06498405  8.6232587   0.2331631   0.2288146  10.22489578], Loss = 1.4452\n",
      "Iteration 406: Weights = [54.07049507  4.06531348  8.62334244  0.23161915  0.22908469 10.22567867], Loss = 1.4267\n",
      "Iteration 407: Weights = [54.07979012  4.06563903  8.62342315  0.23008687  0.22935435 10.22645693], Loss = 1.4085\n",
      "Iteration 408: Weights = [54.08899222  4.06596071  8.62350086  0.22856617  0.22962356 10.22723064], Loss = 1.3907\n",
      "Iteration 409: Weights = [54.0981023   4.06627858  8.62357561  0.22705696  0.22989233 10.22799982], Loss = 1.3732\n",
      "Iteration 410: Weights = [54.10712128  4.06659267  8.62364742  0.22555916  0.23016062 10.22876453], Loss = 1.3561\n",
      "Iteration 411: Weights = [54.11605006  4.06690301  8.62371633  0.22407268  0.23042844 10.22952481], Loss = 1.3393\n",
      "Iteration 412: Weights = [54.12488956  4.06720964  8.62378237  0.22259743  0.23069576 10.2302807 ], Loss = 1.3229\n",
      "Iteration 413: Weights = [54.13364067  4.0675126   8.62384556  0.22113335  0.23096259 10.23103225], Loss = 1.3067\n",
      "Iteration 414: Weights = [54.14230426  4.06781192  8.62390594  0.21968033  0.2312289  10.2317795 ], Loss = 1.2909\n",
      "Iteration 415: Weights = [54.15088122  4.06810763  8.62396354  0.2182383   0.23149468 10.2325225 ], Loss = 1.2754\n",
      "Iteration 416: Weights = [54.15937241  4.06839978  8.62401838  0.21680717  0.23175993 10.23326128], Loss = 1.2602\n",
      "Iteration 417: Weights = [54.16777868  4.06868838  8.6240705   0.21538688  0.23202463 10.2339959 ], Loss = 1.2453\n",
      "Iteration 418: Weights = [54.17610089  4.06897348  8.62411992  0.21397732  0.23228877 10.23472638], Loss = 1.2307\n",
      "Iteration 419: Weights = [54.18433989  4.06925512  8.62416667  0.21257843  0.23255235 10.23545277], Loss = 1.2164\n",
      "Iteration 420: Weights = [54.19249649  4.06953331  8.62421078  0.21119012  0.23281535 10.23617511], Loss = 1.2024\n",
      "Iteration 421: Weights = [54.20057152  4.0698081   8.62425227  0.20981231  0.23307776 10.23689345], Loss = 1.1886\n",
      "Iteration 422: Weights = [54.20856581  4.07007952  8.62429118  0.20844493  0.23333957 10.23760781], Loss = 1.1751\n",
      "Iteration 423: Weights = [54.21648015  4.07034759  8.62432752  0.2070879   0.23360078 10.23831824], Loss = 1.1619\n",
      "Iteration 424: Weights = [54.22431535  4.07061235  8.62436133  0.20574114  0.23386137 10.23902478], Loss = 1.1489\n",
      "Iteration 425: Weights = [54.23207219  4.07087384  8.62439263  0.20440457  0.23412133 10.23972746], Loss = 1.1362\n",
      "Iteration 426: Weights = [54.23975147  4.07113208  8.62442144  0.20307812  0.23438066 10.24042632], Loss = 1.1238\n",
      "Iteration 427: Weights = [54.24735396  4.0713871   8.6244478   0.20176171  0.23463935 10.24112141], Loss = 1.1116\n",
      "Iteration 428: Weights = [54.25488042  4.07163893  8.62447172  0.20045526  0.23489738 10.24181275], Loss = 1.0996\n",
      "Iteration 429: Weights = [54.26233161  4.0718876   8.62449324  0.1991587   0.23515476 10.24250038], Loss = 1.0879\n",
      "Iteration 430: Weights = [54.2697083   4.07213315  8.62451236  0.19787196  0.23541147 10.24318434], Loss = 1.0764\n",
      "Iteration 431: Weights = [54.27701121  4.07237559  8.62452913  0.19659496  0.2356675  10.24386466], Loss = 1.0651\n",
      "Iteration 432: Weights = [54.2842411   4.07261497  8.62454356  0.19532762  0.23592284 10.24454138], Loss = 1.0540\n",
      "Iteration 433: Weights = [54.29139869  4.0728513   8.62455568  0.19406989  0.2361775  10.24521454], Loss = 1.0432\n",
      "Iteration 434: Weights = [54.2984847   4.07308462  8.6245655   0.19282167  0.23643146 10.24588416], Loss = 1.0326\n",
      "Iteration 435: Weights = [54.30549986  4.07331495  8.62457306  0.19158291  0.23668471 10.24655028], Loss = 1.0222\n",
      "Iteration 436: Weights = [54.31244486  4.07354233  8.62457837  0.19035353  0.23693725 10.24721294], Loss = 1.0119\n",
      "Iteration 437: Weights = [54.31932041  4.07376678  8.62458146  0.18913346  0.23718906 10.24787216], Loss = 1.0019\n",
      "Iteration 438: Weights = [54.32612721  4.07398832  8.62458235  0.18792263  0.23744016 10.24852798], Loss = 0.9921\n",
      "Iteration 439: Weights = [54.33286593  4.07420699  8.62458106  0.18672097  0.23769051 10.24918044], Loss = 0.9825\n",
      "Iteration 440: Weights = [54.33953727  4.0744228   8.62457761  0.18552841  0.23794013 10.24982956], Loss = 0.9731\n",
      "Iteration 441: Weights = [54.3461419   4.07463579  8.62457202  0.18434488  0.238189   10.25047537], Loss = 0.9638\n",
      "Iteration 442: Weights = [54.35268048  4.07484599  8.62456432  0.18317031  0.23843712 10.25111791], Loss = 0.9548\n",
      "Iteration 443: Weights = [54.35915368  4.07505341  8.62455453  0.18200465  0.23868449 10.25175721], Loss = 0.9459\n",
      "Iteration 444: Weights = [54.36556214  4.07525809  8.62454266  0.18084781  0.23893109 10.2523933 ], Loss = 0.9372\n",
      "Iteration 445: Weights = [54.37190652  4.07546005  8.62452874  0.17969973  0.23917691 10.2530262 ], Loss = 0.9286\n",
      "Iteration 446: Weights = [54.37818745  4.07565931  8.62451278  0.17856035  0.23942197 10.25365595], Loss = 0.9203\n",
      "Iteration 447: Weights = [54.38440558  4.07585589  8.62449481  0.1774296   0.23966624 10.25428259], Loss = 0.9120\n",
      "Iteration 448: Weights = [54.39056152  4.07604984  8.62447485  0.17630741  0.23990973 10.25490612], Loss = 0.9040\n",
      "Iteration 449: Weights = [54.39665591  4.07624116  8.62445291  0.17519373  0.24015243 10.2555266 ], Loss = 0.8961\n",
      "Iteration 450: Weights = [54.40268935  4.07642988  8.62442901  0.17408848  0.24039433 10.25614403], Loss = 0.8884\n",
      "Iteration 451: Weights = [54.40866246  4.07661602  8.62440318  0.1729916   0.24063544 10.25675847], Loss = 0.8808\n",
      "Iteration 452: Weights = [54.41457583  4.07679962  8.62437543  0.17190304  0.24087573 10.25736992], Loss = 0.8734\n",
      "Iteration 453: Weights = [54.42043007  4.07698068  8.62434578  0.17082272  0.24111522 10.25797842], Loss = 0.8661\n",
      "Iteration 454: Weights = [54.42622577  4.07715924  8.62431425  0.16975058  0.2413539  10.25858399], Loss = 0.8589\n",
      "Iteration 455: Weights = [54.43196351  4.07733532  8.62428086  0.16868656  0.24159176 10.25918667], Loss = 0.8519\n",
      "Iteration 456: Weights = [54.43764388  4.07750894  8.62424561  0.16763061  0.24182879 10.25978647], Loss = 0.8451\n",
      "Iteration 457: Weights = [54.44326744  4.07768012  8.62420855  0.16658265  0.24206501 10.26038343], Loss = 0.8383\n",
      "Iteration 458: Weights = [54.44883477  4.07784889  8.62416967  0.16554263  0.24230039 10.26097758], Loss = 0.8317\n",
      "Iteration 459: Weights = [54.45434642  4.07801526  8.62412899  0.16451049  0.24253494 10.26156893], Loss = 0.8253\n",
      "Iteration 460: Weights = [54.45980295  4.07817926  8.62408655  0.16348617  0.24276865 10.26215751], Loss = 0.8189\n",
      "Iteration 461: Weights = [54.46520493  4.07834092  8.62404234  0.1624696   0.24300152 10.26274336], Loss = 0.8127\n",
      "Iteration 462: Weights = [54.47055288  4.07850024  8.62399639  0.16146074  0.24323355 10.26332648], Loss = 0.8066\n",
      "Iteration 463: Weights = [54.47584735  4.07865725  8.62394871  0.16045952  0.24346473 10.26390692], Loss = 0.8006\n",
      "Iteration 464: Weights = [54.48108887  4.07881198  8.62389933  0.15946588  0.24369506 10.26448469], Loss = 0.7947\n",
      "Iteration 465: Weights = [54.48627798  4.07896444  8.62384825  0.15847977  0.24392454 10.26505981], Loss = 0.7890\n",
      "Iteration 466: Weights = [54.49141521  4.07911466  8.62379549  0.15750113  0.24415316 10.26563232], Loss = 0.7834\n",
      "Iteration 467: Weights = [54.49650105  4.07926265  8.62374107  0.1565299   0.24438093 10.26620223], Loss = 0.7778\n",
      "Iteration 468: Weights = [54.50153604  4.07940843  8.623685    0.15556602  0.24460783 10.26676957], Loss = 0.7724\n",
      "Iteration 469: Weights = [54.50652068  4.07955203  8.62362731  0.15460945  0.24483387 10.26733437], Loss = 0.7671\n",
      "Iteration 470: Weights = [54.51145548  4.07969346  8.623568    0.15366012  0.24505905 10.26789663], Loss = 0.7619\n",
      "Iteration 471: Weights = [54.51634092  4.07983274  8.62350708  0.15271798  0.24528335 10.2684564 ], Loss = 0.7568\n",
      "Iteration 472: Weights = [54.52117751  4.0799699   8.62344458  0.15178298  0.24550679 10.26901369], Loss = 0.7518\n",
      "Iteration 473: Weights = [54.52596574  4.08010495  8.62338051  0.15085506  0.24572935 10.26956851], Loss = 0.7469\n",
      "Iteration 474: Weights = [54.53070608  4.08023791  8.62331489  0.14993416  0.24595104 10.27012091], Loss = 0.7421\n",
      "Iteration 475: Weights = [54.53539902  4.08036879  8.62324772  0.14902024  0.24617185 10.27067089], Loss = 0.7374\n",
      "Iteration 476: Weights = [54.54004503  4.08049763  8.62317903  0.14811324  0.24639178 10.27121848], Loss = 0.7328\n",
      "Iteration 477: Weights = [54.54464458  4.08062443  8.62310882  0.1472131   0.24661084 10.27176369], Loss = 0.7282\n",
      "Iteration 478: Weights = [54.54919813  4.08074921  8.62303711  0.14631979  0.24682901 10.27230656], Loss = 0.7238\n",
      "Iteration 479: Weights = [54.55370615  4.080872    8.62296392  0.14543323  0.24704629 10.2728471 ], Loss = 0.7194\n",
      "Iteration 480: Weights = [54.55816909  4.0809928   8.62288926  0.14455339  0.2472627  10.27338534], Loss = 0.7151\n",
      "Iteration 481: Weights = [54.5625874   4.08111165  8.62281313  0.14368021  0.24747821 10.27392128], Loss = 0.7110\n",
      "Iteration 482: Weights = [54.56696152  4.08122854  8.62273557  0.14281364  0.24769284 10.27445496], Loss = 0.7068\n",
      "Iteration 483: Weights = [54.57129191  4.08134351  8.62265657  0.14195364  0.24790659 10.2749864 ], Loss = 0.7028\n",
      "Iteration 484: Weights = [54.57557899  4.08145657  8.62257615  0.14110014  0.24811944 10.2755156 ], Loss = 0.6989\n",
      "Iteration 485: Weights = [54.5798232   4.08156774  8.62249433  0.1402531   0.2483314  10.2760426 ], Loss = 0.6950\n",
      "Iteration 486: Weights = [54.58402497  4.08167702  8.62241111  0.13941248  0.24854247 10.27656742], Loss = 0.6912\n",
      "Iteration 487: Weights = [54.58818472  4.08178445  8.62232652  0.13857822  0.24875264 10.27709006], Loss = 0.6875\n",
      "Iteration 488: Weights = [54.59230287  4.08189003  8.62224056  0.13775027  0.24896193 10.27761056], Loss = 0.6838\n",
      "Iteration 489: Weights = [54.59637984  4.08199378  8.62215324  0.13692859  0.24917032 10.27812893], Loss = 0.6803\n",
      "Iteration 490: Weights = [54.60041604  4.08209572  8.62206458  0.13611313  0.24937781 10.27864518], Loss = 0.6767\n",
      "Iteration 491: Weights = [54.60441188  4.08219587  8.62197459  0.13530384  0.24958441 10.27915935], Loss = 0.6733\n",
      "Iteration 492: Weights = [54.60836776  4.08229424  8.62188328  0.13450067  0.24979012 10.27967144], Loss = 0.6699\n",
      "Iteration 493: Weights = [54.61228409  4.08239084  8.62179067  0.13370359  0.24999492 10.28018147], Loss = 0.6666\n",
      "Iteration 494: Weights = [54.61616125  4.08248569  8.62169676  0.13291253  0.25019884 10.28068947], Loss = 0.6634\n",
      "Iteration 495: Weights = [54.61999963  4.08257881  8.62160157  0.13212746  0.25040185 10.28119544], Loss = 0.6602\n",
      "Iteration 496: Weights = [54.62379964  4.08267021  8.62150511  0.13134833  0.25060397 10.28169942], Loss = 0.6571\n",
      "Iteration 497: Weights = [54.62756164  4.0827599   8.62140738  0.13057509  0.25080519 10.2822014 ], Loss = 0.6540\n",
      "Iteration 498: Weights = [54.63128602  4.08284791  8.62130841  0.12980771  0.25100552 10.28270143], Loss = 0.6510\n",
      "Iteration 499: Weights = [54.63497316  4.08293425  8.62120821  0.12904613  0.25120495 10.2831995 ], Loss = 0.6481\n",
      "Iteration 500: Weights = [54.63862343  4.08301892  8.62110677  0.12829031  0.25140348 10.28369563], Loss = 0.6452\n",
      "Iteration 501: Weights = [54.6422372   4.08310195  8.62100412  0.1275402   0.25160112 10.28418986], Loss = 0.6424\n",
      "Iteration 502: Weights = [54.64581483  4.08318335  8.62090027  0.12679578  0.25179786 10.28468218], Loss = 0.6396\n",
      "Iteration 503: Weights = [54.64935668  4.08326314  8.62079523  0.12605698  0.2519937  10.28517261], Loss = 0.6369\n",
      "Iteration 504: Weights = [54.65286311  4.08334132  8.620689    0.12532377  0.25218865 10.28566119], Loss = 0.6342\n",
      "Iteration 505: Weights = [54.65633448  4.08341792  8.6205816   0.1245961   0.2523827  10.28614791], Loss = 0.6316\n",
      "Iteration 506: Weights = [54.65977114  4.08349294  8.62047303  0.12387394  0.25257586 10.28663279], Loss = 0.6291\n",
      "Iteration 507: Weights = [54.66317342  4.0835664   8.62036332  0.12315724  0.25276813 10.28711586], Loss = 0.6266\n",
      "Iteration 508: Weights = [54.66654169  4.08363832  8.62025247  0.12244595  0.2529595  10.28759712], Loss = 0.6241\n",
      "Iteration 509: Weights = [54.66987627  4.0837087   8.62014048  0.12174005  0.25314998 10.28807659], Loss = 0.6217\n",
      "Iteration 510: Weights = [54.67317751  4.08377756  8.62002738  0.12103948  0.25333956 10.2885543 ], Loss = 0.6193\n",
      "Iteration 511: Weights = [54.67644574  4.08384491  8.61991316  0.1203442   0.25352825 10.28903024], Loss = 0.6170\n",
      "Iteration 512: Weights = [54.67968128  4.08391077  8.61979784  0.11965419  0.25371606 10.28950444], Loss = 0.6147\n",
      "Iteration 513: Weights = [54.68288446  4.08397515  8.61968143  0.11896939  0.25390297 10.28997692], Loss = 0.6125\n",
      "Iteration 514: Weights = [54.68605562  4.08403807  8.61956394  0.11828976  0.254089   10.29044768], Loss = 0.6103\n",
      "Iteration 515: Weights = [54.68919506  4.08409952  8.61944538  0.11761527  0.25427413 10.29091675], Loss = 0.6081\n",
      "Iteration 516: Weights = [54.69230311  4.08415954  8.61932576  0.11694588  0.25445838 10.29138413], Loss = 0.6060\n",
      "Iteration 517: Weights = [54.69538008  4.08421812  8.61920508  0.11628155  0.25464175 10.29184985], Loss = 0.6040\n",
      "Iteration 518: Weights = [54.69842628  4.08427529  8.61908336  0.11562223  0.25482423 10.29231391], Loss = 0.6019\n",
      "Iteration 519: Weights = [54.70144202  4.08433104  8.6189606   0.1149679   0.25500582 10.29277633], Loss = 0.5999\n",
      "Iteration 520: Weights = [54.7044276   4.08438541  8.61883682  0.11431851  0.25518653 10.29323712], Loss = 0.5980\n",
      "Iteration 521: Weights = [54.70738332  4.0844384   8.61871202  0.11367403  0.25536637 10.2936963 ], Loss = 0.5961\n",
      "Iteration 522: Weights = [54.71030949  4.08449001  8.61858621  0.11303442  0.25554532 10.29415389], Loss = 0.5942\n",
      "Iteration 523: Weights = [54.71320639  4.08454027  8.61845941  0.11239963  0.25572339 10.29460988], Loss = 0.5924\n",
      "Iteration 524: Weights = [54.71607433  4.08458918  8.61833162  0.11176964  0.25590059 10.29506431], Loss = 0.5906\n",
      "Iteration 525: Weights = [54.71891359  4.08463675  8.61820284  0.11114441  0.25607691 10.29551718], Loss = 0.5888\n",
      "Iteration 526: Weights = [54.72172445  4.08468301  8.61807309  0.11052391  0.25625235 10.2959685 ], Loss = 0.5871\n",
      "Iteration 527: Weights = [54.72450721  4.08472795  8.61794238  0.10990808  0.25642693 10.29641829], Loss = 0.5854\n",
      "Iteration 528: Weights = [54.72726213  4.08477158  8.61781071  0.10929691  0.25660063 10.29686656], Loss = 0.5837\n",
      "Iteration 529: Weights = [54.72998951  4.08481393  8.61767809  0.10869035  0.25677346 10.29731332], Loss = 0.5821\n",
      "Iteration 530: Weights = [54.73268962  4.08485501  8.61754454  0.10808838  0.25694542 10.2977586 ], Loss = 0.5805\n",
      "Iteration 531: Weights = [54.73536272  4.08489481  8.61741005  0.10749094  0.25711652 10.29820239], Loss = 0.5789\n",
      "Iteration 532: Weights = [54.73800909  4.08493336  8.61727464  0.10689802  0.25728675 10.29864471], Loss = 0.5774\n",
      "Iteration 533: Weights = [54.740629    4.08497066  8.61713832  0.10630957  0.25745612 10.29908558], Loss = 0.5758\n",
      "Iteration 534: Weights = [54.74322271  4.08500672  8.61700109  0.10572556  0.25762463 10.299525  ], Loss = 0.5744\n",
      "Iteration 535: Weights = [54.74579049  4.08504156  8.61686296  0.10514596  0.25779228 10.29996299], Loss = 0.5729\n",
      "Iteration 536: Weights = [54.74833258  4.08507519  8.61672394  0.10457074  0.25795907 10.30039956], Loss = 0.5715\n",
      "Iteration 537: Weights = [54.75084926  4.08510761  8.61658403  0.10399985  0.25812501 10.30083473], Loss = 0.5701\n",
      "Iteration 538: Weights = [54.75334076  4.08513884  8.61644325  0.10343327  0.25829009 10.3012685 ], Loss = 0.5687\n",
      "Iteration 539: Weights = [54.75580736  4.08516888  8.6163016   0.10287097  0.25845432 10.30170088], Loss = 0.5674\n",
      "Iteration 540: Weights = [54.75824928  4.08519775  8.61615909  0.10231291  0.2586177  10.30213189], Loss = 0.5660\n",
      "Iteration 541: Weights = [54.76066679  4.08522546  8.61601573  0.10175906  0.25878023 10.30256154], Loss = 0.5647\n",
      "Iteration 542: Weights = [54.76306012  4.08525201  8.61587152  0.10120938  0.25894191 10.30298985], Loss = 0.5635\n",
      "Iteration 543: Weights = [54.76542952  4.08527742  8.61572648  0.10066385  0.25910275 10.30341681], Loss = 0.5622\n",
      "Iteration 544: Weights = [54.76777523  4.08530169  8.6155806   0.10012244  0.25926275 10.30384244], Loss = 0.5610\n",
      "Iteration 545: Weights = [54.77009747  4.08532484  8.6154339   0.09958511  0.25942191 10.30426676], Loss = 0.5598\n",
      "Iteration 546: Weights = [54.7723965   4.08534687  8.61528638  0.09905183  0.25958023 10.30468978], Loss = 0.5586\n",
      "Iteration 547: Weights = [54.77467253  4.0853678   8.61513805  0.09852257  0.25973771 10.3051115 ], Loss = 0.5575\n",
      "Iteration 548: Weights = [54.77692581  4.08538763  8.61498891  0.0979973   0.25989437 10.30553194], Loss = 0.5563\n",
      "Iteration 549: Weights = [54.77915655  4.08540637  8.61483898  0.09747599  0.26005019 10.3059511 ], Loss = 0.5552\n",
      "Iteration 550: Weights = [54.78136498  4.08542404  8.61468827  0.09695861  0.26020518 10.306369  ], Loss = 0.5541\n",
      "Iteration 551: Weights = [54.78355133  4.08544063  8.61453676  0.09644513  0.26035934 10.30678565], Loss = 0.5531\n",
      "Iteration 552: Weights = [54.78571582  4.08545617  8.61438449  0.09593552  0.26051268 10.30720106], Loss = 0.5520\n",
      "Iteration 553: Weights = [54.78785866  4.08547065  8.61423144  0.09542975  0.2606652  10.30761524], Loss = 0.5510\n",
      "Iteration 554: Weights = [54.78998008  4.08548409  8.61407763  0.09492779  0.26081689 10.3080282 ], Loss = 0.5500\n",
      "Iteration 555: Weights = [54.79208028  4.0854965   8.61392307  0.09442962  0.26096777 10.30843995], Loss = 0.5490\n",
      "Iteration 556: Weights = [54.79415947  4.08550789  8.61376776  0.0939352   0.26111784 10.30885049], Loss = 0.5480\n",
      "Iteration 557: Weights = [54.79621788  4.08551825  8.6136117   0.0934445   0.26126709 10.30925985], Loss = 0.5471\n",
      "Iteration 558: Weights = [54.7982557   4.08552761  8.6134549   0.0929575   0.26141553 10.30966802], Loss = 0.5461\n",
      "Iteration 559: Weights = [54.80027314  4.08553597  8.61329738  0.09247416  0.26156316 10.31007503], Loss = 0.5452\n",
      "Iteration 560: Weights = [54.80227041  4.08554334  8.61313913  0.09199447  0.26170999 10.31048087], Loss = 0.5443\n",
      "Iteration 561: Weights = [54.80424771  4.08554973  8.61298016  0.09151839  0.26185601 10.31088556], Loss = 0.5434\n",
      "Iteration 562: Weights = [54.80620523  4.08555514  8.61282049  0.09104589  0.26200123 10.31128911], Loss = 0.5426\n",
      "Iteration 563: Weights = [54.80814318  4.08555958  8.6126601   0.09057695  0.26214566 10.31169152], Loss = 0.5417\n",
      "Iteration 564: Weights = [54.81006175  4.08556307  8.61249902  0.09011155  0.26228928 10.31209281], Loss = 0.5409\n",
      "Iteration 565: Weights = [54.81196113  4.08556561  8.61233724  0.08964964  0.26243212 10.31249299], Loss = 0.5401\n",
      "Iteration 566: Weights = [54.81384152  4.0855672   8.61217477  0.08919122  0.26257416 10.31289206], Loss = 0.5393\n",
      "Iteration 567: Weights = [54.8157031   4.08556786  8.61201162  0.08873624  0.26271542 10.31329004], Loss = 0.5385\n",
      "Iteration 568: Weights = [54.81754607  4.0855676   8.6118478   0.08828469  0.26285588 10.31368692], Loss = 0.5377\n",
      "Iteration 569: Weights = [54.81937061  4.08556641  8.6116833   0.08783654  0.26299557 10.31408273], Loss = 0.5370\n",
      "Iteration 570: Weights = [54.8211769   4.08556432  8.61151814  0.08739175  0.26313448 10.31447747], Loss = 0.5362\n",
      "Iteration 571: Weights = [54.82296513  4.08556132  8.61135232  0.08695032  0.2632726  10.31487115], Loss = 0.5355\n",
      "Iteration 572: Weights = [54.82473548  4.08555742  8.61118585  0.08651221  0.26340995 10.31526378], Loss = 0.5348\n",
      "Iteration 573: Weights = [54.82648813  4.08555264  8.61101873  0.08607739  0.26354653 10.31565537], Loss = 0.5341\n",
      "Iteration 574: Weights = [54.82822325  4.08554697  8.61085096  0.08564584  0.26368234 10.31604591], Loss = 0.5334\n",
      "Iteration 575: Weights = [54.82994101  4.08554043  8.61068256  0.08521754  0.26381738 10.31643544], Loss = 0.5327\n",
      "Iteration 576: Weights = [54.8316416   4.08553302  8.61051353  0.08479246  0.26395166 10.31682394], Loss = 0.5320\n",
      "Iteration 577: Weights = [54.83332519  4.08552476  8.61034387  0.08437058  0.26408518 10.31721144], Loss = 0.5314\n",
      "Iteration 578: Weights = [54.83499194  4.08551564  8.61017359  0.08395187  0.26421793 10.31759793], Loss = 0.5308\n",
      "Iteration 579: Weights = [54.83664202  4.08550567  8.61000269  0.08353631  0.26434993 10.31798343], Loss = 0.5301\n",
      "Iteration 580: Weights = [54.8382756   4.08549487  8.60983119  0.08312387  0.26448117 10.31836795], Loss = 0.5295\n",
      "Iteration 581: Weights = [54.83989284  4.08548323  8.60965907  0.08271453  0.26461166 10.31875148], Loss = 0.5289\n",
      "Iteration 582: Weights = [54.84149391  4.08547077  8.60948636  0.08230827  0.26474141 10.31913405], Loss = 0.5283\n",
      "Iteration 583: Weights = [54.84307897  4.0854575   8.60931305  0.08190506  0.26487041 10.31951566], Loss = 0.5277\n",
      "Iteration 584: Weights = [54.84464818  4.08544341  8.60913915  0.08150489  0.26499866 10.31989631], Loss = 0.5272\n",
      "Iteration 585: Weights = [54.8462017   4.08542852  8.60896467  0.08110772  0.26512618 10.32027602], Loss = 0.5266\n",
      "Iteration 586: Weights = [54.84773969  4.08541283  8.60878961  0.08071353  0.26525295 10.32065479], Loss = 0.5261\n",
      "Iteration 587: Weights = [54.84926229  4.08539635  8.60861397  0.08032231  0.26537899 10.32103263], Loss = 0.5255\n",
      "Iteration 588: Weights = [54.85076967  4.08537908  8.60843776  0.07993402  0.2655043  10.32140954], Loss = 0.5250\n",
      "Iteration 589: Weights = [54.85226197  4.08536103  8.60826098  0.07954866  0.26562888 10.32178554], Loss = 0.5245\n",
      "Iteration 590: Weights = [54.85373935  4.08534222  8.60808364  0.07916618  0.26575274 10.32216064], Loss = 0.5240\n",
      "Iteration 591: Weights = [54.85520196  4.08532264  8.60790575  0.07878658  0.26587587 10.32253483], Loss = 0.5235\n",
      "Iteration 592: Weights = [54.85664994  4.0853023   8.6077273   0.07840983  0.26599828 10.32290813], Loss = 0.5230\n",
      "Iteration 593: Weights = [54.85808344  4.0852812   8.60754831  0.07803591  0.26611997 10.32328054], Loss = 0.5225\n",
      "Iteration 594: Weights = [54.8595026   4.08525936  8.60736878  0.0776648   0.26624094 10.32365207], Loss = 0.5220\n",
      "Iteration 595: Weights = [54.86090758  4.08523678  8.6071887   0.07729647  0.2663612  10.32402273], Loss = 0.5215\n",
      "Iteration 596: Weights = [54.8622985   4.08521347  8.6070081   0.07693091  0.26648076 10.32439253], Loss = 0.5211\n",
      "Iteration 597: Weights = [54.86367552  4.08518942  8.60682696  0.0765681   0.2665996  10.32476146], Loss = 0.5206\n",
      "Iteration 598: Weights = [54.86503876  4.08516466  8.6066453   0.076208    0.26671774 10.32512955], Loss = 0.5202\n",
      "Iteration 599: Weights = [54.86638837  4.08513917  8.60646312  0.07585061  0.26683518 10.32549679], Loss = 0.5198\n",
      "Iteration 600: Weights = [54.86772449  4.08511298  8.60628043  0.0754959   0.26695192 10.32586319], Loss = 0.5193\n",
      "Iteration 601: Weights = [54.86904724  4.08508608  8.60609722  0.07514385  0.26706797 10.32622877], Loss = 0.5189\n",
      "Iteration 602: Weights = [54.87035677  4.08505848  8.60591351  0.07479444  0.26718332 10.32659352], Loss = 0.5185\n",
      "Iteration 603: Weights = [54.8716532   4.08503019  8.60572929  0.07444766  0.26729799 10.32695745], Loss = 0.5181\n",
      "Iteration 604: Weights = [54.87293667  4.08500121  8.60554458  0.07410347  0.26741196 10.32732057], Loss = 0.5177\n",
      "Iteration 605: Weights = [54.87420731  4.08497155  8.60535937  0.07376187  0.26752525 10.32768289], Loss = 0.5173\n",
      "Iteration 606: Weights = [54.87546523  4.08494121  8.60517367  0.07342283  0.26763786 10.32804441], Loss = 0.5170\n",
      "Iteration 607: Weights = [54.87671058  4.0849102   8.60498748  0.07308633  0.26774979 10.32840513], Loss = 0.5166\n",
      "Iteration 608: Weights = [54.87794347  4.08487853  8.60480082  0.07275236  0.26786105 10.32876508], Loss = 0.5162\n",
      "Iteration 609: Weights = [54.87916404  4.08484619  8.60461367  0.07242089  0.26797163 10.32912424], Loss = 0.5159\n",
      "Iteration 610: Weights = [54.8803724   4.0848132   8.60442605  0.0720919   0.26808154 10.32948263], Loss = 0.5155\n",
      "Iteration 611: Weights = [54.88156867  4.08477956  8.60423796  0.07176538  0.26819079 10.32984025], Loss = 0.5152\n",
      "Iteration 612: Weights = [54.88275299  4.08474528  8.6040494   0.07144131  0.26829937 10.33019712], Loss = 0.5148\n",
      "Iteration 613: Weights = [54.88392546  4.08471036  8.60386038  0.07111966  0.26840729 10.33055323], Loss = 0.5145\n",
      "Iteration 614: Weights = [54.8850862   4.0846748   8.60367091  0.07080043  0.26851455 10.33090859], Loss = 0.5141\n",
      "Iteration 615: Weights = [54.88623534  4.08463861  8.60348098  0.07048359  0.26862115 10.33126321], Loss = 0.5138\n",
      "Iteration 616: Weights = [54.88737299  4.0846018   8.60329059  0.07016912  0.2687271  10.33161709], Loss = 0.5135\n",
      "Iteration 617: Weights = [54.88849926  4.08456438  8.60309976  0.06985701  0.26883241 10.33197024], Loss = 0.5132\n",
      "Iteration 618: Weights = [54.88961427  4.08452634  8.60290849  0.06954724  0.26893706 10.33232267], Loss = 0.5129\n",
      "Iteration 619: Weights = [54.89071812  4.08448769  8.60271678  0.06923979  0.26904107 10.33267438], Loss = 0.5126\n",
      "Iteration 620: Weights = [54.89181094  4.08444843  8.60252463  0.06893464  0.26914444 10.33302537], Loss = 0.5123\n",
      "Iteration 621: Weights = [54.89289283  4.08440858  8.60233205  0.06863178  0.26924717 10.33337566], Loss = 0.5120\n",
      "Iteration 622: Weights = [54.8939639   4.08436814  8.60213904  0.06833118  0.26934926 10.33372525], Loss = 0.5117\n",
      "Iteration 623: Weights = [54.89502427  4.0843271   8.60194561  0.06803283  0.26945072 10.33407414], Loss = 0.5114\n",
      "Iteration 624: Weights = [54.89607402  4.08428548  8.60175175  0.06773672  0.26955155 10.33442234], Loss = 0.5112\n",
      "Iteration 625: Weights = [54.89711328  4.08424328  8.60155747  0.06744283  0.26965175 10.33476985], Loss = 0.5109\n",
      "Iteration 626: Weights = [54.89814215  4.08420051  8.60136279  0.06715113  0.26975133 10.33511668], Loss = 0.5106\n",
      "Iteration 627: Weights = [54.89916073  4.08415716  8.60116769  0.06686162  0.26985028 10.33546284], Loss = 0.5104\n",
      "Iteration 628: Weights = [54.90016912  4.08411325  8.60097218  0.06657428  0.26994862 10.33580833], Loss = 0.5101\n",
      "Iteration 629: Weights = [54.90116743  4.08406878  8.60077627  0.06628908  0.27004634 10.33615316], Loss = 0.5098\n",
      "Iteration 630: Weights = [54.90215576  4.08402376  8.60057995  0.06600602  0.27014345 10.33649733], Loss = 0.5096\n",
      "Iteration 631: Weights = [54.9031342   4.08397818  8.60038324  0.06572508  0.27023995 10.33684084], Loss = 0.5094\n",
      "Iteration 632: Weights = [54.90410286  4.08393205  8.60018614  0.06544624  0.27033584 10.33718371], Loss = 0.5091\n",
      "Iteration 633: Weights = [54.90506183  4.08388538  8.59998864  0.06516948  0.27043112 10.33752593], Loss = 0.5089\n",
      "Iteration 634: Weights = [54.90601121  4.08383817  8.59979076  0.06489479  0.2705258  10.33786752], Loss = 0.5086\n",
      "Iteration 635: Weights = [54.9069511   4.08379042  8.59959249  0.06462216  0.27061989 10.33820847], Loss = 0.5084\n",
      "Iteration 636: Weights = [54.90788159  4.08374215  8.59939384  0.06435157  0.27071337 10.3385488 ], Loss = 0.5082\n",
      "Iteration 637: Weights = [54.90880277  4.08369335  8.59919481  0.064083    0.27080627 10.3388885 ], Loss = 0.5080\n",
      "Iteration 638: Weights = [54.90971474  4.08364403  8.59899541  0.06381644  0.27089857 10.33922758], Loss = 0.5078\n",
      "Iteration 639: Weights = [54.91061759  4.08359419  8.59879563  0.06355187  0.27099028 10.33956605], Loss = 0.5075\n",
      "Iteration 640: Weights = [54.91151142  4.08354383  8.59859549  0.06328928  0.27108141 10.33990392], Loss = 0.5073\n",
      "Iteration 641: Weights = [54.9123963   4.08349297  8.59839498  0.06302865  0.27117196 10.34024118], Loss = 0.5071\n",
      "Iteration 642: Weights = [54.91327234  4.0834416   8.59819411  0.06276997  0.27126193 10.34057784], Loss = 0.5069\n",
      "Iteration 643: Weights = [54.91413962  4.08338974  8.59799287  0.06251323  0.27135132 10.3409139 ], Loss = 0.5067\n",
      "Iteration 644: Weights = [54.91499822  4.08333737  8.59779129  0.0622584   0.27144013 10.34124938], Loss = 0.5065\n",
      "Iteration 645: Weights = [54.91584824  4.08328451  8.59758934  0.06200547  0.27152838 10.34158427], Loss = 0.5063\n",
      "Iteration 646: Weights = [54.91668976  4.08323116  8.59738705  0.06175444  0.27161605 10.34191858], Loss = 0.5062\n",
      "Iteration 647: Weights = [54.91752286  4.08317733  8.59718441  0.06150528  0.27170316 10.34225232], Loss = 0.5060\n",
      "Iteration 648: Weights = [54.91834763  4.08312301  8.59698142  0.06125798  0.27178971 10.34258549], Loss = 0.5058\n",
      "Iteration 649: Weights = [54.91916415  4.08306822  8.59677809  0.06101252  0.27187569 10.34291809], Loss = 0.5056\n",
      "Iteration 650: Weights = [54.91997251  4.08301295  8.59657442  0.06076891  0.27196112 10.34325012], Loss = 0.5054\n",
      "Iteration 651: Weights = [54.92077279  4.08295721  8.59637042  0.06052711  0.272046   10.3435816 ], Loss = 0.5053\n",
      "Iteration 652: Weights = [54.92156506  4.08290101  8.59616608  0.06028711  0.27213032 10.34391253], Loss = 0.5051\n",
      "Iteration 653: Weights = [54.92234941  4.08284434  8.59596141  0.06004891  0.27221409 10.3442429 ], Loss = 0.5049\n",
      "Iteration 654: Weights = [54.92312592  4.08278722  8.59575641  0.05981248  0.27229731 10.34457274], Loss = 0.5047\n",
      "Iteration 655: Weights = [54.92389466  4.08272964  8.59555109  0.05957782  0.27237999 10.34490203], Loss = 0.5046\n",
      "Iteration 656: Weights = [54.92465571  4.08267161  8.59534544  0.05934491  0.27246213 10.34523078], Loss = 0.5044\n",
      "Iteration 657: Weights = [54.92540915  4.08261313  8.59513948  0.05911374  0.27254373 10.34555901], Loss = 0.5043\n",
      "Iteration 658: Weights = [54.92615506  4.08255421  8.59493319  0.05888429  0.2726248  10.3458867 ], Loss = 0.5041\n",
      "Iteration 659: Weights = [54.92689351  4.08249484  8.5947266   0.05865656  0.27270533 10.34621387], Loss = 0.5040\n",
      "Iteration 660: Weights = [54.92762458  4.08243504  8.59451968  0.05843052  0.27278533 10.34654053], Loss = 0.5038\n",
      "Iteration 661: Weights = [54.92834833  4.0823748   8.59431246  0.05820618  0.2728648  10.34686666], Loss = 0.5037\n",
      "Iteration 662: Weights = [54.92906485  4.08231414  8.59410494  0.0579835   0.27294375 10.34719229], Loss = 0.5035\n",
      "Iteration 663: Weights = [54.9297742   4.08225304  8.5938971   0.05776248  0.27302217 10.34751741], Loss = 0.5034\n",
      "Iteration 664: Weights = [54.93047646  4.08219152  8.59368897  0.05754312  0.27310008 10.34784202], Loss = 0.5032\n",
      "Iteration 665: Weights = [54.93117169  4.08212959  8.59348054  0.05732538  0.27317747 10.34816614], Loss = 0.5031\n",
      "Iteration 666: Weights = [54.93185997  4.08206723  8.59327181  0.05710928  0.27325434 10.34848975], Loss = 0.5029\n",
      "Iteration 667: Weights = [54.93254137  4.08200446  8.59306278  0.05689478  0.2733307  10.34881288], Loss = 0.5028\n",
      "Iteration 668: Weights = [54.93321596  4.08194128  8.59285346  0.05668188  0.27340655 10.34913552], Loss = 0.5027\n",
      "Iteration 669: Weights = [54.9338838   4.0818777   8.59264386  0.05647057  0.27348189 10.34945767], Loss = 0.5025\n",
      "Iteration 670: Weights = [54.93454496  4.08181371  8.59243396  0.05626083  0.27355673 10.34977935], Loss = 0.5024\n",
      "Iteration 671: Weights = [54.93519951  4.08174932  8.59222378  0.05605266  0.27363107 10.35010055], Loss = 0.5023\n",
      "Iteration 672: Weights = [54.93584752  4.08168453  8.59201332  0.05584603  0.2737049  10.35042127], Loss = 0.5022\n",
      "Iteration 673: Weights = [54.93648904  4.08161935  8.59180258  0.05564095  0.27377824 10.35074153], Loss = 0.5020\n",
      "Iteration 674: Weights = [54.93712415  4.08155378  8.59159156  0.05543739  0.27385109 10.35106131], Loss = 0.5019\n",
      "Iteration 675: Weights = [54.93775291  4.08148781  8.59138026  0.05523535  0.27392345 10.35138064], Loss = 0.5018\n",
      "Iteration 676: Weights = [54.93837538  4.08142147  8.59116869  0.05503482  0.27399531 10.35169951], Loss = 0.5017\n",
      "Iteration 677: Weights = [5.49389916e+01 4.08135474e+00 8.59095685e+00 5.48357784e-02\n",
      " 2.74066693e-01 1.03520179e+01], Loss = 0.5016\n",
      "Iteration 678: Weights = [5.49396017e+01 4.08128763e+00 8.59074474e+00 5.46382189e-02\n",
      " 2.74137589e-01 1.03523359e+01], Loss = 0.5015\n",
      "Iteration 679: Weights = [5.49402057e+01 4.08122015e+00 8.59053237e+00 5.44421304e-02\n",
      " 2.74208004e-01 1.03526534e+01], Loss = 0.5013\n",
      "Iteration 680: Weights = [5.49408036e+01 4.08115229e+00 8.59031973e+00 5.42475017e-02\n",
      " 2.74277940e-01 1.03529705e+01], Loss = 0.5012\n",
      "Iteration 681: Weights = [5.49413956e+01 4.08108406e+00 8.59010682e+00 5.40543219e-02\n",
      " 2.74347400e-01 1.03532871e+01], Loss = 0.5011\n",
      "Iteration 682: Weights = [5.49419816e+01 4.08101547e+00 8.58989366e+00 5.38625799e-02\n",
      " 2.74416386e-01 1.03536033e+01], Loss = 0.5010\n",
      "Iteration 683: Weights = [5.49425618e+01 4.08094651e+00 8.58968024e+00 5.36722649e-02\n",
      " 2.74484901e-01 1.03539190e+01], Loss = 0.5009\n",
      "Iteration 684: Weights = [5.49431362e+01 4.08087719e+00 8.58946656e+00 5.34833662e-02\n",
      " 2.74552946e-01 1.03542344e+01], Loss = 0.5008\n",
      "Iteration 685: Weights = [5.49437048e+01 4.08080751e+00 8.58925263e+00 5.32958730e-02\n",
      " 2.74620526e-01 1.03545493e+01], Loss = 0.5007\n",
      "Iteration 686: Weights = [5.49442678e+01 4.08073748e+00 8.58903845e+00 5.31097748e-02\n",
      " 2.74687641e-01 1.03548637e+01], Loss = 0.5006\n",
      "Iteration 687: Weights = [5.49448251e+01 4.08066709e+00 8.58882402e+00 5.29250611e-02\n",
      " 2.74754296e-01 1.03551778e+01], Loss = 0.5005\n",
      "Iteration 688: Weights = [5.49453769e+01 4.08059635e+00 8.58860934e+00 5.27417213e-02\n",
      " 2.74820491e-01 1.03554914e+01], Loss = 0.5004\n",
      "Iteration 689: Weights = [5.49459231e+01 4.08052527e+00 8.58839442e+00 5.25597452e-02\n",
      " 2.74886230e-01 1.03558047e+01], Loss = 0.5003\n",
      "Iteration 690: Weights = [5.49464639e+01 4.08045384e+00 8.58817925e+00 5.23791224e-02\n",
      " 2.74951514e-01 1.03561175e+01], Loss = 0.5002\n",
      "Iteration 691: Weights = [5.49469992e+01 4.08038207e+00 8.58796385e+00 5.21998428e-02\n",
      " 2.75016347e-01 1.03564299e+01], Loss = 0.5001\n",
      "Iteration 692: Weights = [5.49475292e+01 4.08030995e+00 8.58774820e+00 5.20218962e-02\n",
      " 2.75080731e-01 1.03567419e+01], Loss = 0.5000\n",
      "Iteration 693: Weights = [5.49480539e+01 4.08023751e+00 8.58753231e+00 5.18452725e-02\n",
      " 2.75144668e-01 1.03570535e+01], Loss = 0.4999\n",
      "Iteration 694: Weights = [5.49485734e+01 4.08016473e+00 8.58731619e+00 5.16699619e-02\n",
      " 2.75208161e-01 1.03573646e+01], Loss = 0.4998\n",
      "Iteration 695: Weights = [5.49490877e+01 4.08009161e+00 8.58709984e+00 5.14959543e-02\n",
      " 2.75271211e-01 1.03576755e+01], Loss = 0.4997\n",
      "Iteration 696: Weights = [5.49495968e+01 4.08001817e+00 8.58688325e+00 5.13232400e-02\n",
      " 2.75333822e-01 1.03579859e+01], Loss = 0.4996\n",
      "Iteration 697: Weights = [5.49501008e+01 4.07994440e+00 8.58666644e+00 5.11518093e-02\n",
      " 2.75395996e-01 1.03582959e+01], Loss = 0.4996\n",
      "Iteration 698: Weights = [5.49505998e+01 4.07987031e+00 8.58644940e+00 5.09816524e-02\n",
      " 2.75457735e-01 1.03586055e+01], Loss = 0.4995\n",
      "Iteration 699: Weights = [5.49510938e+01 4.07979590e+00 8.58623213e+00 5.08127597e-02\n",
      " 2.75519042e-01 1.03589148e+01], Loss = 0.4994\n",
      "Iteration 700: Weights = [5.49515829e+01 4.07972117e+00 8.58601464e+00 5.06451217e-02\n",
      " 2.75579918e-01 1.03592236e+01], Loss = 0.4993\n",
      "Iteration 701: Weights = [5.49520671e+01 4.07964612e+00 8.58579692e+00 5.04787291e-02\n",
      " 2.75640366e-01 1.03595321e+01], Loss = 0.4992\n",
      "Iteration 702: Weights = [5.49525464e+01 4.07957076e+00 8.58557899e+00 5.03135723e-02\n",
      " 2.75700390e-01 1.03598402e+01], Loss = 0.4991\n",
      "Iteration 703: Weights = [5.49530209e+01 4.07949509e+00 8.58536083e+00 5.01496421e-02\n",
      " 2.75759989e-01 1.03601480e+01], Loss = 0.4991\n",
      "Iteration 704: Weights = [5.49534907e+01 4.07941911e+00 8.58514246e+00 4.99869292e-02\n",
      " 2.75819169e-01 1.03604553e+01], Loss = 0.4990\n",
      "Iteration 705: Weights = [5.49539558e+01 4.07934282e+00 8.58492388e+00 4.98254245e-02\n",
      " 2.75877929e-01 1.03607623e+01], Loss = 0.4989\n",
      "Iteration 706: Weights = [5.49544162e+01 4.07926623e+00 8.58470508e+00 4.96651188e-02\n",
      " 2.75936273e-01 1.03610690e+01], Loss = 0.4988\n",
      "Iteration 707: Weights = [5.49548721e+01 4.07918933e+00 8.58448607e+00 4.95060032e-02\n",
      " 2.75994204e-01 1.03613753e+01], Loss = 0.4987\n",
      "Iteration 708: Weights = [5.49553234e+01 4.07911214e+00 8.58426686e+00 4.93480687e-02\n",
      " 2.76051723e-01 1.03616812e+01], Loss = 0.4987\n",
      "Iteration 709: Weights = [5.49557701e+01 4.07903465e+00 8.58404743e+00 4.91913063e-02\n",
      " 2.76108832e-01 1.03619868e+01], Loss = 0.4986\n",
      "Iteration 710: Weights = [5.49562124e+01 4.07895687e+00 8.58382780e+00 4.90357074e-02\n",
      " 2.76165534e-01 1.03622920e+01], Loss = 0.4985\n",
      "Iteration 711: Weights = [5.49566503e+01 4.07887880e+00 8.58360796e+00 4.88812630e-02\n",
      " 2.76221832e-01 1.03625968e+01], Loss = 0.4984\n",
      "Iteration 712: Weights = [5.49570838e+01 4.07880043e+00 8.58338792e+00 4.87279645e-02\n",
      " 2.76277727e-01 1.03629014e+01], Loss = 0.4984\n",
      "Iteration 713: Weights = [5.49575130e+01 4.07872178e+00 8.58316768e+00 4.85758033e-02\n",
      " 2.76333221e-01 1.03632055e+01], Loss = 0.4983\n",
      "Iteration 714: Weights = [5.49579378e+01 4.07864284e+00 8.58294724e+00 4.84247709e-02\n",
      " 2.76388318e-01 1.03635094e+01], Loss = 0.4982\n",
      "Iteration 715: Weights = [5.49583585e+01 4.07856362e+00 8.58272661e+00 4.82748586e-02\n",
      " 2.76443018e-01 1.03638129e+01], Loss = 0.4981\n",
      "Iteration 716: Weights = [5.49587749e+01 4.07848412e+00 8.58250577e+00 4.81260582e-02\n",
      " 2.76497325e-01 1.03641160e+01], Loss = 0.4981\n",
      "Iteration 717: Weights = [5.49591871e+01 4.07840434e+00 8.58228475e+00 4.79783612e-02\n",
      " 2.76551240e-01 1.03644189e+01], Loss = 0.4980\n",
      "Iteration 718: Weights = [5.49595953e+01 4.07832428e+00 8.58206353e+00 4.78317593e-02\n",
      " 2.76604766e-01 1.03647213e+01], Loss = 0.4979\n",
      "Iteration 719: Weights = [5.49599993e+01 4.07824394e+00 8.58184212e+00 4.76862444e-02\n",
      " 2.76657905e-01 1.03650235e+01], Loss = 0.4979\n",
      "Iteration 720: Weights = [5.49603993e+01 4.07816334e+00 8.58162052e+00 4.75418081e-02\n",
      " 2.76710658e-01 1.03653253e+01], Loss = 0.4978\n",
      "Iteration 721: Weights = [5.49607953e+01 4.07808247e+00 8.58139873e+00 4.73984425e-02\n",
      " 2.76763029e-01 1.03656269e+01], Loss = 0.4977\n",
      "Iteration 722: Weights = [5.49611874e+01 4.07800132e+00 8.58117675e+00 4.72561394e-02\n",
      " 2.76815020e-01 1.03659280e+01], Loss = 0.4977\n",
      "Iteration 723: Weights = [5.49615755e+01 4.07791991e+00 8.58095459e+00 4.71148909e-02\n",
      " 2.76866632e-01 1.03662289e+01], Loss = 0.4976\n",
      "Iteration 724: Weights = [5.49619597e+01 4.07783824e+00 8.58073225e+00 4.69746890e-02\n",
      " 2.76917867e-01 1.03665295e+01], Loss = 0.4975\n",
      "Iteration 725: Weights = [5.49623401e+01 4.07775631e+00 8.58050972e+00 4.68355258e-02\n",
      " 2.76968728e-01 1.03668297e+01], Loss = 0.4975\n",
      "Iteration 726: Weights = [5.49627167e+01 4.07767411e+00 8.58028702e+00 4.66973937e-02\n",
      " 2.77019217e-01 1.03671296e+01], Loss = 0.4974\n",
      "Iteration 727: Weights = [5.49630896e+01 4.07759166e+00 8.58006413e+00 4.65602847e-02\n",
      " 2.77069337e-01 1.03674293e+01], Loss = 0.4974\n",
      "Iteration 728: Weights = [5.49634587e+01 4.07750895e+00 8.57984107e+00 4.64241912e-02\n",
      " 2.77119088e-01 1.03677286e+01], Loss = 0.4973\n",
      "Iteration 729: Weights = [5.49638241e+01 4.07742599e+00 8.57961783e+00 4.62891056e-02\n",
      " 2.77168473e-01 1.03680276e+01], Loss = 0.4972\n",
      "Iteration 730: Weights = [5.49641858e+01 4.07734278e+00 8.57939442e+00 4.61550203e-02\n",
      " 2.77217495e-01 1.03683263e+01], Loss = 0.4972\n",
      "Iteration 731: Weights = [5.49645440e+01 4.07725931e+00 8.57917083e+00 4.60219278e-02\n",
      " 2.77266155e-01 1.03686247e+01], Loss = 0.4971\n",
      "Iteration 732: Weights = [5.49648985e+01 4.07717560e+00 8.57894708e+00 4.58898206e-02\n",
      " 2.77314455e-01 1.03689228e+01], Loss = 0.4971\n",
      "Iteration 733: Weights = [5.49652496e+01 4.07709164e+00 8.57872315e+00 4.57586914e-02\n",
      " 2.77362398e-01 1.03692206e+01], Loss = 0.4970\n",
      "Iteration 734: Weights = [5.49655971e+01 4.07700744e+00 8.57849905e+00 4.56285327e-02\n",
      " 2.77409986e-01 1.03695181e+01], Loss = 0.4969\n",
      "Iteration 735: Weights = [5.49659411e+01 4.07692300e+00 8.57827479e+00 4.54993372e-02\n",
      " 2.77457220e-01 1.03698153e+01], Loss = 0.4969\n",
      "Iteration 736: Weights = [5.49662817e+01 4.07683831e+00 8.57805036e+00 4.53710979e-02\n",
      " 2.77504102e-01 1.03701123e+01], Loss = 0.4968\n",
      "Iteration 737: Weights = [5.49666189e+01 4.07675339e+00 8.57782577e+00 4.52438074e-02\n",
      " 2.77550635e-01 1.03704089e+01], Loss = 0.4968\n",
      "Iteration 738: Weights = [5.49669527e+01 4.07666823e+00 8.57760101e+00 4.51174586e-02\n",
      " 2.77596821e-01 1.03707053e+01], Loss = 0.4967\n",
      "Iteration 739: Weights = [5.49672831e+01 4.07658284e+00 8.57737609e+00 4.49920445e-02\n",
      " 2.77642662e-01 1.03710014e+01], Loss = 0.4967\n",
      "Iteration 740: Weights = [5.49676103e+01 4.07649721e+00 8.57715101e+00 4.48675580e-02\n",
      " 2.77688159e-01 1.03712972e+01], Loss = 0.4966\n",
      "Iteration 741: Weights = [5.49679342e+01 4.07641135e+00 8.57692577e+00 4.47439922e-02\n",
      " 2.77733314e-01 1.03715927e+01], Loss = 0.4966\n",
      "Iteration 742: Weights = [5.49682549e+01 4.07632526e+00 8.57670038e+00 4.46213402e-02\n",
      " 2.77778130e-01 1.03718880e+01], Loss = 0.4965\n",
      "Iteration 743: Weights = [5.49685723e+01 4.07623895e+00 8.57647483e+00 4.44995951e-02\n",
      " 2.77822609e-01 1.03721829e+01], Loss = 0.4965\n",
      "Iteration 744: Weights = [5.49688866e+01 4.07615241e+00 8.57624912e+00 4.43787501e-02\n",
      " 2.77866752e-01 1.03724776e+01], Loss = 0.4964\n",
      "Iteration 745: Weights = [5.49691977e+01 4.07606564e+00 8.57602326e+00 4.42587984e-02\n",
      " 2.77910562e-01 1.03727721e+01], Loss = 0.4963\n",
      "Iteration 746: Weights = [5.49695058e+01 4.07597865e+00 8.57579724e+00 4.41397333e-02\n",
      " 2.77954040e-01 1.03730662e+01], Loss = 0.4963\n",
      "Iteration 747: Weights = [5.49698107e+01 4.07589145e+00 8.57557108e+00 4.40215482e-02\n",
      " 2.77997188e-01 1.03733601e+01], Loss = 0.4962\n",
      "Iteration 748: Weights = [5.49701126e+01 4.07580402e+00 8.57534476e+00 4.39042366e-02\n",
      " 2.78040008e-01 1.03736538e+01], Loss = 0.4962\n",
      "Iteration 749: Weights = [5.49704115e+01 4.07571637e+00 8.57511830e+00 4.37877917e-02\n",
      " 2.78082503e-01 1.03739471e+01], Loss = 0.4961\n",
      "Iteration 750: Weights = [5.49707074e+01 4.07562852e+00 8.57489168e+00 4.36722071e-02\n",
      " 2.78124673e-01 1.03742402e+01], Loss = 0.4961\n",
      "Iteration 751: Weights = [5.49710003e+01 4.07554044e+00 8.57466493e+00 4.35574764e-02\n",
      " 2.78166522e-01 1.03745331e+01], Loss = 0.4960\n",
      "Iteration 752: Weights = [5.49712903e+01 4.07545216e+00 8.57443802e+00 4.34435932e-02\n",
      " 2.78208050e-01 1.03748257e+01], Loss = 0.4960\n",
      "Iteration 753: Weights = [5.49715774e+01 4.07536366e+00 8.57421097e+00 4.33305510e-02\n",
      " 2.78249260e-01 1.03751180e+01], Loss = 0.4959\n",
      "Iteration 754: Weights = [5.49718616e+01 4.07527495e+00 8.57398378e+00 4.32183437e-02\n",
      " 2.78290154e-01 1.03754101e+01], Loss = 0.4959\n",
      "Iteration 755: Weights = [5.49721430e+01 4.07518604e+00 8.57375645e+00 4.31069649e-02\n",
      " 2.78330733e-01 1.03757020e+01], Loss = 0.4958\n",
      "Iteration 756: Weights = [5.49724216e+01 4.07509692e+00 8.57352898e+00 4.29964084e-02\n",
      " 2.78370999e-01 1.03759936e+01], Loss = 0.4958\n",
      "Iteration 757: Weights = [5.49726973e+01 4.07500760e+00 8.57330137e+00 4.28866680e-02\n",
      " 2.78410954e-01 1.03762849e+01], Loss = 0.4958\n",
      "Iteration 758: Weights = [5.49729704e+01 4.07491807e+00 8.57307362e+00 4.27777377e-02\n",
      " 2.78450601e-01 1.03765760e+01], Loss = 0.4957\n",
      "Iteration 759: Weights = [5.49732407e+01 4.07482835e+00 8.57284573e+00 4.26696113e-02\n",
      " 2.78489940e-01 1.03768669e+01], Loss = 0.4957\n",
      "Iteration 760: Weights = [5.49735083e+01 4.07473842e+00 8.57261771e+00 4.25622829e-02\n",
      " 2.78528973e-01 1.03771575e+01], Loss = 0.4956\n",
      "Iteration 761: Weights = [5.49737732e+01 4.07464830e+00 8.57238955e+00 4.24557464e-02\n",
      " 2.78567703e-01 1.03774479e+01], Loss = 0.4956\n",
      "Iteration 762: Weights = [5.49740354e+01 4.07455798e+00 8.57216126e+00 4.23499959e-02\n",
      " 2.78606131e-01 1.03777380e+01], Loss = 0.4955\n",
      "Iteration 763: Weights = [5.49742951e+01 4.07446747e+00 8.57193284e+00 4.22450255e-02\n",
      " 2.78644259e-01 1.03780279e+01], Loss = 0.4955\n",
      "Iteration 764: Weights = [5.49745521e+01 4.07437676e+00 8.57170428e+00 4.21408294e-02\n",
      " 2.78682089e-01 1.03783176e+01], Loss = 0.4954\n",
      "Iteration 765: Weights = [5.49748066e+01 4.07428586e+00 8.57147560e+00 4.20374017e-02\n",
      " 2.78719622e-01 1.03786070e+01], Loss = 0.4954\n",
      "Iteration 766: Weights = [5.49750585e+01 4.07419477e+00 8.57124679e+00 4.19347368e-02\n",
      " 2.78756861e-01 1.03788962e+01], Loss = 0.4953\n",
      "Iteration 767: Weights = [5.49753080e+01 4.07410349e+00 8.57101784e+00 4.18328289e-02\n",
      " 2.78793807e-01 1.03791852e+01], Loss = 0.4953\n",
      "Iteration 768: Weights = [5.49755549e+01 4.07401202e+00 8.57078878e+00 4.17316722e-02\n",
      " 2.78830461e-01 1.03794740e+01], Loss = 0.4953\n",
      "Iteration 769: Weights = [5.49757993e+01 4.07392037e+00 8.57055958e+00 4.16312613e-02\n",
      " 2.78866826e-01 1.03797625e+01], Loss = 0.4952\n",
      "Iteration 770: Weights = [5.49760413e+01 4.07382853e+00 8.57033026e+00 4.15315905e-02\n",
      " 2.78902903e-01 1.03800508e+01], Loss = 0.4952\n",
      "Iteration 771: Weights = [5.49762809e+01 4.07373651e+00 8.57010082e+00 4.14326542e-02\n",
      " 2.78938694e-01 1.03803389e+01], Loss = 0.4951\n",
      "Iteration 772: Weights = [5.49765181e+01 4.07364431e+00 8.56987125e+00 4.13344470e-02\n",
      " 2.78974201e-01 1.03806267e+01], Loss = 0.4951\n",
      "Iteration 773: Weights = [5.49767529e+01 4.07355193e+00 8.56964157e+00 4.12369634e-02\n",
      " 2.79009425e-01 1.03809144e+01], Loss = 0.4950\n",
      "Iteration 774: Weights = [5.49769854e+01 4.07345936e+00 8.56941176e+00 4.11401980e-02\n",
      " 2.79044368e-01 1.03812018e+01], Loss = 0.4950\n",
      "Iteration 775: Weights = [5.49772156e+01 4.07336663e+00 8.56918183e+00 4.10441454e-02\n",
      " 2.79079031e-01 1.03814890e+01], Loss = 0.4950\n",
      "Iteration 776: Weights = [5.49774434e+01 4.07327371e+00 8.56895179e+00 4.09488003e-02\n",
      " 2.79113418e-01 1.03817760e+01], Loss = 0.4949\n",
      "Iteration 777: Weights = [5.49776690e+01 4.07318062e+00 8.56872162e+00 4.08541573e-02\n",
      " 2.79147528e-01 1.03820628e+01], Loss = 0.4949\n",
      "Iteration 778: Weights = [5.49778923e+01 4.07308736e+00 8.56849134e+00 4.07602112e-02\n",
      " 2.79181364e-01 1.03823494e+01], Loss = 0.4948\n",
      "Iteration 779: Weights = [5.49781134e+01 4.07299392e+00 8.56826094e+00 4.06669568e-02\n",
      " 2.79214927e-01 1.03826357e+01], Loss = 0.4948\n",
      "Iteration 780: Weights = [5.49783322e+01 4.07290031e+00 8.56803043e+00 4.05743890e-02\n",
      " 2.79248220e-01 1.03829219e+01], Loss = 0.4948\n",
      "Iteration 781: Weights = [5.49785489e+01 4.07280654e+00 8.56779981e+00 4.04825025e-02\n",
      " 2.79281243e-01 1.03832078e+01], Loss = 0.4947\n",
      "Iteration 782: Weights = [5.49787634e+01 4.07271259e+00 8.56756907e+00 4.03912923e-02\n",
      " 2.79313998e-01 1.03834936e+01], Loss = 0.4947\n",
      "Iteration 783: Weights = [5.49789758e+01 4.07261848e+00 8.56733822e+00 4.03007533e-02\n",
      " 2.79346487e-01 1.03837791e+01], Loss = 0.4946\n",
      "Iteration 784: Weights = [5.49791860e+01 4.07252421e+00 8.56710726e+00 4.02108805e-02\n",
      " 2.79378712e-01 1.03840645e+01], Loss = 0.4946\n",
      "Iteration 785: Weights = [5.49793942e+01 4.07242976e+00 8.56687619e+00 4.01216689e-02\n",
      " 2.79410674e-01 1.03843496e+01], Loss = 0.4946\n",
      "Iteration 786: Weights = [5.49796002e+01 4.07233516e+00 8.56664501e+00 4.00331136e-02\n",
      " 2.79442375e-01 1.03846346e+01], Loss = 0.4945\n",
      "Iteration 787: Weights = [5.49798042e+01 4.07224039e+00 8.56641372e+00 3.99452096e-02\n",
      " 2.79473815e-01 1.03849193e+01], Loss = 0.4945\n",
      "Iteration 788: Weights = [5.49800062e+01 4.07214547e+00 8.56618233e+00 3.98579521e-02\n",
      " 2.79504998e-01 1.03852039e+01], Loss = 0.4944\n",
      "Iteration 789: Weights = [5.49802061e+01 4.07205038e+00 8.56595083e+00 3.97713363e-02\n",
      " 2.79535924e-01 1.03854882e+01], Loss = 0.4944\n",
      "Iteration 790: Weights = [5.49804040e+01 4.07195514e+00 8.56571922e+00 3.96853573e-02\n",
      " 2.79566596e-01 1.03857724e+01], Loss = 0.4944\n",
      "Iteration 791: Weights = [5.49806000e+01 4.07185974e+00 8.56548751e+00 3.96000104e-02\n",
      " 2.79597013e-01 1.03860563e+01], Loss = 0.4943\n",
      "Iteration 792: Weights = [5.49807940e+01 4.07176418e+00 8.56525569e+00 3.95152908e-02\n",
      " 2.79627179e-01 1.03863401e+01], Loss = 0.4943\n",
      "Iteration 793: Weights = [5.49809861e+01 4.07166847e+00 8.56502378e+00 3.94311939e-02\n",
      " 2.79657094e-01 1.03866237e+01], Loss = 0.4943\n",
      "Iteration 794: Weights = [5.49811762e+01 4.07157260e+00 8.56479176e+00 3.93477150e-02\n",
      " 2.79686761e-01 1.03869071e+01], Loss = 0.4942\n",
      "Iteration 795: Weights = [5.49813644e+01 4.07147659e+00 8.56455964e+00 3.92648495e-02\n",
      " 2.79716180e-01 1.03871904e+01], Loss = 0.4942\n",
      "Iteration 796: Weights = [5.49815508e+01 4.07138042e+00 8.56432742e+00 3.91825928e-02\n",
      " 2.79745354e-01 1.03874734e+01], Loss = 0.4941\n",
      "Iteration 797: Weights = [5.49817353e+01 4.07128410e+00 8.56409510e+00 3.91009404e-02\n",
      " 2.79774283e-01 1.03877562e+01], Loss = 0.4941\n",
      "Iteration 798: Weights = [5.49819179e+01 4.07118763e+00 8.56386268e+00 3.90198876e-02\n",
      " 2.79802969e-01 1.03880389e+01], Loss = 0.4941\n",
      "Iteration 799: Weights = [5.49820988e+01 4.07109102e+00 8.56363016e+00 3.89394302e-02\n",
      " 2.79831414e-01 1.03883214e+01], Loss = 0.4940\n",
      "Iteration 800: Weights = [5.49822778e+01 4.07099426e+00 8.56339755e+00 3.88595635e-02\n",
      " 2.79859619e-01 1.03886037e+01], Loss = 0.4940\n",
      "Iteration 801: Weights = [5.49824550e+01 4.07089735e+00 8.56316484e+00 3.87802832e-02\n",
      " 2.79887586e-01 1.03888859e+01], Loss = 0.4940\n",
      "Iteration 802: Weights = [5.49826304e+01 4.07080030e+00 8.56293203e+00 3.87015849e-02\n",
      " 2.79915316e-01 1.03891678e+01], Loss = 0.4939\n",
      "Iteration 803: Weights = [5.49828041e+01 4.07070311e+00 8.56269913e+00 3.86234643e-02\n",
      " 2.79942810e-01 1.03894496e+01], Loss = 0.4939\n",
      "Iteration 804: Weights = [5.49829761e+01 4.07060578e+00 8.56246614e+00 3.85459170e-02\n",
      " 2.79970070e-01 1.03897312e+01], Loss = 0.4938\n",
      "Iteration 805: Weights = [5.49831463e+01 4.07050830e+00 8.56223306e+00 3.84689387e-02\n",
      " 2.79997098e-01 1.03900126e+01], Loss = 0.4938\n",
      "Iteration 806: Weights = [5.49833149e+01 4.07041069e+00 8.56199988e+00 3.83925253e-02\n",
      " 2.80023894e-01 1.03902939e+01], Loss = 0.4938\n",
      "Iteration 807: Weights = [5.49834817e+01 4.07031293e+00 8.56176661e+00 3.83166724e-02\n",
      " 2.80050461e-01 1.03905750e+01], Loss = 0.4937\n",
      "Iteration 808: Weights = [5.49836469e+01 4.07021504e+00 8.56153325e+00 3.82413760e-02\n",
      " 2.80076800e-01 1.03908559e+01], Loss = 0.4937\n",
      "Iteration 809: Weights = [5.49838104e+01 4.07011701e+00 8.56129980e+00 3.81666318e-02\n",
      " 2.80102912e-01 1.03911367e+01], Loss = 0.4937\n",
      "Iteration 810: Weights = [5.49839723e+01 4.07001885e+00 8.56106626e+00 3.80924357e-02\n",
      " 2.80128798e-01 1.03914173e+01], Loss = 0.4936\n",
      "Iteration 811: Weights = [5.49841326e+01 4.06992055e+00 8.56083264e+00 3.80187836e-02\n",
      " 2.80154460e-01 1.03916977e+01], Loss = 0.4936\n",
      "Iteration 812: Weights = [5.49842913e+01 4.06982212e+00 8.56059892e+00 3.79456715e-02\n",
      " 2.80179899e-01 1.03919780e+01], Loss = 0.4936\n",
      "Iteration 813: Weights = [5.49844484e+01 4.06972355e+00 8.56036512e+00 3.78730953e-02\n",
      " 2.80205117e-01 1.03922581e+01], Loss = 0.4935\n",
      "Iteration 814: Weights = [5.49846039e+01 4.06962486e+00 8.56013124e+00 3.78010510e-02\n",
      " 2.80230115e-01 1.03925380e+01], Loss = 0.4935\n",
      "Iteration 815: Weights = [5.49847578e+01 4.06952603e+00 8.55989726e+00 3.77295347e-02\n",
      " 2.80254895e-01 1.03928178e+01], Loss = 0.4935\n",
      "Iteration 816: Weights = [5.49849103e+01 4.06942708e+00 8.55966321e+00 3.76585424e-02\n",
      " 2.80279457e-01 1.03930974e+01], Loss = 0.4934\n",
      "Iteration 817: Weights = [5.49850612e+01 4.06932799e+00 8.55942907e+00 3.75880703e-02\n",
      " 2.80303804e-01 1.03933769e+01], Loss = 0.4934\n",
      "Iteration 818: Weights = [5.49852106e+01 4.06922878e+00 8.55919485e+00 3.75181143e-02\n",
      " 2.80327936e-01 1.03936562e+01], Loss = 0.4934\n",
      "Iteration 819: Weights = [5.49853584e+01 4.06912944e+00 8.55896054e+00 3.74486707e-02\n",
      " 2.80351854e-01 1.03939354e+01], Loss = 0.4933\n",
      "Iteration 820: Weights = [5.49855049e+01 4.06902998e+00 8.55872615e+00 3.73797356e-02\n",
      " 2.80375561e-01 1.03942143e+01], Loss = 0.4933\n",
      "Iteration 821: Weights = [5.49856498e+01 4.06893039e+00 8.55849169e+00 3.73113053e-02\n",
      " 2.80399057e-01 1.03944932e+01], Loss = 0.4933\n",
      "Iteration 822: Weights = [5.49857933e+01 4.06883068e+00 8.55825714e+00 3.72433760e-02\n",
      " 2.80422344e-01 1.03947719e+01], Loss = 0.4932\n",
      "Iteration 823: Weights = [5.49859354e+01 4.06873085e+00 8.55802251e+00 3.71759440e-02\n",
      " 2.80445423e-01 1.03950504e+01], Loss = 0.4932\n",
      "Iteration 824: Weights = [5.49860760e+01 4.06863089e+00 8.55778780e+00 3.71090054e-02\n",
      " 2.80468296e-01 1.03953288e+01], Loss = 0.4932\n",
      "Iteration 825: Weights = [5.49862153e+01 4.06853082e+00 8.55755302e+00 3.70425567e-02\n",
      " 2.80490963e-01 1.03956071e+01], Loss = 0.4931\n",
      "Iteration 826: Weights = [5.49863531e+01 4.06843062e+00 8.55731816e+00 3.69765943e-02\n",
      " 2.80513426e-01 1.03958851e+01], Loss = 0.4931\n",
      "Iteration 827: Weights = [5.49864896e+01 4.06833030e+00 8.55708322e+00 3.69111143e-02\n",
      " 2.80535686e-01 1.03961631e+01], Loss = 0.4931\n",
      "Iteration 828: Weights = [5.49866247e+01 4.06822987e+00 8.55684820e+00 3.68461134e-02\n",
      " 2.80557745e-01 1.03964409e+01], Loss = 0.4930\n",
      "Iteration 829: Weights = [5.49867584e+01 4.06812932e+00 8.55661311e+00 3.67815879e-02\n",
      " 2.80579603e-01 1.03967185e+01], Loss = 0.4930\n",
      "Iteration 830: Weights = [5.49868909e+01 4.06802865e+00 8.55637794e+00 3.67175342e-02\n",
      " 2.80601263e-01 1.03969961e+01], Loss = 0.4930\n",
      "Iteration 831: Weights = [5.49870220e+01 4.06792787e+00 8.55614270e+00 3.66539488e-02\n",
      " 2.80622724e-01 1.03972734e+01], Loss = 0.4929\n",
      "Iteration 832: Weights = [5.49871517e+01 4.06782698e+00 8.55590739e+00 3.65908283e-02\n",
      " 2.80643989e-01 1.03975507e+01], Loss = 0.4929\n",
      "Iteration 833: Weights = [5.49872802e+01 4.06772597e+00 8.55567200e+00 3.65281692e-02\n",
      " 2.80665059e-01 1.03978277e+01], Loss = 0.4929\n",
      "Iteration 834: Weights = [5.49874074e+01 4.06762485e+00 8.55543654e+00 3.64659680e-02\n",
      " 2.80685935e-01 1.03981047e+01], Loss = 0.4928\n",
      "Iteration 835: Weights = [5.49875333e+01 4.06752361e+00 8.55520101e+00 3.64042213e-02\n",
      " 2.80706618e-01 1.03983815e+01], Loss = 0.4928\n",
      "Iteration 836: Weights = [5.49876580e+01 4.06742227e+00 8.55496541e+00 3.63429258e-02\n",
      " 2.80727110e-01 1.03986582e+01], Loss = 0.4928\n",
      "Iteration 837: Weights = [5.49877814e+01 4.06732081e+00 8.55472974e+00 3.62820780e-02\n",
      " 2.80747411e-01 1.03989347e+01], Loss = 0.4927\n",
      "Iteration 838: Weights = [5.49879036e+01 4.06721925e+00 8.55449400e+00 3.62216747e-02\n",
      " 2.80767522e-01 1.03992111e+01], Loss = 0.4927\n",
      "Iteration 839: Weights = [5.49880246e+01 4.06711757e+00 8.55425818e+00 3.61617125e-02\n",
      " 2.80787446e-01 1.03994874e+01], Loss = 0.4927\n",
      "Iteration 840: Weights = [5.49881443e+01 4.06701579e+00 8.55402230e+00 3.61021882e-02\n",
      " 2.80807183e-01 1.03997635e+01], Loss = 0.4926\n",
      "Iteration 841: Weights = [5.49882629e+01 4.06691391e+00 8.55378635e+00 3.60430984e-02\n",
      " 2.80826735e-01 1.04000395e+01], Loss = 0.4926\n",
      "Iteration 842: Weights = [5.49883803e+01 4.06681191e+00 8.55355034e+00 3.59844399e-02\n",
      " 2.80846102e-01 1.04003154e+01], Loss = 0.4926\n",
      "Iteration 843: Weights = [5.49884965e+01 4.06670982e+00 8.55331426e+00 3.59262096e-02\n",
      " 2.80865285e-01 1.04005911e+01], Loss = 0.4925\n",
      "Iteration 844: Weights = [5.49886115e+01 4.06660761e+00 8.55307811e+00 3.58684042e-02\n",
      " 2.80884287e-01 1.04008667e+01], Loss = 0.4925\n",
      "Iteration 845: Weights = [5.49887254e+01 4.06650531e+00 8.55284189e+00 3.58110205e-02\n",
      " 2.80903107e-01 1.04011422e+01], Loss = 0.4925\n",
      "Iteration 846: Weights = [5.49888381e+01 4.06640290e+00 8.55260561e+00 3.57540555e-02\n",
      " 2.80921748e-01 1.04014175e+01], Loss = 0.4924\n",
      "Iteration 847: Weights = [5.49889497e+01 4.06630039e+00 8.55236926e+00 3.56975060e-02\n",
      " 2.80940210e-01 1.04016928e+01], Loss = 0.4924\n",
      "Iteration 848: Weights = [5.49890602e+01 4.06619778e+00 8.55213286e+00 3.56413689e-02\n",
      " 2.80958494e-01 1.04019679e+01], Loss = 0.4924\n",
      "Iteration 849: Weights = [5.49891696e+01 4.06609507e+00 8.55189638e+00 3.55856411e-02\n",
      " 2.80976602e-01 1.04022428e+01], Loss = 0.4923\n",
      "Iteration 850: Weights = [5.49892779e+01 4.06599225e+00 8.55165985e+00 3.55303197e-02\n",
      " 2.80994534e-01 1.04025177e+01], Loss = 0.4923\n",
      "Iteration 851: Weights = [5.49893852e+01 4.06588934e+00 8.55142325e+00 3.54754015e-02\n",
      " 2.81012293e-01 1.04027924e+01], Loss = 0.4923\n",
      "Iteration 852: Weights = [5.49894913e+01 4.06578634e+00 8.55118659e+00 3.54208835e-02\n",
      " 2.81029878e-01 1.04030670e+01], Loss = 0.4922\n",
      "Iteration 853: Weights = [5.49895964e+01 4.06568323e+00 8.55094987e+00 3.53667629e-02\n",
      " 2.81047291e-01 1.04033415e+01], Loss = 0.4922\n",
      "Iteration 854: Weights = [5.49897004e+01 4.06558003e+00 8.55071308e+00 3.53130365e-02\n",
      " 2.81064534e-01 1.04036158e+01], Loss = 0.4922\n",
      "Iteration 855: Weights = [5.49898034e+01 4.06547673e+00 8.55047624e+00 3.52597016e-02\n",
      " 2.81081606e-01 1.04038901e+01], Loss = 0.4922\n",
      "Iteration 856: Weights = [5.49899054e+01 4.06537334e+00 8.55023934e+00 3.52067551e-02\n",
      " 2.81098510e-01 1.04041642e+01], Loss = 0.4921\n",
      "Iteration 857: Weights = [5.49900063e+01 4.06526985e+00 8.55000238e+00 3.51541942e-02\n",
      " 2.81115246e-01 1.04044382e+01], Loss = 0.4921\n",
      "Iteration 858: Weights = [5.49901063e+01 4.06516627e+00 8.54976536e+00 3.51020160e-02\n",
      " 2.81131816e-01 1.04047121e+01], Loss = 0.4921\n",
      "Iteration 859: Weights = [5.49902052e+01 4.06506259e+00 8.54952828e+00 3.50502177e-02\n",
      " 2.81148220e-01 1.04049858e+01], Loss = 0.4920\n",
      "Iteration 860: Weights = [5.49903032e+01 4.06495883e+00 8.54929114e+00 3.49987964e-02\n",
      " 2.81164460e-01 1.04052595e+01], Loss = 0.4920\n",
      "Iteration 861: Weights = [5.49904001e+01 4.06485497e+00 8.54905395e+00 3.49477493e-02\n",
      " 2.81180536e-01 1.04055330e+01], Loss = 0.4920\n",
      "Iteration 862: Weights = [5.49904961e+01 4.06475102e+00 8.54881670e+00 3.48970737e-02\n",
      " 2.81196450e-01 1.04058065e+01], Loss = 0.4919\n",
      "Iteration 863: Weights = [5.49905912e+01 4.06464698e+00 8.54857940e+00 3.48467668e-02\n",
      " 2.81212203e-01 1.04060798e+01], Loss = 0.4919\n",
      "Iteration 864: Weights = [5.49906853e+01 4.06454285e+00 8.54834203e+00 3.47968258e-02\n",
      " 2.81227795e-01 1.04063530e+01], Loss = 0.4919\n",
      "Iteration 865: Weights = [5.49907784e+01 4.06443864e+00 8.54810462e+00 3.47472480e-02\n",
      " 2.81243228e-01 1.04066260e+01], Loss = 0.4918\n",
      "Iteration 866: Weights = [5.49908706e+01 4.06433433e+00 8.54786714e+00 3.46980307e-02\n",
      " 2.81258503e-01 1.04068990e+01], Loss = 0.4918\n",
      "Iteration 867: Weights = [5.49909619e+01 4.06422994e+00 8.54762962e+00 3.46491713e-02\n",
      " 2.81273620e-01 1.04071719e+01], Loss = 0.4918\n",
      "Iteration 868: Weights = [5.49910523e+01 4.06412546e+00 8.54739204e+00 3.46006671e-02\n",
      " 2.81288582e-01 1.04074446e+01], Loss = 0.4918\n",
      "Iteration 869: Weights = [5.49911418e+01 4.06402090e+00 8.54715441e+00 3.45525153e-02\n",
      " 2.81303388e-01 1.04077173e+01], Loss = 0.4917\n",
      "Iteration 870: Weights = [5.49912304e+01 4.06391625e+00 8.54691672e+00 3.45047135e-02\n",
      " 2.81318040e-01 1.04079898e+01], Loss = 0.4917\n",
      "Iteration 871: Weights = [5.49913181e+01 4.06381151e+00 8.54667898e+00 3.44572590e-02\n",
      " 2.81332538e-01 1.04082622e+01], Loss = 0.4917\n",
      "Iteration 872: Weights = [5.49914049e+01 4.06370669e+00 8.54644119e+00 3.44101492e-02\n",
      " 2.81346885e-01 1.04085346e+01], Loss = 0.4916\n",
      "Iteration 873: Weights = [5.49914908e+01 4.06360179e+00 8.54620335e+00 3.43633815e-02\n",
      " 2.81361080e-01 1.04088068e+01], Loss = 0.4916\n",
      "Iteration 874: Weights = [5.49915759e+01 4.06349680e+00 8.54596546e+00 3.43169535e-02\n",
      " 2.81375125e-01 1.04090789e+01], Loss = 0.4916\n",
      "Iteration 875: Weights = [5.49916602e+01 4.06339174e+00 8.54572752e+00 3.42708625e-02\n",
      " 2.81389021e-01 1.04093509e+01], Loss = 0.4915\n",
      "Iteration 876: Weights = [5.49917436e+01 4.06328659e+00 8.54548952e+00 3.42251062e-02\n",
      " 2.81402768e-01 1.04096228e+01], Loss = 0.4915\n",
      "Iteration 877: Weights = [5.49918261e+01 4.06318136e+00 8.54525148e+00 3.41796819e-02\n",
      " 2.81416368e-01 1.04098946e+01], Loss = 0.4915\n",
      "Iteration 878: Weights = [5.49919079e+01 4.06307605e+00 8.54501339e+00 3.41345873e-02\n",
      " 2.81429821e-01 1.04101663e+01], Loss = 0.4915\n",
      "Iteration 879: Weights = [5.49919888e+01 4.06297066e+00 8.54477525e+00 3.40898198e-02\n",
      " 2.81443129e-01 1.04104379e+01], Loss = 0.4914\n",
      "Iteration 880: Weights = [5.49920689e+01 4.06286519e+00 8.54453706e+00 3.40453771e-02\n",
      " 2.81456293e-01 1.04107094e+01], Loss = 0.4914\n",
      "Iteration 881: Weights = [5.49921482e+01 4.06275964e+00 8.54429883e+00 3.40012567e-02\n",
      " 2.81469312e-01 1.04109808e+01], Loss = 0.4914\n",
      "Iteration 882: Weights = [5.49922267e+01 4.06265402e+00 8.54406054e+00 3.39574562e-02\n",
      " 2.81482190e-01 1.04112521e+01], Loss = 0.4913\n",
      "Iteration 883: Weights = [5.49923045e+01 4.06254832e+00 8.54382221e+00 3.39139733e-02\n",
      " 2.81494925e-01 1.04115233e+01], Loss = 0.4913\n",
      "Iteration 884: Weights = [5.49923814e+01 4.06244254e+00 8.54358383e+00 3.38708056e-02\n",
      " 2.81507519e-01 1.04117944e+01], Loss = 0.4913\n",
      "Iteration 885: Weights = [5.49924576e+01 4.06233668e+00 8.54334541e+00 3.38279508e-02\n",
      " 2.81519974e-01 1.04120655e+01], Loss = 0.4912\n",
      "Iteration 886: Weights = [5.49925330e+01 4.06223075e+00 8.54310694e+00 3.37854065e-02\n",
      " 2.81532289e-01 1.04123364e+01], Loss = 0.4912\n",
      "Iteration 887: Weights = [5.49926077e+01 4.06212475e+00 8.54286843e+00 3.37431704e-02\n",
      " 2.81544467e-01 1.04126072e+01], Loss = 0.4912\n",
      "Iteration 888: Weights = [5.49926816e+01 4.06201867e+00 8.54262987e+00 3.37012402e-02\n",
      " 2.81556507e-01 1.04128779e+01], Loss = 0.4912\n",
      "Iteration 889: Weights = [5.49927548e+01 4.06191252e+00 8.54239126e+00 3.36596137e-02\n",
      " 2.81568411e-01 1.04131485e+01], Loss = 0.4911\n",
      "Iteration 890: Weights = [5.49928272e+01 4.06180629e+00 8.54215262e+00 3.36182886e-02\n",
      " 2.81580179e-01 1.04134191e+01], Loss = 0.4911\n",
      "Iteration 891: Weights = [5.49928990e+01 4.06169999e+00 8.54191393e+00 3.35772627e-02\n",
      " 2.81591813e-01 1.04136895e+01], Loss = 0.4911\n",
      "Iteration 892: Weights = [5.49929700e+01 4.06159362e+00 8.54167519e+00 3.35365337e-02\n",
      " 2.81603313e-01 1.04139599e+01], Loss = 0.4910\n",
      "Iteration 893: Weights = [5.49930403e+01 4.06148718e+00 8.54143641e+00 3.34960995e-02\n",
      " 2.81614680e-01 1.04142301e+01], Loss = 0.4910\n",
      "Iteration 894: Weights = [5.49931099e+01 4.06138067e+00 8.54119759e+00 3.34559578e-02\n",
      " 2.81625915e-01 1.04145003e+01], Loss = 0.4910\n",
      "Iteration 895: Weights = [5.49931788e+01 4.06127408e+00 8.54095873e+00 3.34161065e-02\n",
      " 2.81637020e-01 1.04147704e+01], Loss = 0.4909\n",
      "Iteration 896: Weights = [5.49932470e+01 4.06116743e+00 8.54071982e+00 3.33765434e-02\n",
      " 2.81647993e-01 1.04150403e+01], Loss = 0.4909\n",
      "Iteration 897: Weights = [5.49933145e+01 4.06106071e+00 8.54048088e+00 3.33372664e-02\n",
      " 2.81658838e-01 1.04153102e+01], Loss = 0.4909\n",
      "Iteration 898: Weights = [5.49933814e+01 4.06095392e+00 8.54024189e+00 3.32982733e-02\n",
      " 2.81669554e-01 1.04155800e+01], Loss = 0.4909\n",
      "Iteration 899: Weights = [5.49934476e+01 4.06084706e+00 8.54000286e+00 3.32595621e-02\n",
      " 2.81680142e-01 1.04158498e+01], Loss = 0.4908\n",
      "Iteration 900: Weights = [5.49935131e+01 4.06074013e+00 8.53976380e+00 3.32211307e-02\n",
      " 2.81690603e-01 1.04161194e+01], Loss = 0.4908\n",
      "Iteration 901: Weights = [5.49935780e+01 4.06063314e+00 8.53952469e+00 3.31829769e-02\n",
      " 2.81700939e-01 1.04163890e+01], Loss = 0.4908\n",
      "Iteration 902: Weights = [5.49936422e+01 4.06052608e+00 8.53928554e+00 3.31450988e-02\n",
      " 2.81711149e-01 1.04166584e+01], Loss = 0.4907\n",
      "Iteration 903: Weights = [5.49937058e+01 4.06041895e+00 8.53904636e+00 3.31074942e-02\n",
      " 2.81721234e-01 1.04169278e+01], Loss = 0.4907\n",
      "Iteration 904: Weights = [5.49937687e+01 4.06031176e+00 8.53880713e+00 3.30701612e-02\n",
      " 2.81731196e-01 1.04171971e+01], Loss = 0.4907\n",
      "Iteration 905: Weights = [5.49938310e+01 4.06020450e+00 8.53856787e+00 3.30330977e-02\n",
      " 2.81741036e-01 1.04174663e+01], Loss = 0.4906\n",
      "Iteration 906: Weights = [5.49938927e+01 4.06009718e+00 8.53832857e+00 3.29963017e-02\n",
      " 2.81750753e-01 1.04177354e+01], Loss = 0.4906\n",
      "Iteration 907: Weights = [5.49939538e+01 4.05998979e+00 8.53808923e+00 3.29597712e-02\n",
      " 2.81760349e-01 1.04180044e+01], Loss = 0.4906\n",
      "Iteration 908: Weights = [5.49940142e+01 4.05988234e+00 8.53784985e+00 3.29235044e-02\n",
      " 2.81769825e-01 1.04182734e+01], Loss = 0.4906\n",
      "Iteration 909: Weights = [5.49940741e+01 4.05977483e+00 8.53761044e+00 3.28874991e-02\n",
      " 2.81779181e-01 1.04185423e+01], Loss = 0.4905\n",
      "Iteration 910: Weights = [5.49941334e+01 4.05966725e+00 8.53737099e+00 3.28517536e-02\n",
      " 2.81788418e-01 1.04188111e+01], Loss = 0.4905\n",
      "Iteration 911: Weights = [5.49941920e+01 4.05955961e+00 8.53713150e+00 3.28162657e-02\n",
      " 2.81797537e-01 1.04190798e+01], Loss = 0.4905\n",
      "Iteration 912: Weights = [5.49942501e+01 4.05945191e+00 8.53689198e+00 3.27810338e-02\n",
      " 2.81806539e-01 1.04193484e+01], Loss = 0.4904\n",
      "Iteration 913: Weights = [5.49943076e+01 4.05934415e+00 8.53665242e+00 3.27460557e-02\n",
      " 2.81815424e-01 1.04196170e+01], Loss = 0.4904\n",
      "Iteration 914: Weights = [5.49943645e+01 4.05923633e+00 8.53641282e+00 3.27113297e-02\n",
      " 2.81824194e-01 1.04198854e+01], Loss = 0.4904\n",
      "Iteration 915: Weights = [5.49944209e+01 4.05912845e+00 8.53617319e+00 3.26768539e-02\n",
      " 2.81832848e-01 1.04201538e+01], Loss = 0.4904\n",
      "Iteration 916: Weights = [5.49944767e+01 4.05902051e+00 8.53593353e+00 3.26426264e-02\n",
      " 2.81841389e-01 1.04204221e+01], Loss = 0.4903\n",
      "Iteration 917: Weights = [5.49945319e+01 4.05891251e+00 8.53569383e+00 3.26086454e-02\n",
      " 2.81849816e-01 1.04206904e+01], Loss = 0.4903\n",
      "Iteration 918: Weights = [5.49945866e+01 4.05880445e+00 8.53545410e+00 3.25749091e-02\n",
      " 2.81858130e-01 1.04209585e+01], Loss = 0.4903\n",
      "Iteration 919: Weights = [5.49946407e+01 4.05869633e+00 8.53521434e+00 3.25414156e-02\n",
      " 2.81866332e-01 1.04212266e+01], Loss = 0.4902\n",
      "Iteration 920: Weights = [5.49946943e+01 4.05858815e+00 8.53497454e+00 3.25081632e-02\n",
      " 2.81874423e-01 1.04214946e+01], Loss = 0.4902\n",
      "Iteration 921: Weights = [5.49947474e+01 4.05847992e+00 8.53473470e+00 3.24751500e-02\n",
      " 2.81882404e-01 1.04217626e+01], Loss = 0.4902\n",
      "Iteration 922: Weights = [5.49947999e+01 4.05837163e+00 8.53449484e+00 3.24423743e-02\n",
      " 2.81890275e-01 1.04220304e+01], Loss = 0.4902\n",
      "Iteration 923: Weights = [5.49948519e+01 4.05826328e+00 8.53425494e+00 3.24098344e-02\n",
      " 2.81898036e-01 1.04222982e+01], Loss = 0.4901\n",
      "Iteration 924: Weights = [5.49949034e+01 4.05815488e+00 8.53401501e+00 3.23775284e-02\n",
      " 2.81905690e-01 1.04225659e+01], Loss = 0.4901\n",
      "Iteration 925: Weights = [5.49949543e+01 4.05804642e+00 8.53377505e+00 3.23454546e-02\n",
      " 2.81913235e-01 1.04228335e+01], Loss = 0.4901\n",
      "Iteration 926: Weights = [5.49950048e+01 4.05793791e+00 8.53353506e+00 3.23136114e-02\n",
      " 2.81920674e-01 1.04231011e+01], Loss = 0.4900\n",
      "Iteration 927: Weights = [5.49950548e+01 4.05782934e+00 8.53329503e+00 3.22819969e-02\n",
      " 2.81928007e-01 1.04233686e+01], Loss = 0.4900\n",
      "Iteration 928: Weights = [5.49951042e+01 4.05772071e+00 8.53305498e+00 3.22506096e-02\n",
      " 2.81935234e-01 1.04236360e+01], Loss = 0.4900\n",
      "Iteration 929: Weights = [5.49951532e+01 4.05761204e+00 8.53281489e+00 3.22194478e-02\n",
      " 2.81942356e-01 1.04239034e+01], Loss = 0.4900\n",
      "Iteration 930: Weights = [5.49952016e+01 4.05750330e+00 8.53257477e+00 3.21885097e-02\n",
      " 2.81949374e-01 1.04241706e+01], Loss = 0.4899\n",
      "Iteration 931: Weights = [5.49952496e+01 4.05739452e+00 8.53233463e+00 3.21577936e-02\n",
      " 2.81956289e-01 1.04244378e+01], Loss = 0.4899\n",
      "Iteration 932: Weights = [5.49952971e+01 4.05728568e+00 8.53209445e+00 3.21272981e-02\n",
      " 2.81963101e-01 1.04247050e+01], Loss = 0.4899\n",
      "Iteration 933: Weights = [5.49953441e+01 4.05717679e+00 8.53185424e+00 3.20970214e-02\n",
      " 2.81969811e-01 1.04249720e+01], Loss = 0.4898\n",
      "Iteration 934: Weights = [5.49953907e+01 4.05706785e+00 8.53161401e+00 3.20669618e-02\n",
      " 2.81976419e-01 1.04252390e+01], Loss = 0.4898\n",
      "Iteration 935: Weights = [5.49954368e+01 4.05695886e+00 8.53137374e+00 3.20371179e-02\n",
      " 2.81982927e-01 1.04255060e+01], Loss = 0.4898\n",
      "Iteration 936: Weights = [5.49954824e+01 4.05684982e+00 8.53113345e+00 3.20074880e-02\n",
      " 2.81989335e-01 1.04257728e+01], Loss = 0.4897\n",
      "Iteration 937: Weights = [5.49955276e+01 4.05674072e+00 8.53089313e+00 3.19780705e-02\n",
      " 2.81995643e-01 1.04260396e+01], Loss = 0.4897\n",
      "Iteration 938: Weights = [5.49955723e+01 4.05663158e+00 8.53065278e+00 3.19488638e-02\n",
      " 2.82001853e-01 1.04263063e+01], Loss = 0.4897\n",
      "Iteration 939: Weights = [5.49956166e+01 4.05652238e+00 8.53041240e+00 3.19198664e-02\n",
      " 2.82007965e-01 1.04265730e+01], Loss = 0.4897\n",
      "Iteration 940: Weights = [5.49956604e+01 4.05641314e+00 8.53017200e+00 3.18910767e-02\n",
      " 2.82013979e-01 1.04268396e+01], Loss = 0.4896\n",
      "Iteration 941: Weights = [5.49957038e+01 4.05630384e+00 8.52993157e+00 3.18624932e-02\n",
      " 2.82019896e-01 1.04271061e+01], Loss = 0.4896\n",
      "Iteration 942: Weights = [5.49957468e+01 4.05619450e+00 8.52969111e+00 3.18341144e-02\n",
      " 2.82025718e-01 1.04273726e+01], Loss = 0.4896\n",
      "Iteration 943: Weights = [5.49957893e+01 4.05608511e+00 8.52945062e+00 3.18059387e-02\n",
      " 2.82031443e-01 1.04276390e+01], Loss = 0.4895\n",
      "Iteration 944: Weights = [5.49958314e+01 4.05597567e+00 8.52921011e+00 3.17779646e-02\n",
      " 2.82037074e-01 1.04279053e+01], Loss = 0.4895\n",
      "Iteration 945: Weights = [5.49958731e+01 4.05586618e+00 8.52896957e+00 3.17501907e-02\n",
      " 2.82042611e-01 1.04281716e+01], Loss = 0.4895\n",
      "Iteration 946: Weights = [5.49959144e+01 4.05575665e+00 8.52872900e+00 3.17226155e-02\n",
      " 2.82048054e-01 1.04284378e+01], Loss = 0.4895\n",
      "Iteration 947: Weights = [5.49959552e+01 4.05564707e+00 8.52848841e+00 3.16952375e-02\n",
      " 2.82053404e-01 1.04287039e+01], Loss = 0.4894\n",
      "Iteration 948: Weights = [5.49959957e+01 4.05553744e+00 8.52824780e+00 3.16680551e-02\n",
      " 2.82058662e-01 1.04289700e+01], Loss = 0.4894\n",
      "Iteration 949: Weights = [5.49960357e+01 4.05542777e+00 8.52800716e+00 3.16410671e-02\n",
      " 2.82063828e-01 1.04292360e+01], Loss = 0.4894\n",
      "Iteration 950: Weights = [5.49960754e+01 4.05531805e+00 8.52776649e+00 3.16142720e-02\n",
      " 2.82068903e-01 1.04295019e+01], Loss = 0.4893\n",
      "Iteration 951: Weights = [5.49961146e+01 4.05520828e+00 8.52752580e+00 3.15876682e-02\n",
      " 2.82073888e-01 1.04297678e+01], Loss = 0.4893\n",
      "Iteration 952: Weights = [5.49961535e+01 4.05509847e+00 8.52728508e+00 3.15612545e-02\n",
      " 2.82078782e-01 1.04300336e+01], Loss = 0.4893\n",
      "Iteration 953: Weights = [5.49961919e+01 4.05498862e+00 8.52704434e+00 3.15350293e-02\n",
      " 2.82083587e-01 1.04302994e+01], Loss = 0.4893\n",
      "Iteration 954: Weights = [5.49962300e+01 4.05487872e+00 8.52680358e+00 3.15089914e-02\n",
      " 2.82088304e-01 1.04305651e+01], Loss = 0.4892\n",
      "Iteration 955: Weights = [5.49962677e+01 4.05476878e+00 8.52656279e+00 3.14831392e-02\n",
      " 2.82092932e-01 1.04308308e+01], Loss = 0.4892\n",
      "Iteration 956: Weights = [5.49963050e+01 4.05465879e+00 8.52632198e+00 3.14574715e-02\n",
      " 2.82097473e-01 1.04310963e+01], Loss = 0.4892\n",
      "Iteration 957: Weights = [5.49963420e+01 4.05454876e+00 8.52608114e+00 3.14319869e-02\n",
      " 2.82101927e-01 1.04313619e+01], Loss = 0.4891\n",
      "Iteration 958: Weights = [5.49963786e+01 4.05443869e+00 8.52584029e+00 3.14066840e-02\n",
      " 2.82106294e-01 1.04316273e+01], Loss = 0.4891\n",
      "Iteration 959: Weights = [5.49964148e+01 4.05432857e+00 8.52559941e+00 3.13815615e-02\n",
      " 2.82110576e-01 1.04318927e+01], Loss = 0.4891\n",
      "Iteration 960: Weights = [5.49964506e+01 4.05421841e+00 8.52535850e+00 3.13566180e-02\n",
      " 2.82114772e-01 1.04321581e+01], Loss = 0.4891\n",
      "Iteration 961: Weights = [5.49964861e+01 4.05410821e+00 8.52511758e+00 3.13318522e-02\n",
      " 2.82118884e-01 1.04324234e+01], Loss = 0.4890\n",
      "Iteration 962: Weights = [5.49965213e+01 4.05399797e+00 8.52487663e+00 3.13072629e-02\n",
      " 2.82122912e-01 1.04326886e+01], Loss = 0.4890\n",
      "Iteration 963: Weights = [5.49965561e+01 4.05388769e+00 8.52463566e+00 3.12828486e-02\n",
      " 2.82126856e-01 1.04329538e+01], Loss = 0.4890\n",
      "Iteration 964: Weights = [5.49965905e+01 4.05377737e+00 8.52439467e+00 3.12586082e-02\n",
      " 2.82130717e-01 1.04332189e+01], Loss = 0.4889\n",
      "Iteration 965: Weights = [5.49966246e+01 4.05366700e+00 8.52415366e+00 3.12345402e-02\n",
      " 2.82134496e-01 1.04334840e+01], Loss = 0.4889\n",
      "Iteration 966: Weights = [5.49966584e+01 4.05355660e+00 8.52391262e+00 3.12106435e-02\n",
      " 2.82138193e-01 1.04337490e+01], Loss = 0.4889\n",
      "Iteration 967: Weights = [5.49966918e+01 4.05344615e+00 8.52367157e+00 3.11869168e-02\n",
      " 2.82141809e-01 1.04340139e+01], Loss = 0.4889\n",
      "Iteration 968: Weights = [5.49967249e+01 4.05333567e+00 8.52343049e+00 3.11633588e-02\n",
      " 2.82145344e-01 1.04342788e+01], Loss = 0.4888\n",
      "Iteration 969: Weights = [5.49967576e+01 4.05322514e+00 8.52318940e+00 3.11399682e-02\n",
      " 2.82148799e-01 1.04345437e+01], Loss = 0.4888\n",
      "Iteration 970: Weights = [5.49967900e+01 4.05311458e+00 8.52294828e+00 3.11167439e-02\n",
      " 2.82152174e-01 1.04348085e+01], Loss = 0.4888\n",
      "Iteration 971: Weights = [5.49968221e+01 4.05300398e+00 8.52270714e+00 3.10936846e-02\n",
      " 2.82155469e-01 1.04350732e+01], Loss = 0.4887\n",
      "Iteration 972: Weights = [5.49968539e+01 4.05289334e+00 8.52246598e+00 3.10707891e-02\n",
      " 2.82158687e-01 1.04353379e+01], Loss = 0.4887\n",
      "Iteration 973: Weights = [5.49968854e+01 4.05278266e+00 8.52222481e+00 3.10480561e-02\n",
      " 2.82161826e-01 1.04356025e+01], Loss = 0.4887\n",
      "Iteration 974: Weights = [5.49969165e+01 4.05267194e+00 8.52198361e+00 3.10254845e-02\n",
      " 2.82164888e-01 1.04358671e+01], Loss = 0.4887\n",
      "Iteration 975: Weights = [5.49969473e+01 4.05256119e+00 8.52174240e+00 3.10030731e-02\n",
      " 2.82167872e-01 1.04361316e+01], Loss = 0.4886\n",
      "Iteration 976: Weights = [5.49969779e+01 4.05245039e+00 8.52150116e+00 3.09808207e-02\n",
      " 2.82170780e-01 1.04363961e+01], Loss = 0.4886\n",
      "Iteration 977: Weights = [5.49970081e+01 4.05233957e+00 8.52125991e+00 3.09587261e-02\n",
      " 2.82173612e-01 1.04366605e+01], Loss = 0.4886\n",
      "Iteration 978: Weights = [5.49970380e+01 4.05222870e+00 8.52101863e+00 3.09367881e-02\n",
      " 2.82176369e-01 1.04369249e+01], Loss = 0.4886\n",
      "Iteration 979: Weights = [5.49970676e+01 4.05211780e+00 8.52077734e+00 3.09150056e-02\n",
      " 2.82179050e-01 1.04371892e+01], Loss = 0.4885\n",
      "Iteration 980: Weights = [5.49970970e+01 4.05200686e+00 8.52053603e+00 3.08933775e-02\n",
      " 2.82181658e-01 1.04374534e+01], Loss = 0.4885\n",
      "Iteration 981: Weights = [5.49971260e+01 4.05189589e+00 8.52029471e+00 3.08719026e-02\n",
      " 2.82184191e-01 1.04377177e+01], Loss = 0.4885\n",
      "Iteration 982: Weights = [5.49971547e+01 4.05178488e+00 8.52005336e+00 3.08505797e-02\n",
      " 2.82186650e-01 1.04379818e+01], Loss = 0.4884\n",
      "Iteration 983: Weights = [5.49971832e+01 4.05167383e+00 8.51981200e+00 3.08294078e-02\n",
      " 2.82189037e-01 1.04382459e+01], Loss = 0.4884\n",
      "Iteration 984: Weights = [5.49972113e+01 4.05156275e+00 8.51957062e+00 3.08083857e-02\n",
      " 2.82191351e-01 1.04385100e+01], Loss = 0.4884\n",
      "Iteration 985: Weights = [5.49972392e+01 4.05145164e+00 8.51932922e+00 3.07875124e-02\n",
      " 2.82193593e-01 1.04387740e+01], Loss = 0.4884\n",
      "Iteration 986: Weights = [5.49972668e+01 4.05134049e+00 8.51908780e+00 3.07667867e-02\n",
      " 2.82195764e-01 1.04390380e+01], Loss = 0.4883\n",
      "Iteration 987: Weights = [5.49972942e+01 4.05122931e+00 8.51884637e+00 3.07462075e-02\n",
      " 2.82197864e-01 1.04393019e+01], Loss = 0.4883\n",
      "Iteration 988: Weights = [5.49973212e+01 4.05111809e+00 8.51860492e+00 3.07257737e-02\n",
      " 2.82199893e-01 1.04395657e+01], Loss = 0.4883\n",
      "Iteration 989: Weights = [5.49973480e+01 4.05100684e+00 8.51836345e+00 3.07054843e-02\n",
      " 2.82201852e-01 1.04398296e+01], Loss = 0.4882\n",
      "Iteration 990: Weights = [5.49973745e+01 4.05089556e+00 8.51812197e+00 3.06853383e-02\n",
      " 2.82203741e-01 1.04400933e+01], Loss = 0.4882\n",
      "Iteration 991: Weights = [5.49974008e+01 4.05078424e+00 8.51788047e+00 3.06653345e-02\n",
      " 2.82205562e-01 1.04403571e+01], Loss = 0.4882\n",
      "Iteration 992: Weights = [5.49974268e+01 4.05067289e+00 8.51763896e+00 3.06454718e-02\n",
      " 2.82207313e-01 1.04406207e+01], Loss = 0.4882\n",
      "Iteration 993: Weights = [5.49974525e+01 4.05056151e+00 8.51739743e+00 3.06257494e-02\n",
      " 2.82208997e-01 1.04408844e+01], Loss = 0.4881\n",
      "Iteration 994: Weights = [5.49974780e+01 4.05045010e+00 8.51715588e+00 3.06061660e-02\n",
      " 2.82210612e-01 1.04411479e+01], Loss = 0.4881\n",
      "Iteration 995: Weights = [5.49975032e+01 4.05033865e+00 8.51691432e+00 3.05867208e-02\n",
      " 2.82212161e-01 1.04414115e+01], Loss = 0.4881\n",
      "Iteration 996: Weights = [5.49975282e+01 4.05022717e+00 8.51667274e+00 3.05674126e-02\n",
      " 2.82213642e-01 1.04416750e+01], Loss = 0.4880\n",
      "Iteration 997: Weights = [5.49975529e+01 4.05011567e+00 8.51643115e+00 3.05482405e-02\n",
      " 2.82215057e-01 1.04419384e+01], Loss = 0.4880\n",
      "Iteration 998: Weights = [5.49975774e+01 4.05000412e+00 8.51618954e+00 3.05292035e-02\n",
      " 2.82216407e-01 1.04422018e+01], Loss = 0.4880\n",
      "Iteration 999: Weights = [5.49976016e+01 4.04989255e+00 8.51594792e+00 3.05103005e-02\n",
      " 2.82217690e-01 1.04424652e+01], Loss = 0.4880\n",
      "Iteration 1000: Weights = [5.49976256e+01 4.04978095e+00 8.51570628e+00 3.04915306e-02\n",
      " 2.82218909e-01 1.04427285e+01], Loss = 0.4879\n",
      "Iteration 1001: Weights = [5.49976493e+01 4.04966932e+00 8.51546463e+00 3.04728927e-02\n",
      " 2.82220063e-01 1.04429917e+01], Loss = 0.4879\n",
      "Iteration 1002: Weights = [5.49976728e+01 4.04955766e+00 8.51522296e+00 3.04543860e-02\n",
      " 2.82221153e-01 1.04432549e+01], Loss = 0.4879\n",
      "Iteration 1003: Weights = [5.49976961e+01 4.04944596e+00 8.51498128e+00 3.04360094e-02\n",
      " 2.82222179e-01 1.04435181e+01], Loss = 0.4878\n",
      "Iteration 1004: Weights = [5.49977191e+01 4.04933424e+00 8.51473959e+00 3.04177621e-02\n",
      " 2.82223142e-01 1.04437813e+01], Loss = 0.4878\n",
      "Iteration 1005: Weights = [5.49977420e+01 4.04922249e+00 8.51449788e+00 3.03996429e-02\n",
      " 2.82224043e-01 1.04440443e+01], Loss = 0.4878\n",
      "Iteration 1006: Weights = [5.49977645e+01 4.04911071e+00 8.51425616e+00 3.03816510e-02\n",
      " 2.82224880e-01 1.04443074e+01], Loss = 0.4878\n",
      "Iteration 1007: Weights = [5.49977869e+01 4.04899890e+00 8.51401442e+00 3.03637855e-02\n",
      " 2.82225656e-01 1.04445704e+01], Loss = 0.4877\n",
      "Iteration 1008: Weights = [5.49978090e+01 4.04888706e+00 8.51377267e+00 3.03460453e-02\n",
      " 2.82226370e-01 1.04448333e+01], Loss = 0.4877\n",
      "Iteration 1009: Weights = [5.49978309e+01 4.04877519e+00 8.51353091e+00 3.03284297e-02\n",
      " 2.82227023e-01 1.04450963e+01], Loss = 0.4877\n",
      "Iteration 1010: Weights = [5.49978526e+01 4.04866329e+00 8.51328913e+00 3.03109376e-02\n",
      " 2.82227615e-01 1.04453591e+01], Loss = 0.4876\n",
      "Iteration 1011: Weights = [5.49978741e+01 4.04855137e+00 8.51304735e+00 3.02935682e-02\n",
      " 2.82228147e-01 1.04456220e+01], Loss = 0.4876\n",
      "Iteration 1012: Weights = [5.49978954e+01 4.04843941e+00 8.51280554e+00 3.02763205e-02\n",
      " 2.82228619e-01 1.04458847e+01], Loss = 0.4876\n",
      "Iteration 1013: Weights = [5.49979164e+01 4.04832743e+00 8.51256373e+00 3.02591937e-02\n",
      " 2.82229031e-01 1.04461475e+01], Loss = 0.4876\n",
      "Iteration 1014: Weights = [5.49979372e+01 4.04821543e+00 8.51232190e+00 3.02421869e-02\n",
      " 2.82229385e-01 1.04464102e+01], Loss = 0.4875\n",
      "Iteration 1015: Weights = [5.49979579e+01 4.04810339e+00 8.51208007e+00 3.02252991e-02\n",
      " 2.82229679e-01 1.04466729e+01], Loss = 0.4875\n",
      "Iteration 1016: Weights = [5.49979783e+01 4.04799133e+00 8.51183821e+00 3.02085295e-02\n",
      " 2.82229915e-01 1.04469355e+01], Loss = 0.4875\n",
      "Iteration 1017: Weights = [5.49979985e+01 4.04787924e+00 8.51159635e+00 3.01918772e-02\n",
      " 2.82230094e-01 1.04471981e+01], Loss = 0.4874\n",
      "Iteration 1018: Weights = [5.49980185e+01 4.04776713e+00 8.51135448e+00 3.01753414e-02\n",
      " 2.82230215e-01 1.04474606e+01], Loss = 0.4874\n",
      "Iteration 1019: Weights = [5.49980383e+01 4.04765499e+00 8.51111259e+00 3.01589212e-02\n",
      " 2.82230278e-01 1.04477231e+01], Loss = 0.4874\n",
      "Iteration 1020: Weights = [5.49980579e+01 4.04754282e+00 8.51087069e+00 3.01426157e-02\n",
      " 2.82230285e-01 1.04479856e+01], Loss = 0.4874\n",
      "Iteration 1021: Weights = [5.49980774e+01 4.04743063e+00 8.51062878e+00 3.01264241e-02\n",
      " 2.82230236e-01 1.04482480e+01], Loss = 0.4873\n",
      "Iteration 1022: Weights = [5.49980966e+01 4.04731841e+00 8.51038686e+00 3.01103456e-02\n",
      " 2.82230131e-01 1.04485104e+01], Loss = 0.4873\n",
      "Iteration 1023: Weights = [5.49981156e+01 4.04720616e+00 8.51014493e+00 3.00943793e-02\n",
      " 2.82229970e-01 1.04487727e+01], Loss = 0.4873\n",
      "Iteration 1024: Weights = [5.49981345e+01 4.04709389e+00 8.50990298e+00 3.00785244e-02\n",
      " 2.82229753e-01 1.04490351e+01], Loss = 0.4873\n",
      "Iteration 1025: Weights = [5.49981531e+01 4.04698160e+00 8.50966103e+00 3.00627801e-02\n",
      " 2.82229483e-01 1.04492973e+01], Loss = 0.4872\n",
      "Iteration 1026: Weights = [5.49981716e+01 4.04686928e+00 8.50941907e+00 3.00471456e-02\n",
      " 2.82229157e-01 1.04495596e+01], Loss = 0.4872\n",
      "Iteration 1027: Weights = [5.49981899e+01 4.04675693e+00 8.50917709e+00 3.00316200e-02\n",
      " 2.82228778e-01 1.04498217e+01], Loss = 0.4872\n",
      "Iteration 1028: Weights = [5.49982080e+01 4.04664456e+00 8.50893510e+00 3.00162025e-02\n",
      " 2.82228344e-01 1.04500839e+01], Loss = 0.4871\n",
      "Iteration 1029: Weights = [5.49982259e+01 4.04653217e+00 8.50869311e+00 3.00008924e-02\n",
      " 2.82227858e-01 1.04503460e+01], Loss = 0.4871\n",
      "Iteration 1030: Weights = [5.49982436e+01 4.04641975e+00 8.50845110e+00 2.99856888e-02\n",
      " 2.82227318e-01 1.04506081e+01], Loss = 0.4871\n",
      "Iteration 1031: Weights = [5.49982612e+01 4.04630731e+00 8.50820908e+00 2.99705911e-02\n",
      " 2.82226726e-01 1.04508701e+01], Loss = 0.4871\n",
      "Iteration 1032: Weights = [5.49982786e+01 4.04619485e+00 8.50796706e+00 2.99555983e-02\n",
      " 2.82226082e-01 1.04511321e+01], Loss = 0.4870\n",
      "Iteration 1033: Weights = [5.49982958e+01 4.04608236e+00 8.50772502e+00 2.99407097e-02\n",
      " 2.82225385e-01 1.04513941e+01], Loss = 0.4870\n",
      "Iteration 1034: Weights = [5.49983128e+01 4.04596985e+00 8.50748297e+00 2.99259246e-02\n",
      " 2.82224637e-01 1.04516560e+01], Loss = 0.4870\n",
      "Iteration 1035: Weights = [5.49983297e+01 4.04585732e+00 8.50724092e+00 2.99112422e-02\n",
      " 2.82223838e-01 1.04519179e+01], Loss = 0.4869\n",
      "Iteration 1036: Weights = [5.49983464e+01 4.04574476e+00 8.50699885e+00 2.98966617e-02\n",
      " 2.82222988e-01 1.04521798e+01], Loss = 0.4869\n",
      "Iteration 1037: Weights = [5.49983630e+01 4.04563218e+00 8.50675678e+00 2.98821823e-02\n",
      " 2.82222088e-01 1.04524416e+01], Loss = 0.4869\n",
      "Iteration 1038: Weights = [5.49983793e+01 4.04551958e+00 8.50651469e+00 2.98678034e-02\n",
      " 2.82221137e-01 1.04527034e+01], Loss = 0.4869\n",
      "Iteration 1039: Weights = [5.49983955e+01 4.04540695e+00 8.50627260e+00 2.98535242e-02\n",
      " 2.82220137e-01 1.04529652e+01], Loss = 0.4868\n",
      "Iteration 1040: Weights = [5.49984116e+01 4.04529431e+00 8.50603050e+00 2.98393440e-02\n",
      " 2.82219087e-01 1.04532269e+01], Loss = 0.4868\n",
      "Iteration 1041: Weights = [5.49984275e+01 4.04518164e+00 8.50578839e+00 2.98252620e-02\n",
      " 2.82217988e-01 1.04534886e+01], Loss = 0.4868\n",
      "Iteration 1042: Weights = [5.49984432e+01 4.04506895e+00 8.50554627e+00 2.98112775e-02\n",
      " 2.82216840e-01 1.04537502e+01], Loss = 0.4867\n",
      "Iteration 1043: Weights = [5.49984588e+01 4.04495623e+00 8.50530414e+00 2.97973898e-02\n",
      " 2.82215644e-01 1.04540118e+01], Loss = 0.4867\n",
      "Iteration 1044: Weights = [5.49984742e+01 4.04484350e+00 8.50506200e+00 2.97835981e-02\n",
      " 2.82214400e-01 1.04542734e+01], Loss = 0.4867\n",
      "Iteration 1045: Weights = [5.49984894e+01 4.04473075e+00 8.50481986e+00 2.97699018e-02\n",
      " 2.82213108e-01 1.04545350e+01], Loss = 0.4867\n",
      "Iteration 1046: Weights = [5.49985045e+01 4.04461797e+00 8.50457771e+00 2.97563002e-02\n",
      " 2.82211768e-01 1.04547965e+01], Loss = 0.4866\n",
      "Iteration 1047: Weights = [5.49985195e+01 4.04450517e+00 8.50433555e+00 2.97427925e-02\n",
      " 2.82210382e-01 1.04550579e+01], Loss = 0.4866\n",
      "Iteration 1048: Weights = [5.49985343e+01 4.04439236e+00 8.50409338e+00 2.97293782e-02\n",
      " 2.82208948e-01 1.04553194e+01], Loss = 0.4866\n",
      "Iteration 1049: Weights = [5.49985490e+01 4.04427952e+00 8.50385120e+00 2.97160563e-02\n",
      " 2.82207468e-01 1.04555808e+01], Loss = 0.4866\n",
      "Iteration 1050: Weights = [5.49985635e+01 4.04416666e+00 8.50360901e+00 2.97028264e-02\n",
      " 2.82205942e-01 1.04558422e+01], Loss = 0.4865\n",
      "Iteration 1051: Weights = [5.49985778e+01 4.04405378e+00 8.50336682e+00 2.96896878e-02\n",
      " 2.82204370e-01 1.04561035e+01], Loss = 0.4865\n",
      "Iteration 1052: Weights = [5.49985920e+01 4.04394088e+00 8.50312462e+00 2.96766396e-02\n",
      " 2.82202752e-01 1.04563648e+01], Loss = 0.4865\n",
      "Iteration 1053: Weights = [5.49986061e+01 4.04382797e+00 8.50288241e+00 2.96636814e-02\n",
      " 2.82201089e-01 1.04566261e+01], Loss = 0.4864\n",
      "Iteration 1054: Weights = [5.49986201e+01 4.04371503e+00 8.50264020e+00 2.96508124e-02\n",
      " 2.82199382e-01 1.04568874e+01], Loss = 0.4864\n",
      "Iteration 1055: Weights = [5.49986339e+01 4.04360207e+00 8.50239798e+00 2.96380320e-02\n",
      " 2.82197629e-01 1.04571486e+01], Loss = 0.4864\n",
      "Iteration 1056: Weights = [5.49986475e+01 4.04348909e+00 8.50215575e+00 2.96253394e-02\n",
      " 2.82195833e-01 1.04574097e+01], Loss = 0.4864\n",
      "Iteration 1057: Weights = [5.49986611e+01 4.04337610e+00 8.50191351e+00 2.96127342e-02\n",
      " 2.82193992e-01 1.04576709e+01], Loss = 0.4863\n",
      "Iteration 1058: Weights = [5.49986744e+01 4.04326308e+00 8.50167127e+00 2.96002155e-02\n",
      " 2.82192108e-01 1.04579320e+01], Loss = 0.4863\n",
      "Iteration 1059: Weights = [5.49986877e+01 4.04315005e+00 8.50142902e+00 2.95877829e-02\n",
      " 2.82190180e-01 1.04581931e+01], Loss = 0.4863\n",
      "Iteration 1060: Weights = [5.49987008e+01 4.04303700e+00 8.50118676e+00 2.95754356e-02\n",
      " 2.82188210e-01 1.04584542e+01], Loss = 0.4862\n",
      "Iteration 1061: Weights = [5.49987138e+01 4.04292393e+00 8.50094450e+00 2.95631730e-02\n",
      " 2.82186196e-01 1.04587152e+01], Loss = 0.4862\n",
      "Iteration 1062: Weights = [5.49987267e+01 4.04281084e+00 8.50070223e+00 2.95509945e-02\n",
      " 2.82184140e-01 1.04589762e+01], Loss = 0.4862\n",
      "Iteration 1063: Weights = [5.49987394e+01 4.04269773e+00 8.50045995e+00 2.95388995e-02\n",
      " 2.82182042e-01 1.04592371e+01], Loss = 0.4862\n",
      "Iteration 1064: Weights = [5.49987520e+01 4.04258461e+00 8.50021767e+00 2.95268874e-02\n",
      " 2.82179902e-01 1.04594981e+01], Loss = 0.4861\n",
      "Iteration 1065: Weights = [5.49987645e+01 4.04247146e+00 8.49997538e+00 2.95149575e-02\n",
      " 2.82177720e-01 1.04597590e+01], Loss = 0.4861\n",
      "Iteration 1066: Weights = [5.49987768e+01 4.04235830e+00 8.49973309e+00 2.95031093e-02\n",
      " 2.82175497e-01 1.04600198e+01], Loss = 0.4861\n",
      "Iteration 1067: Weights = [5.49987891e+01 4.04224512e+00 8.49949079e+00 2.94913421e-02\n",
      " 2.82173232e-01 1.04602807e+01], Loss = 0.4860\n",
      "Iteration 1068: Weights = [5.49988012e+01 4.04213193e+00 8.49924848e+00 2.94796554e-02\n",
      " 2.82170927e-01 1.04605415e+01], Loss = 0.4860\n",
      "Iteration 1069: Weights = [5.49988132e+01 4.04201871e+00 8.49900617e+00 2.94680486e-02\n",
      " 2.82168582e-01 1.04608023e+01], Loss = 0.4860\n",
      "Iteration 1070: Weights = [5.49988250e+01 4.04190548e+00 8.49876385e+00 2.94565210e-02\n",
      " 2.82166196e-01 1.04610630e+01], Loss = 0.4860\n",
      "Iteration 1071: Weights = [5.49988368e+01 4.04179224e+00 8.49852153e+00 2.94450721e-02\n",
      " 2.82163771e-01 1.04613237e+01], Loss = 0.4859\n",
      "Iteration 1072: Weights = [5.49988484e+01 4.04167897e+00 8.49827920e+00 2.94337013e-02\n",
      " 2.82161306e-01 1.04615844e+01], Loss = 0.4859\n",
      "Iteration 1073: Weights = [5.49988599e+01 4.04156569e+00 8.49803687e+00 2.94224080e-02\n",
      " 2.82158801e-01 1.04618451e+01], Loss = 0.4859\n",
      "Iteration 1074: Weights = [5.49988713e+01 4.04145239e+00 8.49779453e+00 2.94111918e-02\n",
      " 2.82156257e-01 1.04621057e+01], Loss = 0.4859\n",
      "Iteration 1075: Weights = [5.49988826e+01 4.04133908e+00 8.49755218e+00 2.94000519e-02\n",
      " 2.82153675e-01 1.04623663e+01], Loss = 0.4858\n",
      "Iteration 1076: Weights = [5.49988938e+01 4.04122575e+00 8.49730983e+00 2.93889878e-02\n",
      " 2.82151054e-01 1.04626269e+01], Loss = 0.4858\n",
      "Iteration 1077: Weights = [5.49989049e+01 4.04111240e+00 8.49706748e+00 2.93779990e-02\n",
      " 2.82148394e-01 1.04628875e+01], Loss = 0.4858\n",
      "Iteration 1078: Weights = [5.49989158e+01 4.04099904e+00 8.49682512e+00 2.93670850e-02\n",
      " 2.82145697e-01 1.04631480e+01], Loss = 0.4857\n",
      "Iteration 1079: Weights = [5.49989267e+01 4.04088566e+00 8.49658275e+00 2.93562451e-02\n",
      " 2.82142962e-01 1.04634085e+01], Loss = 0.4857\n",
      "Iteration 1080: Weights = [5.49989374e+01 4.04077227e+00 8.49634038e+00 2.93454789e-02\n",
      " 2.82140189e-01 1.04636689e+01], Loss = 0.4857\n",
      "Iteration 1081: Weights = [5.49989480e+01 4.04065886e+00 8.49609801e+00 2.93347857e-02\n",
      " 2.82137379e-01 1.04639294e+01], Loss = 0.4857\n",
      "Iteration 1082: Weights = [5.49989585e+01 4.04054544e+00 8.49585563e+00 2.93241651e-02\n",
      " 2.82134532e-01 1.04641898e+01], Loss = 0.4856\n",
      "Iteration 1083: Weights = [5.49989690e+01 4.04043200e+00 8.49561325e+00 2.93136165e-02\n",
      " 2.82131648e-01 1.04644502e+01], Loss = 0.4856\n",
      "Iteration 1084: Weights = [5.49989793e+01 4.04031854e+00 8.49537086e+00 2.93031394e-02\n",
      " 2.82128728e-01 1.04647105e+01], Loss = 0.4856\n",
      "Iteration 1085: Weights = [5.49989895e+01 4.04020507e+00 8.49512847e+00 2.92927332e-02\n",
      " 2.82125772e-01 1.04649708e+01], Loss = 0.4855\n",
      "Iteration 1086: Weights = [5.49989996e+01 4.04009159e+00 8.49488607e+00 2.92823975e-02\n",
      " 2.82122779e-01 1.04652311e+01], Loss = 0.4855\n",
      "Iteration 1087: Weights = [5.49990096e+01 4.03997809e+00 8.49464367e+00 2.92721317e-02\n",
      " 2.82119751e-01 1.04654914e+01], Loss = 0.4855\n",
      "Iteration 1088: Weights = [5.49990195e+01 4.03986457e+00 8.49440127e+00 2.92619353e-02\n",
      " 2.82116687e-01 1.04657516e+01], Loss = 0.4855\n",
      "Iteration 1089: Weights = [5.49990293e+01 4.03975104e+00 8.49415886e+00 2.92518078e-02\n",
      " 2.82113589e-01 1.04660119e+01], Loss = 0.4854\n",
      "Iteration 1090: Weights = [5.49990390e+01 4.03963750e+00 8.49391645e+00 2.92417486e-02\n",
      " 2.82110455e-01 1.04662721e+01], Loss = 0.4854\n",
      "Iteration 1091: Weights = [5.49990486e+01 4.03952394e+00 8.49367403e+00 2.92317574e-02\n",
      " 2.82107286e-01 1.04665322e+01], Loss = 0.4854\n",
      "Iteration 1092: Weights = [5.49990581e+01 4.03941037e+00 8.49343161e+00 2.92218335e-02\n",
      " 2.82104083e-01 1.04667924e+01], Loss = 0.4853\n",
      "Iteration 1093: Weights = [5.49990675e+01 4.03929678e+00 8.49318919e+00 2.92119766e-02\n",
      " 2.82100846e-01 1.04670525e+01], Loss = 0.4853\n",
      "Iteration 1094: Weights = [5.49990769e+01 4.03918319e+00 8.49294677e+00 2.92021860e-02\n",
      " 2.82097574e-01 1.04673126e+01], Loss = 0.4853\n",
      "Iteration 1095: Weights = [5.49990861e+01 4.03906957e+00 8.49270434e+00 2.91924614e-02\n",
      " 2.82094269e-01 1.04675726e+01], Loss = 0.4853\n",
      "Iteration 1096: Weights = [5.49990952e+01 4.03895595e+00 8.49246190e+00 2.91828021e-02\n",
      " 2.82090931e-01 1.04678326e+01], Loss = 0.4852\n",
      "Iteration 1097: Weights = [5.49991043e+01 4.03884231e+00 8.49221947e+00 2.91732078e-02\n",
      " 2.82087559e-01 1.04680927e+01], Loss = 0.4852\n",
      "Iteration 1098: Weights = [5.49991132e+01 4.03872865e+00 8.49197703e+00 2.91636780e-02\n",
      " 2.82084153e-01 1.04683526e+01], Loss = 0.4852\n",
      "Iteration 1099: Weights = [5.49991221e+01 4.03861498e+00 8.49173458e+00 2.91542122e-02\n",
      " 2.82080715e-01 1.04686126e+01], Loss = 0.4852\n",
      "Iteration 1100: Weights = [5.49991309e+01 4.03850130e+00 8.49149214e+00 2.91448099e-02\n",
      " 2.82077245e-01 1.04688725e+01], Loss = 0.4851\n",
      "Iteration 1101: Weights = [5.49991396e+01 4.03838761e+00 8.49124969e+00 2.91354706e-02\n",
      " 2.82073742e-01 1.04691324e+01], Loss = 0.4851\n",
      "Iteration 1102: Weights = [5.49991482e+01 4.03827391e+00 8.49100724e+00 2.91261939e-02\n",
      " 2.82070207e-01 1.04693923e+01], Loss = 0.4851\n",
      "Iteration 1103: Weights = [5.49991567e+01 4.03816019e+00 8.49076478e+00 2.91169794e-02\n",
      " 2.82066639e-01 1.04696522e+01], Loss = 0.4850\n",
      "Iteration 1104: Weights = [5.49991651e+01 4.03804646e+00 8.49052232e+00 2.91078265e-02\n",
      " 2.82063041e-01 1.04699120e+01], Loss = 0.4850\n",
      "Iteration 1105: Weights = [5.49991735e+01 4.03793271e+00 8.49027986e+00 2.90987349e-02\n",
      " 2.82059410e-01 1.04701718e+01], Loss = 0.4850\n",
      "Iteration 1106: Weights = [5.49991817e+01 4.03781896e+00 8.49003740e+00 2.90897040e-02\n",
      " 2.82055748e-01 1.04704316e+01], Loss = 0.4850\n",
      "Iteration 1107: Weights = [5.49991899e+01 4.03770519e+00 8.48979493e+00 2.90807334e-02\n",
      " 2.82052056e-01 1.04706914e+01], Loss = 0.4849\n",
      "Iteration 1108: Weights = [5.49991980e+01 4.03759141e+00 8.48955247e+00 2.90718228e-02\n",
      " 2.82048332e-01 1.04709511e+01], Loss = 0.4849\n",
      "Iteration 1109: Weights = [5.49992060e+01 4.03747761e+00 8.48931000e+00 2.90629715e-02\n",
      " 2.82044578e-01 1.04712108e+01], Loss = 0.4849\n",
      "Iteration 1110: Weights = [5.49992140e+01 4.03736381e+00 8.48906752e+00 2.90541793e-02\n",
      " 2.82040793e-01 1.04714705e+01], Loss = 0.4848\n",
      "Iteration 1111: Weights = [5.49992218e+01 4.03724999e+00 8.48882505e+00 2.90454456e-02\n",
      " 2.82036978e-01 1.04717302e+01], Loss = 0.4848\n",
      "Iteration 1112: Weights = [5.49992296e+01 4.03713616e+00 8.48858257e+00 2.90367701e-02\n",
      " 2.82033133e-01 1.04719898e+01], Loss = 0.4848\n",
      "Iteration 1113: Weights = [5.49992373e+01 4.03702232e+00 8.48834009e+00 2.90281523e-02\n",
      " 2.82029259e-01 1.04722494e+01], Loss = 0.4848\n",
      "Iteration 1114: Weights = [5.49992450e+01 4.03690847e+00 8.48809761e+00 2.90195917e-02\n",
      " 2.82025354e-01 1.04725090e+01], Loss = 0.4847\n",
      "Iteration 1115: Weights = [5.49992525e+01 4.03679461e+00 8.48785513e+00 2.90110881e-02\n",
      " 2.82021421e-01 1.04727686e+01], Loss = 0.4847\n",
      "Iteration 1116: Weights = [5.49992600e+01 4.03668073e+00 8.48761264e+00 2.90026409e-02\n",
      " 2.82017458e-01 1.04730281e+01], Loss = 0.4847\n",
      "Iteration 1117: Weights = [5.49992674e+01 4.03656685e+00 8.48737015e+00 2.89942497e-02\n",
      " 2.82013466e-01 1.04732877e+01], Loss = 0.4847\n",
      "Iteration 1118: Weights = [5.49992747e+01 4.03645295e+00 8.48712766e+00 2.89859141e-02\n",
      " 2.82009445e-01 1.04735472e+01], Loss = 0.4846\n",
      "Iteration 1119: Weights = [5.49992820e+01 4.03633904e+00 8.48688517e+00 2.89776338e-02\n",
      " 2.82005396e-01 1.04738067e+01], Loss = 0.4846\n",
      "Iteration 1120: Weights = [5.49992891e+01 4.03622512e+00 8.48664268e+00 2.89694082e-02\n",
      " 2.82001319e-01 1.04740661e+01], Loss = 0.4846\n",
      "Iteration 1121: Weights = [5.49992963e+01 4.03611119e+00 8.48640019e+00 2.89612371e-02\n",
      " 2.81997213e-01 1.04743255e+01], Loss = 0.4845\n",
      "Iteration 1122: Weights = [5.49993033e+01 4.03599725e+00 8.48615769e+00 2.89531200e-02\n",
      " 2.81993079e-01 1.04745850e+01], Loss = 0.4845\n",
      "Iteration 1123: Weights = [5.49993103e+01 4.03588330e+00 8.48591520e+00 2.89450564e-02\n",
      " 2.81988918e-01 1.04748443e+01], Loss = 0.4845\n",
      "Iteration 1124: Weights = [5.49993172e+01 4.03576934e+00 8.48567270e+00 2.89370461e-02\n",
      " 2.81984729e-01 1.04751037e+01], Loss = 0.4845\n",
      "Iteration 1125: Weights = [5.49993240e+01 4.03565537e+00 8.48543020e+00 2.89290886e-02\n",
      " 2.81980512e-01 1.04753631e+01], Loss = 0.4844\n",
      "Iteration 1126: Weights = [5.49993307e+01 4.03554139e+00 8.48518770e+00 2.89211836e-02\n",
      " 2.81976269e-01 1.04756224e+01], Loss = 0.4844\n",
      "Iteration 1127: Weights = [5.49993374e+01 4.03542740e+00 8.48494519e+00 2.89133306e-02\n",
      " 2.81971998e-01 1.04758817e+01], Loss = 0.4844\n",
      "Iteration 1128: Weights = [5.49993441e+01 4.03531339e+00 8.48470269e+00 2.89055293e-02\n",
      " 2.81967701e-01 1.04761410e+01], Loss = 0.4843\n",
      "Iteration 1129: Weights = [5.49993506e+01 4.03519938e+00 8.48446019e+00 2.88977792e-02\n",
      " 2.81963376e-01 1.04764002e+01], Loss = 0.4843\n",
      "Iteration 1130: Weights = [5.49993571e+01 4.03508536e+00 8.48421768e+00 2.88900801e-02\n",
      " 2.81959026e-01 1.04766594e+01], Loss = 0.4843\n",
      "Iteration 1131: Weights = [5.49993635e+01 4.03497133e+00 8.48397518e+00 2.88824315e-02\n",
      " 2.81954649e-01 1.04769187e+01], Loss = 0.4843\n",
      "Iteration 1132: Weights = [5.49993699e+01 4.03485729e+00 8.48373267e+00 2.88748330e-02\n",
      " 2.81950246e-01 1.04771779e+01], Loss = 0.4842\n",
      "Iteration 1133: Weights = [5.49993762e+01 4.03474323e+00 8.48349016e+00 2.88672844e-02\n",
      " 2.81945817e-01 1.04774370e+01], Loss = 0.4842\n",
      "Iteration 1134: Weights = [5.49993824e+01 4.03462917e+00 8.48324765e+00 2.88597852e-02\n",
      " 2.81941363e-01 1.04776962e+01], Loss = 0.4842\n",
      "Iteration 1135: Weights = [5.49993886e+01 4.03451510e+00 8.48300514e+00 2.88523351e-02\n",
      " 2.81936883e-01 1.04779553e+01], Loss = 0.4842\n",
      "Iteration 1136: Weights = [5.49993947e+01 4.03440102e+00 8.48276263e+00 2.88449337e-02\n",
      " 2.81932378e-01 1.04782144e+01], Loss = 0.4841\n",
      "Iteration 1137: Weights = [5.49994008e+01 4.03428693e+00 8.48252012e+00 2.88375806e-02\n",
      " 2.81927847e-01 1.04784735e+01], Loss = 0.4841\n",
      "Iteration 1138: Weights = [5.49994068e+01 4.03417284e+00 8.48227761e+00 2.88302755e-02\n",
      " 2.81923292e-01 1.04787326e+01], Loss = 0.4841\n",
      "Iteration 1139: Weights = [5.49994127e+01 4.03405873e+00 8.48203510e+00 2.88230181e-02\n",
      " 2.81918711e-01 1.04789916e+01], Loss = 0.4840\n",
      "Iteration 1140: Weights = [5.49994186e+01 4.03394461e+00 8.48179259e+00 2.88158079e-02\n",
      " 2.81914106e-01 1.04792506e+01], Loss = 0.4840\n",
      "Iteration 1141: Weights = [5.49994244e+01 4.03383049e+00 8.48155007e+00 2.88086447e-02\n",
      " 2.81909477e-01 1.04795096e+01], Loss = 0.4840\n",
      "Iteration 1142: Weights = [5.49994302e+01 4.03371635e+00 8.48130756e+00 2.88015282e-02\n",
      " 2.81904823e-01 1.04797686e+01], Loss = 0.4840\n",
      "Iteration 1143: Weights = [5.49994359e+01 4.03360221e+00 8.48106505e+00 2.87944578e-02\n",
      " 2.81900145e-01 1.04800276e+01], Loss = 0.4839\n",
      "Iteration 1144: Weights = [5.49994415e+01 4.03348806e+00 8.48082253e+00 2.87874334e-02\n",
      " 2.81895443e-01 1.04802865e+01], Loss = 0.4839\n",
      "Iteration 1145: Weights = [5.49994471e+01 4.03337390e+00 8.48058002e+00 2.87804546e-02\n",
      " 2.81890717e-01 1.04805455e+01], Loss = 0.4839\n",
      "Iteration 1146: Weights = [5.49994526e+01 4.03325973e+00 8.48033751e+00 2.87735210e-02\n",
      " 2.81885968e-01 1.04808044e+01], Loss = 0.4838\n",
      "Iteration 1147: Weights = [5.49994581e+01 4.03314556e+00 8.48009499e+00 2.87666324e-02\n",
      " 2.81881195e-01 1.04810632e+01], Loss = 0.4838\n",
      "Iteration 1148: Weights = [5.49994635e+01 4.03303137e+00 8.47985248e+00 2.87597883e-02\n",
      " 2.81876399e-01 1.04813221e+01], Loss = 0.4838\n",
      "Iteration 1149: Weights = [5.49994689e+01 4.03291718e+00 8.47960997e+00 2.87529885e-02\n",
      " 2.81871580e-01 1.04815810e+01], Loss = 0.4838\n",
      "Iteration 1150: Weights = [5.49994742e+01 4.03280298e+00 8.47936745e+00 2.87462326e-02\n",
      " 2.81866738e-01 1.04818398e+01], Loss = 0.4837\n",
      "Iteration 1151: Weights = [5.49994794e+01 4.03268877e+00 8.47912494e+00 2.87395203e-02\n",
      " 2.81861873e-01 1.04820986e+01], Loss = 0.4837\n",
      "Iteration 1152: Weights = [5.49994846e+01 4.03257455e+00 8.47888243e+00 2.87328513e-02\n",
      " 2.81856985e-01 1.04823574e+01], Loss = 0.4837\n",
      "Iteration 1153: Weights = [5.49994898e+01 4.03246032e+00 8.47863991e+00 2.87262253e-02\n",
      " 2.81852075e-01 1.04826161e+01], Loss = 0.4837\n",
      "Iteration 1154: Weights = [5.49994949e+01 4.03234609e+00 8.47839740e+00 2.87196420e-02\n",
      " 2.81847143e-01 1.04828749e+01], Loss = 0.4836\n",
      "Iteration 1155: Weights = [5.49995000e+01 4.03223185e+00 8.47815489e+00 2.87131010e-02\n",
      " 2.81842188e-01 1.04831336e+01], Loss = 0.4836\n",
      "Iteration 1156: Weights = [5.49995050e+01 4.03211760e+00 8.47791238e+00 2.87066020e-02\n",
      " 2.81837212e-01 1.04833923e+01], Loss = 0.4836\n",
      "Iteration 1157: Weights = [5.49995099e+01 4.03200335e+00 8.47766987e+00 2.87001448e-02\n",
      " 2.81832213e-01 1.04836510e+01], Loss = 0.4835\n",
      "Iteration 1158: Weights = [5.49995148e+01 4.03188908e+00 8.47742736e+00 2.86937290e-02\n",
      " 2.81827193e-01 1.04839097e+01], Loss = 0.4835\n",
      "Iteration 1159: Weights = [5.49995197e+01 4.03177481e+00 8.47718485e+00 2.86873543e-02\n",
      " 2.81822151e-01 1.04841683e+01], Loss = 0.4835\n",
      "Iteration 1160: Weights = [5.49995245e+01 4.03166053e+00 8.47694234e+00 2.86810204e-02\n",
      " 2.81817088e-01 1.04844270e+01], Loss = 0.4835\n",
      "Iteration 1161: Weights = [5.49995292e+01 4.03154625e+00 8.47669983e+00 2.86747271e-02\n",
      " 2.81812004e-01 1.04846856e+01], Loss = 0.4834\n",
      "Iteration 1162: Weights = [5.49995339e+01 4.03143196e+00 8.47645732e+00 2.86684739e-02\n",
      " 2.81806898e-01 1.04849442e+01], Loss = 0.4834\n",
      "Iteration 1163: Weights = [5.49995386e+01 4.03131766e+00 8.47621481e+00 2.86622607e-02\n",
      " 2.81801772e-01 1.04852027e+01], Loss = 0.4834\n",
      "Iteration 1164: Weights = [5.49995432e+01 4.03120335e+00 8.47597230e+00 2.86560871e-02\n",
      " 2.81796624e-01 1.04854613e+01], Loss = 0.4833\n",
      "Iteration 1165: Weights = [5.49995478e+01 4.03108904e+00 8.47572980e+00 2.86499528e-02\n",
      " 2.81791457e-01 1.04857198e+01], Loss = 0.4833\n",
      "Iteration 1166: Weights = [5.49995523e+01 4.03097472e+00 8.47548729e+00 2.86438576e-02\n",
      " 2.81786268e-01 1.04859784e+01], Loss = 0.4833\n",
      "Iteration 1167: Weights = [5.49995568e+01 4.03086039e+00 8.47524479e+00 2.86378012e-02\n",
      " 2.81781059e-01 1.04862369e+01], Loss = 0.4833\n",
      "Iteration 1168: Weights = [5.49995612e+01 4.03074606e+00 8.47500229e+00 2.86317832e-02\n",
      " 2.81775830e-01 1.04864954e+01], Loss = 0.4832\n",
      "Iteration 1169: Weights = [5.49995656e+01 4.03063172e+00 8.47475978e+00 2.86258035e-02\n",
      " 2.81770581e-01 1.04867538e+01], Loss = 0.4832\n",
      "Iteration 1170: Weights = [5.49995699e+01 4.03051737e+00 8.47451728e+00 2.86198616e-02\n",
      " 2.81765312e-01 1.04870123e+01], Loss = 0.4832\n",
      "Iteration 1171: Weights = [5.49995742e+01 4.03040301e+00 8.47427478e+00 2.86139574e-02\n",
      " 2.81760023e-01 1.04872707e+01], Loss = 0.4832\n",
      "Iteration 1172: Weights = [5.49995785e+01 4.03028865e+00 8.47403229e+00 2.86080906e-02\n",
      " 2.81754715e-01 1.04875291e+01], Loss = 0.4831\n",
      "Iteration 1173: Weights = [5.49995827e+01 4.03017429e+00 8.47378979e+00 2.86022608e-02\n",
      " 2.81749387e-01 1.04877875e+01], Loss = 0.4831\n",
      "Iteration 1174: Weights = [5.49995869e+01 4.03005991e+00 8.47354729e+00 2.85964679e-02\n",
      " 2.81744039e-01 1.04880459e+01], Loss = 0.4831\n",
      "Iteration 1175: Weights = [5.49995910e+01 4.02994554e+00 8.47330480e+00 2.85907115e-02\n",
      " 2.81738673e-01 1.04883043e+01], Loss = 0.4830\n",
      "Iteration 1176: Weights = [5.49995951e+01 4.02983115e+00 8.47306230e+00 2.85849914e-02\n",
      " 2.81733287e-01 1.04885626e+01], Loss = 0.4830\n",
      "Iteration 1177: Weights = [5.49995991e+01 4.02971676e+00 8.47281981e+00 2.85793073e-02\n",
      " 2.81727882e-01 1.04888209e+01], Loss = 0.4830\n",
      "Iteration 1178: Weights = [5.49996032e+01 4.02960236e+00 8.47257732e+00 2.85736589e-02\n",
      " 2.81722459e-01 1.04890792e+01], Loss = 0.4830\n",
      "Iteration 1179: Weights = [5.49996071e+01 4.02948796e+00 8.47233483e+00 2.85680461e-02\n",
      " 2.81717017e-01 1.04893375e+01], Loss = 0.4829\n",
      "Iteration 1180: Weights = [5.49996111e+01 4.02937355e+00 8.47209234e+00 2.85624685e-02\n",
      " 2.81711556e-01 1.04895958e+01], Loss = 0.4829\n",
      "Iteration 1181: Weights = [5.49996149e+01 4.02925913e+00 8.47184986e+00 2.85569258e-02\n",
      " 2.81706077e-01 1.04898541e+01], Loss = 0.4829\n",
      "Iteration 1182: Weights = [5.49996188e+01 4.02914471e+00 8.47160737e+00 2.85514179e-02\n",
      " 2.81700579e-01 1.04901123e+01], Loss = 0.4828\n",
      "Iteration 1183: Weights = [5.49996226e+01 4.02903029e+00 8.47136489e+00 2.85459444e-02\n",
      " 2.81695063e-01 1.04903705e+01], Loss = 0.4828\n",
      "Iteration 1184: Weights = [5.49996264e+01 4.02891586e+00 8.47112241e+00 2.85405051e-02\n",
      " 2.81689529e-01 1.04906287e+01], Loss = 0.4828\n",
      "Iteration 1185: Weights = [5.49996301e+01 4.02880142e+00 8.47087993e+00 2.85350997e-02\n",
      " 2.81683978e-01 1.04908869e+01], Loss = 0.4828\n",
      "Iteration 1186: Weights = [5.49996338e+01 4.02868697e+00 8.47063745e+00 2.85297281e-02\n",
      " 2.81678408e-01 1.04911451e+01], Loss = 0.4827\n",
      "Iteration 1187: Weights = [5.49996375e+01 4.02857253e+00 8.47039498e+00 2.85243900e-02\n",
      " 2.81672821e-01 1.04914033e+01], Loss = 0.4827\n",
      "Iteration 1188: Weights = [5.49996411e+01 4.02845807e+00 8.47015250e+00 2.85190850e-02\n",
      " 2.81667216e-01 1.04916614e+01], Loss = 0.4827\n",
      "Iteration 1189: Weights = [5.49996447e+01 4.02834361e+00 8.46991003e+00 2.85138130e-02\n",
      " 2.81661594e-01 1.04919195e+01], Loss = 0.4827\n",
      "Iteration 1190: Weights = [5.49996482e+01 4.02822915e+00 8.46966756e+00 2.85085738e-02\n",
      " 2.81655955e-01 1.04921776e+01], Loss = 0.4826\n",
      "Iteration 1191: Weights = [5.49996518e+01 4.02811468e+00 8.46942509e+00 2.85033670e-02\n",
      " 2.81650298e-01 1.04924357e+01], Loss = 0.4826\n",
      "Iteration 1192: Weights = [5.49996552e+01 4.02800020e+00 8.46918262e+00 2.84981925e-02\n",
      " 2.81644624e-01 1.04926938e+01], Loss = 0.4826\n",
      "Iteration 1193: Weights = [5.49996587e+01 4.02788572e+00 8.46894016e+00 2.84930500e-02\n",
      " 2.81638934e-01 1.04929518e+01], Loss = 0.4825\n",
      "Iteration 1194: Weights = [5.49996621e+01 4.02777124e+00 8.46869770e+00 2.84879392e-02\n",
      " 2.81633226e-01 1.04932099e+01], Loss = 0.4825\n",
      "Iteration 1195: Weights = [5.49996655e+01 4.02765675e+00 8.46845524e+00 2.84828601e-02\n",
      " 2.81627502e-01 1.04934679e+01], Loss = 0.4825\n",
      "Iteration 1196: Weights = [5.49996688e+01 4.02754225e+00 8.46821278e+00 2.84778122e-02\n",
      " 2.81621762e-01 1.04937259e+01], Loss = 0.4825\n",
      "Iteration 1197: Weights = [5.49996721e+01 4.02742776e+00 8.46797032e+00 2.84727954e-02\n",
      " 2.81616004e-01 1.04939839e+01], Loss = 0.4824\n",
      "Iteration 1198: Weights = [5.49996754e+01 4.02731325e+00 8.46772787e+00 2.84678095e-02\n",
      " 2.81610231e-01 1.04942419e+01], Loss = 0.4824\n",
      "Iteration 1199: Weights = [5.49996787e+01 4.02719874e+00 8.46748542e+00 2.84628542e-02\n",
      " 2.81604441e-01 1.04944998e+01], Loss = 0.4824\n",
      "Iteration 1200: Weights = [5.49996819e+01 4.02708423e+00 8.46724297e+00 2.84579293e-02\n",
      " 2.81598635e-01 1.04947578e+01], Loss = 0.4823\n",
      "Iteration 1201: Weights = [5.49996851e+01 4.02696971e+00 8.46700052e+00 2.84530346e-02\n",
      " 2.81592814e-01 1.04950157e+01], Loss = 0.4823\n",
      "Iteration 1202: Weights = [5.49996882e+01 4.02685519e+00 8.46675808e+00 2.84481699e-02\n",
      " 2.81586976e-01 1.04952736e+01], Loss = 0.4823\n",
      "Iteration 1203: Weights = [5.49996913e+01 4.02674066e+00 8.46651564e+00 2.84433349e-02\n",
      " 2.81581123e-01 1.04955315e+01], Loss = 0.4823\n",
      "Iteration 1204: Weights = [5.49996944e+01 4.02662613e+00 8.46627320e+00 2.84385294e-02\n",
      " 2.81575254e-01 1.04957894e+01], Loss = 0.4822\n",
      "Iteration 1205: Weights = [5.49996975e+01 4.02651159e+00 8.46603076e+00 2.84337533e-02\n",
      " 2.81569369e-01 1.04960473e+01], Loss = 0.4822\n",
      "Iteration 1206: Weights = [5.49997005e+01 4.02639705e+00 8.46578832e+00 2.84290062e-02\n",
      " 2.81563469e-01 1.04963051e+01], Loss = 0.4822\n",
      "Iteration 1207: Weights = [5.49997035e+01 4.02628251e+00 8.46554589e+00 2.84242881e-02\n",
      " 2.81557553e-01 1.04965630e+01], Loss = 0.4822\n",
      "Iteration 1208: Weights = [5.49997065e+01 4.02616796e+00 8.46530346e+00 2.84195985e-02\n",
      " 2.81551623e-01 1.04968208e+01], Loss = 0.4821\n",
      "Iteration 1209: Weights = [5.49997094e+01 4.02605341e+00 8.46506103e+00 2.84149375e-02\n",
      " 2.81545677e-01 1.04970786e+01], Loss = 0.4821\n",
      "Iteration 1210: Weights = [5.49997123e+01 4.02593885e+00 8.46481861e+00 2.84103047e-02\n",
      " 2.81539717e-01 1.04973364e+01], Loss = 0.4821\n",
      "Iteration 1211: Weights = [5.49997152e+01 4.02582429e+00 8.46457619e+00 2.84056999e-02\n",
      " 2.81533741e-01 1.04975942e+01], Loss = 0.4820\n",
      "Iteration 1212: Weights = [5.49997180e+01 4.02570972e+00 8.46433377e+00 2.84011230e-02\n",
      " 2.81527751e-01 1.04978519e+01], Loss = 0.4820\n",
      "Iteration 1213: Weights = [5.49997208e+01 4.02559515e+00 8.46409135e+00 2.83965738e-02\n",
      " 2.81521746e-01 1.04981097e+01], Loss = 0.4820\n",
      "Iteration 1214: Weights = [5.49997236e+01 4.02548058e+00 8.46384894e+00 2.83920519e-02\n",
      " 2.81515726e-01 1.04983674e+01], Loss = 0.4820\n",
      "Iteration 1215: Weights = [5.49997264e+01 4.02536600e+00 8.46360653e+00 2.83875573e-02\n",
      " 2.81509692e-01 1.04986251e+01], Loss = 0.4819\n",
      "Iteration 1216: Weights = [5.49997291e+01 4.02525142e+00 8.46336412e+00 2.83830897e-02\n",
      " 2.81503643e-01 1.04988828e+01], Loss = 0.4819\n",
      "Iteration 1217: Weights = [5.49997318e+01 4.02513684e+00 8.46312171e+00 2.83786490e-02\n",
      " 2.81497581e-01 1.04991405e+01], Loss = 0.4819\n",
      "Iteration 1218: Weights = [5.49997345e+01 4.02502225e+00 8.46287931e+00 2.83742349e-02\n",
      " 2.81491504e-01 1.04993982e+01], Loss = 0.4818\n",
      "Iteration 1219: Weights = [5.49997372e+01 4.02490766e+00 8.46263691e+00 2.83698472e-02\n",
      " 2.81485413e-01 1.04996558e+01], Loss = 0.4818\n",
      "Iteration 1220: Weights = [5.49997398e+01 4.02479306e+00 8.46239451e+00 2.83654858e-02\n",
      " 2.81479308e-01 1.04999135e+01], Loss = 0.4818\n",
      "Iteration 1221: Weights = [5.49997424e+01 4.02467847e+00 8.46215212e+00 2.83611504e-02\n",
      " 2.81473189e-01 1.05001711e+01], Loss = 0.4818\n",
      "Iteration 1222: Weights = [5.49997450e+01 4.02456386e+00 8.46190973e+00 2.83568409e-02\n",
      " 2.81467057e-01 1.05004287e+01], Loss = 0.4817\n",
      "Iteration 1223: Weights = [5.49997475e+01 4.02444926e+00 8.46166734e+00 2.83525571e-02\n",
      " 2.81460911e-01 1.05006863e+01], Loss = 0.4817\n",
      "Iteration 1224: Weights = [5.49997501e+01 4.02433465e+00 8.46142496e+00 2.83482988e-02\n",
      " 2.81454751e-01 1.05009439e+01], Loss = 0.4817\n",
      "Iteration 1225: Weights = [5.49997526e+01 4.02422004e+00 8.46118258e+00 2.83440658e-02\n",
      " 2.81448578e-01 1.05012015e+01], Loss = 0.4817\n",
      "Iteration 1226: Weights = [5.49997550e+01 4.02410542e+00 8.46094020e+00 2.83398578e-02\n",
      " 2.81442391e-01 1.05014590e+01], Loss = 0.4816\n",
      "Iteration 1227: Weights = [5.49997575e+01 4.02399080e+00 8.46069782e+00 2.83356749e-02\n",
      " 2.81436192e-01 1.05017166e+01], Loss = 0.4816\n",
      "Iteration 1228: Weights = [5.49997599e+01 4.02387618e+00 8.46045545e+00 2.83315166e-02\n",
      " 2.81429979e-01 1.05019741e+01], Loss = 0.4816\n",
      "Iteration 1229: Weights = [5.49997623e+01 4.02376156e+00 8.46021308e+00 2.83273830e-02\n",
      " 2.81423753e-01 1.05022316e+01], Loss = 0.4815\n",
      "Iteration 1230: Weights = [5.49997647e+01 4.02364693e+00 8.45997072e+00 2.83232737e-02\n",
      " 2.81417513e-01 1.05024891e+01], Loss = 0.4815\n",
      "Iteration 1231: Weights = [5.49997670e+01 4.02353230e+00 8.45972835e+00 2.83191887e-02\n",
      " 2.81411261e-01 1.05027466e+01], Loss = 0.4815\n",
      "Iteration 1232: Weights = [5.49997694e+01 4.02341766e+00 8.45948599e+00 2.83151276e-02\n",
      " 2.81404997e-01 1.05030040e+01], Loss = 0.4815\n",
      "Iteration 1233: Weights = [5.49997717e+01 4.02330302e+00 8.45924364e+00 2.83110905e-02\n",
      " 2.81398719e-01 1.05032615e+01], Loss = 0.4814\n",
      "Iteration 1234: Weights = [5.49997740e+01 4.02318838e+00 8.45900128e+00 2.83070770e-02\n",
      " 2.81392429e-01 1.05035189e+01], Loss = 0.4814\n",
      "Iteration 1235: Weights = [5.49997762e+01 4.02307374e+00 8.45875894e+00 2.83030870e-02\n",
      " 2.81386126e-01 1.05037764e+01], Loss = 0.4814\n",
      "Iteration 1236: Weights = [5.49997785e+01 4.02295910e+00 8.45851659e+00 2.82991204e-02\n",
      " 2.81379811e-01 1.05040338e+01], Loss = 0.4814\n",
      "Iteration 1237: Weights = [5.49997807e+01 4.02284445e+00 8.45827425e+00 2.82951769e-02\n",
      " 2.81373484e-01 1.05042912e+01], Loss = 0.4813\n",
      "Iteration 1238: Weights = [5.49997829e+01 4.02272980e+00 8.45803191e+00 2.82912565e-02\n",
      " 2.81367144e-01 1.05045486e+01], Loss = 0.4813\n",
      "Iteration 1239: Weights = [5.49997850e+01 4.02261514e+00 8.45778957e+00 2.82873588e-02\n",
      " 2.81360792e-01 1.05048059e+01], Loss = 0.4813\n",
      "Iteration 1240: Weights = [5.49997872e+01 4.02250048e+00 8.45754724e+00 2.82834838e-02\n",
      " 2.81354428e-01 1.05050633e+01], Loss = 0.4812\n",
      "Iteration 1241: Weights = [5.49997893e+01 4.02238582e+00 8.45730491e+00 2.82796314e-02\n",
      " 2.81348052e-01 1.05053206e+01], Loss = 0.4812\n",
      "Iteration 1242: Weights = [5.49997914e+01 4.02227116e+00 8.45706259e+00 2.82758012e-02\n",
      " 2.81341664e-01 1.05055780e+01], Loss = 0.4812\n",
      "Iteration 1243: Weights = [5.49997935e+01 4.02215650e+00 8.45682027e+00 2.82719932e-02\n",
      " 2.81335265e-01 1.05058353e+01], Loss = 0.4812\n",
      "Iteration 1244: Weights = [5.49997956e+01 4.02204183e+00 8.45657795e+00 2.82682073e-02\n",
      " 2.81328853e-01 1.05060926e+01], Loss = 0.4811\n",
      "Iteration 1245: Weights = [5.49997976e+01 4.02192716e+00 8.45633563e+00 2.82644431e-02\n",
      " 2.81322430e-01 1.05063499e+01], Loss = 0.4811\n",
      "Iteration 1246: Weights = [5.49997996e+01 4.02181249e+00 8.45609332e+00 2.82607007e-02\n",
      " 2.81315995e-01 1.05066072e+01], Loss = 0.4811\n",
      "Iteration 1247: Weights = [5.49998016e+01 4.02169782e+00 8.45585102e+00 2.82569798e-02\n",
      " 2.81309549e-01 1.05068644e+01], Loss = 0.4810\n",
      "Iteration 1248: Weights = [5.49998036e+01 4.02158314e+00 8.45560871e+00 2.82532802e-02\n",
      " 2.81303092e-01 1.05071217e+01], Loss = 0.4810\n",
      "Iteration 1249: Weights = [5.49998056e+01 4.02146846e+00 8.45536642e+00 2.82496019e-02\n",
      " 2.81296623e-01 1.05073789e+01], Loss = 0.4810\n",
      "Iteration 1250: Weights = [5.49998075e+01 4.02135378e+00 8.45512412e+00 2.82459446e-02\n",
      " 2.81290143e-01 1.05076361e+01], Loss = 0.4810\n",
      "Iteration 1251: Weights = [5.49998095e+01 4.02123910e+00 8.45488183e+00 2.82423082e-02\n",
      " 2.81283651e-01 1.05078934e+01], Loss = 0.4809\n",
      "Iteration 1252: Weights = [5.49998114e+01 4.02112441e+00 8.45463954e+00 2.82386926e-02\n",
      " 2.81277149e-01 1.05081506e+01], Loss = 0.4809\n",
      "Iteration 1253: Weights = [5.49998132e+01 4.02100972e+00 8.45439726e+00 2.82350976e-02\n",
      " 2.81270635e-01 1.05084077e+01], Loss = 0.4809\n",
      "Iteration 1254: Weights = [5.49998151e+01 4.02089504e+00 8.45415497e+00 2.82315230e-02\n",
      " 2.81264111e-01 1.05086649e+01], Loss = 0.4809\n",
      "Iteration 1255: Weights = [5.49998170e+01 4.02078034e+00 8.45391270e+00 2.82279687e-02\n",
      " 2.81257576e-01 1.05089221e+01], Loss = 0.4808\n",
      "Iteration 1256: Weights = [5.49998188e+01 4.02066565e+00 8.45367043e+00 2.82244346e-02\n",
      " 2.81251030e-01 1.05091792e+01], Loss = 0.4808\n",
      "Iteration 1257: Weights = [5.49998206e+01 4.02055095e+00 8.45342816e+00 2.82209204e-02\n",
      " 2.81244473e-01 1.05094364e+01], Loss = 0.4808\n",
      "Iteration 1258: Weights = [5.49998224e+01 4.02043626e+00 8.45318589e+00 2.82174262e-02\n",
      " 2.81237906e-01 1.05096935e+01], Loss = 0.4807\n",
      "Iteration 1259: Weights = [5.49998242e+01 4.02032156e+00 8.45294363e+00 2.82139516e-02\n",
      " 2.81231328e-01 1.05099506e+01], Loss = 0.4807\n",
      "Iteration 1260: Weights = [5.49998259e+01 4.02020686e+00 8.45270137e+00 2.82104966e-02\n",
      " 2.81224740e-01 1.05102077e+01], Loss = 0.4807\n",
      "Iteration 1261: Weights = [5.49998277e+01 4.02009215e+00 8.45245912e+00 2.82070610e-02\n",
      " 2.81218141e-01 1.05104648e+01], Loss = 0.4807\n",
      "Iteration 1262: Weights = [5.49998294e+01 4.01997745e+00 8.45221687e+00 2.82036447e-02\n",
      " 2.81211532e-01 1.05107218e+01], Loss = 0.4806\n",
      "Iteration 1263: Weights = [5.49998311e+01 4.01986274e+00 8.45197463e+00 2.82002476e-02\n",
      " 2.81204913e-01 1.05109789e+01], Loss = 0.4806\n",
      "Iteration 1264: Weights = [5.49998328e+01 4.01974803e+00 8.45173239e+00 2.81968694e-02\n",
      " 2.81198283e-01 1.05112359e+01], Loss = 0.4806\n",
      "Iteration 1265: Weights = [5.49998345e+01 4.01963332e+00 8.45149015e+00 2.81935101e-02\n",
      " 2.81191644e-01 1.05114930e+01], Loss = 0.4805\n",
      "Iteration 1266: Weights = [5.49998361e+01 4.01951861e+00 8.45124792e+00 2.81901696e-02\n",
      " 2.81184994e-01 1.05117500e+01], Loss = 0.4805\n",
      "Iteration 1267: Weights = [5.49998378e+01 4.01940390e+00 8.45100569e+00 2.81868476e-02\n",
      " 2.81178335e-01 1.05120070e+01], Loss = 0.4805\n",
      "Iteration 1268: Weights = [5.49998394e+01 4.01928919e+00 8.45076347e+00 2.81835441e-02\n",
      " 2.81171665e-01 1.05122640e+01], Loss = 0.4805\n",
      "Iteration 1269: Weights = [5.49998410e+01 4.01917447e+00 8.45052125e+00 2.81802589e-02\n",
      " 2.81164986e-01 1.05125210e+01], Loss = 0.4804\n",
      "Iteration 1270: Weights = [5.49998426e+01 4.01905975e+00 8.45027903e+00 2.81769918e-02\n",
      " 2.81158297e-01 1.05127779e+01], Loss = 0.4804\n",
      "Iteration 1271: Weights = [5.49998442e+01 4.01894503e+00 8.45003682e+00 2.81737429e-02\n",
      " 2.81151599e-01 1.05130349e+01], Loss = 0.4804\n",
      "Iteration 1272: Weights = [5.49998457e+01 4.01883031e+00 8.44979461e+00 2.81705118e-02\n",
      " 2.81144891e-01 1.05132918e+01], Loss = 0.4804\n",
      "Iteration 1273: Weights = [5.49998473e+01 4.01871559e+00 8.44955241e+00 2.81672985e-02\n",
      " 2.81138173e-01 1.05135488e+01], Loss = 0.4803\n",
      "Iteration 1274: Weights = [5.49998488e+01 4.01860087e+00 8.44931021e+00 2.81641029e-02\n",
      " 2.81131446e-01 1.05138057e+01], Loss = 0.4803\n",
      "Iteration 1275: Weights = [5.49998503e+01 4.01848614e+00 8.44906801e+00 2.81609248e-02\n",
      " 2.81124709e-01 1.05140626e+01], Loss = 0.4803\n",
      "Iteration 1276: Weights = [5.49998518e+01 4.01837142e+00 8.44882582e+00 2.81577641e-02\n",
      " 2.81117964e-01 1.05143195e+01], Loss = 0.4802\n",
      "Iteration 1277: Weights = [5.49998533e+01 4.01825669e+00 8.44858364e+00 2.81546207e-02\n",
      " 2.81111209e-01 1.05145764e+01], Loss = 0.4802\n",
      "Iteration 1278: Weights = [5.49998547e+01 4.01814196e+00 8.44834146e+00 2.81514944e-02\n",
      " 2.81104444e-01 1.05148332e+01], Loss = 0.4802\n",
      "Iteration 1279: Weights = [5.49998562e+01 4.01802723e+00 8.44809928e+00 2.81483852e-02\n",
      " 2.81097671e-01 1.05150901e+01], Loss = 0.4802\n",
      "Iteration 1280: Weights = [5.49998576e+01 4.01791250e+00 8.44785711e+00 2.81452928e-02\n",
      " 2.81090889e-01 1.05153470e+01], Loss = 0.4801\n",
      "Iteration 1281: Weights = [5.49998591e+01 4.01779777e+00 8.44761494e+00 2.81422172e-02\n",
      " 2.81084097e-01 1.05156038e+01], Loss = 0.4801\n",
      "Iteration 1282: Weights = [5.49998605e+01 4.01768304e+00 8.44737277e+00 2.81391583e-02\n",
      " 2.81077297e-01 1.05158606e+01], Loss = 0.4801\n",
      "Iteration 1283: Weights = [5.49998619e+01 4.01756830e+00 8.44713061e+00 2.81361159e-02\n",
      " 2.81070488e-01 1.05161174e+01], Loss = 0.4801\n",
      "Iteration 1284: Weights = [5.49998632e+01 4.01745357e+00 8.44688846e+00 2.81330899e-02\n",
      " 2.81063670e-01 1.05163742e+01], Loss = 0.4800\n",
      "Iteration 1285: Weights = [5.49998646e+01 4.01733883e+00 8.44664631e+00 2.81300801e-02\n",
      " 2.81056843e-01 1.05166310e+01], Loss = 0.4800\n",
      "Iteration 1286: Weights = [5.49998660e+01 4.01722410e+00 8.44640416e+00 2.81270866e-02\n",
      " 2.81050008e-01 1.05168878e+01], Loss = 0.4800\n",
      "Iteration 1287: Weights = [5.49998673e+01 4.01710936e+00 8.44616202e+00 2.81241091e-02\n",
      " 2.81043164e-01 1.05171446e+01], Loss = 0.4799\n",
      "Iteration 1288: Weights = [5.49998686e+01 4.01699462e+00 8.44591988e+00 2.81211475e-02\n",
      " 2.81036312e-01 1.05174013e+01], Loss = 0.4799\n",
      "Iteration 1289: Weights = [5.49998699e+01 4.01687988e+00 8.44567775e+00 2.81182018e-02\n",
      " 2.81029451e-01 1.05176580e+01], Loss = 0.4799\n",
      "Iteration 1290: Weights = [5.49998712e+01 4.01676514e+00 8.44543562e+00 2.81152718e-02\n",
      " 2.81022581e-01 1.05179148e+01], Loss = 0.4799\n",
      "Iteration 1291: Weights = [5.49998725e+01 4.01665040e+00 8.44519350e+00 2.81123573e-02\n",
      " 2.81015704e-01 1.05181715e+01], Loss = 0.4798\n",
      "Iteration 1292: Weights = [5.49998738e+01 4.01653566e+00 8.44495138e+00 2.81094583e-02\n",
      " 2.81008818e-01 1.05184282e+01], Loss = 0.4798\n",
      "Iteration 1293: Weights = [5.49998751e+01 4.01642091e+00 8.44470927e+00 2.81065747e-02\n",
      " 2.81001923e-01 1.05186849e+01], Loss = 0.4798\n",
      "Iteration 1294: Weights = [5.49998763e+01 4.01630617e+00 8.44446716e+00 2.81037063e-02\n",
      " 2.80995021e-01 1.05189416e+01], Loss = 0.4797\n",
      "Iteration 1295: Weights = [5.49998776e+01 4.01619142e+00 8.44422505e+00 2.81008531e-02\n",
      " 2.80988110e-01 1.05191982e+01], Loss = 0.4797\n",
      "Iteration 1296: Weights = [5.49998788e+01 4.01607668e+00 8.44398295e+00 2.80980148e-02\n",
      " 2.80981192e-01 1.05194549e+01], Loss = 0.4797\n",
      "Iteration 1297: Weights = [5.49998800e+01 4.01596193e+00 8.44374086e+00 2.80951915e-02\n",
      " 2.80974265e-01 1.05197116e+01], Loss = 0.4797\n",
      "Iteration 1298: Weights = [5.49998812e+01 4.01584719e+00 8.44349877e+00 2.80923830e-02\n",
      " 2.80967331e-01 1.05199682e+01], Loss = 0.4796\n",
      "Iteration 1299: Weights = [5.49998824e+01 4.01573244e+00 8.44325668e+00 2.80895892e-02\n",
      " 2.80960388e-01 1.05202248e+01], Loss = 0.4796\n",
      "Iteration 1300: Weights = [5.49998836e+01 4.01561769e+00 8.44301460e+00 2.80868100e-02\n",
      " 2.80953438e-01 1.05204814e+01], Loss = 0.4796\n",
      "Iteration 1301: Weights = [5.49998847e+01 4.01550295e+00 8.44277252e+00 2.80840453e-02\n",
      " 2.80946480e-01 1.05207380e+01], Loss = 0.4796\n",
      "Iteration 1302: Weights = [5.49998859e+01 4.01538820e+00 8.44253045e+00 2.80812949e-02\n",
      " 2.80939515e-01 1.05209946e+01], Loss = 0.4795\n",
      "Iteration 1303: Weights = [5.49998870e+01 4.01527345e+00 8.44228839e+00 2.80785589e-02\n",
      " 2.80932541e-01 1.05212512e+01], Loss = 0.4795\n",
      "Iteration 1304: Weights = [5.49998881e+01 4.01515870e+00 8.44204632e+00 2.80758370e-02\n",
      " 2.80925561e-01 1.05215078e+01], Loss = 0.4795\n",
      "Iteration 1305: Weights = [5.49998893e+01 4.01504395e+00 8.44180427e+00 2.80731291e-02\n",
      " 2.80918572e-01 1.05217643e+01], Loss = 0.4794\n",
      "Iteration 1306: Weights = [5.49998904e+01 4.01492920e+00 8.44156221e+00 2.80704353e-02\n",
      " 2.80911576e-01 1.05220209e+01], Loss = 0.4794\n",
      "Iteration 1307: Weights = [5.49998915e+01 4.01481445e+00 8.44132017e+00 2.80677552e-02\n",
      " 2.80904573e-01 1.05222774e+01], Loss = 0.4794\n",
      "Iteration 1308: Weights = [5.49998926e+01 4.01469970e+00 8.44107812e+00 2.80650890e-02\n",
      " 2.80897562e-01 1.05225339e+01], Loss = 0.4794\n",
      "Iteration 1309: Weights = [5.49998936e+01 4.01458495e+00 8.44083609e+00 2.80624364e-02\n",
      " 2.80890544e-01 1.05227904e+01], Loss = 0.4793\n",
      "Iteration 1310: Weights = [5.49998947e+01 4.01447020e+00 8.44059405e+00 2.80597974e-02\n",
      " 2.80883519e-01 1.05230469e+01], Loss = 0.4793\n",
      "Iteration 1311: Weights = [5.49998957e+01 4.01435545e+00 8.44035203e+00 2.80571718e-02\n",
      " 2.80876486e-01 1.05233034e+01], Loss = 0.4793\n",
      "Iteration 1312: Weights = [5.49998968e+01 4.01424069e+00 8.44011000e+00 2.80545596e-02\n",
      " 2.80869446e-01 1.05235599e+01], Loss = 0.4793\n",
      "Iteration 1313: Weights = [5.49998978e+01 4.01412594e+00 8.43986799e+00 2.80519606e-02\n",
      " 2.80862400e-01 1.05238164e+01], Loss = 0.4792\n",
      "Iteration 1314: Weights = [5.49998988e+01 4.01401119e+00 8.43962597e+00 2.80493749e-02\n",
      " 2.80855346e-01 1.05240728e+01], Loss = 0.4792\n",
      "Iteration 1315: Weights = [5.49998999e+01 4.01389644e+00 8.43938396e+00 2.80468021e-02\n",
      " 2.80848285e-01 1.05243293e+01], Loss = 0.4792\n",
      "Iteration 1316: Weights = [5.49999009e+01 4.01378168e+00 8.43914196e+00 2.80442424e-02\n",
      " 2.80841217e-01 1.05245857e+01], Loss = 0.4791\n",
      "Iteration 1317: Weights = [5.49999018e+01 4.01366693e+00 8.43889996e+00 2.80416956e-02\n",
      " 2.80834142e-01 1.05248421e+01], Loss = 0.4791\n",
      "Iteration 1318: Weights = [5.49999028e+01 4.01355218e+00 8.43865797e+00 2.80391615e-02\n",
      " 2.80827061e-01 1.05250986e+01], Loss = 0.4791\n",
      "Iteration 1319: Weights = [5.49999038e+01 4.01343743e+00 8.43841598e+00 2.80366401e-02\n",
      " 2.80819973e-01 1.05253550e+01], Loss = 0.4791\n",
      "Iteration 1320: Weights = [5.49999048e+01 4.01332267e+00 8.43817400e+00 2.80341314e-02\n",
      " 2.80812877e-01 1.05256114e+01], Loss = 0.4790\n",
      "Iteration 1321: Weights = [5.49999057e+01 4.01320792e+00 8.43793202e+00 2.80316351e-02\n",
      " 2.80805776e-01 1.05258677e+01], Loss = 0.4790\n",
      "Iteration 1322: Weights = [5.49999067e+01 4.01309317e+00 8.43769005e+00 2.80291513e-02\n",
      " 2.80798667e-01 1.05261241e+01], Loss = 0.4790\n",
      "Iteration 1323: Weights = [5.49999076e+01 4.01297842e+00 8.43744808e+00 2.80266798e-02\n",
      " 2.80791552e-01 1.05263805e+01], Loss = 0.4790\n",
      "Iteration 1324: Weights = [5.49999085e+01 4.01286366e+00 8.43720612e+00 2.80242205e-02\n",
      " 2.80784430e-01 1.05266368e+01], Loss = 0.4789\n",
      "Iteration 1325: Weights = [5.49999094e+01 4.01274891e+00 8.43696416e+00 2.80217734e-02\n",
      " 2.80777302e-01 1.05268932e+01], Loss = 0.4789\n",
      "Iteration 1326: Weights = [5.49999103e+01 4.01263416e+00 8.43672221e+00 2.80193383e-02\n",
      " 2.80770168e-01 1.05271495e+01], Loss = 0.4789\n",
      "Iteration 1327: Weights = [5.49999112e+01 4.01251940e+00 8.43648026e+00 2.80169152e-02\n",
      " 2.80763027e-01 1.05274058e+01], Loss = 0.4788\n",
      "Iteration 1328: Weights = [5.49999121e+01 4.01240465e+00 8.43623832e+00 2.80145040e-02\n",
      " 2.80755879e-01 1.05276621e+01], Loss = 0.4788\n",
      "Iteration 1329: Weights = [5.49999130e+01 4.01228990e+00 8.43599638e+00 2.80121046e-02\n",
      " 2.80748725e-01 1.05279184e+01], Loss = 0.4788\n",
      "Iteration 1330: Weights = [5.49999139e+01 4.01217515e+00 8.43575445e+00 2.80097169e-02\n",
      " 2.80741566e-01 1.05281747e+01], Loss = 0.4788\n",
      "Iteration 1331: Weights = [5.49999147e+01 4.01206040e+00 8.43551253e+00 2.80073408e-02\n",
      " 2.80734399e-01 1.05284310e+01], Loss = 0.4787\n",
      "Iteration 1332: Weights = [5.49999156e+01 4.01194565e+00 8.43527060e+00 2.80049763e-02\n",
      " 2.80727227e-01 1.05286872e+01], Loss = 0.4787\n",
      "Iteration 1333: Weights = [5.49999164e+01 4.01183089e+00 8.43502869e+00 2.80026232e-02\n",
      " 2.80720048e-01 1.05289435e+01], Loss = 0.4787\n",
      "Iteration 1334: Weights = [5.49999173e+01 4.01171614e+00 8.43478678e+00 2.80002815e-02\n",
      " 2.80712864e-01 1.05291997e+01], Loss = 0.4786\n",
      "Iteration 1335: Weights = [5.49999181e+01 4.01160139e+00 8.43454487e+00 2.79979511e-02\n",
      " 2.80705673e-01 1.05294560e+01], Loss = 0.4786\n",
      "Iteration 1336: Weights = [5.49999189e+01 4.01148664e+00 8.43430297e+00 2.79956319e-02\n",
      " 2.80698476e-01 1.05297122e+01], Loss = 0.4786\n",
      "Iteration 1337: Weights = [5.49999197e+01 4.01137189e+00 8.43406108e+00 2.79933238e-02\n",
      " 2.80691274e-01 1.05299684e+01], Loss = 0.4786\n",
      "Iteration 1338: Weights = [5.49999205e+01 4.01125714e+00 8.43381919e+00 2.79910268e-02\n",
      " 2.80684065e-01 1.05302246e+01], Loss = 0.4785\n",
      "Iteration 1339: Weights = [5.49999213e+01 4.01114239e+00 8.43357730e+00 2.79887407e-02\n",
      " 2.80676851e-01 1.05304808e+01], Loss = 0.4785\n",
      "Iteration 1340: Weights = [5.49999221e+01 4.01102765e+00 8.43333542e+00 2.79864655e-02\n",
      " 2.80669631e-01 1.05307370e+01], Loss = 0.4785\n",
      "Iteration 1341: Weights = [5.49999229e+01 4.01091290e+00 8.43309355e+00 2.79842011e-02\n",
      " 2.80662405e-01 1.05309931e+01], Loss = 0.4785\n",
      "Iteration 1342: Weights = [5.49999237e+01 4.01079815e+00 8.43285168e+00 2.79819475e-02\n",
      " 2.80655173e-01 1.05312493e+01], Loss = 0.4784\n",
      "Iteration 1343: Weights = [5.49999244e+01 4.01068340e+00 8.43260982e+00 2.79797045e-02\n",
      " 2.80647936e-01 1.05315054e+01], Loss = 0.4784\n",
      "Iteration 1344: Weights = [5.49999252e+01 4.01056866e+00 8.43236796e+00 2.79774720e-02\n",
      " 2.80640693e-01 1.05317616e+01], Loss = 0.4784\n",
      "Iteration 1345: Weights = [5.49999259e+01 4.01045391e+00 8.43212611e+00 2.79752501e-02\n",
      " 2.80633444e-01 1.05320177e+01], Loss = 0.4783\n",
      "Iteration 1346: Weights = [5.49999267e+01 4.01033916e+00 8.43188426e+00 2.79730386e-02\n",
      " 2.80626190e-01 1.05322738e+01], Loss = 0.4783\n",
      "Iteration 1347: Weights = [5.49999274e+01 4.01022442e+00 8.43164242e+00 2.79708374e-02\n",
      " 2.80618930e-01 1.05325299e+01], Loss = 0.4783\n",
      "Iteration 1348: Weights = [5.49999281e+01 4.01010967e+00 8.43140058e+00 2.79686465e-02\n",
      " 2.80611665e-01 1.05327860e+01], Loss = 0.4783\n",
      "Iteration 1349: Weights = [5.49999288e+01 4.00999493e+00 8.43115875e+00 2.79664657e-02\n",
      " 2.80604394e-01 1.05330421e+01], Loss = 0.4782\n",
      "Iteration 1350: Weights = [5.49999296e+01 4.00988019e+00 8.43091693e+00 2.79642951e-02\n",
      " 2.80597118e-01 1.05332982e+01], Loss = 0.4782\n",
      "Iteration 1351: Weights = [5.49999303e+01 4.00976544e+00 8.43067511e+00 2.79621345e-02\n",
      " 2.80589836e-01 1.05335543e+01], Loss = 0.4782\n",
      "Iteration 1352: Weights = [5.49999310e+01 4.00965070e+00 8.43043329e+00 2.79599839e-02\n",
      " 2.80582549e-01 1.05338103e+01], Loss = 0.4782\n",
      "Iteration 1353: Weights = [5.49999316e+01 4.00953596e+00 8.43019149e+00 2.79578432e-02\n",
      " 2.80575257e-01 1.05340664e+01], Loss = 0.4781\n",
      "Iteration 1354: Weights = [5.49999323e+01 4.00942122e+00 8.42994968e+00 2.79557123e-02\n",
      " 2.80567960e-01 1.05343224e+01], Loss = 0.4781\n",
      "Iteration 1355: Weights = [5.49999330e+01 4.00930648e+00 8.42970788e+00 2.79535912e-02\n",
      " 2.80560657e-01 1.05345784e+01], Loss = 0.4781\n",
      "Iteration 1356: Weights = [5.49999337e+01 4.00919174e+00 8.42946609e+00 2.79514798e-02\n",
      " 2.80553349e-01 1.05348345e+01], Loss = 0.4780\n",
      "Iteration 1357: Weights = [5.49999343e+01 4.00907700e+00 8.42922430e+00 2.79493779e-02\n",
      " 2.80546037e-01 1.05350905e+01], Loss = 0.4780\n",
      "Iteration 1358: Weights = [5.49999350e+01 4.00896226e+00 8.42898252e+00 2.79472856e-02\n",
      " 2.80538719e-01 1.05353465e+01], Loss = 0.4780\n",
      "Iteration 1359: Weights = [5.49999356e+01 4.00884753e+00 8.42874075e+00 2.79452028e-02\n",
      " 2.80531396e-01 1.05356024e+01], Loss = 0.4780\n",
      "Iteration 1360: Weights = [5.49999363e+01 4.00873279e+00 8.42849898e+00 2.79431294e-02\n",
      " 2.80524068e-01 1.05358584e+01], Loss = 0.4779\n",
      "Iteration 1361: Weights = [5.49999369e+01 4.00861805e+00 8.42825721e+00 2.79410653e-02\n",
      " 2.80516734e-01 1.05361144e+01], Loss = 0.4779\n",
      "Iteration 1362: Weights = [5.49999376e+01 4.00850332e+00 8.42801545e+00 2.79390105e-02\n",
      " 2.80509396e-01 1.05363704e+01], Loss = 0.4779\n",
      "Iteration 1363: Weights = [5.49999382e+01 4.00838858e+00 8.42777370e+00 2.79369649e-02\n",
      " 2.80502054e-01 1.05366263e+01], Loss = 0.4779\n",
      "Iteration 1364: Weights = [5.49999388e+01 4.00827385e+00 8.42753195e+00 2.79349284e-02\n",
      " 2.80494706e-01 1.05368822e+01], Loss = 0.4778\n",
      "Iteration 1365: Weights = [5.49999394e+01 4.00815912e+00 8.42729021e+00 2.79329009e-02\n",
      " 2.80487353e-01 1.05371382e+01], Loss = 0.4778\n",
      "Iteration 1366: Weights = [5.49999400e+01 4.00804439e+00 8.42704847e+00 2.79308825e-02\n",
      " 2.80479996e-01 1.05373941e+01], Loss = 0.4778\n",
      "Iteration 1367: Weights = [5.49999406e+01 4.00792966e+00 8.42680674e+00 2.79288730e-02\n",
      " 2.80472634e-01 1.05376500e+01], Loss = 0.4777\n",
      "Iteration 1368: Weights = [5.49999412e+01 4.00781493e+00 8.42656502e+00 2.79268724e-02\n",
      " 2.80465267e-01 1.05379059e+01], Loss = 0.4777\n",
      "Iteration 1369: Weights = [5.49999418e+01 4.00770020e+00 8.42632330e+00 2.79248805e-02\n",
      " 2.80457895e-01 1.05381618e+01], Loss = 0.4777\n",
      "Iteration 1370: Weights = [5.49999424e+01 4.00758547e+00 8.42608158e+00 2.79228975e-02\n",
      " 2.80450519e-01 1.05384177e+01], Loss = 0.4777\n",
      "Iteration 1371: Weights = [5.49999430e+01 4.00747075e+00 8.42583987e+00 2.79209230e-02\n",
      " 2.80443138e-01 1.05386735e+01], Loss = 0.4776\n",
      "Iteration 1372: Weights = [5.49999435e+01 4.00735602e+00 8.42559817e+00 2.79189572e-02\n",
      " 2.80435753e-01 1.05389294e+01], Loss = 0.4776\n",
      "Iteration 1373: Weights = [5.49999441e+01 4.00724130e+00 8.42535647e+00 2.79170000e-02\n",
      " 2.80428363e-01 1.05391852e+01], Loss = 0.4776\n",
      "Iteration 1374: Weights = [5.49999446e+01 4.00712657e+00 8.42511478e+00 2.79150512e-02\n",
      " 2.80420968e-01 1.05394411e+01], Loss = 0.4776\n",
      "Iteration 1375: Weights = [5.49999452e+01 4.00701185e+00 8.42487309e+00 2.79131109e-02\n",
      " 2.80413569e-01 1.05396969e+01], Loss = 0.4775\n",
      "Iteration 1376: Weights = [5.49999458e+01 4.00689713e+00 8.42463141e+00 2.79111789e-02\n",
      " 2.80406166e-01 1.05399527e+01], Loss = 0.4775\n",
      "Iteration 1377: Weights = [5.49999463e+01 4.00678241e+00 8.42438974e+00 2.79092552e-02\n",
      " 2.80398758e-01 1.05402085e+01], Loss = 0.4775\n",
      "Iteration 1378: Weights = [5.49999468e+01 4.00666769e+00 8.42414807e+00 2.79073398e-02\n",
      " 2.80391346e-01 1.05404644e+01], Loss = 0.4774\n",
      "Iteration 1379: Weights = [5.49999474e+01 4.00655297e+00 8.42390641e+00 2.79054326e-02\n",
      " 2.80383929e-01 1.05407201e+01], Loss = 0.4774\n",
      "Iteration 1380: Weights = [5.49999479e+01 4.00643826e+00 8.42366475e+00 2.79035334e-02\n",
      " 2.80376508e-01 1.05409759e+01], Loss = 0.4774\n",
      "Iteration 1381: Weights = [5.49999484e+01 4.00632354e+00 8.42342310e+00 2.79016424e-02\n",
      " 2.80369083e-01 1.05412317e+01], Loss = 0.4774\n",
      "Iteration 1382: Weights = [5.49999489e+01 4.00620883e+00 8.42318145e+00 2.78997593e-02\n",
      " 2.80361653e-01 1.05414875e+01], Loss = 0.4773\n",
      "Iteration 1383: Weights = [5.49999494e+01 4.00609411e+00 8.42293981e+00 2.78978842e-02\n",
      " 2.80354220e-01 1.05417432e+01], Loss = 0.4773\n",
      "Iteration 1384: Weights = [5.49999499e+01 4.00597940e+00 8.42269818e+00 2.78960170e-02\n",
      " 2.80346782e-01 1.05419990e+01], Loss = 0.4773\n",
      "Iteration 1385: Weights = [5.49999504e+01 4.00586469e+00 8.42245655e+00 2.78941576e-02\n",
      " 2.80339340e-01 1.05422547e+01], Loss = 0.4772\n",
      "Iteration 1386: Weights = [5.49999509e+01 4.00574998e+00 8.42221492e+00 2.78923060e-02\n",
      " 2.80331893e-01 1.05425104e+01], Loss = 0.4772\n",
      "Iteration 1387: Weights = [5.49999514e+01 4.00563527e+00 8.42197331e+00 2.78904621e-02\n",
      " 2.80324443e-01 1.05427661e+01], Loss = 0.4772\n",
      "Iteration 1388: Weights = [5.49999519e+01 4.00552057e+00 8.42173170e+00 2.78886258e-02\n",
      " 2.80316989e-01 1.05430218e+01], Loss = 0.4772\n",
      "Iteration 1389: Weights = [5.49999524e+01 4.00540586e+00 8.42149009e+00 2.78867972e-02\n",
      " 2.80309530e-01 1.05432775e+01], Loss = 0.4771\n",
      "Iteration 1390: Weights = [5.49999529e+01 4.00529116e+00 8.42124849e+00 2.78849761e-02\n",
      " 2.80302068e-01 1.05435332e+01], Loss = 0.4771\n",
      "Iteration 1391: Weights = [5.49999533e+01 4.00517645e+00 8.42100690e+00 2.78831625e-02\n",
      " 2.80294602e-01 1.05437889e+01], Loss = 0.4771\n",
      "Iteration 1392: Weights = [5.49999538e+01 4.00506175e+00 8.42076531e+00 2.78813564e-02\n",
      " 2.80287131e-01 1.05440446e+01], Loss = 0.4771\n",
      "Iteration 1393: Weights = [5.49999543e+01 4.00494705e+00 8.42052373e+00 2.78795576e-02\n",
      " 2.80279657e-01 1.05443002e+01], Loss = 0.4770\n",
      "Iteration 1394: Weights = [5.49999547e+01 4.00483235e+00 8.42028215e+00 2.78777662e-02\n",
      " 2.80272179e-01 1.05445559e+01], Loss = 0.4770\n",
      "Iteration 1395: Weights = [5.49999552e+01 4.00471765e+00 8.42004058e+00 2.78759820e-02\n",
      " 2.80264697e-01 1.05448115e+01], Loss = 0.4770\n",
      "Iteration 1396: Weights = [5.49999556e+01 4.00460296e+00 8.41979902e+00 2.78742051e-02\n",
      " 2.80257211e-01 1.05450672e+01], Loss = 0.4769\n",
      "Iteration 1397: Weights = [5.49999561e+01 4.00448826e+00 8.41955746e+00 2.78724354e-02\n",
      " 2.80249722e-01 1.05453228e+01], Loss = 0.4769\n",
      "Iteration 1398: Weights = [5.49999565e+01 4.00437357e+00 8.41931590e+00 2.78706727e-02\n",
      " 2.80242228e-01 1.05455784e+01], Loss = 0.4769\n",
      "Iteration 1399: Weights = [5.49999569e+01 4.00425888e+00 8.41907436e+00 2.78689172e-02\n",
      " 2.80234731e-01 1.05458340e+01], Loss = 0.4769\n",
      "Iteration 1400: Weights = [5.49999574e+01 4.00414419e+00 8.41883282e+00 2.78671686e-02\n",
      " 2.80227230e-01 1.05460896e+01], Loss = 0.4768\n",
      "Iteration 1401: Weights = [5.49999578e+01 4.00402950e+00 8.41859128e+00 2.78654271e-02\n",
      " 2.80219726e-01 1.05463452e+01], Loss = 0.4768\n",
      "Iteration 1402: Weights = [5.49999582e+01 4.00391481e+00 8.41834975e+00 2.78636924e-02\n",
      " 2.80212218e-01 1.05466008e+01], Loss = 0.4768\n",
      "Iteration 1403: Weights = [5.49999586e+01 4.00380012e+00 8.41810823e+00 2.78619646e-02\n",
      " 2.80204706e-01 1.05468563e+01], Loss = 0.4768\n",
      "Iteration 1404: Weights = [5.49999591e+01 4.00368544e+00 8.41786671e+00 2.78602436e-02\n",
      " 2.80197191e-01 1.05471119e+01], Loss = 0.4767\n",
      "Iteration 1405: Weights = [5.49999595e+01 4.00357075e+00 8.41762520e+00 2.78585294e-02\n",
      " 2.80189672e-01 1.05473674e+01], Loss = 0.4767\n",
      "Iteration 1406: Weights = [5.49999599e+01 4.00345607e+00 8.41738369e+00 2.78568219e-02\n",
      " 2.80182149e-01 1.05476230e+01], Loss = 0.4767\n",
      "Iteration 1407: Weights = [5.49999603e+01 4.00334139e+00 8.41714219e+00 2.78551211e-02\n",
      " 2.80174623e-01 1.05478785e+01], Loss = 0.4766\n",
      "Iteration 1408: Weights = [5.49999607e+01 4.00322671e+00 8.41690070e+00 2.78534269e-02\n",
      " 2.80167094e-01 1.05481340e+01], Loss = 0.4766\n",
      "Iteration 1409: Weights = [5.49999611e+01 4.00311203e+00 8.41665921e+00 2.78517393e-02\n",
      " 2.80159561e-01 1.05483895e+01], Loss = 0.4766\n",
      "Iteration 1410: Weights = [5.49999615e+01 4.00299736e+00 8.41641773e+00 2.78500582e-02\n",
      " 2.80152024e-01 1.05486450e+01], Loss = 0.4766\n",
      "Iteration 1411: Weights = [5.49999618e+01 4.00288268e+00 8.41617625e+00 2.78483835e-02\n",
      " 2.80144484e-01 1.05489005e+01], Loss = 0.4765\n",
      "Iteration 1412: Weights = [5.49999622e+01 4.00276801e+00 8.41593478e+00 2.78467153e-02\n",
      " 2.80136941e-01 1.05491560e+01], Loss = 0.4765\n",
      "Iteration 1413: Weights = [5.49999626e+01 4.00265334e+00 8.41569332e+00 2.78450535e-02\n",
      " 2.80129394e-01 1.05494115e+01], Loss = 0.4765\n",
      "Iteration 1414: Weights = [5.49999630e+01 4.00253867e+00 8.41545186e+00 2.78433980e-02\n",
      " 2.80121844e-01 1.05496670e+01], Loss = 0.4765\n",
      "Iteration 1415: Weights = [5.49999633e+01 4.00242400e+00 8.41521041e+00 2.78417488e-02\n",
      " 2.80114291e-01 1.05499224e+01], Loss = 0.4764\n",
      "Iteration 1416: Weights = [5.49999637e+01 4.00230934e+00 8.41496896e+00 2.78401059e-02\n",
      " 2.80106735e-01 1.05501779e+01], Loss = 0.4764\n",
      "Iteration 1417: Weights = [5.49999641e+01 4.00219467e+00 8.41472752e+00 2.78384691e-02\n",
      " 2.80099175e-01 1.05504333e+01], Loss = 0.4764\n",
      "Iteration 1418: Weights = [5.49999644e+01 4.00208001e+00 8.41448609e+00 2.78368385e-02\n",
      " 2.80091612e-01 1.05506887e+01], Loss = 0.4763\n",
      "Iteration 1419: Weights = [5.49999648e+01 4.00196535e+00 8.41424466e+00 2.78352140e-02\n",
      " 2.80084046e-01 1.05509442e+01], Loss = 0.4763\n",
      "Iteration 1420: Weights = [5.49999651e+01 4.00185069e+00 8.41400324e+00 2.78335956e-02\n",
      " 2.80076476e-01 1.05511996e+01], Loss = 0.4763\n",
      "Iteration 1421: Weights = [5.49999655e+01 4.00173603e+00 8.41376183e+00 2.78319832e-02\n",
      " 2.80068904e-01 1.05514550e+01], Loss = 0.4763\n",
      "Iteration 1422: Weights = [5.49999658e+01 4.00162137e+00 8.41352042e+00 2.78303768e-02\n",
      " 2.80061328e-01 1.05517104e+01], Loss = 0.4762\n",
      "Iteration 1423: Weights = [5.49999662e+01 4.00150672e+00 8.41327901e+00 2.78287763e-02\n",
      " 2.80053749e-01 1.05519658e+01], Loss = 0.4762\n",
      "Iteration 1424: Weights = [5.49999665e+01 4.00139207e+00 8.41303761e+00 2.78271817e-02\n",
      " 2.80046167e-01 1.05522211e+01], Loss = 0.4762\n",
      "Iteration 1425: Weights = [5.49999668e+01 4.00127742e+00 8.41279622e+00 2.78255929e-02\n",
      " 2.80038582e-01 1.05524765e+01], Loss = 0.4762\n",
      "Iteration 1426: Weights = [5.49999672e+01 4.00116277e+00 8.41255484e+00 2.78240100e-02\n",
      " 2.80030994e-01 1.05527319e+01], Loss = 0.4761\n",
      "Iteration 1427: Weights = [5.49999675e+01 4.00104812e+00 8.41231346e+00 2.78224328e-02\n",
      " 2.80023403e-01 1.05529872e+01], Loss = 0.4761\n",
      "Iteration 1428: Weights = [5.49999678e+01 4.00093347e+00 8.41207209e+00 2.78208613e-02\n",
      " 2.80015809e-01 1.05532426e+01], Loss = 0.4761\n",
      "Iteration 1429: Weights = [5.49999682e+01 4.00081883e+00 8.41183072e+00 2.78192955e-02\n",
      " 2.80008212e-01 1.05534979e+01], Loss = 0.4760\n",
      "Iteration 1430: Weights = [5.49999685e+01 4.00070419e+00 8.41158936e+00 2.78177353e-02\n",
      " 2.80000612e-01 1.05537532e+01], Loss = 0.4760\n",
      "Iteration 1431: Weights = [5.49999688e+01 4.00058955e+00 8.41134800e+00 2.78161808e-02\n",
      " 2.79993009e-01 1.05540085e+01], Loss = 0.4760\n",
      "Iteration 1432: Weights = [5.49999691e+01 4.00047491e+00 8.41110665e+00 2.78146318e-02\n",
      " 2.79985403e-01 1.05542638e+01], Loss = 0.4760\n",
      "Iteration 1433: Weights = [5.49999694e+01 4.00036027e+00 8.41086531e+00 2.78130883e-02\n",
      " 2.79977794e-01 1.05545191e+01], Loss = 0.4759\n",
      "Iteration 1434: Weights = [5.49999697e+01 4.00024564e+00 8.41062397e+00 2.78115503e-02\n",
      " 2.79970183e-01 1.05547744e+01], Loss = 0.4759\n",
      "Iteration 1435: Weights = [5.49999700e+01 4.00013100e+00 8.41038264e+00 2.78100177e-02\n",
      " 2.79962568e-01 1.05550297e+01], Loss = 0.4759\n",
      "Iteration 1436: Weights = [5.49999703e+01 4.00001637e+00 8.41014132e+00 2.78084905e-02\n",
      " 2.79954951e-01 1.05552850e+01], Loss = 0.4759\n",
      "Iteration 1437: Weights = [5.49999706e+01 3.99990174e+00 8.40990000e+00 2.78069687e-02\n",
      " 2.79947331e-01 1.05555402e+01], Loss = 0.4758\n",
      "Iteration 1438: Weights = [5.49999709e+01 3.99978711e+00 8.40965869e+00 2.78054522e-02\n",
      " 2.79939708e-01 1.05557955e+01], Loss = 0.4758\n",
      "Iteration 1439: Weights = [5.49999712e+01 3.99967249e+00 8.40941738e+00 2.78039409e-02\n",
      " 2.79932083e-01 1.05560507e+01], Loss = 0.4758\n",
      "Iteration 1440: Weights = [5.49999715e+01 3.99955787e+00 8.40917608e+00 2.78024350e-02\n",
      " 2.79924455e-01 1.05563060e+01], Loss = 0.4757\n",
      "Iteration 1441: Weights = [5.49999718e+01 3.99944324e+00 8.40893479e+00 2.78009342e-02\n",
      " 2.79916824e-01 1.05565612e+01], Loss = 0.4757\n",
      "Iteration 1442: Weights = [5.49999721e+01 3.99932862e+00 8.40869350e+00 2.77994385e-02\n",
      " 2.79909190e-01 1.05568164e+01], Loss = 0.4757\n",
      "Iteration 1443: Weights = [5.49999723e+01 3.99921401e+00 8.40845222e+00 2.77979481e-02\n",
      " 2.79901554e-01 1.05570716e+01], Loss = 0.4757\n",
      "Iteration 1444: Weights = [5.49999726e+01 3.99909939e+00 8.40821095e+00 2.77964627e-02\n",
      " 2.79893915e-01 1.05573268e+01], Loss = 0.4756\n",
      "Iteration 1445: Weights = [5.49999729e+01 3.99898477e+00 8.40796968e+00 2.77949823e-02\n",
      " 2.79886273e-01 1.05575820e+01], Loss = 0.4756\n",
      "Iteration 1446: Weights = [5.49999732e+01 3.99887016e+00 8.40772841e+00 2.77935070e-02\n",
      " 2.79878629e-01 1.05578372e+01], Loss = 0.4756\n",
      "Iteration 1447: Weights = [5.49999734e+01 3.99875555e+00 8.40748716e+00 2.77920366e-02\n",
      " 2.79870982e-01 1.05580924e+01], Loss = 0.4756\n",
      "Iteration 1448: Weights = [5.49999737e+01 3.99864094e+00 8.40724591e+00 2.77905712e-02\n",
      " 2.79863333e-01 1.05583475e+01], Loss = 0.4755\n",
      "Iteration 1449: Weights = [5.49999740e+01 3.99852634e+00 8.40700466e+00 2.77891107e-02\n",
      " 2.79855681e-01 1.05586027e+01], Loss = 0.4755\n",
      "Iteration 1450: Weights = [5.49999742e+01 3.99841173e+00 8.40676343e+00 2.77876551e-02\n",
      " 2.79848026e-01 1.05588578e+01], Loss = 0.4755\n",
      "Iteration 1451: Weights = [5.49999745e+01 3.99829713e+00 8.40652219e+00 2.77862043e-02\n",
      " 2.79840369e-01 1.05591130e+01], Loss = 0.4754\n",
      "Iteration 1452: Weights = [5.49999747e+01 3.99818253e+00 8.40628097e+00 2.77847583e-02\n",
      " 2.79832710e-01 1.05593681e+01], Loss = 0.4754\n",
      "Iteration 1453: Weights = [5.49999750e+01 3.99806793e+00 8.40603975e+00 2.77833171e-02\n",
      " 2.79825048e-01 1.05596232e+01], Loss = 0.4754\n",
      "Iteration 1454: Weights = [5.49999752e+01 3.99795334e+00 8.40579854e+00 2.77818806e-02\n",
      " 2.79817384e-01 1.05598783e+01], Loss = 0.4754\n",
      "Iteration 1455: Weights = [5.49999755e+01 3.99783874e+00 8.40555733e+00 2.77804488e-02\n",
      " 2.79809717e-01 1.05601334e+01], Loss = 0.4753\n",
      "Iteration 1456: Weights = [5.49999757e+01 3.99772415e+00 8.40531613e+00 2.77790217e-02\n",
      " 2.79802048e-01 1.05603885e+01], Loss = 0.4753\n",
      "Iteration 1457: Weights = [5.49999760e+01 3.99760956e+00 8.40507493e+00 2.77775992e-02\n",
      " 2.79794376e-01 1.05606436e+01], Loss = 0.4753\n",
      "Iteration 1458: Weights = [5.49999762e+01 3.99749497e+00 8.40483375e+00 2.77761813e-02\n",
      " 2.79786702e-01 1.05608987e+01], Loss = 0.4753\n",
      "Iteration 1459: Weights = [5.49999764e+01 3.99738039e+00 8.40459256e+00 2.77747679e-02\n",
      " 2.79779026e-01 1.05611538e+01], Loss = 0.4752\n",
      "Iteration 1460: Weights = [5.49999767e+01 3.99726580e+00 8.40435139e+00 2.77733591e-02\n",
      " 2.79771347e-01 1.05614088e+01], Loss = 0.4752\n",
      "Iteration 1461: Weights = [5.49999769e+01 3.99715122e+00 8.40411022e+00 2.77719548e-02\n",
      " 2.79763666e-01 1.05616639e+01], Loss = 0.4752\n",
      "Iteration 1462: Weights = [5.49999771e+01 3.99703664e+00 8.40386906e+00 2.77705549e-02\n",
      " 2.79755983e-01 1.05619189e+01], Loss = 0.4751\n",
      "Iteration 1463: Weights = [5.49999774e+01 3.99692206e+00 8.40362790e+00 2.77691595e-02\n",
      " 2.79748298e-01 1.05621740e+01], Loss = 0.4751\n",
      "Iteration 1464: Weights = [5.49999776e+01 3.99680749e+00 8.40338675e+00 2.77677685e-02\n",
      " 2.79740610e-01 1.05624290e+01], Loss = 0.4751\n",
      "Iteration 1465: Weights = [5.49999778e+01 3.99669291e+00 8.40314561e+00 2.77663818e-02\n",
      " 2.79732920e-01 1.05626840e+01], Loss = 0.4751\n",
      "Iteration 1466: Weights = [5.49999780e+01 3.99657834e+00 8.40290447e+00 2.77649995e-02\n",
      " 2.79725228e-01 1.05629390e+01], Loss = 0.4750\n",
      "Iteration 1467: Weights = [5.49999783e+01 3.99646377e+00 8.40266334e+00 2.77636215e-02\n",
      " 2.79717533e-01 1.05631940e+01], Loss = 0.4750\n",
      "Iteration 1468: Weights = [5.49999785e+01 3.99634921e+00 8.40242221e+00 2.77622478e-02\n",
      " 2.79709837e-01 1.05634490e+01], Loss = 0.4750\n",
      "Iteration 1469: Weights = [5.49999787e+01 3.99623464e+00 8.40218109e+00 2.77608783e-02\n",
      " 2.79702138e-01 1.05637040e+01], Loss = 0.4750\n",
      "Iteration 1470: Weights = [5.49999789e+01 3.99612008e+00 8.40193998e+00 2.77595130e-02\n",
      " 2.79694437e-01 1.05639590e+01], Loss = 0.4749\n",
      "Iteration 1471: Weights = [5.49999791e+01 3.99600552e+00 8.40169887e+00 2.77581519e-02\n",
      " 2.79686734e-01 1.05642140e+01], Loss = 0.4749\n",
      "Iteration 1472: Weights = [5.49999793e+01 3.99589096e+00 8.40145777e+00 2.77567950e-02\n",
      " 2.79679028e-01 1.05644689e+01], Loss = 0.4749\n",
      "Iteration 1473: Weights = [5.49999795e+01 3.99577640e+00 8.40121668e+00 2.77554421e-02\n",
      " 2.79671321e-01 1.05647239e+01], Loss = 0.4748\n",
      "Iteration 1474: Weights = [5.49999797e+01 3.99566185e+00 8.40097559e+00 2.77540934e-02\n",
      " 2.79663612e-01 1.05649788e+01], Loss = 0.4748\n",
      "Iteration 1475: Weights = [5.49999799e+01 3.99554730e+00 8.40073451e+00 2.77527487e-02\n",
      " 2.79655900e-01 1.05652337e+01], Loss = 0.4748\n",
      "Iteration 1476: Weights = [5.49999801e+01 3.99543275e+00 8.40049344e+00 2.77514081e-02\n",
      " 2.79648186e-01 1.05654887e+01], Loss = 0.4748\n",
      "Iteration 1477: Weights = [5.49999803e+01 3.99531820e+00 8.40025237e+00 2.77500714e-02\n",
      " 2.79640471e-01 1.05657436e+01], Loss = 0.4747\n",
      "Iteration 1478: Weights = [5.49999805e+01 3.99520366e+00 8.40001131e+00 2.77487387e-02\n",
      " 2.79632753e-01 1.05659985e+01], Loss = 0.4747\n",
      "Iteration 1479: Weights = [5.49999807e+01 3.99508911e+00 8.39977025e+00 2.77474100e-02\n",
      " 2.79625034e-01 1.05662534e+01], Loss = 0.4747\n",
      "Iteration 1480: Weights = [5.49999809e+01 3.99497457e+00 8.39952920e+00 2.77460852e-02\n",
      " 2.79617312e-01 1.05665083e+01], Loss = 0.4747\n",
      "Iteration 1481: Weights = [5.49999811e+01 3.99486004e+00 8.39928816e+00 2.77447643e-02\n",
      " 2.79609588e-01 1.05667632e+01], Loss = 0.4746\n",
      "Iteration 1482: Weights = [5.49999813e+01 3.99474550e+00 8.39904712e+00 2.77434472e-02\n",
      " 2.79601863e-01 1.05670181e+01], Loss = 0.4746\n",
      "Iteration 1483: Weights = [5.49999815e+01 3.99463097e+00 8.39880609e+00 2.77421340e-02\n",
      " 2.79594135e-01 1.05672729e+01], Loss = 0.4746\n",
      "Iteration 1484: Weights = [5.49999817e+01 3.99451643e+00 8.39856507e+00 2.77408245e-02\n",
      " 2.79586406e-01 1.05675278e+01], Loss = 0.4745\n",
      "Iteration 1485: Weights = [5.49999819e+01 3.99440191e+00 8.39832405e+00 2.77395189e-02\n",
      " 2.79578675e-01 1.05677826e+01], Loss = 0.4745\n",
      "Iteration 1486: Weights = [5.49999820e+01 3.99428738e+00 8.39808304e+00 2.77382170e-02\n",
      " 2.79570941e-01 1.05680375e+01], Loss = 0.4745\n",
      "Iteration 1487: Weights = [5.49999822e+01 3.99417285e+00 8.39784203e+00 2.77369188e-02\n",
      " 2.79563206e-01 1.05682923e+01], Loss = 0.4745\n",
      "Iteration 1488: Weights = [5.49999824e+01 3.99405833e+00 8.39760103e+00 2.77356243e-02\n",
      " 2.79555469e-01 1.05685471e+01], Loss = 0.4744\n",
      "Iteration 1489: Weights = [5.49999826e+01 3.99394381e+00 8.39736004e+00 2.77343335e-02\n",
      " 2.79547730e-01 1.05688019e+01], Loss = 0.4744\n",
      "Iteration 1490: Weights = [5.49999827e+01 3.99382929e+00 8.39711906e+00 2.77330463e-02\n",
      " 2.79539990e-01 1.05690568e+01], Loss = 0.4744\n",
      "Iteration 1491: Weights = [5.49999829e+01 3.99371478e+00 8.39687808e+00 2.77317627e-02\n",
      " 2.79532247e-01 1.05693116e+01], Loss = 0.4744\n",
      "Iteration 1492: Weights = [5.49999831e+01 3.99360026e+00 8.39663710e+00 2.77304827e-02\n",
      " 2.79524503e-01 1.05695664e+01], Loss = 0.4743\n",
      "Iteration 1493: Weights = [5.49999833e+01 3.99348575e+00 8.39639614e+00 2.77292063e-02\n",
      " 2.79516757e-01 1.05698211e+01], Loss = 0.4743\n",
      "Iteration 1494: Weights = [5.49999834e+01 3.99337125e+00 8.39615518e+00 2.77279334e-02\n",
      " 2.79509009e-01 1.05700759e+01], Loss = 0.4743\n",
      "Iteration 1495: Weights = [5.49999836e+01 3.99325674e+00 8.39591422e+00 2.77266641e-02\n",
      " 2.79501259e-01 1.05703307e+01], Loss = 0.4742\n",
      "Iteration 1496: Weights = [5.49999838e+01 3.99314224e+00 8.39567328e+00 2.77253982e-02\n",
      " 2.79493508e-01 1.05705854e+01], Loss = 0.4742\n",
      "Iteration 1497: Weights = [5.49999839e+01 3.99302773e+00 8.39543234e+00 2.77241357e-02\n",
      " 2.79485755e-01 1.05708402e+01], Loss = 0.4742\n",
      "Iteration 1498: Weights = [5.49999841e+01 3.99291324e+00 8.39519140e+00 2.77228768e-02\n",
      " 2.79478000e-01 1.05710949e+01], Loss = 0.4742\n",
      "Iteration 1499: Weights = [5.49999842e+01 3.99279874e+00 8.39495047e+00 2.77216212e-02\n",
      " 2.79470243e-01 1.05713497e+01], Loss = 0.4741\n",
      "Iteration 1500: Weights = [5.49999844e+01 3.99268424e+00 8.39470955e+00 2.77203690e-02\n",
      " 2.79462485e-01 1.05716044e+01], Loss = 0.4741\n",
      "Iteration 1501: Weights = [5.49999846e+01 3.99256975e+00 8.39446864e+00 2.77191201e-02\n",
      " 2.79454725e-01 1.05718591e+01], Loss = 0.4741\n",
      "Iteration 1502: Weights = [5.49999847e+01 3.99245526e+00 8.39422773e+00 2.77178747e-02\n",
      " 2.79446963e-01 1.05721138e+01], Loss = 0.4741\n",
      "Iteration 1503: Weights = [5.49999849e+01 3.99234078e+00 8.39398683e+00 2.77166325e-02\n",
      " 2.79439200e-01 1.05723685e+01], Loss = 0.4740\n",
      "Iteration 1504: Weights = [5.49999850e+01 3.99222629e+00 8.39374593e+00 2.77153936e-02\n",
      " 2.79431435e-01 1.05726232e+01], Loss = 0.4740\n",
      "Iteration 1505: Weights = [5.49999852e+01 3.99211181e+00 8.39350504e+00 2.77141579e-02\n",
      " 2.79423669e-01 1.05728779e+01], Loss = 0.4740\n",
      "Iteration 1506: Weights = [5.49999853e+01 3.99199733e+00 8.39326416e+00 2.77129255e-02\n",
      " 2.79415901e-01 1.05731326e+01], Loss = 0.4739\n",
      "Iteration 1507: Weights = [5.49999855e+01 3.99188285e+00 8.39302328e+00 2.77116964e-02\n",
      " 2.79408131e-01 1.05733873e+01], Loss = 0.4739\n",
      "Iteration 1508: Weights = [5.49999856e+01 3.99176838e+00 8.39278241e+00 2.77104704e-02\n",
      " 2.79400360e-01 1.05736419e+01], Loss = 0.4739\n",
      "Iteration 1509: Weights = [5.49999857e+01 3.99165391e+00 8.39254155e+00 2.77092476e-02\n",
      " 2.79392587e-01 1.05738966e+01], Loss = 0.4739\n",
      "Iteration 1510: Weights = [5.49999859e+01 3.99153944e+00 8.39230069e+00 2.77080279e-02\n",
      " 2.79384812e-01 1.05741512e+01], Loss = 0.4738\n",
      "Iteration 1511: Weights = [5.49999860e+01 3.99142497e+00 8.39205984e+00 2.77068114e-02\n",
      " 2.79377036e-01 1.05744058e+01], Loss = 0.4738\n",
      "Iteration 1512: Weights = [5.49999862e+01 3.99131050e+00 8.39181899e+00 2.77055980e-02\n",
      " 2.79369259e-01 1.05746605e+01], Loss = 0.4738\n",
      "Iteration 1513: Weights = [5.49999863e+01 3.99119604e+00 8.39157816e+00 2.77043876e-02\n",
      " 2.79361480e-01 1.05749151e+01], Loss = 0.4738\n",
      "Iteration 1514: Weights = [5.49999864e+01 3.99108158e+00 8.39133733e+00 2.77031803e-02\n",
      " 2.79353699e-01 1.05751697e+01], Loss = 0.4737\n",
      "Iteration 1515: Weights = [5.49999866e+01 3.99096712e+00 8.39109650e+00 2.77019761e-02\n",
      " 2.79345917e-01 1.05754243e+01], Loss = 0.4737\n",
      "Iteration 1516: Weights = [5.49999867e+01 3.99085267e+00 8.39085568e+00 2.77007748e-02\n",
      " 2.79338134e-01 1.05756789e+01], Loss = 0.4737\n",
      "Iteration 1517: Weights = [5.49999868e+01 3.99073821e+00 8.39061487e+00 2.76995766e-02\n",
      " 2.79330349e-01 1.05759335e+01], Loss = 0.4736\n",
      "Iteration 1518: Weights = [5.49999870e+01 3.99062376e+00 8.39037406e+00 2.76983813e-02\n",
      " 2.79322562e-01 1.05761881e+01], Loss = 0.4736\n",
      "Iteration 1519: Weights = [5.49999871e+01 3.99050932e+00 8.39013327e+00 2.76971890e-02\n",
      " 2.79314774e-01 1.05764426e+01], Loss = 0.4736\n",
      "Iteration 1520: Weights = [5.49999872e+01 3.99039487e+00 8.38989247e+00 2.76959995e-02\n",
      " 2.79306985e-01 1.05766972e+01], Loss = 0.4736\n",
      "Iteration 1521: Weights = [5.49999874e+01 3.99028043e+00 8.38965169e+00 2.76948130e-02\n",
      " 2.79299194e-01 1.05769518e+01], Loss = 0.4735\n",
      "Iteration 1522: Weights = [5.49999875e+01 3.99016599e+00 8.38941091e+00 2.76936294e-02\n",
      " 2.79291402e-01 1.05772063e+01], Loss = 0.4735\n",
      "Iteration 1523: Weights = [5.49999876e+01 3.99005155e+00 8.38917013e+00 2.76924487e-02\n",
      " 2.79283608e-01 1.05774608e+01], Loss = 0.4735\n",
      "Iteration 1524: Weights = [5.49999877e+01 3.98993711e+00 8.38892937e+00 2.76912708e-02\n",
      " 2.79275813e-01 1.05777154e+01], Loss = 0.4735\n",
      "Iteration 1525: Weights = [5.49999879e+01 3.98982268e+00 8.38868861e+00 2.76900957e-02\n",
      " 2.79268017e-01 1.05779699e+01], Loss = 0.4734\n",
      "Iteration 1526: Weights = [5.49999880e+01 3.98970825e+00 8.38844785e+00 2.76889234e-02\n",
      " 2.79260219e-01 1.05782244e+01], Loss = 0.4734\n",
      "Iteration 1527: Weights = [5.49999881e+01 3.98959382e+00 8.38820711e+00 2.76877539e-02\n",
      " 2.79252420e-01 1.05784789e+01], Loss = 0.4734\n",
      "Iteration 1528: Weights = [5.49999882e+01 3.98947940e+00 8.38796637e+00 2.76865872e-02\n",
      " 2.79244620e-01 1.05787334e+01], Loss = 0.4733\n",
      "Iteration 1529: Weights = [5.49999883e+01 3.98936498e+00 8.38772563e+00 2.76854232e-02\n",
      " 2.79236818e-01 1.05789879e+01], Loss = 0.4733\n",
      "Iteration 1530: Weights = [5.49999885e+01 3.98925056e+00 8.38748491e+00 2.76842619e-02\n",
      " 2.79229015e-01 1.05792424e+01], Loss = 0.4733\n",
      "Iteration 1531: Weights = [5.49999886e+01 3.98913614e+00 8.38724418e+00 2.76831034e-02\n",
      " 2.79221210e-01 1.05794969e+01], Loss = 0.4733\n",
      "Iteration 1532: Weights = [5.49999887e+01 3.98902172e+00 8.38700347e+00 2.76819475e-02\n",
      " 2.79213405e-01 1.05797513e+01], Loss = 0.4732\n",
      "Iteration 1533: Weights = [5.49999888e+01 3.98890731e+00 8.38676276e+00 2.76807943e-02\n",
      " 2.79205598e-01 1.05800058e+01], Loss = 0.4732\n",
      "Iteration 1534: Weights = [5.49999889e+01 3.98879290e+00 8.38652206e+00 2.76796437e-02\n",
      " 2.79197790e-01 1.05802602e+01], Loss = 0.4732\n",
      "Iteration 1535: Weights = [5.49999890e+01 3.98867850e+00 8.38628137e+00 2.76784957e-02\n",
      " 2.79189980e-01 1.05805147e+01], Loss = 0.4732\n",
      "Iteration 1536: Weights = [5.49999891e+01 3.98856409e+00 8.38604068e+00 2.76773504e-02\n",
      " 2.79182169e-01 1.05807691e+01], Loss = 0.4731\n",
      "Iteration 1537: Weights = [5.49999892e+01 3.98844969e+00 8.38580000e+00 2.76762076e-02\n",
      " 2.79174357e-01 1.05810235e+01], Loss = 0.4731\n",
      "Iteration 1538: Weights = [5.49999894e+01 3.98833529e+00 8.38555932e+00 2.76750675e-02\n",
      " 2.79166544e-01 1.05812780e+01], Loss = 0.4731\n",
      "Iteration 1539: Weights = [5.49999895e+01 3.98822089e+00 8.38531865e+00 2.76739298e-02\n",
      " 2.79158730e-01 1.05815324e+01], Loss = 0.4730\n",
      "Iteration 1540: Weights = [5.49999896e+01 3.98810650e+00 8.38507799e+00 2.76727947e-02\n",
      " 2.79150914e-01 1.05817868e+01], Loss = 0.4730\n",
      "Iteration 1541: Weights = [5.49999897e+01 3.98799211e+00 8.38483733e+00 2.76716621e-02\n",
      " 2.79143097e-01 1.05820412e+01], Loss = 0.4730\n",
      "Iteration 1542: Weights = [5.49999898e+01 3.98787772e+00 8.38459669e+00 2.76705320e-02\n",
      " 2.79135279e-01 1.05822956e+01], Loss = 0.4730\n",
      "Iteration 1543: Weights = [5.49999899e+01 3.98776333e+00 8.38435604e+00 2.76694044e-02\n",
      " 2.79127460e-01 1.05825499e+01], Loss = 0.4729\n",
      "Iteration 1544: Weights = [5.49999900e+01 3.98764895e+00 8.38411541e+00 2.76682793e-02\n",
      " 2.79119639e-01 1.05828043e+01], Loss = 0.4729\n",
      "Iteration 1545: Weights = [5.49999901e+01 3.98753457e+00 8.38387478e+00 2.76671565e-02\n",
      " 2.79111818e-01 1.05830587e+01], Loss = 0.4729\n",
      "Iteration 1546: Weights = [5.49999902e+01 3.98742019e+00 8.38363416e+00 2.76660363e-02\n",
      " 2.79103995e-01 1.05833130e+01], Loss = 0.4729\n",
      "Iteration 1547: Weights = [5.49999903e+01 3.98730581e+00 8.38339354e+00 2.76649184e-02\n",
      " 2.79096171e-01 1.05835674e+01], Loss = 0.4728\n",
      "Iteration 1548: Weights = [5.49999904e+01 3.98719144e+00 8.38315293e+00 2.76638029e-02\n",
      " 2.79088346e-01 1.05838217e+01], Loss = 0.4728\n",
      "Iteration 1549: Weights = [5.49999905e+01 3.98707707e+00 8.38291233e+00 2.76626898e-02\n",
      " 2.79080520e-01 1.05840760e+01], Loss = 0.4728\n",
      "Iteration 1550: Weights = [5.49999906e+01 3.98696270e+00 8.38267173e+00 2.76615790e-02\n",
      " 2.79072693e-01 1.05843304e+01], Loss = 0.4727\n",
      "Iteration 1551: Weights = [5.49999907e+01 3.98684834e+00 8.38243114e+00 2.76604706e-02\n",
      " 2.79064864e-01 1.05845847e+01], Loss = 0.4727\n",
      "Iteration 1552: Weights = [5.49999907e+01 3.98673398e+00 8.38219056e+00 2.76593645e-02\n",
      " 2.79057035e-01 1.05848390e+01], Loss = 0.4727\n",
      "Iteration 1553: Weights = [5.49999908e+01 3.98661962e+00 8.38194998e+00 2.76582607e-02\n",
      " 2.79049204e-01 1.05850933e+01], Loss = 0.4727\n",
      "Iteration 1554: Weights = [5.49999909e+01 3.98650526e+00 8.38170941e+00 2.76571591e-02\n",
      " 2.79041373e-01 1.05853476e+01], Loss = 0.4726\n",
      "Iteration 1555: Weights = [5.49999910e+01 3.98639090e+00 8.38146885e+00 2.76560599e-02\n",
      " 2.79033540e-01 1.05856019e+01], Loss = 0.4726\n",
      "Iteration 1556: Weights = [5.49999911e+01 3.98627655e+00 8.38122829e+00 2.76549629e-02\n",
      " 2.79025706e-01 1.05858561e+01], Loss = 0.4726\n",
      "Iteration 1557: Weights = [5.49999912e+01 3.98616220e+00 8.38098774e+00 2.76538682e-02\n",
      " 2.79017872e-01 1.05861104e+01], Loss = 0.4726\n",
      "Iteration 1558: Weights = [5.49999913e+01 3.98604786e+00 8.38074719e+00 2.76527756e-02\n",
      " 2.79010036e-01 1.05863647e+01], Loss = 0.4725\n",
      "Iteration 1559: Weights = [5.49999914e+01 3.98593351e+00 8.38050666e+00 2.76516853e-02\n",
      " 2.79002199e-01 1.05866189e+01], Loss = 0.4725\n",
      "Iteration 1560: Weights = [5.49999915e+01 3.98581917e+00 8.38026613e+00 2.76505972e-02\n",
      " 2.78994361e-01 1.05868732e+01], Loss = 0.4725\n",
      "Iteration 1561: Weights = [5.49999915e+01 3.98570483e+00 8.38002560e+00 2.76495112e-02\n",
      " 2.78986522e-01 1.05871274e+01], Loss = 0.4725\n",
      "Iteration 1562: Weights = [5.49999916e+01 3.98559050e+00 8.37978508e+00 2.76484274e-02\n",
      " 2.78978683e-01 1.05873816e+01], Loss = 0.4724\n",
      "Iteration 1563: Weights = [5.49999917e+01 3.98547617e+00 8.37954457e+00 2.76473458e-02\n",
      " 2.78970842e-01 1.05876358e+01], Loss = 0.4724\n",
      "Iteration 1564: Weights = [5.49999918e+01 3.98536183e+00 8.37930407e+00 2.76462662e-02\n",
      " 2.78963000e-01 1.05878900e+01], Loss = 0.4724\n",
      "Iteration 1565: Weights = [5.49999919e+01 3.98524751e+00 8.37906357e+00 2.76451888e-02\n",
      " 2.78955157e-01 1.05881443e+01], Loss = 0.4723\n",
      "Iteration 1566: Weights = [5.49999920e+01 3.98513318e+00 8.37882308e+00 2.76441135e-02\n",
      " 2.78947313e-01 1.05883984e+01], Loss = 0.4723\n",
      "Iteration 1567: Weights = [5.49999920e+01 3.98501886e+00 8.37858259e+00 2.76430403e-02\n",
      " 2.78939469e-01 1.05886526e+01], Loss = 0.4723\n",
      "Iteration 1568: Weights = [5.49999921e+01 3.98490454e+00 8.37834212e+00 2.76419691e-02\n",
      " 2.78931623e-01 1.05889068e+01], Loss = 0.4723\n",
      "Iteration 1569: Weights = [5.49999922e+01 3.98479022e+00 8.37810165e+00 2.76409000e-02\n",
      " 2.78923776e-01 1.05891610e+01], Loss = 0.4722\n",
      "Iteration 1570: Weights = [5.49999923e+01 3.98467591e+00 8.37786118e+00 2.76398329e-02\n",
      " 2.78915929e-01 1.05894152e+01], Loss = 0.4722\n",
      "Iteration 1571: Weights = [5.49999924e+01 3.98456160e+00 8.37762072e+00 2.76387679e-02\n",
      " 2.78908080e-01 1.05896693e+01], Loss = 0.4722\n",
      "Iteration 1572: Weights = [5.49999924e+01 3.98444729e+00 8.37738027e+00 2.76377048e-02\n",
      " 2.78900231e-01 1.05899235e+01], Loss = 0.4722\n",
      "Iteration 1573: Weights = [5.49999925e+01 3.98433299e+00 8.37713983e+00 2.76366438e-02\n",
      " 2.78892381e-01 1.05901776e+01], Loss = 0.4721\n",
      "Iteration 1574: Weights = [5.49999926e+01 3.98421868e+00 8.37689939e+00 2.76355847e-02\n",
      " 2.78884529e-01 1.05904317e+01], Loss = 0.4721\n",
      "Iteration 1575: Weights = [5.49999927e+01 3.98410438e+00 8.37665896e+00 2.76345276e-02\n",
      " 2.78876677e-01 1.05906859e+01], Loss = 0.4721\n",
      "Iteration 1576: Weights = [5.49999927e+01 3.98399009e+00 8.37641853e+00 2.76334724e-02\n",
      " 2.78868824e-01 1.05909400e+01], Loss = 0.4720\n",
      "Iteration 1577: Weights = [5.49999928e+01 3.98387579e+00 8.37617811e+00 2.76324192e-02\n",
      " 2.78860970e-01 1.05911941e+01], Loss = 0.4720\n",
      "Iteration 1578: Weights = [5.49999929e+01 3.98376150e+00 8.37593770e+00 2.76313679e-02\n",
      " 2.78853116e-01 1.05914482e+01], Loss = 0.4720\n",
      "Iteration 1579: Weights = [5.49999929e+01 3.98364721e+00 8.37569729e+00 2.76303185e-02\n",
      " 2.78845260e-01 1.05917023e+01], Loss = 0.4720\n",
      "Iteration 1580: Weights = [5.49999930e+01 3.98353292e+00 8.37545690e+00 2.76292710e-02\n",
      " 2.78837404e-01 1.05919564e+01], Loss = 0.4719\n",
      "Iteration 1581: Weights = [5.49999931e+01 3.98341864e+00 8.37521650e+00 2.76282254e-02\n",
      " 2.78829546e-01 1.05922104e+01], Loss = 0.4719\n",
      "Iteration 1582: Weights = [5.49999932e+01 3.98330436e+00 8.37497612e+00 2.76271817e-02\n",
      " 2.78821688e-01 1.05924645e+01], Loss = 0.4719\n",
      "Iteration 1583: Weights = [5.49999932e+01 3.98319008e+00 8.37473574e+00 2.76261398e-02\n",
      " 2.78813829e-01 1.05927186e+01], Loss = 0.4719\n",
      "Iteration 1584: Weights = [5.49999933e+01 3.98307581e+00 8.37449537e+00 2.76250998e-02\n",
      " 2.78805970e-01 1.05929726e+01], Loss = 0.4718\n",
      "Iteration 1585: Weights = [5.49999934e+01 3.98296153e+00 8.37425500e+00 2.76240615e-02\n",
      " 2.78798109e-01 1.05932267e+01], Loss = 0.4718\n",
      "Iteration 1586: Weights = [5.49999934e+01 3.98284727e+00 8.37401464e+00 2.76230251e-02\n",
      " 2.78790248e-01 1.05934807e+01], Loss = 0.4718\n",
      "Iteration 1587: Weights = [5.49999935e+01 3.98273300e+00 8.37377429e+00 2.76219905e-02\n",
      " 2.78782386e-01 1.05937348e+01], Loss = 0.4717\n",
      "Iteration 1588: Weights = [5.49999936e+01 3.98261873e+00 8.37353395e+00 2.76209577e-02\n",
      " 2.78774523e-01 1.05939888e+01], Loss = 0.4717\n",
      "Iteration 1589: Weights = [5.49999936e+01 3.98250447e+00 8.37329361e+00 2.76199267e-02\n",
      " 2.78766659e-01 1.05942428e+01], Loss = 0.4717\n",
      "Iteration 1590: Weights = [5.49999937e+01 3.98239022e+00 8.37305328e+00 2.76188974e-02\n",
      " 2.78758794e-01 1.05944968e+01], Loss = 0.4717\n",
      "Iteration 1591: Weights = [5.49999937e+01 3.98227596e+00 8.37281295e+00 2.76178699e-02\n",
      " 2.78750929e-01 1.05947508e+01], Loss = 0.4716\n",
      "Iteration 1592: Weights = [5.49999938e+01 3.98216171e+00 8.37257263e+00 2.76168441e-02\n",
      " 2.78743063e-01 1.05950048e+01], Loss = 0.4716\n",
      "Iteration 1593: Weights = [5.49999939e+01 3.98204746e+00 8.37233232e+00 2.76158201e-02\n",
      " 2.78735196e-01 1.05952588e+01], Loss = 0.4716\n",
      "Iteration 1594: Weights = [5.49999939e+01 3.98193321e+00 8.37209201e+00 2.76147977e-02\n",
      " 2.78727329e-01 1.05955128e+01], Loss = 0.4716\n",
      "Iteration 1595: Weights = [5.49999940e+01 3.98181897e+00 8.37185171e+00 2.76137771e-02\n",
      " 2.78719460e-01 1.05957667e+01], Loss = 0.4715\n",
      "Iteration 1596: Weights = [5.49999941e+01 3.98170472e+00 8.37161142e+00 2.76127581e-02\n",
      " 2.78711591e-01 1.05960207e+01], Loss = 0.4715\n",
      "Iteration 1597: Weights = [5.49999941e+01 3.98159049e+00 8.37137114e+00 2.76117408e-02\n",
      " 2.78703722e-01 1.05962747e+01], Loss = 0.4715\n",
      "Iteration 1598: Weights = [5.49999942e+01 3.98147625e+00 8.37113086e+00 2.76107252e-02\n",
      " 2.78695851e-01 1.05965286e+01], Loss = 0.4714\n",
      "Iteration 1599: Weights = [5.49999942e+01 3.98136202e+00 8.37089059e+00 2.76097113e-02\n",
      " 2.78687980e-01 1.05967825e+01], Loss = 0.4714\n",
      "Iteration 1600: Weights = [5.49999943e+01 3.98124779e+00 8.37065032e+00 2.76086989e-02\n",
      " 2.78680108e-01 1.05970365e+01], Loss = 0.4714\n",
      "Iteration 1601: Weights = [5.49999943e+01 3.98113356e+00 8.37041006e+00 2.76076883e-02\n",
      " 2.78672236e-01 1.05972904e+01], Loss = 0.4714\n",
      "Iteration 1602: Weights = [5.49999944e+01 3.98101934e+00 8.37016981e+00 2.76066792e-02\n",
      " 2.78664362e-01 1.05975443e+01], Loss = 0.4713\n",
      "Iteration 1603: Weights = [5.49999945e+01 3.98090511e+00 8.36992956e+00 2.76056717e-02\n",
      " 2.78656488e-01 1.05977982e+01], Loss = 0.4713\n",
      "Iteration 1604: Weights = [5.49999945e+01 3.98079090e+00 8.36968932e+00 2.76046658e-02\n",
      " 2.78648614e-01 1.05980521e+01], Loss = 0.4713\n",
      "Iteration 1605: Weights = [5.49999946e+01 3.98067668e+00 8.36944909e+00 2.76036615e-02\n",
      " 2.78640738e-01 1.05983060e+01], Loss = 0.4713\n",
      "Iteration 1606: Weights = [5.49999946e+01 3.98056247e+00 8.36920887e+00 2.76026588e-02\n",
      " 2.78632862e-01 1.05985599e+01], Loss = 0.4712\n",
      "Iteration 1607: Weights = [5.49999947e+01 3.98044826e+00 8.36896865e+00 2.76016577e-02\n",
      " 2.78624986e-01 1.05988138e+01], Loss = 0.4712\n",
      "Iteration 1608: Weights = [5.49999947e+01 3.98033405e+00 8.36872843e+00 2.76006580e-02\n",
      " 2.78617109e-01 1.05990676e+01], Loss = 0.4712\n",
      "Iteration 1609: Weights = [5.49999948e+01 3.98021985e+00 8.36848823e+00 2.75996600e-02\n",
      " 2.78609231e-01 1.05993215e+01], Loss = 0.4712\n",
      "Iteration 1610: Weights = [5.49999948e+01 3.98010564e+00 8.36824803e+00 2.75986634e-02\n",
      " 2.78601352e-01 1.05995754e+01], Loss = 0.4711\n",
      "Iteration 1611: Weights = [5.49999949e+01 3.97999145e+00 8.36800784e+00 2.75976684e-02\n",
      " 2.78593473e-01 1.05998292e+01], Loss = 0.4711\n",
      "Iteration 1612: Weights = [5.49999949e+01 3.97987725e+00 8.36776765e+00 2.75966749e-02\n",
      " 2.78585593e-01 1.06000830e+01], Loss = 0.4711\n",
      "Iteration 1613: Weights = [5.49999950e+01 3.97976306e+00 8.36752747e+00 2.75956828e-02\n",
      " 2.78577712e-01 1.06003369e+01], Loss = 0.4710\n",
      "Iteration 1614: Weights = [5.49999950e+01 3.97964887e+00 8.36728730e+00 2.75946923e-02\n",
      " 2.78569831e-01 1.06005907e+01], Loss = 0.4710\n",
      "Iteration 1615: Weights = [5.49999951e+01 3.97953468e+00 8.36704714e+00 2.75937032e-02\n",
      " 2.78561950e-01 1.06008445e+01], Loss = 0.4710\n",
      "Iteration 1616: Weights = [5.49999951e+01 3.97942050e+00 8.36680698e+00 2.75927156e-02\n",
      " 2.78554067e-01 1.06010983e+01], Loss = 0.4710\n",
      "Iteration 1617: Weights = [5.49999952e+01 3.97930631e+00 8.36656682e+00 2.75917294e-02\n",
      " 2.78546185e-01 1.06013521e+01], Loss = 0.4709\n",
      "Iteration 1618: Weights = [5.49999952e+01 3.97919214e+00 8.36632668e+00 2.75907447e-02\n",
      " 2.78538301e-01 1.06016059e+01], Loss = 0.4709\n",
      "Iteration 1619: Weights = [5.49999953e+01 3.97907796e+00 8.36608654e+00 2.75897614e-02\n",
      " 2.78530417e-01 1.06018597e+01], Loss = 0.4709\n",
      "Iteration 1620: Weights = [5.49999953e+01 3.97896379e+00 8.36584641e+00 2.75887795e-02\n",
      " 2.78522532e-01 1.06021135e+01], Loss = 0.4709\n",
      "Iteration 1621: Weights = [5.49999954e+01 3.97884962e+00 8.36560628e+00 2.75877991e-02\n",
      " 2.78514647e-01 1.06023672e+01], Loss = 0.4708\n",
      "Iteration 1622: Weights = [5.49999954e+01 3.97873545e+00 8.36536616e+00 2.75868200e-02\n",
      " 2.78506761e-01 1.06026210e+01], Loss = 0.4708\n",
      "Iteration 1623: Weights = [5.49999955e+01 3.97862129e+00 8.36512605e+00 2.75858423e-02\n",
      " 2.78498875e-01 1.06028748e+01], Loss = 0.4708\n",
      "Iteration 1624: Weights = [5.49999955e+01 3.97850713e+00 8.36488595e+00 2.75848660e-02\n",
      " 2.78490988e-01 1.06031285e+01], Loss = 0.4707\n",
      "Iteration 1625: Weights = [5.49999956e+01 3.97839297e+00 8.36464585e+00 2.75838911e-02\n",
      " 2.78483101e-01 1.06033822e+01], Loss = 0.4707\n",
      "Iteration 1626: Weights = [5.49999956e+01 3.97827881e+00 8.36440576e+00 2.75829175e-02\n",
      " 2.78475213e-01 1.06036360e+01], Loss = 0.4707\n",
      "Iteration 1627: Weights = [5.49999956e+01 3.97816466e+00 8.36416567e+00 2.75819453e-02\n",
      " 2.78467324e-01 1.06038897e+01], Loss = 0.4707\n",
      "Iteration 1628: Weights = [5.49999957e+01 3.97805051e+00 8.36392559e+00 2.75809745e-02\n",
      " 2.78459435e-01 1.06041434e+01], Loss = 0.4706\n",
      "Iteration 1629: Weights = [5.49999957e+01 3.97793637e+00 8.36368552e+00 2.75800049e-02\n",
      " 2.78451545e-01 1.06043971e+01], Loss = 0.4706\n",
      "Iteration 1630: Weights = [5.49999958e+01 3.97782222e+00 8.36344546e+00 2.75790367e-02\n",
      " 2.78443655e-01 1.06046508e+01], Loss = 0.4706\n",
      "Iteration 1631: Weights = [5.49999958e+01 3.97770808e+00 8.36320540e+00 2.75780698e-02\n",
      " 2.78435764e-01 1.06049045e+01], Loss = 0.4706\n",
      "Iteration 1632: Weights = [5.49999959e+01 3.97759394e+00 8.36296535e+00 2.75771042e-02\n",
      " 2.78427873e-01 1.06051582e+01], Loss = 0.4705\n",
      "Iteration 1633: Weights = [5.49999959e+01 3.97747981e+00 8.36272530e+00 2.75761399e-02\n",
      " 2.78419982e-01 1.06054119e+01], Loss = 0.4705\n",
      "Iteration 1634: Weights = [5.49999959e+01 3.97736568e+00 8.36248526e+00 2.75751769e-02\n",
      " 2.78412089e-01 1.06056656e+01], Loss = 0.4705\n",
      "Iteration 1635: Weights = [5.49999960e+01 3.97725155e+00 8.36224523e+00 2.75742151e-02\n",
      " 2.78404197e-01 1.06059192e+01], Loss = 0.4704\n",
      "Iteration 1636: Weights = [5.49999960e+01 3.97713742e+00 8.36200521e+00 2.75732546e-02\n",
      " 2.78396304e-01 1.06061729e+01], Loss = 0.4704\n",
      "Iteration 1637: Weights = [5.49999961e+01 3.97702330e+00 8.36176519e+00 2.75722954e-02\n",
      " 2.78388410e-01 1.06064265e+01], Loss = 0.4704\n",
      "Iteration 1638: Weights = [5.49999961e+01 3.97690918e+00 8.36152518e+00 2.75713374e-02\n",
      " 2.78380516e-01 1.06066802e+01], Loss = 0.4704\n",
      "Iteration 1639: Weights = [5.49999961e+01 3.97679506e+00 8.36128517e+00 2.75703807e-02\n",
      " 2.78372621e-01 1.06069338e+01], Loss = 0.4703\n",
      "Iteration 1640: Weights = [5.49999962e+01 3.97668095e+00 8.36104517e+00 2.75694252e-02\n",
      " 2.78364726e-01 1.06071874e+01], Loss = 0.4703\n",
      "Iteration 1641: Weights = [5.49999962e+01 3.97656684e+00 8.36080518e+00 2.75684709e-02\n",
      " 2.78356831e-01 1.06074410e+01], Loss = 0.4703\n",
      "Iteration 1642: Weights = [5.49999963e+01 3.97645273e+00 8.36056520e+00 2.75675178e-02\n",
      " 2.78348935e-01 1.06076946e+01], Loss = 0.4703\n",
      "Iteration 1643: Weights = [5.49999963e+01 3.97633862e+00 8.36032522e+00 2.75665660e-02\n",
      " 2.78341038e-01 1.06079482e+01], Loss = 0.4702\n",
      "Iteration 1644: Weights = [5.49999963e+01 3.97622452e+00 8.36008525e+00 2.75656153e-02\n",
      " 2.78333141e-01 1.06082018e+01], Loss = 0.4702\n",
      "Iteration 1645: Weights = [5.49999964e+01 3.97611042e+00 8.35984528e+00 2.75646658e-02\n",
      " 2.78325244e-01 1.06084554e+01], Loss = 0.4702\n",
      "Iteration 1646: Weights = [5.49999964e+01 3.97599633e+00 8.35960533e+00 2.75637175e-02\n",
      " 2.78317346e-01 1.06087090e+01], Loss = 0.4702\n",
      "Iteration 1647: Weights = [5.49999964e+01 3.97588223e+00 8.35936538e+00 2.75627704e-02\n",
      " 2.78309448e-01 1.06089626e+01], Loss = 0.4701\n",
      "Iteration 1648: Weights = [5.49999965e+01 3.97576814e+00 8.35912543e+00 2.75618244e-02\n",
      " 2.78301549e-01 1.06092161e+01], Loss = 0.4701\n",
      "Iteration 1649: Weights = [5.49999965e+01 3.97565405e+00 8.35888549e+00 2.75608796e-02\n",
      " 2.78293650e-01 1.06094697e+01], Loss = 0.4701\n",
      "Iteration 1650: Weights = [5.49999965e+01 3.97553997e+00 8.35864556e+00 2.75599359e-02\n",
      " 2.78285750e-01 1.06097232e+01], Loss = 0.4700\n",
      "Iteration 1651: Weights = [5.49999966e+01 3.97542589e+00 8.35840564e+00 2.75589934e-02\n",
      " 2.78277850e-01 1.06099768e+01], Loss = 0.4700\n",
      "Iteration 1652: Weights = [5.49999966e+01 3.97531181e+00 8.35816572e+00 2.75580519e-02\n",
      " 2.78269950e-01 1.06102303e+01], Loss = 0.4700\n",
      "Iteration 1653: Weights = [5.49999966e+01 3.97519773e+00 8.35792581e+00 2.75571117e-02\n",
      " 2.78262049e-01 1.06104838e+01], Loss = 0.4700\n",
      "Iteration 1654: Weights = [5.49999967e+01 3.97508366e+00 8.35768591e+00 2.75561725e-02\n",
      " 2.78254148e-01 1.06107374e+01], Loss = 0.4699\n",
      "Iteration 1655: Weights = [5.49999967e+01 3.97496959e+00 8.35744601e+00 2.75552344e-02\n",
      " 2.78246247e-01 1.06109909e+01], Loss = 0.4699\n",
      "Iteration 1656: Weights = [5.49999967e+01 3.97485553e+00 8.35720612e+00 2.75542974e-02\n",
      " 2.78238345e-01 1.06112444e+01], Loss = 0.4699\n",
      "Iteration 1657: Weights = [5.49999968e+01 3.97474146e+00 8.35696624e+00 2.75533615e-02\n",
      " 2.78230442e-01 1.06114979e+01], Loss = 0.4699\n",
      "Iteration 1658: Weights = [5.49999968e+01 3.97462740e+00 8.35672636e+00 2.75524267e-02\n",
      " 2.78222539e-01 1.06117514e+01], Loss = 0.4698\n",
      "Iteration 1659: Weights = [5.49999968e+01 3.97451334e+00 8.35648649e+00 2.75514930e-02\n",
      " 2.78214636e-01 1.06120048e+01], Loss = 0.4698\n",
      "Iteration 1660: Weights = [5.49999969e+01 3.97439929e+00 8.35624663e+00 2.75505603e-02\n",
      " 2.78206733e-01 1.06122583e+01], Loss = 0.4698\n",
      "Iteration 1661: Weights = [5.49999969e+01 3.97428524e+00 8.35600677e+00 2.75496287e-02\n",
      " 2.78198829e-01 1.06125118e+01], Loss = 0.4697\n",
      "Iteration 1662: Weights = [5.49999969e+01 3.97417119e+00 8.35576692e+00 2.75486982e-02\n",
      " 2.78190925e-01 1.06127652e+01], Loss = 0.4697\n",
      "Iteration 1663: Weights = [5.49999970e+01 3.97405714e+00 8.35552707e+00 2.75477687e-02\n",
      " 2.78183020e-01 1.06130187e+01], Loss = 0.4697\n",
      "Iteration 1664: Weights = [5.49999970e+01 3.97394310e+00 8.35528724e+00 2.75468402e-02\n",
      " 2.78175115e-01 1.06132721e+01], Loss = 0.4697\n",
      "Iteration 1665: Weights = [5.49999970e+01 3.97382906e+00 8.35504741e+00 2.75459127e-02\n",
      " 2.78167210e-01 1.06135256e+01], Loss = 0.4696\n",
      "Iteration 1666: Weights = [5.49999971e+01 3.97371502e+00 8.35480759e+00 2.75449863e-02\n",
      " 2.78159304e-01 1.06137790e+01], Loss = 0.4696\n",
      "Iteration 1667: Weights = [5.49999971e+01 3.97360099e+00 8.35456777e+00 2.75440609e-02\n",
      " 2.78151398e-01 1.06140324e+01], Loss = 0.4696\n",
      "Iteration 1668: Weights = [5.49999971e+01 3.97348696e+00 8.35432796e+00 2.75431365e-02\n",
      " 2.78143492e-01 1.06142858e+01], Loss = 0.4696\n",
      "Iteration 1669: Weights = [5.49999971e+01 3.97337293e+00 8.35408816e+00 2.75422131e-02\n",
      " 2.78135585e-01 1.06145392e+01], Loss = 0.4695\n",
      "Iteration 1670: Weights = [5.49999972e+01 3.97325891e+00 8.35384836e+00 2.75412907e-02\n",
      " 2.78127678e-01 1.06147926e+01], Loss = 0.4695\n",
      "Iteration 1671: Weights = [5.49999972e+01 3.97314489e+00 8.35360857e+00 2.75403692e-02\n",
      " 2.78119771e-01 1.06150460e+01], Loss = 0.4695\n",
      "Iteration 1672: Weights = [5.49999972e+01 3.97303087e+00 8.35336879e+00 2.75394488e-02\n",
      " 2.78111863e-01 1.06152994e+01], Loss = 0.4695\n",
      "Iteration 1673: Weights = [5.49999973e+01 3.97291685e+00 8.35312901e+00 2.75385293e-02\n",
      " 2.78103955e-01 1.06155528e+01], Loss = 0.4694\n",
      "Iteration 1674: Weights = [5.49999973e+01 3.97280284e+00 8.35288924e+00 2.75376108e-02\n",
      " 2.78096047e-01 1.06158061e+01], Loss = 0.4694\n",
      "Iteration 1675: Weights = [5.49999973e+01 3.97268883e+00 8.35264948e+00 2.75366932e-02\n",
      " 2.78088138e-01 1.06160595e+01], Loss = 0.4694\n",
      "Iteration 1676: Weights = [5.49999973e+01 3.97257482e+00 8.35240973e+00 2.75357766e-02\n",
      " 2.78080229e-01 1.06163128e+01], Loss = 0.4693\n",
      "Iteration 1677: Weights = [5.49999974e+01 3.97246082e+00 8.35216998e+00 2.75348610e-02\n",
      " 2.78072320e-01 1.06165662e+01], Loss = 0.4693\n",
      "Iteration 1678: Weights = [5.49999974e+01 3.97234682e+00 8.35193023e+00 2.75339463e-02\n",
      " 2.78064410e-01 1.06168195e+01], Loss = 0.4693\n",
      "Iteration 1679: Weights = [5.49999974e+01 3.97223282e+00 8.35169050e+00 2.75330325e-02\n",
      " 2.78056500e-01 1.06170729e+01], Loss = 0.4693\n",
      "Iteration 1680: Weights = [5.49999974e+01 3.97211883e+00 8.35145077e+00 2.75321196e-02\n",
      " 2.78048590e-01 1.06173262e+01], Loss = 0.4692\n",
      "Iteration 1681: Weights = [5.49999975e+01 3.97200483e+00 8.35121105e+00 2.75312076e-02\n",
      " 2.78040680e-01 1.06175795e+01], Loss = 0.4692\n",
      "Iteration 1682: Weights = [5.49999975e+01 3.97189085e+00 8.35097133e+00 2.75302966e-02\n",
      " 2.78032769e-01 1.06178328e+01], Loss = 0.4692\n",
      "Iteration 1683: Weights = [5.49999975e+01 3.97177686e+00 8.35073163e+00 2.75293865e-02\n",
      " 2.78024858e-01 1.06180861e+01], Loss = 0.4692\n",
      "Iteration 1684: Weights = [5.49999975e+01 3.97166288e+00 8.35049192e+00 2.75284772e-02\n",
      " 2.78016947e-01 1.06183394e+01], Loss = 0.4691\n",
      "Iteration 1685: Weights = [5.49999976e+01 3.97154890e+00 8.35025223e+00 2.75275689e-02\n",
      " 2.78009035e-01 1.06185927e+01], Loss = 0.4691\n",
      "Iteration 1686: Weights = [5.49999976e+01 3.97143492e+00 8.35001254e+00 2.75266614e-02\n",
      " 2.78001123e-01 1.06188459e+01], Loss = 0.4691\n",
      "Iteration 1687: Weights = [5.49999976e+01 3.97132095e+00 8.34977286e+00 2.75257548e-02\n",
      " 2.77993211e-01 1.06190992e+01], Loss = 0.4690\n",
      "Iteration 1688: Weights = [5.49999976e+01 3.97120698e+00 8.34953319e+00 2.75248491e-02\n",
      " 2.77985299e-01 1.06193525e+01], Loss = 0.4690\n",
      "Iteration 1689: Weights = [5.49999977e+01 3.97109301e+00 8.34929352e+00 2.75239443e-02\n",
      " 2.77977386e-01 1.06196057e+01], Loss = 0.4690\n",
      "Iteration 1690: Weights = [5.49999977e+01 3.97097905e+00 8.34905386e+00 2.75230403e-02\n",
      " 2.77969473e-01 1.06198590e+01], Loss = 0.4690\n",
      "Iteration 1691: Weights = [5.49999977e+01 3.97086509e+00 8.34881420e+00 2.75221372e-02\n",
      " 2.77961560e-01 1.06201122e+01], Loss = 0.4689\n",
      "Iteration 1692: Weights = [5.49999977e+01 3.97075113e+00 8.34857455e+00 2.75212349e-02\n",
      " 2.77953646e-01 1.06203655e+01], Loss = 0.4689\n",
      "Iteration 1693: Weights = [5.49999978e+01 3.97063717e+00 8.34833491e+00 2.75203335e-02\n",
      " 2.77945733e-01 1.06206187e+01], Loss = 0.4689\n",
      "Iteration 1694: Weights = [5.49999978e+01 3.97052322e+00 8.34809528e+00 2.75194329e-02\n",
      " 2.77937819e-01 1.06208719e+01], Loss = 0.4689\n",
      "Iteration 1695: Weights = [5.49999978e+01 3.97040927e+00 8.34785565e+00 2.75185331e-02\n",
      " 2.77929905e-01 1.06211251e+01], Loss = 0.4688\n",
      "Iteration 1696: Weights = [5.49999978e+01 3.97029533e+00 8.34761603e+00 2.75176342e-02\n",
      " 2.77921990e-01 1.06213783e+01], Loss = 0.4688\n",
      "Iteration 1697: Weights = [5.49999978e+01 3.97018138e+00 8.34737642e+00 2.75167360e-02\n",
      " 2.77914076e-01 1.06216315e+01], Loss = 0.4688\n",
      "Iteration 1698: Weights = [5.49999979e+01 3.97006745e+00 8.34713681e+00 2.75158387e-02\n",
      " 2.77906161e-01 1.06218847e+01], Loss = 0.4687\n",
      "Iteration 1699: Weights = [5.49999979e+01 3.96995351e+00 8.34689721e+00 2.75149422e-02\n",
      " 2.77898246e-01 1.06221379e+01], Loss = 0.4687\n",
      "Iteration 1700: Weights = [5.49999979e+01 3.96983957e+00 8.34665762e+00 2.75140465e-02\n",
      " 2.77890330e-01 1.06223910e+01], Loss = 0.4687\n",
      "Iteration 1701: Weights = [5.49999979e+01 3.96972564e+00 8.34641803e+00 2.75131516e-02\n",
      " 2.77882415e-01 1.06226442e+01], Loss = 0.4687\n",
      "Iteration 1702: Weights = [5.49999980e+01 3.96961172e+00 8.34617845e+00 2.75122575e-02\n",
      " 2.77874499e-01 1.06228974e+01], Loss = 0.4686\n",
      "Iteration 1703: Weights = [5.49999980e+01 3.96949779e+00 8.34593888e+00 2.75113642e-02\n",
      " 2.77866583e-01 1.06231505e+01], Loss = 0.4686\n",
      "Iteration 1704: Weights = [5.49999980e+01 3.96938387e+00 8.34569931e+00 2.75104716e-02\n",
      " 2.77858667e-01 1.06234037e+01], Loss = 0.4686\n",
      "Iteration 1705: Weights = [5.49999980e+01 3.96926995e+00 8.34545975e+00 2.75095798e-02\n",
      " 2.77850750e-01 1.06236568e+01], Loss = 0.4686\n",
      "Iteration 1706: Weights = [5.49999980e+01 3.96915604e+00 8.34522020e+00 2.75086888e-02\n",
      " 2.77842834e-01 1.06239099e+01], Loss = 0.4685\n",
      "Iteration 1707: Weights = [5.49999981e+01 3.96904213e+00 8.34498065e+00 2.75077986e-02\n",
      " 2.77834917e-01 1.06241630e+01], Loss = 0.4685\n",
      "Iteration 1708: Weights = [5.49999981e+01 3.96892822e+00 8.34474111e+00 2.75069091e-02\n",
      " 2.77827000e-01 1.06244161e+01], Loss = 0.4685\n",
      "Iteration 1709: Weights = [5.49999981e+01 3.96881431e+00 8.34450158e+00 2.75060203e-02\n",
      " 2.77819083e-01 1.06246692e+01], Loss = 0.4685\n",
      "Iteration 1710: Weights = [5.49999981e+01 3.96870041e+00 8.34426206e+00 2.75051324e-02\n",
      " 2.77811165e-01 1.06249223e+01], Loss = 0.4684\n",
      "Iteration 1711: Weights = [5.49999981e+01 3.96858651e+00 8.34402254e+00 2.75042451e-02\n",
      " 2.77803248e-01 1.06251754e+01], Loss = 0.4684\n",
      "Iteration 1712: Weights = [5.49999981e+01 3.96847261e+00 8.34378302e+00 2.75033586e-02\n",
      " 2.77795330e-01 1.06254285e+01], Loss = 0.4684\n",
      "Iteration 1713: Weights = [5.49999982e+01 3.96835872e+00 8.34354352e+00 2.75024728e-02\n",
      " 2.77787412e-01 1.06256816e+01], Loss = 0.4683\n",
      "Iteration 1714: Weights = [5.49999982e+01 3.96824483e+00 8.34330402e+00 2.75015877e-02\n",
      " 2.77779494e-01 1.06259347e+01], Loss = 0.4683\n",
      "Iteration 1715: Weights = [5.49999982e+01 3.96813094e+00 8.34306453e+00 2.75007034e-02\n",
      " 2.77771576e-01 1.06261877e+01], Loss = 0.4683\n",
      "Iteration 1716: Weights = [5.49999982e+01 3.96801705e+00 8.34282504e+00 2.74998198e-02\n",
      " 2.77763657e-01 1.06264408e+01], Loss = 0.4683\n",
      "Iteration 1717: Weights = [5.49999982e+01 3.96790317e+00 8.34258557e+00 2.74989369e-02\n",
      " 2.77755738e-01 1.06266938e+01], Loss = 0.4682\n",
      "Iteration 1718: Weights = [5.49999983e+01 3.96778929e+00 8.34234609e+00 2.74980547e-02\n",
      " 2.77747820e-01 1.06269469e+01], Loss = 0.4682\n",
      "Iteration 1719: Weights = [5.49999983e+01 3.96767542e+00 8.34210663e+00 2.74971732e-02\n",
      " 2.77739901e-01 1.06271999e+01], Loss = 0.4682\n",
      "Iteration 1720: Weights = [5.49999983e+01 3.96756155e+00 8.34186717e+00 2.74962924e-02\n",
      " 2.77731981e-01 1.06274529e+01], Loss = 0.4682\n",
      "Iteration 1721: Weights = [5.49999983e+01 3.96744768e+00 8.34162772e+00 2.74954122e-02\n",
      " 2.77724062e-01 1.06277059e+01], Loss = 0.4681\n",
      "Iteration 1722: Weights = [5.49999983e+01 3.96733381e+00 8.34138828e+00 2.74945328e-02\n",
      " 2.77716143e-01 1.06279589e+01], Loss = 0.4681\n",
      "Iteration 1723: Weights = [5.49999983e+01 3.96721995e+00 8.34114884e+00 2.74936541e-02\n",
      " 2.77708223e-01 1.06282119e+01], Loss = 0.4681\n",
      "Iteration 1724: Weights = [5.49999984e+01 3.96710609e+00 8.34090941e+00 2.74927760e-02\n",
      " 2.77700303e-01 1.06284649e+01], Loss = 0.4681\n",
      "Iteration 1725: Weights = [5.49999984e+01 3.96699223e+00 8.34066998e+00 2.74918986e-02\n",
      " 2.77692383e-01 1.06287179e+01], Loss = 0.4680\n",
      "Iteration 1726: Weights = [5.49999984e+01 3.96687838e+00 8.34043057e+00 2.74910218e-02\n",
      " 2.77684463e-01 1.06289709e+01], Loss = 0.4680\n",
      "Iteration 1727: Weights = [5.49999984e+01 3.96676453e+00 8.34019116e+00 2.74901458e-02\n",
      " 2.77676543e-01 1.06292239e+01], Loss = 0.4680\n",
      "Iteration 1728: Weights = [5.49999984e+01 3.96665068e+00 8.33995175e+00 2.74892703e-02\n",
      " 2.77668622e-01 1.06294768e+01], Loss = 0.4679\n",
      "Iteration 1729: Weights = [5.49999984e+01 3.96653684e+00 8.33971235e+00 2.74883956e-02\n",
      " 2.77660702e-01 1.06297298e+01], Loss = 0.4679\n",
      "Iteration 1730: Weights = [5.49999985e+01 3.96642300e+00 8.33947296e+00 2.74875215e-02\n",
      " 2.77652781e-01 1.06299827e+01], Loss = 0.4679\n",
      "Iteration 1731: Weights = [5.49999985e+01 3.96630916e+00 8.33923358e+00 2.74866480e-02\n",
      " 2.77644860e-01 1.06302357e+01], Loss = 0.4679\n",
      "Iteration 1732: Weights = [5.49999985e+01 3.96619532e+00 8.33899420e+00 2.74857752e-02\n",
      " 2.77636940e-01 1.06304886e+01], Loss = 0.4678\n",
      "Iteration 1733: Weights = [5.49999985e+01 3.96608149e+00 8.33875483e+00 2.74849030e-02\n",
      " 2.77629019e-01 1.06307415e+01], Loss = 0.4678\n",
      "Iteration 1734: Weights = [5.49999985e+01 3.96596766e+00 8.33851547e+00 2.74840314e-02\n",
      " 2.77621097e-01 1.06309944e+01], Loss = 0.4678\n",
      "Iteration 1735: Weights = [5.49999985e+01 3.96585384e+00 8.33827612e+00 2.74831604e-02\n",
      " 2.77613176e-01 1.06312474e+01], Loss = 0.4678\n",
      "Iteration 1736: Weights = [5.49999985e+01 3.96574001e+00 8.33803677e+00 2.74822901e-02\n",
      " 2.77605255e-01 1.06315003e+01], Loss = 0.4677\n",
      "Iteration 1737: Weights = [5.49999986e+01 3.96562619e+00 8.33779742e+00 2.74814204e-02\n",
      " 2.77597333e-01 1.06317532e+01], Loss = 0.4677\n",
      "Iteration 1738: Weights = [5.49999986e+01 3.96551238e+00 8.33755809e+00 2.74805513e-02\n",
      " 2.77589411e-01 1.06320060e+01], Loss = 0.4677\n",
      "Iteration 1739: Weights = [5.49999986e+01 3.96539856e+00 8.33731876e+00 2.74796828e-02\n",
      " 2.77581490e-01 1.06322589e+01], Loss = 0.4676\n",
      "Iteration 1740: Weights = [5.49999986e+01 3.96528475e+00 8.33707944e+00 2.74788150e-02\n",
      " 2.77573568e-01 1.06325118e+01], Loss = 0.4676\n",
      "Iteration 1741: Weights = [5.49999986e+01 3.96517095e+00 8.33684012e+00 2.74779477e-02\n",
      " 2.77565646e-01 1.06327647e+01], Loss = 0.4676\n",
      "Iteration 1742: Weights = [5.49999986e+01 3.96505714e+00 8.33660081e+00 2.74770810e-02\n",
      " 2.77557724e-01 1.06330175e+01], Loss = 0.4676\n",
      "Iteration 1743: Weights = [5.49999986e+01 3.96494334e+00 8.33636151e+00 2.74762149e-02\n",
      " 2.77549802e-01 1.06332704e+01], Loss = 0.4675\n",
      "Iteration 1744: Weights = [5.49999987e+01 3.96482954e+00 8.33612221e+00 2.74753494e-02\n",
      " 2.77541879e-01 1.06335232e+01], Loss = 0.4675\n",
      "Iteration 1745: Weights = [5.49999987e+01 3.96471575e+00 8.33588293e+00 2.74744845e-02\n",
      " 2.77533957e-01 1.06337761e+01], Loss = 0.4675\n",
      "Iteration 1746: Weights = [5.49999987e+01 3.96460196e+00 8.33564364e+00 2.74736201e-02\n",
      " 2.77526034e-01 1.06340289e+01], Loss = 0.4675\n",
      "Iteration 1747: Weights = [5.49999987e+01 3.96448817e+00 8.33540437e+00 2.74727564e-02\n",
      " 2.77518112e-01 1.06342817e+01], Loss = 0.4674\n",
      "Iteration 1748: Weights = [5.49999987e+01 3.96437438e+00 8.33516510e+00 2.74718932e-02\n",
      " 2.77510189e-01 1.06345345e+01], Loss = 0.4674\n",
      "Iteration 1749: Weights = [5.49999987e+01 3.96426060e+00 8.33492584e+00 2.74710305e-02\n",
      " 2.77502266e-01 1.06347873e+01], Loss = 0.4674\n",
      "Iteration 1750: Weights = [5.49999987e+01 3.96414682e+00 8.33468659e+00 2.74701685e-02\n",
      " 2.77494343e-01 1.06350401e+01], Loss = 0.4674\n",
      "Iteration 1751: Weights = [5.49999987e+01 3.96403305e+00 8.33444734e+00 2.74693070e-02\n",
      " 2.77486420e-01 1.06352929e+01], Loss = 0.4673\n",
      "Iteration 1752: Weights = [5.49999988e+01 3.96391927e+00 8.33420810e+00 2.74684460e-02\n",
      " 2.77478497e-01 1.06355457e+01], Loss = 0.4673\n",
      "Iteration 1753: Weights = [5.49999988e+01 3.96380551e+00 8.33396886e+00 2.74675856e-02\n",
      " 2.77470574e-01 1.06357985e+01], Loss = 0.4673\n",
      "Iteration 1754: Weights = [5.49999988e+01 3.96369174e+00 8.33372964e+00 2.74667258e-02\n",
      " 2.77462651e-01 1.06360513e+01], Loss = 0.4672\n",
      "Iteration 1755: Weights = [5.49999988e+01 3.96357798e+00 8.33349042e+00 2.74658665e-02\n",
      " 2.77454728e-01 1.06363040e+01], Loss = 0.4672\n",
      "Iteration 1756: Weights = [5.49999988e+01 3.96346421e+00 8.33325120e+00 2.74650077e-02\n",
      " 2.77446805e-01 1.06365568e+01], Loss = 0.4672\n",
      "Iteration 1757: Weights = [5.49999988e+01 3.96335046e+00 8.33301199e+00 2.74641495e-02\n",
      " 2.77438881e-01 1.06368095e+01], Loss = 0.4672\n",
      "Iteration 1758: Weights = [5.49999988e+01 3.96323670e+00 8.33277279e+00 2.74632918e-02\n",
      " 2.77430958e-01 1.06370623e+01], Loss = 0.4671\n",
      "Iteration 1759: Weights = [5.49999988e+01 3.96312295e+00 8.33253360e+00 2.74624346e-02\n",
      " 2.77423034e-01 1.06373150e+01], Loss = 0.4671\n",
      "Iteration 1760: Weights = [5.49999989e+01 3.96300920e+00 8.33229441e+00 2.74615779e-02\n",
      " 2.77415111e-01 1.06375677e+01], Loss = 0.4671\n",
      "Iteration 1761: Weights = [5.49999989e+01 3.96289546e+00 8.33205524e+00 2.74607218e-02\n",
      " 2.77407187e-01 1.06378204e+01], Loss = 0.4671\n",
      "Iteration 1762: Weights = [5.49999989e+01 3.96278172e+00 8.33181606e+00 2.74598662e-02\n",
      " 2.77399263e-01 1.06380732e+01], Loss = 0.4670\n",
      "Iteration 1763: Weights = [5.49999989e+01 3.96266798e+00 8.33157690e+00 2.74590111e-02\n",
      " 2.77391339e-01 1.06383259e+01], Loss = 0.4670\n",
      "Iteration 1764: Weights = [5.49999989e+01 3.96255424e+00 8.33133774e+00 2.74581565e-02\n",
      " 2.77383415e-01 1.06385786e+01], Loss = 0.4670\n",
      "Iteration 1765: Weights = [5.49999989e+01 3.96244051e+00 8.33109858e+00 2.74573025e-02\n",
      " 2.77375492e-01 1.06388312e+01], Loss = 0.4670\n",
      "Iteration 1766: Weights = [5.49999989e+01 3.96232678e+00 8.33085944e+00 2.74564489e-02\n",
      " 2.77367568e-01 1.06390839e+01], Loss = 0.4669\n",
      "Iteration 1767: Weights = [5.49999989e+01 3.96221306e+00 8.33062030e+00 2.74555958e-02\n",
      " 2.77359644e-01 1.06393366e+01], Loss = 0.4669\n",
      "Iteration 1768: Weights = [5.49999989e+01 3.96209934e+00 8.33038117e+00 2.74547432e-02\n",
      " 2.77351720e-01 1.06395893e+01], Loss = 0.4669\n",
      "Iteration 1769: Weights = [5.49999990e+01 3.96198562e+00 8.33014204e+00 2.74538912e-02\n",
      " 2.77343795e-01 1.06398419e+01], Loss = 0.4668\n",
      "Iteration 1770: Weights = [5.49999990e+01 3.96187190e+00 8.32990292e+00 2.74530396e-02\n",
      " 2.77335871e-01 1.06400946e+01], Loss = 0.4668\n",
      "Iteration 1771: Weights = [5.49999990e+01 3.96175819e+00 8.32966381e+00 2.74521885e-02\n",
      " 2.77327947e-01 1.06403472e+01], Loss = 0.4668\n",
      "Iteration 1772: Weights = [5.49999990e+01 3.96164448e+00 8.32942471e+00 2.74513378e-02\n",
      " 2.77320023e-01 1.06405999e+01], Loss = 0.4668\n",
      "Iteration 1773: Weights = [5.49999990e+01 3.96153077e+00 8.32918561e+00 2.74504877e-02\n",
      " 2.77312099e-01 1.06408525e+01], Loss = 0.4667\n",
      "Iteration 1774: Weights = [5.49999990e+01 3.96141706e+00 8.32894652e+00 2.74496380e-02\n",
      " 2.77304174e-01 1.06411051e+01], Loss = 0.4667\n",
      "Iteration 1775: Weights = [5.49999990e+01 3.96130336e+00 8.32870743e+00 2.74487888e-02\n",
      " 2.77296250e-01 1.06413577e+01], Loss = 0.4667\n",
      "Iteration 1776: Weights = [5.49999990e+01 3.96118967e+00 8.32846836e+00 2.74479401e-02\n",
      " 2.77288326e-01 1.06416103e+01], Loss = 0.4667\n",
      "Iteration 1777: Weights = [5.49999990e+01 3.96107597e+00 8.32822928e+00 2.74470918e-02\n",
      " 2.77280401e-01 1.06418629e+01], Loss = 0.4666\n",
      "Iteration 1778: Weights = [5.49999990e+01 3.96096228e+00 8.32799022e+00 2.74462441e-02\n",
      " 2.77272477e-01 1.06421155e+01], Loss = 0.4666\n",
      "Iteration 1779: Weights = [5.49999991e+01 3.96084859e+00 8.32775116e+00 2.74453967e-02\n",
      " 2.77264552e-01 1.06423681e+01], Loss = 0.4666\n",
      "Iteration 1780: Weights = [5.49999991e+01 3.96073491e+00 8.32751211e+00 2.74445498e-02\n",
      " 2.77256628e-01 1.06426207e+01], Loss = 0.4665\n",
      "Iteration 1781: Weights = [5.49999991e+01 3.96062122e+00 8.32727307e+00 2.74437034e-02\n",
      " 2.77248703e-01 1.06428733e+01], Loss = 0.4665\n",
      "Iteration 1782: Weights = [5.49999991e+01 3.96050755e+00 8.32703403e+00 2.74428574e-02\n",
      " 2.77240779e-01 1.06431258e+01], Loss = 0.4665\n",
      "Iteration 1783: Weights = [5.49999991e+01 3.96039387e+00 8.32679500e+00 2.74420119e-02\n",
      " 2.77232854e-01 1.06433784e+01], Loss = 0.4665\n",
      "Iteration 1784: Weights = [5.49999991e+01 3.96028020e+00 8.32655598e+00 2.74411668e-02\n",
      " 2.77224930e-01 1.06436309e+01], Loss = 0.4664\n",
      "Iteration 1785: Weights = [5.49999991e+01 3.96016653e+00 8.32631696e+00 2.74403222e-02\n",
      " 2.77217005e-01 1.06438835e+01], Loss = 0.4664\n",
      "Iteration 1786: Weights = [5.49999991e+01 3.96005286e+00 8.32607795e+00 2.74394780e-02\n",
      " 2.77209080e-01 1.06441360e+01], Loss = 0.4664\n",
      "Iteration 1787: Weights = [5.49999991e+01 3.95993920e+00 8.32583895e+00 2.74386342e-02\n",
      " 2.77201156e-01 1.06443885e+01], Loss = 0.4664\n",
      "Iteration 1788: Weights = [5.49999991e+01 3.95982554e+00 8.32559995e+00 2.74377909e-02\n",
      " 2.77193231e-01 1.06446411e+01], Loss = 0.4663\n",
      "Iteration 1789: Weights = [5.49999991e+01 3.95971188e+00 8.32536096e+00 2.74369480e-02\n",
      " 2.77185306e-01 1.06448936e+01], Loss = 0.4663\n",
      "Iteration 1790: Weights = [5.49999992e+01 3.95959823e+00 8.32512198e+00 2.74361055e-02\n",
      " 2.77177382e-01 1.06451461e+01], Loss = 0.4663\n",
      "Iteration 1791: Weights = [5.49999992e+01 3.95948458e+00 8.32488300e+00 2.74352634e-02\n",
      " 2.77169457e-01 1.06453986e+01], Loss = 0.4663\n",
      "Iteration 1792: Weights = [5.49999992e+01 3.95937093e+00 8.32464404e+00 2.74344218e-02\n",
      " 2.77161533e-01 1.06456511e+01], Loss = 0.4662\n",
      "Iteration 1793: Weights = [5.49999992e+01 3.95925729e+00 8.32440507e+00 2.74335806e-02\n",
      " 2.77153608e-01 1.06459035e+01], Loss = 0.4662\n",
      "Iteration 1794: Weights = [5.49999992e+01 3.95914365e+00 8.32416612e+00 2.74327398e-02\n",
      " 2.77145683e-01 1.06461560e+01], Loss = 0.4662\n",
      "Iteration 1795: Weights = [5.49999992e+01 3.95903001e+00 8.32392717e+00 2.74318994e-02\n",
      " 2.77137759e-01 1.06464085e+01], Loss = 0.4661\n",
      "Iteration 1796: Weights = [5.49999992e+01 3.95891637e+00 8.32368823e+00 2.74310594e-02\n",
      " 2.77129834e-01 1.06466609e+01], Loss = 0.4661\n",
      "Iteration 1797: Weights = [5.49999992e+01 3.95880274e+00 8.32344929e+00 2.74302198e-02\n",
      " 2.77121909e-01 1.06469134e+01], Loss = 0.4661\n",
      "Iteration 1798: Weights = [5.49999992e+01 3.95868911e+00 8.32321037e+00 2.74293806e-02\n",
      " 2.77113985e-01 1.06471658e+01], Loss = 0.4661\n",
      "Iteration 1799: Weights = [5.49999992e+01 3.95857549e+00 8.32297144e+00 2.74285419e-02\n",
      " 2.77106060e-01 1.06474183e+01], Loss = 0.4660\n",
      "Iteration 1800: Weights = [5.49999992e+01 3.95846187e+00 8.32273253e+00 2.74277035e-02\n",
      " 2.77098135e-01 1.06476707e+01], Loss = 0.4660\n",
      "Iteration 1801: Weights = [5.49999992e+01 3.95834825e+00 8.32249362e+00 2.74268655e-02\n",
      " 2.77090211e-01 1.06479231e+01], Loss = 0.4660\n",
      "Iteration 1802: Weights = [5.49999993e+01 3.95823463e+00 8.32225472e+00 2.74260279e-02\n",
      " 2.77082286e-01 1.06481756e+01], Loss = 0.4660\n",
      "Iteration 1803: Weights = [5.49999993e+01 3.95812102e+00 8.32201583e+00 2.74251907e-02\n",
      " 2.77074361e-01 1.06484280e+01], Loss = 0.4659\n",
      "Iteration 1804: Weights = [5.49999993e+01 3.95800741e+00 8.32177694e+00 2.74243539e-02\n",
      " 2.77066437e-01 1.06486804e+01], Loss = 0.4659\n",
      "Iteration 1805: Weights = [5.49999993e+01 3.95789380e+00 8.32153806e+00 2.74235175e-02\n",
      " 2.77058512e-01 1.06489328e+01], Loss = 0.4659\n",
      "Iteration 1806: Weights = [5.49999993e+01 3.95778020e+00 8.32129919e+00 2.74226814e-02\n",
      " 2.77050588e-01 1.06491851e+01], Loss = 0.4659\n",
      "Iteration 1807: Weights = [5.49999993e+01 3.95766660e+00 8.32106032e+00 2.74218458e-02\n",
      " 2.77042663e-01 1.06494375e+01], Loss = 0.4658\n",
      "Iteration 1808: Weights = [5.49999993e+01 3.95755300e+00 8.32082146e+00 2.74210105e-02\n",
      " 2.77034739e-01 1.06496899e+01], Loss = 0.4658\n",
      "Iteration 1809: Weights = [5.49999993e+01 3.95743941e+00 8.32058260e+00 2.74201756e-02\n",
      " 2.77026814e-01 1.06499423e+01], Loss = 0.4658\n",
      "Iteration 1810: Weights = [5.49999993e+01 3.95732582e+00 8.32034376e+00 2.74193410e-02\n",
      " 2.77018890e-01 1.06501946e+01], Loss = 0.4657\n",
      "Iteration 1811: Weights = [5.49999993e+01 3.95721223e+00 8.32010492e+00 2.74185068e-02\n",
      " 2.77010965e-01 1.06504470e+01], Loss = 0.4657\n",
      "Iteration 1812: Weights = [5.49999993e+01 3.95709865e+00 8.31986609e+00 2.74176730e-02\n",
      " 2.77003041e-01 1.06506993e+01], Loss = 0.4657\n",
      "Iteration 1813: Weights = [5.49999993e+01 3.95698507e+00 8.31962726e+00 2.74168396e-02\n",
      " 2.76995116e-01 1.06509517e+01], Loss = 0.4657\n",
      "Iteration 1814: Weights = [5.49999993e+01 3.95687149e+00 8.31938844e+00 2.74160065e-02\n",
      " 2.76987192e-01 1.06512040e+01], Loss = 0.4656\n",
      "Iteration 1815: Weights = [5.49999993e+01 3.95675792e+00 8.31914963e+00 2.74151738e-02\n",
      " 2.76979268e-01 1.06514563e+01], Loss = 0.4656\n",
      "Iteration 1816: Weights = [5.49999993e+01 3.95664435e+00 8.31891082e+00 2.74143414e-02\n",
      " 2.76971343e-01 1.06517086e+01], Loss = 0.4656\n",
      "Iteration 1817: Weights = [5.49999994e+01 3.95653078e+00 8.31867202e+00 2.74135094e-02\n",
      " 2.76963419e-01 1.06519609e+01], Loss = 0.4656\n",
      "Iteration 1818: Weights = [5.49999994e+01 3.95641721e+00 8.31843323e+00 2.74126777e-02\n",
      " 2.76955495e-01 1.06522132e+01], Loss = 0.4655\n",
      "Iteration 1819: Weights = [5.49999994e+01 3.95630365e+00 8.31819445e+00 2.74118464e-02\n",
      " 2.76947571e-01 1.06524655e+01], Loss = 0.4655\n",
      "Iteration 1820: Weights = [5.49999994e+01 3.95619009e+00 8.31795567e+00 2.74110154e-02\n",
      " 2.76939647e-01 1.06527178e+01], Loss = 0.4655\n",
      "Iteration 1821: Weights = [5.49999994e+01 3.95607654e+00 8.31771690e+00 2.74101848e-02\n",
      " 2.76931722e-01 1.06529701e+01], Loss = 0.4655\n",
      "Iteration 1822: Weights = [5.49999994e+01 3.95596298e+00 8.31747813e+00 2.74093545e-02\n",
      " 2.76923798e-01 1.06532223e+01], Loss = 0.4654\n",
      "Iteration 1823: Weights = [5.49999994e+01 3.95584943e+00 8.31723937e+00 2.74085246e-02\n",
      " 2.76915874e-01 1.06534746e+01], Loss = 0.4654\n",
      "Iteration 1824: Weights = [5.49999994e+01 3.95573589e+00 8.31700062e+00 2.74076950e-02\n",
      " 2.76907950e-01 1.06537269e+01], Loss = 0.4654\n",
      "Iteration 1825: Weights = [5.49999994e+01 3.95562235e+00 8.31676188e+00 2.74068657e-02\n",
      " 2.76900026e-01 1.06539791e+01], Loss = 0.4653\n",
      "Iteration 1826: Weights = [5.49999994e+01 3.95550881e+00 8.31652314e+00 2.74060368e-02\n",
      " 2.76892103e-01 1.06542313e+01], Loss = 0.4653\n",
      "Iteration 1827: Weights = [5.49999994e+01 3.95539527e+00 8.31628441e+00 2.74052081e-02\n",
      " 2.76884179e-01 1.06544836e+01], Loss = 0.4653\n",
      "Iteration 1828: Weights = [5.49999994e+01 3.95528174e+00 8.31604569e+00 2.74043799e-02\n",
      " 2.76876255e-01 1.06547358e+01], Loss = 0.4653\n",
      "Iteration 1829: Weights = [5.49999994e+01 3.95516821e+00 8.31580697e+00 2.74035519e-02\n",
      " 2.76868331e-01 1.06549880e+01], Loss = 0.4652\n",
      "Iteration 1830: Weights = [5.49999994e+01 3.95505468e+00 8.31556826e+00 2.74027243e-02\n",
      " 2.76860407e-01 1.06552402e+01], Loss = 0.4652\n",
      "Iteration 1831: Weights = [5.49999994e+01 3.95494115e+00 8.31532956e+00 2.74018970e-02\n",
      " 2.76852484e-01 1.06554924e+01], Loss = 0.4652\n",
      "Iteration 1832: Weights = [5.49999994e+01 3.95482763e+00 8.31509086e+00 2.74010700e-02\n",
      " 2.76844560e-01 1.06557446e+01], Loss = 0.4652\n",
      "Iteration 1833: Weights = [5.49999995e+01 3.95471412e+00 8.31485217e+00 2.74002433e-02\n",
      " 2.76836637e-01 1.06559968e+01], Loss = 0.4651\n",
      "Iteration 1834: Weights = [5.49999995e+01 3.95460060e+00 8.31461349e+00 2.73994170e-02\n",
      " 2.76828713e-01 1.06562490e+01], Loss = 0.4651\n",
      "Iteration 1835: Weights = [5.49999995e+01 3.95448709e+00 8.31437481e+00 2.73985909e-02\n",
      " 2.76820790e-01 1.06565012e+01], Loss = 0.4651\n",
      "Iteration 1836: Weights = [5.49999995e+01 3.95437358e+00 8.31413614e+00 2.73977652e-02\n",
      " 2.76812866e-01 1.06567533e+01], Loss = 0.4651\n",
      "Iteration 1837: Weights = [5.49999995e+01 3.95426008e+00 8.31389748e+00 2.73969398e-02\n",
      " 2.76804943e-01 1.06570055e+01], Loss = 0.4650\n",
      "Iteration 1838: Weights = [5.49999995e+01 3.95414658e+00 8.31365882e+00 2.73961147e-02\n",
      " 2.76797020e-01 1.06572577e+01], Loss = 0.4650\n",
      "Iteration 1839: Weights = [5.49999995e+01 3.95403308e+00 8.31342017e+00 2.73952899e-02\n",
      " 2.76789097e-01 1.06575098e+01], Loss = 0.4650\n",
      "Iteration 1840: Weights = [5.49999995e+01 3.95391958e+00 8.31318153e+00 2.73944653e-02\n",
      " 2.76781173e-01 1.06577619e+01], Loss = 0.4649\n",
      "Iteration 1841: Weights = [5.49999995e+01 3.95380609e+00 8.31294290e+00 2.73936411e-02\n",
      " 2.76773250e-01 1.06580141e+01], Loss = 0.4649\n",
      "Iteration 1842: Weights = [5.49999995e+01 3.95369260e+00 8.31270427e+00 2.73928172e-02\n",
      " 2.76765327e-01 1.06582662e+01], Loss = 0.4649\n",
      "Iteration 1843: Weights = [5.49999995e+01 3.95357912e+00 8.31246565e+00 2.73919936e-02\n",
      " 2.76757405e-01 1.06585183e+01], Loss = 0.4649\n",
      "Iteration 1844: Weights = [5.49999995e+01 3.95346563e+00 8.31222703e+00 2.73911703e-02\n",
      " 2.76749482e-01 1.06587704e+01], Loss = 0.4648\n",
      "Iteration 1845: Weights = [5.49999995e+01 3.95335216e+00 8.31198842e+00 2.73903473e-02\n",
      " 2.76741559e-01 1.06590225e+01], Loss = 0.4648\n",
      "Iteration 1846: Weights = [5.49999995e+01 3.95323868e+00 8.31174982e+00 2.73895245e-02\n",
      " 2.76733636e-01 1.06592746e+01], Loss = 0.4648\n",
      "Iteration 1847: Weights = [5.49999995e+01 3.95312521e+00 8.31151123e+00 2.73887021e-02\n",
      " 2.76725714e-01 1.06595267e+01], Loss = 0.4648\n",
      "Iteration 1848: Weights = [5.49999995e+01 3.95301174e+00 8.31127264e+00 2.73878799e-02\n",
      " 2.76717791e-01 1.06597788e+01], Loss = 0.4647\n",
      "Iteration 1849: Weights = [5.49999995e+01 3.95289827e+00 8.31103406e+00 2.73870581e-02\n",
      " 2.76709868e-01 1.06600309e+01], Loss = 0.4647\n",
      "Iteration 1850: Weights = [5.49999995e+01 3.95278481e+00 8.31079548e+00 2.73862365e-02\n",
      " 2.76701946e-01 1.06602829e+01], Loss = 0.4647\n",
      "Iteration 1851: Weights = [5.49999995e+01 3.95267135e+00 8.31055692e+00 2.73854152e-02\n",
      " 2.76694024e-01 1.06605350e+01], Loss = 0.4647\n",
      "Iteration 1852: Weights = [5.49999995e+01 3.95255789e+00 8.31031836e+00 2.73845941e-02\n",
      " 2.76686101e-01 1.06607870e+01], Loss = 0.4646\n",
      "Iteration 1853: Weights = [5.49999996e+01 3.95244444e+00 8.31007980e+00 2.73837734e-02\n",
      " 2.76678179e-01 1.06610391e+01], Loss = 0.4646\n",
      "Iteration 1854: Weights = [5.49999996e+01 3.95233099e+00 8.30984126e+00 2.73829529e-02\n",
      " 2.76670257e-01 1.06612911e+01], Loss = 0.4646\n",
      "Iteration 1855: Weights = [5.49999996e+01 3.95221754e+00 8.30960272e+00 2.73821327e-02\n",
      " 2.76662335e-01 1.06615431e+01], Loss = 0.4645\n",
      "Iteration 1856: Weights = [5.49999996e+01 3.95210409e+00 8.30936418e+00 2.73813128e-02\n",
      " 2.76654413e-01 1.06617952e+01], Loss = 0.4645\n",
      "Iteration 1857: Weights = [5.49999996e+01 3.95199065e+00 8.30912566e+00 2.73804931e-02\n",
      " 2.76646491e-01 1.06620472e+01], Loss = 0.4645\n",
      "Iteration 1858: Weights = [5.49999996e+01 3.95187722e+00 8.30888714e+00 2.73796737e-02\n",
      " 2.76638569e-01 1.06622992e+01], Loss = 0.4645\n",
      "Iteration 1859: Weights = [5.49999996e+01 3.95176378e+00 8.30864862e+00 2.73788546e-02\n",
      " 2.76630648e-01 1.06625512e+01], Loss = 0.4644\n",
      "Iteration 1860: Weights = [5.49999996e+01 3.95165035e+00 8.30841012e+00 2.73780357e-02\n",
      " 2.76622726e-01 1.06628032e+01], Loss = 0.4644\n",
      "Iteration 1861: Weights = [5.49999996e+01 3.95153692e+00 8.30817162e+00 2.73772171e-02\n",
      " 2.76614805e-01 1.06630552e+01], Loss = 0.4644\n",
      "Iteration 1862: Weights = [5.49999996e+01 3.95142350e+00 8.30793313e+00 2.73763988e-02\n",
      " 2.76606883e-01 1.06633071e+01], Loss = 0.4644\n",
      "Iteration 1863: Weights = [5.49999996e+01 3.95131007e+00 8.30769464e+00 2.73755807e-02\n",
      " 2.76598962e-01 1.06635591e+01], Loss = 0.4643\n",
      "Iteration 1864: Weights = [5.49999996e+01 3.95119666e+00 8.30745616e+00 2.73747629e-02\n",
      " 2.76591041e-01 1.06638111e+01], Loss = 0.4643\n",
      "Iteration 1865: Weights = [5.49999996e+01 3.95108324e+00 8.30721769e+00 2.73739453e-02\n",
      " 2.76583119e-01 1.06640630e+01], Loss = 0.4643\n",
      "Iteration 1866: Weights = [5.49999996e+01 3.95096983e+00 8.30697923e+00 2.73731280e-02\n",
      " 2.76575198e-01 1.06643150e+01], Loss = 0.4643\n",
      "Iteration 1867: Weights = [5.49999996e+01 3.95085642e+00 8.30674077e+00 2.73723110e-02\n",
      " 2.76567277e-01 1.06645669e+01], Loss = 0.4642\n",
      "Iteration 1868: Weights = [5.49999996e+01 3.95074301e+00 8.30650232e+00 2.73714941e-02\n",
      " 2.76559356e-01 1.06648188e+01], Loss = 0.4642\n",
      "Iteration 1869: Weights = [5.49999996e+01 3.95062961e+00 8.30626387e+00 2.73706776e-02\n",
      " 2.76551436e-01 1.06650708e+01], Loss = 0.4642\n",
      "Iteration 1870: Weights = [5.49999996e+01 3.95051621e+00 8.30602543e+00 2.73698613e-02\n",
      " 2.76543515e-01 1.06653227e+01], Loss = 0.4641\n",
      "Iteration 1871: Weights = [5.49999996e+01 3.95040281e+00 8.30578700e+00 2.73690452e-02\n",
      " 2.76535594e-01 1.06655746e+01], Loss = 0.4641\n",
      "Iteration 1872: Weights = [5.49999996e+01 3.95028942e+00 8.30554858e+00 2.73682294e-02\n",
      " 2.76527674e-01 1.06658265e+01], Loss = 0.4641\n",
      "Iteration 1873: Weights = [5.49999996e+01 3.95017603e+00 8.30531016e+00 2.73674138e-02\n",
      " 2.76519753e-01 1.06660784e+01], Loss = 0.4641\n",
      "Iteration 1874: Weights = [5.49999996e+01 3.95006264e+00 8.30507175e+00 2.73665985e-02\n",
      " 2.76511833e-01 1.06663303e+01], Loss = 0.4640\n",
      "Iteration 1875: Weights = [5.49999996e+01 3.94994926e+00 8.30483335e+00 2.73657834e-02\n",
      " 2.76503913e-01 1.06665822e+01], Loss = 0.4640\n",
      "Iteration 1876: Weights = [5.49999996e+01 3.94983588e+00 8.30459495e+00 2.73649685e-02\n",
      " 2.76495993e-01 1.06668340e+01], Loss = 0.4640\n",
      "Iteration 1877: Weights = [5.49999996e+01 3.94972250e+00 8.30435656e+00 2.73641539e-02\n",
      " 2.76488073e-01 1.06670859e+01], Loss = 0.4640\n",
      "Iteration 1878: Weights = [5.49999997e+01 3.94960913e+00 8.30411818e+00 2.73633395e-02\n",
      " 2.76480153e-01 1.06673378e+01], Loss = 0.4639\n",
      "Iteration 1879: Weights = [5.49999997e+01 3.94949576e+00 8.30387980e+00 2.73625253e-02\n",
      " 2.76472233e-01 1.06675896e+01], Loss = 0.4639\n",
      "Iteration 1880: Weights = [5.49999997e+01 3.94938239e+00 8.30364143e+00 2.73617114e-02\n",
      " 2.76464313e-01 1.06678415e+01], Loss = 0.4639\n",
      "Iteration 1881: Weights = [5.49999997e+01 3.94926903e+00 8.30340307e+00 2.73608977e-02\n",
      " 2.76456394e-01 1.06680933e+01], Loss = 0.4639\n",
      "Iteration 1882: Weights = [5.49999997e+01 3.94915566e+00 8.30316471e+00 2.73600843e-02\n",
      " 2.76448474e-01 1.06683451e+01], Loss = 0.4638\n",
      "Iteration 1883: Weights = [5.49999997e+01 3.94904231e+00 8.30292636e+00 2.73592710e-02\n",
      " 2.76440555e-01 1.06685970e+01], Loss = 0.4638\n",
      "Iteration 1884: Weights = [5.49999997e+01 3.94892895e+00 8.30268802e+00 2.73584580e-02\n",
      " 2.76432636e-01 1.06688488e+01], Loss = 0.4638\n",
      "Iteration 1885: Weights = [5.49999997e+01 3.94881560e+00 8.30244968e+00 2.73576452e-02\n",
      " 2.76424717e-01 1.06691006e+01], Loss = 0.4637\n",
      "Iteration 1886: Weights = [5.49999997e+01 3.94870225e+00 8.30221135e+00 2.73568327e-02\n",
      " 2.76416798e-01 1.06693524e+01], Loss = 0.4637\n",
      "Iteration 1887: Weights = [5.49999997e+01 3.94858891e+00 8.30197303e+00 2.73560203e-02\n",
      " 2.76408879e-01 1.06696042e+01], Loss = 0.4637\n",
      "Iteration 1888: Weights = [5.49999997e+01 3.94847557e+00 8.30173472e+00 2.73552082e-02\n",
      " 2.76400960e-01 1.06698560e+01], Loss = 0.4637\n",
      "Iteration 1889: Weights = [5.49999997e+01 3.94836223e+00 8.30149641e+00 2.73543963e-02\n",
      " 2.76393041e-01 1.06701078e+01], Loss = 0.4636\n",
      "Iteration 1890: Weights = [5.49999997e+01 3.94824889e+00 8.30125811e+00 2.73535846e-02\n",
      " 2.76385122e-01 1.06703595e+01], Loss = 0.4636\n",
      "Iteration 1891: Weights = [5.49999997e+01 3.94813556e+00 8.30101981e+00 2.73527731e-02\n",
      " 2.76377204e-01 1.06706113e+01], Loss = 0.4636\n",
      "Iteration 1892: Weights = [5.49999997e+01 3.94802223e+00 8.30078152e+00 2.73519619e-02\n",
      " 2.76369286e-01 1.06708631e+01], Loss = 0.4636\n",
      "Iteration 1893: Weights = [5.49999997e+01 3.94790890e+00 8.30054324e+00 2.73511508e-02\n",
      " 2.76361367e-01 1.06711148e+01], Loss = 0.4635\n",
      "Iteration 1894: Weights = [5.49999997e+01 3.94779558e+00 8.30030497e+00 2.73503400e-02\n",
      " 2.76353449e-01 1.06713665e+01], Loss = 0.4635\n",
      "Iteration 1895: Weights = [5.49999997e+01 3.94768226e+00 8.30006670e+00 2.73495294e-02\n",
      " 2.76345531e-01 1.06716183e+01], Loss = 0.4635\n",
      "Iteration 1896: Weights = [5.49999997e+01 3.94756894e+00 8.29982844e+00 2.73487190e-02\n",
      " 2.76337613e-01 1.06718700e+01], Loss = 0.4635\n",
      "Iteration 1897: Weights = [5.49999997e+01 3.94745563e+00 8.29959019e+00 2.73479088e-02\n",
      " 2.76329695e-01 1.06721217e+01], Loss = 0.4634\n",
      "Iteration 1898: Weights = [5.49999997e+01 3.94734232e+00 8.29935194e+00 2.73470987e-02\n",
      " 2.76321778e-01 1.06723735e+01], Loss = 0.4634\n",
      "Iteration 1899: Weights = [5.49999997e+01 3.94722901e+00 8.29911370e+00 2.73462890e-02\n",
      " 2.76313860e-01 1.06726252e+01], Loss = 0.4634\n",
      "Iteration 1900: Weights = [5.49999997e+01 3.94711571e+00 8.29887547e+00 2.73454794e-02\n",
      " 2.76305943e-01 1.06728769e+01], Loss = 0.4633\n",
      "Iteration 1901: Weights = [5.49999997e+01 3.94700241e+00 8.29863724e+00 2.73446700e-02\n",
      " 2.76298026e-01 1.06731286e+01], Loss = 0.4633\n",
      "Iteration 1902: Weights = [5.49999997e+01 3.94688911e+00 8.29839902e+00 2.73438608e-02\n",
      " 2.76290108e-01 1.06733802e+01], Loss = 0.4633\n",
      "Iteration 1903: Weights = [5.49999997e+01 3.94677582e+00 8.29816081e+00 2.73430518e-02\n",
      " 2.76282191e-01 1.06736319e+01], Loss = 0.4633\n",
      "Iteration 1904: Weights = [5.49999997e+01 3.94666253e+00 8.29792260e+00 2.73422430e-02\n",
      " 2.76274274e-01 1.06738836e+01], Loss = 0.4632\n",
      "Iteration 1905: Weights = [5.49999997e+01 3.94654924e+00 8.29768440e+00 2.73414344e-02\n",
      " 2.76266358e-01 1.06741353e+01], Loss = 0.4632\n",
      "Iteration 1906: Weights = [5.49999997e+01 3.94643596e+00 8.29744621e+00 2.73406260e-02\n",
      " 2.76258441e-01 1.06743869e+01], Loss = 0.4632\n",
      "Iteration 1907: Weights = [5.49999997e+01 3.94632268e+00 8.29720802e+00 2.73398178e-02\n",
      " 2.76250524e-01 1.06746386e+01], Loss = 0.4632\n",
      "Iteration 1908: Weights = [5.49999997e+01 3.94620940e+00 8.29696984e+00 2.73390098e-02\n",
      " 2.76242608e-01 1.06748902e+01], Loss = 0.4631\n",
      "Iteration 1909: Weights = [5.49999997e+01 3.94609612e+00 8.29673167e+00 2.73382019e-02\n",
      " 2.76234692e-01 1.06751418e+01], Loss = 0.4631\n",
      "Iteration 1910: Weights = [5.49999997e+01 3.94598285e+00 8.29649351e+00 2.73373943e-02\n",
      " 2.76226775e-01 1.06753935e+01], Loss = 0.4631\n",
      "Iteration 1911: Weights = [5.49999997e+01 3.94586958e+00 8.29625535e+00 2.73365869e-02\n",
      " 2.76218859e-01 1.06756451e+01], Loss = 0.4631\n",
      "Iteration 1912: Weights = [5.49999998e+01 3.94575632e+00 8.29601720e+00 2.73357796e-02\n",
      " 2.76210944e-01 1.06758967e+01], Loss = 0.4630\n",
      "Iteration 1913: Weights = [5.49999998e+01 3.94564306e+00 8.29577905e+00 2.73349725e-02\n",
      " 2.76203028e-01 1.06761483e+01], Loss = 0.4630\n",
      "Iteration 1914: Weights = [5.49999998e+01 3.94552980e+00 8.29554091e+00 2.73341657e-02\n",
      " 2.76195112e-01 1.06763999e+01], Loss = 0.4630\n",
      "Iteration 1915: Weights = [5.49999998e+01 3.94541654e+00 8.29530278e+00 2.73333590e-02\n",
      " 2.76187197e-01 1.06766515e+01], Loss = 0.4629\n",
      "Iteration 1916: Weights = [5.49999998e+01 3.94530329e+00 8.29506466e+00 2.73325525e-02\n",
      " 2.76179281e-01 1.06769031e+01], Loss = 0.4629\n",
      "Iteration 1917: Weights = [5.49999998e+01 3.94519004e+00 8.29482654e+00 2.73317461e-02\n",
      " 2.76171366e-01 1.06771547e+01], Loss = 0.4629\n",
      "Iteration 1918: Weights = [5.49999998e+01 3.94507679e+00 8.29458843e+00 2.73309400e-02\n",
      " 2.76163451e-01 1.06774062e+01], Loss = 0.4629\n",
      "Iteration 1919: Weights = [5.49999998e+01 3.94496355e+00 8.29435033e+00 2.73301340e-02\n",
      " 2.76155536e-01 1.06776578e+01], Loss = 0.4628\n",
      "Iteration 1920: Weights = [5.49999998e+01 3.94485031e+00 8.29411223e+00 2.73293282e-02\n",
      " 2.76147621e-01 1.06779093e+01], Loss = 0.4628\n",
      "Iteration 1921: Weights = [5.49999998e+01 3.94473708e+00 8.29387414e+00 2.73285226e-02\n",
      " 2.76139706e-01 1.06781609e+01], Loss = 0.4628\n",
      "Iteration 1922: Weights = [5.49999998e+01 3.94462384e+00 8.29363606e+00 2.73277172e-02\n",
      " 2.76131792e-01 1.06784124e+01], Loss = 0.4628\n",
      "Iteration 1923: Weights = [5.49999998e+01 3.94451061e+00 8.29339798e+00 2.73269119e-02\n",
      " 2.76123877e-01 1.06786640e+01], Loss = 0.4627\n",
      "Iteration 1924: Weights = [5.49999998e+01 3.94439739e+00 8.29315991e+00 2.73261068e-02\n",
      " 2.76115963e-01 1.06789155e+01], Loss = 0.4627\n",
      "Iteration 1925: Weights = [5.49999998e+01 3.94428416e+00 8.29292185e+00 2.73253019e-02\n",
      " 2.76108049e-01 1.06791670e+01], Loss = 0.4627\n",
      "Iteration 1926: Weights = [5.49999998e+01 3.94417094e+00 8.29268379e+00 2.73244971e-02\n",
      " 2.76100135e-01 1.06794185e+01], Loss = 0.4627\n",
      "Iteration 1927: Weights = [5.49999998e+01 3.94405773e+00 8.29244574e+00 2.73236926e-02\n",
      " 2.76092221e-01 1.06796700e+01], Loss = 0.4626\n",
      "Iteration 1928: Weights = [5.49999998e+01 3.94394451e+00 8.29220770e+00 2.73228882e-02\n",
      " 2.76084307e-01 1.06799215e+01], Loss = 0.4626\n",
      "Iteration 1929: Weights = [5.49999998e+01 3.94383130e+00 8.29196966e+00 2.73220839e-02\n",
      " 2.76076394e-01 1.06801730e+01], Loss = 0.4626\n",
      "Iteration 1930: Weights = [5.49999998e+01 3.94371809e+00 8.29173163e+00 2.73212799e-02\n",
      " 2.76068480e-01 1.06804245e+01], Loss = 0.4625\n",
      "Iteration 1931: Weights = [5.49999998e+01 3.94360489e+00 8.29149361e+00 2.73204760e-02\n",
      " 2.76060567e-01 1.06806760e+01], Loss = 0.4625\n",
      "Iteration 1932: Weights = [5.49999998e+01 3.94349169e+00 8.29125559e+00 2.73196722e-02\n",
      " 2.76052654e-01 1.06809274e+01], Loss = 0.4625\n",
      "Iteration 1933: Weights = [5.49999998e+01 3.94337849e+00 8.29101759e+00 2.73188687e-02\n",
      " 2.76044741e-01 1.06811789e+01], Loss = 0.4625\n",
      "Iteration 1934: Weights = [5.49999998e+01 3.94326530e+00 8.29077958e+00 2.73180653e-02\n",
      " 2.76036828e-01 1.06814303e+01], Loss = 0.4624\n",
      "Iteration 1935: Weights = [5.49999998e+01 3.94315211e+00 8.29054159e+00 2.73172620e-02\n",
      " 2.76028915e-01 1.06816818e+01], Loss = 0.4624\n",
      "Iteration 1936: Weights = [5.49999998e+01 3.94303892e+00 8.29030360e+00 2.73164589e-02\n",
      " 2.76021002e-01 1.06819332e+01], Loss = 0.4624\n",
      "Iteration 1937: Weights = [5.49999998e+01 3.94292573e+00 8.29006562e+00 2.73156560e-02\n",
      " 2.76013090e-01 1.06821847e+01], Loss = 0.4624\n",
      "Iteration 1938: Weights = [5.49999998e+01 3.94281255e+00 8.28982765e+00 2.73148533e-02\n",
      " 2.76005178e-01 1.06824361e+01], Loss = 0.4623\n",
      "Iteration 1939: Weights = [5.49999998e+01 3.94269937e+00 8.28958968e+00 2.73140506e-02\n",
      " 2.75997266e-01 1.06826875e+01], Loss = 0.4623\n",
      "Iteration 1940: Weights = [5.49999998e+01 3.94258620e+00 8.28935172e+00 2.73132482e-02\n",
      " 2.75989354e-01 1.06829389e+01], Loss = 0.4623\n",
      "Iteration 1941: Weights = [5.49999998e+01 3.94247303e+00 8.28911376e+00 2.73124459e-02\n",
      " 2.75981442e-01 1.06831903e+01], Loss = 0.4623\n",
      "Iteration 1942: Weights = [5.49999998e+01 3.94235986e+00 8.28887581e+00 2.73116438e-02\n",
      " 2.75973530e-01 1.06834417e+01], Loss = 0.4622\n",
      "Iteration 1943: Weights = [5.49999998e+01 3.94224669e+00 8.28863787e+00 2.73108418e-02\n",
      " 2.75965618e-01 1.06836931e+01], Loss = 0.4622\n",
      "Iteration 1944: Weights = [5.49999998e+01 3.94213353e+00 8.28839994e+00 2.73100400e-02\n",
      " 2.75957707e-01 1.06839445e+01], Loss = 0.4622\n",
      "Iteration 1945: Weights = [5.49999998e+01 3.94202037e+00 8.28816201e+00 2.73092383e-02\n",
      " 2.75949796e-01 1.06841959e+01], Loss = 0.4621\n",
      "Iteration 1946: Weights = [5.49999998e+01 3.94190721e+00 8.28792409e+00 2.73084368e-02\n",
      " 2.75941885e-01 1.06844472e+01], Loss = 0.4621\n",
      "Iteration 1947: Weights = [5.49999998e+01 3.94179406e+00 8.28768618e+00 2.73076354e-02\n",
      " 2.75933974e-01 1.06846986e+01], Loss = 0.4621\n",
      "Iteration 1948: Weights = [5.49999998e+01 3.94168091e+00 8.28744827e+00 2.73068342e-02\n",
      " 2.75926063e-01 1.06849499e+01], Loss = 0.4621\n",
      "Iteration 1949: Weights = [5.49999998e+01 3.94156776e+00 8.28721037e+00 2.73060331e-02\n",
      " 2.75918152e-01 1.06852013e+01], Loss = 0.4620\n",
      "Iteration 1950: Weights = [5.49999998e+01 3.94145462e+00 8.28697248e+00 2.73052322e-02\n",
      " 2.75910242e-01 1.06854526e+01], Loss = 0.4620\n",
      "Iteration 1951: Weights = [5.49999998e+01 3.94134148e+00 8.28673460e+00 2.73044314e-02\n",
      " 2.75902332e-01 1.06857039e+01], Loss = 0.4620\n",
      "Iteration 1952: Weights = [5.49999998e+01 3.94122834e+00 8.28649672e+00 2.73036308e-02\n",
      " 2.75894421e-01 1.06859553e+01], Loss = 0.4620\n",
      "Iteration 1953: Weights = [5.49999998e+01 3.94111521e+00 8.28625884e+00 2.73028303e-02\n",
      " 2.75886511e-01 1.06862066e+01], Loss = 0.4619\n",
      "Iteration 1954: Weights = [5.49999998e+01 3.94100208e+00 8.28602098e+00 2.73020300e-02\n",
      " 2.75878601e-01 1.06864579e+01], Loss = 0.4619\n",
      "Iteration 1955: Weights = [5.49999998e+01 3.94088895e+00 8.28578312e+00 2.73012298e-02\n",
      " 2.75870692e-01 1.06867092e+01], Loss = 0.4619\n",
      "Iteration 1956: Weights = [5.49999998e+01 3.94077583e+00 8.28554527e+00 2.73004297e-02\n",
      " 2.75862782e-01 1.06869605e+01], Loss = 0.4619\n",
      "Iteration 1957: Weights = [5.49999998e+01 3.94066271e+00 8.28530742e+00 2.72996298e-02\n",
      " 2.75854873e-01 1.06872118e+01], Loss = 0.4618\n",
      "Iteration 1958: Weights = [5.49999998e+01 3.94054959e+00 8.28506958e+00 2.72988300e-02\n",
      " 2.75846963e-01 1.06874630e+01], Loss = 0.4618\n",
      "Iteration 1959: Weights = [5.49999998e+01 3.94043648e+00 8.28483175e+00 2.72980304e-02\n",
      " 2.75839054e-01 1.06877143e+01], Loss = 0.4618\n",
      "Iteration 1960: Weights = [5.49999998e+01 3.94032337e+00 8.28459393e+00 2.72972309e-02\n",
      " 2.75831145e-01 1.06879656e+01], Loss = 0.4618\n",
      "Iteration 1961: Weights = [5.49999998e+01 3.94021026e+00 8.28435611e+00 2.72964315e-02\n",
      " 2.75823237e-01 1.06882168e+01], Loss = 0.4617\n",
      "Iteration 1962: Weights = [5.49999998e+01 3.94009715e+00 8.28411830e+00 2.72956323e-02\n",
      " 2.75815328e-01 1.06884681e+01], Loss = 0.4617\n",
      "Iteration 1963: Weights = [5.49999999e+01 3.93998405e+00 8.28388050e+00 2.72948333e-02\n",
      " 2.75807420e-01 1.06887193e+01], Loss = 0.4617\n",
      "Iteration 1964: Weights = [5.49999999e+01 3.93987095e+00 8.28364270e+00 2.72940343e-02\n",
      " 2.75799511e-01 1.06889706e+01], Loss = 0.4616\n",
      "Iteration 1965: Weights = [5.49999999e+01 3.93975786e+00 8.28340491e+00 2.72932355e-02\n",
      " 2.75791603e-01 1.06892218e+01], Loss = 0.4616\n",
      "Iteration 1966: Weights = [5.49999999e+01 3.93964477e+00 8.28316712e+00 2.72924368e-02\n",
      " 2.75783695e-01 1.06894730e+01], Loss = 0.4616\n",
      "Iteration 1967: Weights = [5.49999999e+01 3.93953168e+00 8.28292935e+00 2.72916383e-02\n",
      " 2.75775787e-01 1.06897242e+01], Loss = 0.4616\n",
      "Iteration 1968: Weights = [5.49999999e+01 3.93941859e+00 8.28269158e+00 2.72908399e-02\n",
      " 2.75767880e-01 1.06899754e+01], Loss = 0.4615\n",
      "Iteration 1969: Weights = [5.49999999e+01 3.93930551e+00 8.28245381e+00 2.72900416e-02\n",
      " 2.75759972e-01 1.06902266e+01], Loss = 0.4615\n",
      "Iteration 1970: Weights = [5.49999999e+01 3.93919243e+00 8.28221606e+00 2.72892434e-02\n",
      " 2.75752065e-01 1.06904778e+01], Loss = 0.4615\n",
      "Iteration 1971: Weights = [5.49999999e+01 3.93907936e+00 8.28197831e+00 2.72884454e-02\n",
      " 2.75744158e-01 1.06907290e+01], Loss = 0.4615\n",
      "Iteration 1972: Weights = [5.49999999e+01 3.93896629e+00 8.28174056e+00 2.72876475e-02\n",
      " 2.75736251e-01 1.06909802e+01], Loss = 0.4614\n",
      "Iteration 1973: Weights = [5.49999999e+01 3.93885322e+00 8.28150283e+00 2.72868498e-02\n",
      " 2.75728344e-01 1.06912314e+01], Loss = 0.4614\n",
      "Iteration 1974: Weights = [5.49999999e+01 3.93874015e+00 8.28126510e+00 2.72860521e-02\n",
      " 2.75720437e-01 1.06914825e+01], Loss = 0.4614\n",
      "Iteration 1975: Weights = [5.49999999e+01 3.93862709e+00 8.28102738e+00 2.72852546e-02\n",
      " 2.75712531e-01 1.06917337e+01], Loss = 0.4614\n",
      "Iteration 1976: Weights = [5.49999999e+01 3.93851403e+00 8.28078966e+00 2.72844573e-02\n",
      " 2.75704625e-01 1.06919848e+01], Loss = 0.4613\n",
      "Iteration 1977: Weights = [5.49999999e+01 3.93840097e+00 8.28055195e+00 2.72836600e-02\n",
      " 2.75696718e-01 1.06922360e+01], Loss = 0.4613\n",
      "Iteration 1978: Weights = [5.49999999e+01 3.93828792e+00 8.28031425e+00 2.72828629e-02\n",
      " 2.75688812e-01 1.06924871e+01], Loss = 0.4613\n",
      "Iteration 1979: Weights = [5.49999999e+01 3.93817487e+00 8.28007655e+00 2.72820659e-02\n",
      " 2.75680907e-01 1.06927382e+01], Loss = 0.4612\n",
      "Iteration 1980: Weights = [5.49999999e+01 3.93806182e+00 8.27983886e+00 2.72812690e-02\n",
      " 2.75673001e-01 1.06929894e+01], Loss = 0.4612\n",
      "Iteration 1981: Weights = [5.49999999e+01 3.93794878e+00 8.27960118e+00 2.72804722e-02\n",
      " 2.75665095e-01 1.06932405e+01], Loss = 0.4612\n",
      "Iteration 1982: Weights = [5.49999999e+01 3.93783574e+00 8.27936351e+00 2.72796756e-02\n",
      " 2.75657190e-01 1.06934916e+01], Loss = 0.4612\n",
      "Iteration 1983: Weights = [5.49999999e+01 3.93772270e+00 8.27912584e+00 2.72788791e-02\n",
      " 2.75649285e-01 1.06937427e+01], Loss = 0.4611\n",
      "Iteration 1984: Weights = [5.49999999e+01 3.93760967e+00 8.27888818e+00 2.72780827e-02\n",
      " 2.75641380e-01 1.06939938e+01], Loss = 0.4611\n",
      "Iteration 1985: Weights = [5.49999999e+01 3.93749664e+00 8.27865052e+00 2.72772864e-02\n",
      " 2.75633475e-01 1.06942448e+01], Loss = 0.4611\n",
      "Iteration 1986: Weights = [5.49999999e+01 3.93738361e+00 8.27841288e+00 2.72764903e-02\n",
      " 2.75625570e-01 1.06944959e+01], Loss = 0.4611\n",
      "Iteration 1987: Weights = [5.49999999e+01 3.93727059e+00 8.27817524e+00 2.72756942e-02\n",
      " 2.75617666e-01 1.06947470e+01], Loss = 0.4610\n",
      "Iteration 1988: Weights = [5.49999999e+01 3.93715756e+00 8.27793760e+00 2.72748983e-02\n",
      " 2.75609762e-01 1.06949981e+01], Loss = 0.4610\n",
      "Iteration 1989: Weights = [5.49999999e+01 3.93704455e+00 8.27769997e+00 2.72741025e-02\n",
      " 2.75601858e-01 1.06952491e+01], Loss = 0.4610\n",
      "Iteration 1990: Weights = [5.49999999e+01 3.93693153e+00 8.27746235e+00 2.72733068e-02\n",
      " 2.75593954e-01 1.06955002e+01], Loss = 0.4610\n",
      "Iteration 1991: Weights = [5.49999999e+01 3.93681852e+00 8.27722474e+00 2.72725113e-02\n",
      " 2.75586050e-01 1.06957512e+01], Loss = 0.4609\n",
      "Iteration 1992: Weights = [5.49999999e+01 3.93670551e+00 8.27698713e+00 2.72717158e-02\n",
      " 2.75578146e-01 1.06960022e+01], Loss = 0.4609\n",
      "Iteration 1993: Weights = [5.49999999e+01 3.93659251e+00 8.27674953e+00 2.72709205e-02\n",
      " 2.75570243e-01 1.06962533e+01], Loss = 0.4609\n",
      "Iteration 1994: Weights = [5.49999999e+01 3.93647951e+00 8.27651194e+00 2.72701252e-02\n",
      " 2.75562339e-01 1.06965043e+01], Loss = 0.4609\n",
      "Iteration 1995: Weights = [5.49999999e+01 3.93636651e+00 8.27627435e+00 2.72693301e-02\n",
      " 2.75554436e-01 1.06967553e+01], Loss = 0.4608\n",
      "Iteration 1996: Weights = [5.49999999e+01 3.93625351e+00 8.27603678e+00 2.72685351e-02\n",
      " 2.75546533e-01 1.06970063e+01], Loss = 0.4608\n",
      "Iteration 1997: Weights = [5.49999999e+01 3.93614052e+00 8.27579920e+00 2.72677402e-02\n",
      " 2.75538631e-01 1.06972573e+01], Loss = 0.4608\n",
      "Iteration 1998: Weights = [5.49999999e+01 3.93602753e+00 8.27556164e+00 2.72669454e-02\n",
      " 2.75530728e-01 1.06975083e+01], Loss = 0.4607\n",
      "Iteration 1999: Weights = [5.49999999e+01 3.93591455e+00 8.27532408e+00 2.72661508e-02\n",
      " 2.75522826e-01 1.06977593e+01], Loss = 0.4607\n",
      "Iteration 2000: Weights = [5.49999999e+01 3.93580156e+00 8.27508652e+00 2.72653562e-02\n",
      " 2.75514924e-01 1.06980102e+01], Loss = 0.4607\n",
      "Iteration 2001: Weights = [5.49999999e+01 3.93568859e+00 8.27484898e+00 2.72645617e-02\n",
      " 2.75507021e-01 1.06982612e+01], Loss = 0.4607\n",
      "Iteration 2002: Weights = [5.49999999e+01 3.93557561e+00 8.27461144e+00 2.72637674e-02\n",
      " 2.75499120e-01 1.06985122e+01], Loss = 0.4606\n",
      "Iteration 2003: Weights = [5.49999999e+01 3.93546264e+00 8.27437391e+00 2.72629732e-02\n",
      " 2.75491218e-01 1.06987631e+01], Loss = 0.4606\n",
      "Iteration 2004: Weights = [5.49999999e+01 3.93534967e+00 8.27413638e+00 2.72621790e-02\n",
      " 2.75483316e-01 1.06990141e+01], Loss = 0.4606\n",
      "Iteration 2005: Weights = [5.49999999e+01 3.93523670e+00 8.27389887e+00 2.72613850e-02\n",
      " 2.75475415e-01 1.06992650e+01], Loss = 0.4606\n",
      "Iteration 2006: Weights = [5.49999999e+01 3.93512374e+00 8.27366135e+00 2.72605911e-02\n",
      " 2.75467514e-01 1.06995159e+01], Loss = 0.4605\n",
      "Iteration 2007: Weights = [5.49999999e+01 3.93501078e+00 8.27342385e+00 2.72597973e-02\n",
      " 2.75459613e-01 1.06997669e+01], Loss = 0.4605\n",
      "Iteration 2008: Weights = [5.49999999e+01 3.93489782e+00 8.27318635e+00 2.72590036e-02\n",
      " 2.75451712e-01 1.07000178e+01], Loss = 0.4605\n",
      "Iteration 2009: Weights = [5.49999999e+01 3.93478487e+00 8.27294886e+00 2.72582100e-02\n",
      " 2.75443811e-01 1.07002687e+01], Loss = 0.4605\n",
      "Iteration 2010: Weights = [5.49999999e+01 3.93467192e+00 8.27271138e+00 2.72574165e-02\n",
      " 2.75435911e-01 1.07005196e+01], Loss = 0.4604\n",
      "Iteration 2011: Weights = [5.49999999e+01 3.93455897e+00 8.27247390e+00 2.72566231e-02\n",
      " 2.75428011e-01 1.07007705e+01], Loss = 0.4604\n",
      "Iteration 2012: Weights = [5.49999999e+01 3.93444603e+00 8.27223643e+00 2.72558298e-02\n",
      " 2.75420111e-01 1.07010214e+01], Loss = 0.4604\n",
      "Iteration 2013: Weights = [5.49999999e+01 3.93433309e+00 8.27199896e+00 2.72550366e-02\n",
      " 2.75412211e-01 1.07012723e+01], Loss = 0.4603\n",
      "Iteration 2014: Weights = [5.49999999e+01 3.93422015e+00 8.27176151e+00 2.72542435e-02\n",
      " 2.75404311e-01 1.07015231e+01], Loss = 0.4603\n",
      "Iteration 2015: Weights = [5.49999999e+01 3.93410722e+00 8.27152406e+00 2.72534505e-02\n",
      " 2.75396411e-01 1.07017740e+01], Loss = 0.4603\n",
      "Iteration 2016: Weights = [5.49999999e+01 3.93399429e+00 8.27128661e+00 2.72526576e-02\n",
      " 2.75388512e-01 1.07020249e+01], Loss = 0.4603\n",
      "Iteration 2017: Weights = [5.49999999e+01 3.93388136e+00 8.27104918e+00 2.72518648e-02\n",
      " 2.75380613e-01 1.07022757e+01], Loss = 0.4602\n",
      "Iteration 2018: Weights = [5.49999999e+01 3.93376843e+00 8.27081175e+00 2.72510721e-02\n",
      " 2.75372714e-01 1.07025266e+01], Loss = 0.4602\n",
      "Iteration 2019: Weights = [5.49999999e+01 3.93365551e+00 8.27057432e+00 2.72502795e-02\n",
      " 2.75364815e-01 1.07027774e+01], Loss = 0.4602\n",
      "Iteration 2020: Weights = [5.49999999e+01 3.93354260e+00 8.27033691e+00 2.72494870e-02\n",
      " 2.75356916e-01 1.07030282e+01], Loss = 0.4602\n",
      "Iteration 2021: Weights = [5.49999999e+01 3.93342968e+00 8.27009950e+00 2.72486946e-02\n",
      " 2.75349018e-01 1.07032791e+01], Loss = 0.4601\n",
      "Iteration 2022: Weights = [5.49999999e+01 3.93331677e+00 8.26986210e+00 2.72479023e-02\n",
      " 2.75341120e-01 1.07035299e+01], Loss = 0.4601\n",
      "Iteration 2023: Weights = [5.49999999e+01 3.93320386e+00 8.26962470e+00 2.72471101e-02\n",
      " 2.75333222e-01 1.07037807e+01], Loss = 0.4601\n",
      "Iteration 2024: Weights = [5.49999999e+01 3.93309096e+00 8.26938731e+00 2.72463180e-02\n",
      " 2.75325324e-01 1.07040315e+01], Loss = 0.4601\n",
      "Iteration 2025: Weights = [5.49999999e+01 3.93297805e+00 8.26914993e+00 2.72455260e-02\n",
      " 2.75317426e-01 1.07042823e+01], Loss = 0.4600\n",
      "Iteration 2026: Weights = [5.49999999e+01 3.93286516e+00 8.26891255e+00 2.72447341e-02\n",
      " 2.75309528e-01 1.07045331e+01], Loss = 0.4600\n",
      "Iteration 2027: Weights = [5.49999999e+01 3.93275226e+00 8.26867518e+00 2.72439423e-02\n",
      " 2.75301631e-01 1.07047838e+01], Loss = 0.4600\n",
      "Iteration 2028: Weights = [5.49999999e+01 3.93263937e+00 8.26843782e+00 2.72431505e-02\n",
      " 2.75293734e-01 1.07050346e+01], Loss = 0.4600\n",
      "Iteration 2029: Weights = [5.49999999e+01 3.93252648e+00 8.26820047e+00 2.72423589e-02\n",
      " 2.75285837e-01 1.07052854e+01], Loss = 0.4599\n",
      "Iteration 2030: Weights = [5.49999999e+01 3.93241359e+00 8.26796312e+00 2.72415673e-02\n",
      " 2.75277940e-01 1.07055361e+01], Loss = 0.4599\n",
      "Iteration 2031: Weights = [5.49999999e+01 3.93230071e+00 8.26772578e+00 2.72407759e-02\n",
      " 2.75270044e-01 1.07057869e+01], Loss = 0.4599\n",
      "Iteration 2032: Weights = [5.49999999e+01 3.93218783e+00 8.26748844e+00 2.72399845e-02\n",
      " 2.75262147e-01 1.07060376e+01], Loss = 0.4598\n",
      "Iteration 2033: Weights = [5.49999999e+01 3.93207496e+00 8.26725112e+00 2.72391932e-02\n",
      " 2.75254251e-01 1.07062884e+01], Loss = 0.4598\n",
      "Iteration 2034: Weights = [5.49999999e+01 3.93196208e+00 8.26701380e+00 2.72384020e-02\n",
      " 2.75246355e-01 1.07065391e+01], Loss = 0.4598\n",
      "Iteration 2035: Weights = [5.49999999e+01 3.93184921e+00 8.26677648e+00 2.72376110e-02\n",
      " 2.75238459e-01 1.07067898e+01], Loss = 0.4598\n",
      "Iteration 2036: Weights = [5.49999999e+01 3.93173635e+00 8.26653917e+00 2.72368199e-02\n",
      " 2.75230563e-01 1.07070405e+01], Loss = 0.4597\n",
      "Iteration 2037: Weights = [5.49999999e+01 3.93162348e+00 8.26630187e+00 2.72360290e-02\n",
      " 2.75222668e-01 1.07072912e+01], Loss = 0.4597\n",
      "Iteration 2038: Weights = [5.49999999e+01 3.93151062e+00 8.26606458e+00 2.72352382e-02\n",
      " 2.75214773e-01 1.07075419e+01], Loss = 0.4597\n",
      "Iteration 2039: Weights = [5.49999999e+01 3.93139777e+00 8.26582729e+00 2.72344475e-02\n",
      " 2.75206877e-01 1.07077926e+01], Loss = 0.4597\n",
      "Iteration 2040: Weights = [5.49999999e+01 3.93128491e+00 8.26559001e+00 2.72336568e-02\n",
      " 2.75198982e-01 1.07080433e+01], Loss = 0.4596\n",
      "Iteration 2041: Weights = [5.49999999e+01 3.93117206e+00 8.26535274e+00 2.72328662e-02\n",
      " 2.75191088e-01 1.07082940e+01], Loss = 0.4596\n",
      "Iteration 2042: Weights = [5.49999999e+01 3.93105922e+00 8.26511547e+00 2.72320758e-02\n",
      " 2.75183193e-01 1.07085447e+01], Loss = 0.4596\n",
      "Iteration 2043: Weights = [5.49999999e+01 3.93094637e+00 8.26487821e+00 2.72312854e-02\n",
      " 2.75175299e-01 1.07087953e+01], Loss = 0.4596\n",
      "Iteration 2044: Weights = [5.49999999e+01 3.93083353e+00 8.26464096e+00 2.72304951e-02\n",
      " 2.75167405e-01 1.07090460e+01], Loss = 0.4595\n",
      "Iteration 2045: Weights = [5.49999999e+01 3.93072069e+00 8.26440371e+00 2.72297049e-02\n",
      " 2.75159511e-01 1.07092967e+01], Loss = 0.4595\n",
      "Iteration 2046: Weights = [5.49999999e+01 3.93060786e+00 8.26416647e+00 2.72289147e-02\n",
      " 2.75151617e-01 1.07095473e+01], Loss = 0.4595\n",
      "Iteration 2047: Weights = [5.49999999e+01 3.93049503e+00 8.26392924e+00 2.72281247e-02\n",
      " 2.75143723e-01 1.07097979e+01], Loss = 0.4595\n",
      "Iteration 2048: Weights = [5.49999999e+01 3.93038220e+00 8.26369202e+00 2.72273347e-02\n",
      " 2.75135830e-01 1.07100486e+01], Loss = 0.4594\n",
      "Iteration 2049: Weights = [5.49999999e+01 3.93026938e+00 8.26345480e+00 2.72265448e-02\n",
      " 2.75127937e-01 1.07102992e+01], Loss = 0.4594\n",
      "Iteration 2050: Weights = [5.49999999e+01 3.93015656e+00 8.26321759e+00 2.72257550e-02\n",
      " 2.75120044e-01 1.07105498e+01], Loss = 0.4594\n",
      "Iteration 2051: Weights = [5.49999999e+01 3.93004374e+00 8.26298038e+00 2.72249653e-02\n",
      " 2.75112151e-01 1.07108004e+01], Loss = 0.4593\n",
      "Iteration 2052: Weights = [5.49999999e+01 3.92993092e+00 8.26274318e+00 2.72241756e-02\n",
      " 2.75104258e-01 1.07110510e+01], Loss = 0.4593\n",
      "Iteration 2053: Weights = [5.49999999e+01 3.92981811e+00 8.26250599e+00 2.72233861e-02\n",
      " 2.75096366e-01 1.07113016e+01], Loss = 0.4593\n",
      "Iteration 2054: Weights = [5.49999999e+01 3.92970530e+00 8.26226880e+00 2.72225966e-02\n",
      " 2.75088473e-01 1.07115522e+01], Loss = 0.4593\n",
      "Iteration 2055: Weights = [5.49999999e+01 3.92959250e+00 8.26203163e+00 2.72218072e-02\n",
      " 2.75080581e-01 1.07118028e+01], Loss = 0.4592\n",
      "Iteration 2056: Weights = [5.49999999e+01 3.92947970e+00 8.26179446e+00 2.72210179e-02\n",
      " 2.75072689e-01 1.07120533e+01], Loss = 0.4592\n",
      "Iteration 2057: Weights = [5.49999999e+01 3.92936690e+00 8.26155729e+00 2.72202287e-02\n",
      " 2.75064798e-01 1.07123039e+01], Loss = 0.4592\n",
      "Iteration 2058: Weights = [5.49999999e+01 3.92925410e+00 8.26132013e+00 2.72194395e-02\n",
      " 2.75056906e-01 1.07125544e+01], Loss = 0.4592\n",
      "Iteration 2059: Weights = [5.49999999e+01 3.92914131e+00 8.26108298e+00 2.72186504e-02\n",
      " 2.75049015e-01 1.07128050e+01], Loss = 0.4591\n",
      "Iteration 2060: Weights = [5.49999999e+01 3.92902852e+00 8.26084584e+00 2.72178614e-02\n",
      " 2.75041124e-01 1.07130555e+01], Loss = 0.4591\n",
      "Iteration 2061: Weights = [5.49999999e+01 3.92891574e+00 8.26060870e+00 2.72170725e-02\n",
      " 2.75033233e-01 1.07133061e+01], Loss = 0.4591\n",
      "Iteration 2062: Weights = [5.49999999e+01 3.92880295e+00 8.26037157e+00 2.72162837e-02\n",
      " 2.75025342e-01 1.07135566e+01], Loss = 0.4591\n",
      "Iteration 2063: Weights = [5.49999999e+01 3.92869017e+00 8.26013445e+00 2.72154949e-02\n",
      " 2.75017452e-01 1.07138071e+01], Loss = 0.4590\n",
      "Iteration 2064: Weights = [5.49999999e+01 3.92857740e+00 8.25989733e+00 2.72147062e-02\n",
      " 2.75009561e-01 1.07140576e+01], Loss = 0.4590\n",
      "Iteration 2065: Weights = [5.49999999e+01 3.92846462e+00 8.25966022e+00 2.72139176e-02\n",
      " 2.75001671e-01 1.07143081e+01], Loss = 0.4590\n",
      "Iteration 2066: Weights = [5.49999999e+01 3.92835185e+00 8.25942312e+00 2.72131291e-02\n",
      " 2.74993781e-01 1.07145586e+01], Loss = 0.4589\n",
      "Iteration 2067: Weights = [5.49999999e+01 3.92823909e+00 8.25918602e+00 2.72123406e-02\n",
      " 2.74985892e-01 1.07148091e+01], Loss = 0.4589\n",
      "Iteration 2068: Weights = [5.49999999e+01 3.92812632e+00 8.25894893e+00 2.72115523e-02\n",
      " 2.74978002e-01 1.07150596e+01], Loss = 0.4589\n",
      "Iteration 2069: Weights = [5.49999999e+01 3.92801356e+00 8.25871185e+00 2.72107639e-02\n",
      " 2.74970113e-01 1.07153101e+01], Loss = 0.4589\n",
      "Iteration 2070: Weights = [5.49999999e+01 3.92790081e+00 8.25847477e+00 2.72099757e-02\n",
      " 2.74962224e-01 1.07155606e+01], Loss = 0.4588\n",
      "Iteration 2071: Weights = [5.49999999e+01 3.92778805e+00 8.25823770e+00 2.72091876e-02\n",
      " 2.74954335e-01 1.07158110e+01], Loss = 0.4588\n",
      "Iteration 2072: Weights = [5.50000000e+01 3.92767530e+00 8.25800064e+00 2.72083995e-02\n",
      " 2.74946446e-01 1.07160615e+01], Loss = 0.4588\n",
      "Iteration 2073: Weights = [5.50000000e+01 3.92756256e+00 8.25776358e+00 2.72076115e-02\n",
      " 2.74938557e-01 1.07163119e+01], Loss = 0.4588\n",
      "Iteration 2074: Weights = [5.50000000e+01 3.92744981e+00 8.25752653e+00 2.72068235e-02\n",
      " 2.74930669e-01 1.07165624e+01], Loss = 0.4587\n",
      "Iteration 2075: Weights = [5.50000000e+01 3.92733707e+00 8.25728949e+00 2.72060357e-02\n",
      " 2.74922781e-01 1.07168128e+01], Loss = 0.4587\n",
      "Iteration 2076: Weights = [5.50000000e+01 3.92722433e+00 8.25705246e+00 2.72052479e-02\n",
      " 2.74914893e-01 1.07170632e+01], Loss = 0.4587\n",
      "Iteration 2077: Weights = [5.50000000e+01 3.92711160e+00 8.25681543e+00 2.72044602e-02\n",
      " 2.74907005e-01 1.07173137e+01], Loss = 0.4587\n",
      "Iteration 2078: Weights = [5.50000000e+01 3.92699887e+00 8.25657841e+00 2.72036725e-02\n",
      " 2.74899117e-01 1.07175641e+01], Loss = 0.4586\n",
      "Iteration 2079: Weights = [5.50000000e+01 3.92688614e+00 8.25634139e+00 2.72028849e-02\n",
      " 2.74891230e-01 1.07178145e+01], Loss = 0.4586\n",
      "Iteration 2080: Weights = [5.50000000e+01 3.92677342e+00 8.25610438e+00 2.72020974e-02\n",
      " 2.74883343e-01 1.07180649e+01], Loss = 0.4586\n",
      "Iteration 2081: Weights = [5.50000000e+01 3.92666070e+00 8.25586738e+00 2.72013100e-02\n",
      " 2.74875456e-01 1.07183153e+01], Loss = 0.4586\n",
      "Iteration 2082: Weights = [5.50000000e+01 3.92654798e+00 8.25563039e+00 2.72005226e-02\n",
      " 2.74867569e-01 1.07185656e+01], Loss = 0.4585\n",
      "Iteration 2083: Weights = [5.50000000e+01 3.92643526e+00 8.25539340e+00 2.71997353e-02\n",
      " 2.74859682e-01 1.07188160e+01], Loss = 0.4585\n",
      "Iteration 2084: Weights = [5.50000000e+01 3.92632255e+00 8.25515642e+00 2.71989481e-02\n",
      " 2.74851796e-01 1.07190664e+01], Loss = 0.4585\n",
      "Iteration 2085: Weights = [5.50000000e+01 3.92620984e+00 8.25491944e+00 2.71981609e-02\n",
      " 2.74843910e-01 1.07193168e+01], Loss = 0.4584\n",
      "Iteration 2086: Weights = [5.50000000e+01 3.92609714e+00 8.25468248e+00 2.71973739e-02\n",
      " 2.74836024e-01 1.07195671e+01], Loss = 0.4584\n",
      "Iteration 2087: Weights = [5.50000000e+01 3.92598444e+00 8.25444552e+00 2.71965868e-02\n",
      " 2.74828138e-01 1.07198175e+01], Loss = 0.4584\n",
      "Iteration 2088: Weights = [5.50000000e+01 3.92587174e+00 8.25420856e+00 2.71957999e-02\n",
      " 2.74820252e-01 1.07200678e+01], Loss = 0.4584\n",
      "Iteration 2089: Weights = [5.50000000e+01 3.92575904e+00 8.25397162e+00 2.71950130e-02\n",
      " 2.74812367e-01 1.07203181e+01], Loss = 0.4583\n",
      "Iteration 2090: Weights = [5.50000000e+01 3.92564635e+00 8.25373468e+00 2.71942262e-02\n",
      " 2.74804482e-01 1.07205685e+01], Loss = 0.4583\n",
      "Iteration 2091: Weights = [5.50000000e+01 3.92553366e+00 8.25349774e+00 2.71934394e-02\n",
      " 2.74796597e-01 1.07208188e+01], Loss = 0.4583\n",
      "Iteration 2092: Weights = [5.50000000e+01 3.92542097e+00 8.25326082e+00 2.71926528e-02\n",
      " 2.74788712e-01 1.07210691e+01], Loss = 0.4583\n",
      "Iteration 2093: Weights = [5.50000000e+01 3.92530829e+00 8.25302390e+00 2.71918662e-02\n",
      " 2.74780827e-01 1.07213194e+01], Loss = 0.4582\n",
      "Iteration 2094: Weights = [5.50000000e+01 3.92519561e+00 8.25278698e+00 2.71910796e-02\n",
      " 2.74772943e-01 1.07215697e+01], Loss = 0.4582\n",
      "Iteration 2095: Weights = [5.50000000e+01 3.92508294e+00 8.25255008e+00 2.71902931e-02\n",
      " 2.74765059e-01 1.07218200e+01], Loss = 0.4582\n",
      "Iteration 2096: Weights = [5.50000000e+01 3.92497026e+00 8.25231318e+00 2.71895067e-02\n",
      " 2.74757175e-01 1.07220703e+01], Loss = 0.4582\n",
      "Iteration 2097: Weights = [5.50000000e+01 3.92485759e+00 8.25207628e+00 2.71887204e-02\n",
      " 2.74749291e-01 1.07223205e+01], Loss = 0.4581\n",
      "Iteration 2098: Weights = [5.50000000e+01 3.92474493e+00 8.25183940e+00 2.71879341e-02\n",
      " 2.74741407e-01 1.07225708e+01], Loss = 0.4581\n",
      "Iteration 2099: Weights = [5.50000000e+01 3.92463226e+00 8.25160252e+00 2.71871478e-02\n",
      " 2.74733524e-01 1.07228211e+01], Loss = 0.4581\n",
      "Iteration 2100: Weights = [5.50000000e+01 3.92451960e+00 8.25136565e+00 2.71863617e-02\n",
      " 2.74725641e-01 1.07230713e+01], Loss = 0.4581\n",
      "Iteration 2101: Weights = [5.50000000e+01 3.92440695e+00 8.25112878e+00 2.71855756e-02\n",
      " 2.74717758e-01 1.07233216e+01], Loss = 0.4580\n",
      "Iteration 2102: Weights = [5.50000000e+01 3.92429429e+00 8.25089192e+00 2.71847896e-02\n",
      " 2.74709875e-01 1.07235718e+01], Loss = 0.4580\n",
      "Iteration 2103: Weights = [5.50000000e+01 3.92418164e+00 8.25065507e+00 2.71840036e-02\n",
      " 2.74701992e-01 1.07238220e+01], Loss = 0.4580\n",
      "Iteration 2104: Weights = [5.50000000e+01 3.92406899e+00 8.25041823e+00 2.71832177e-02\n",
      " 2.74694110e-01 1.07240723e+01], Loss = 0.4579\n",
      "Iteration 2105: Weights = [5.50000000e+01 3.92395635e+00 8.25018139e+00 2.71824319e-02\n",
      " 2.74686228e-01 1.07243225e+01], Loss = 0.4579\n",
      "Iteration 2106: Weights = [5.50000000e+01 3.92384371e+00 8.24994456e+00 2.71816461e-02\n",
      " 2.74678346e-01 1.07245727e+01], Loss = 0.4579\n",
      "Iteration 2107: Weights = [5.50000000e+01 3.92373107e+00 8.24970773e+00 2.71808604e-02\n",
      " 2.74670464e-01 1.07248229e+01], Loss = 0.4579\n",
      "Iteration 2108: Weights = [5.50000000e+01 3.92361844e+00 8.24947091e+00 2.71800747e-02\n",
      " 2.74662582e-01 1.07250731e+01], Loss = 0.4578\n",
      "Iteration 2109: Weights = [5.50000000e+01 3.92350581e+00 8.24923410e+00 2.71792891e-02\n",
      " 2.74654701e-01 1.07253233e+01], Loss = 0.4578\n",
      "Iteration 2110: Weights = [5.50000000e+01 3.92339318e+00 8.24899730e+00 2.71785036e-02\n",
      " 2.74646820e-01 1.07255735e+01], Loss = 0.4578\n",
      "Iteration 2111: Weights = [5.50000000e+01 3.92328055e+00 8.24876050e+00 2.71777181e-02\n",
      " 2.74638939e-01 1.07258236e+01], Loss = 0.4578\n",
      "Iteration 2112: Weights = [5.50000000e+01 3.92316793e+00 8.24852371e+00 2.71769327e-02\n",
      " 2.74631058e-01 1.07260738e+01], Loss = 0.4577\n",
      "Iteration 2113: Weights = [5.50000000e+01 3.92305531e+00 8.24828693e+00 2.71761474e-02\n",
      " 2.74623178e-01 1.07263240e+01], Loss = 0.4577\n",
      "Iteration 2114: Weights = [5.50000000e+01 3.92294270e+00 8.24805015e+00 2.71753621e-02\n",
      " 2.74615297e-01 1.07265741e+01], Loss = 0.4577\n",
      "Iteration 2115: Weights = [5.50000000e+01 3.92283009e+00 8.24781338e+00 2.71745769e-02\n",
      " 2.74607417e-01 1.07268243e+01], Loss = 0.4577\n",
      "Iteration 2116: Weights = [5.50000000e+01 3.92271748e+00 8.24757662e+00 2.71737917e-02\n",
      " 2.74599537e-01 1.07270744e+01], Loss = 0.4576\n",
      "Iteration 2117: Weights = [5.50000000e+01 3.92260487e+00 8.24733986e+00 2.71730066e-02\n",
      " 2.74591657e-01 1.07273245e+01], Loss = 0.4576\n",
      "Iteration 2118: Weights = [5.50000000e+01 3.92249227e+00 8.24710311e+00 2.71722215e-02\n",
      " 2.74583778e-01 1.07275747e+01], Loss = 0.4576\n",
      "Iteration 2119: Weights = [5.50000000e+01 3.92237967e+00 8.24686637e+00 2.71714366e-02\n",
      " 2.74575899e-01 1.07278248e+01], Loss = 0.4576\n",
      "Iteration 2120: Weights = [5.50000000e+01 3.92226708e+00 8.24662963e+00 2.71706516e-02\n",
      " 2.74568019e-01 1.07280749e+01], Loss = 0.4575\n",
      "Iteration 2121: Weights = [5.50000000e+01 3.92215448e+00 8.24639290e+00 2.71698668e-02\n",
      " 2.74560141e-01 1.07283250e+01], Loss = 0.4575\n",
      "Iteration 2122: Weights = [5.50000000e+01 3.92204190e+00 8.24615618e+00 2.71690819e-02\n",
      " 2.74552262e-01 1.07285751e+01], Loss = 0.4575\n",
      "Iteration 2123: Weights = [5.50000000e+01 3.92192931e+00 8.24591946e+00 2.71682972e-02\n",
      " 2.74544383e-01 1.07288252e+01], Loss = 0.4575\n",
      "Iteration 2124: Weights = [5.50000000e+01 3.92181673e+00 8.24568275e+00 2.71675125e-02\n",
      " 2.74536505e-01 1.07290753e+01], Loss = 0.4574\n",
      "Iteration 2125: Weights = [5.50000000e+01 3.92170415e+00 8.24544605e+00 2.71667279e-02\n",
      " 2.74528627e-01 1.07293253e+01], Loss = 0.4574\n",
      "Iteration 2126: Weights = [5.50000000e+01 3.92159157e+00 8.24520935e+00 2.71659433e-02\n",
      " 2.74520749e-01 1.07295754e+01], Loss = 0.4574\n",
      "Iteration 2127: Weights = [5.50000000e+01 3.92147900e+00 8.24497266e+00 2.71651587e-02\n",
      " 2.74512871e-01 1.07298255e+01], Loss = 0.4573\n",
      "Iteration 2128: Weights = [5.50000000e+01 3.92136643e+00 8.24473598e+00 2.71643743e-02\n",
      " 2.74504994e-01 1.07300755e+01], Loss = 0.4573\n",
      "Iteration 2129: Weights = [5.50000000e+01 3.92125386e+00 8.24449931e+00 2.71635899e-02\n",
      " 2.74497117e-01 1.07303256e+01], Loss = 0.4573\n",
      "Iteration 2130: Weights = [5.50000000e+01 3.92114130e+00 8.24426264e+00 2.71628055e-02\n",
      " 2.74489239e-01 1.07305756e+01], Loss = 0.4573\n",
      "Iteration 2131: Weights = [5.50000000e+01 3.92102874e+00 8.24402598e+00 2.71620212e-02\n",
      " 2.74481363e-01 1.07308256e+01], Loss = 0.4572\n",
      "Iteration 2132: Weights = [5.50000000e+01 3.92091618e+00 8.24378932e+00 2.71612370e-02\n",
      " 2.74473486e-01 1.07310757e+01], Loss = 0.4572\n",
      "Iteration 2133: Weights = [5.50000000e+01 3.92080363e+00 8.24355267e+00 2.71604528e-02\n",
      " 2.74465609e-01 1.07313257e+01], Loss = 0.4572\n",
      "Iteration 2134: Weights = [5.50000000e+01 3.92069108e+00 8.24331603e+00 2.71596686e-02\n",
      " 2.74457733e-01 1.07315757e+01], Loss = 0.4572\n",
      "Iteration 2135: Weights = [5.50000000e+01 3.92057853e+00 8.24307940e+00 2.71588845e-02\n",
      " 2.74449857e-01 1.07318257e+01], Loss = 0.4571\n",
      "Iteration 2136: Weights = [5.50000000e+01 3.92046598e+00 8.24284277e+00 2.71581005e-02\n",
      " 2.74441981e-01 1.07320757e+01], Loss = 0.4571\n",
      "Iteration 2137: Weights = [5.50000000e+01 3.92035344e+00 8.24260615e+00 2.71573166e-02\n",
      " 2.74434106e-01 1.07323257e+01], Loss = 0.4571\n",
      "Iteration 2138: Weights = [5.50000000e+01 3.92024091e+00 8.24236954e+00 2.71565326e-02\n",
      " 2.74426230e-01 1.07325757e+01], Loss = 0.4571\n",
      "Iteration 2139: Weights = [5.50000000e+01 3.92012837e+00 8.24213293e+00 2.71557488e-02\n",
      " 2.74418355e-01 1.07328256e+01], Loss = 0.4570\n",
      "Iteration 2140: Weights = [5.50000000e+01 3.92001584e+00 8.24189633e+00 2.71549650e-02\n",
      " 2.74410480e-01 1.07330756e+01], Loss = 0.4570\n",
      "Iteration 2141: Weights = [5.50000000e+01 3.91990331e+00 8.24165973e+00 2.71541812e-02\n",
      " 2.74402605e-01 1.07333256e+01], Loss = 0.4570\n",
      "Iteration 2142: Weights = [5.50000000e+01 3.91979079e+00 8.24142315e+00 2.71533975e-02\n",
      " 2.74394731e-01 1.07335755e+01], Loss = 0.4570\n",
      "Iteration 2143: Weights = [5.50000000e+01 3.91967827e+00 8.24118657e+00 2.71526139e-02\n",
      " 2.74386856e-01 1.07338254e+01], Loss = 0.4569\n",
      "Iteration 2144: Weights = [5.50000000e+01 3.91956575e+00 8.24094999e+00 2.71518303e-02\n",
      " 2.74378982e-01 1.07340754e+01], Loss = 0.4569\n",
      "Iteration 2145: Weights = [5.50000000e+01 3.91945323e+00 8.24071343e+00 2.71510467e-02\n",
      " 2.74371108e-01 1.07343253e+01], Loss = 0.4569\n",
      "Iteration 2146: Weights = [5.50000000e+01 3.91934072e+00 8.24047687e+00 2.71502632e-02\n",
      " 2.74363234e-01 1.07345752e+01], Loss = 0.4568\n",
      "Iteration 2147: Weights = [5.50000000e+01 3.91922821e+00 8.24024031e+00 2.71494798e-02\n",
      " 2.74355361e-01 1.07348252e+01], Loss = 0.4568\n",
      "Iteration 2148: Weights = [5.50000000e+01 3.91911571e+00 8.24000377e+00 2.71486964e-02\n",
      " 2.74347488e-01 1.07350751e+01], Loss = 0.4568\n",
      "Iteration 2149: Weights = [5.50000000e+01 3.91900320e+00 8.23976723e+00 2.71479131e-02\n",
      " 2.74339614e-01 1.07353250e+01], Loss = 0.4568\n",
      "Iteration 2150: Weights = [5.50000000e+01 3.91889071e+00 8.23953069e+00 2.71471298e-02\n",
      " 2.74331741e-01 1.07355749e+01], Loss = 0.4567\n",
      "Iteration 2151: Weights = [5.50000000e+01 3.91877821e+00 8.23929417e+00 2.71463465e-02\n",
      " 2.74323869e-01 1.07358248e+01], Loss = 0.4567\n",
      "Iteration 2152: Weights = [5.50000000e+01 3.91866572e+00 8.23905765e+00 2.71455634e-02\n",
      " 2.74315996e-01 1.07360746e+01], Loss = 0.4567\n",
      "Iteration 2153: Weights = [5.50000000e+01 3.91855323e+00 8.23882114e+00 2.71447802e-02\n",
      " 2.74308124e-01 1.07363245e+01], Loss = 0.4567\n",
      "Iteration 2154: Weights = [5.50000000e+01 3.91844074e+00 8.23858463e+00 2.71439972e-02\n",
      " 2.74300252e-01 1.07365744e+01], Loss = 0.4566\n",
      "Iteration 2155: Weights = [5.50000000e+01 3.91832826e+00 8.23834813e+00 2.71432141e-02\n",
      " 2.74292380e-01 1.07368242e+01], Loss = 0.4566\n",
      "Iteration 2156: Weights = [5.50000000e+01 3.91821578e+00 8.23811164e+00 2.71424311e-02\n",
      " 2.74284508e-01 1.07370741e+01], Loss = 0.4566\n",
      "Iteration 2157: Weights = [5.50000000e+01 3.91810330e+00 8.23787515e+00 2.71416482e-02\n",
      " 2.74276637e-01 1.07373239e+01], Loss = 0.4566\n",
      "Iteration 2158: Weights = [5.50000000e+01 3.91799083e+00 8.23763868e+00 2.71408653e-02\n",
      " 2.74268766e-01 1.07375738e+01], Loss = 0.4565\n",
      "Iteration 2159: Weights = [5.50000000e+01 3.91787836e+00 8.23740220e+00 2.71400825e-02\n",
      " 2.74260895e-01 1.07378236e+01], Loss = 0.4565\n",
      "Iteration 2160: Weights = [5.50000000e+01 3.91776589e+00 8.23716574e+00 2.71392997e-02\n",
      " 2.74253024e-01 1.07380734e+01], Loss = 0.4565\n",
      "Iteration 2161: Weights = [5.50000000e+01 3.91765343e+00 8.23692928e+00 2.71385170e-02\n",
      " 2.74245153e-01 1.07383232e+01], Loss = 0.4565\n",
      "Iteration 2162: Weights = [5.50000000e+01 3.91754097e+00 8.23669283e+00 2.71377343e-02\n",
      " 2.74237283e-01 1.07385730e+01], Loss = 0.4564\n",
      "Iteration 2163: Weights = [5.50000000e+01 3.91742851e+00 8.23645639e+00 2.71369517e-02\n",
      " 2.74229413e-01 1.07388228e+01], Loss = 0.4564\n",
      "Iteration 2164: Weights = [5.50000000e+01 3.91731606e+00 8.23621995e+00 2.71361691e-02\n",
      " 2.74221543e-01 1.07390726e+01], Loss = 0.4564\n",
      "Iteration 2165: Weights = [5.50000000e+01 3.91720361e+00 8.23598352e+00 2.71353866e-02\n",
      " 2.74213673e-01 1.07393224e+01], Loss = 0.4563\n",
      "Iteration 2166: Weights = [5.50000000e+01 3.91709116e+00 8.23574709e+00 2.71346041e-02\n",
      " 2.74205803e-01 1.07395722e+01], Loss = 0.4563\n",
      "Iteration 2167: Weights = [5.50000000e+01 3.91697871e+00 8.23551068e+00 2.71338216e-02\n",
      " 2.74197934e-01 1.07398220e+01], Loss = 0.4563\n",
      "Iteration 2168: Weights = [5.50000000e+01 3.91686627e+00 8.23527427e+00 2.71330392e-02\n",
      " 2.74190065e-01 1.07400717e+01], Loss = 0.4563\n",
      "Iteration 2169: Weights = [5.50000000e+01 3.91675384e+00 8.23503786e+00 2.71322569e-02\n",
      " 2.74182196e-01 1.07403215e+01], Loss = 0.4562\n",
      "Iteration 2170: Weights = [5.50000000e+01 3.91664140e+00 8.23480146e+00 2.71314746e-02\n",
      " 2.74174327e-01 1.07405713e+01], Loss = 0.4562\n",
      "Iteration 2171: Weights = [5.50000000e+01 3.91652897e+00 8.23456507e+00 2.71306924e-02\n",
      " 2.74166459e-01 1.07408210e+01], Loss = 0.4562\n",
      "Iteration 2172: Weights = [5.50000000e+01 3.91641654e+00 8.23432869e+00 2.71299102e-02\n",
      " 2.74158590e-01 1.07410707e+01], Loss = 0.4562\n",
      "Iteration 2173: Weights = [5.50000000e+01 3.91630412e+00 8.23409231e+00 2.71291280e-02\n",
      " 2.74150722e-01 1.07413205e+01], Loss = 0.4561\n",
      "Iteration 2174: Weights = [5.50000000e+01 3.91619170e+00 8.23385594e+00 2.71283459e-02\n",
      " 2.74142854e-01 1.07415702e+01], Loss = 0.4561\n",
      "Iteration 2175: Weights = [5.50000000e+01 3.91607928e+00 8.23361958e+00 2.71275638e-02\n",
      " 2.74134987e-01 1.07418199e+01], Loss = 0.4561\n",
      "Iteration 2176: Weights = [5.50000000e+01 3.91596686e+00 8.23338322e+00 2.71267818e-02\n",
      " 2.74127119e-01 1.07420696e+01], Loss = 0.4561\n",
      "Iteration 2177: Weights = [5.50000000e+01 3.91585445e+00 8.23314687e+00 2.71259998e-02\n",
      " 2.74119252e-01 1.07423193e+01], Loss = 0.4560\n",
      "Iteration 2178: Weights = [5.50000000e+01 3.91574204e+00 8.23291053e+00 2.71252179e-02\n",
      " 2.74111385e-01 1.07425690e+01], Loss = 0.4560\n",
      "Iteration 2179: Weights = [5.50000000e+01 3.91562963e+00 8.23267420e+00 2.71244360e-02\n",
      " 2.74103518e-01 1.07428187e+01], Loss = 0.4560\n",
      "Iteration 2180: Weights = [5.50000000e+01 3.91551723e+00 8.23243787e+00 2.71236542e-02\n",
      " 2.74095651e-01 1.07430684e+01], Loss = 0.4560\n",
      "Iteration 2181: Weights = [5.50000000e+01 3.91540483e+00 8.23220154e+00 2.71228724e-02\n",
      " 2.74087785e-01 1.07433180e+01], Loss = 0.4559\n",
      "Iteration 2182: Weights = [5.50000000e+01 3.91529244e+00 8.23196523e+00 2.71220907e-02\n",
      " 2.74079919e-01 1.07435677e+01], Loss = 0.4559\n",
      "Iteration 2183: Weights = [5.50000000e+01 3.91518004e+00 8.23172892e+00 2.71213090e-02\n",
      " 2.74072053e-01 1.07438174e+01], Loss = 0.4559\n",
      "Iteration 2184: Weights = [5.50000000e+01 3.91506766e+00 8.23149262e+00 2.71205273e-02\n",
      " 2.74064187e-01 1.07440670e+01], Loss = 0.4559\n",
      "Iteration 2185: Weights = [5.50000000e+01 3.91495527e+00 8.23125632e+00 2.71197457e-02\n",
      " 2.74056322e-01 1.07443167e+01], Loss = 0.4558\n",
      "Iteration 2186: Weights = [5.50000000e+01 3.91484289e+00 8.23102003e+00 2.71189642e-02\n",
      " 2.74048456e-01 1.07445663e+01], Loss = 0.4558\n",
      "Iteration 2187: Weights = [5.50000000e+01 3.91473051e+00 8.23078375e+00 2.71181827e-02\n",
      " 2.74040591e-01 1.07448159e+01], Loss = 0.4558\n",
      "Iteration 2188: Weights = [5.50000000e+01 3.91461813e+00 8.23054748e+00 2.71174012e-02\n",
      " 2.74032726e-01 1.07450655e+01], Loss = 0.4557\n",
      "Iteration 2189: Weights = [5.50000000e+01 3.91450576e+00 8.23031121e+00 2.71166198e-02\n",
      " 2.74024862e-01 1.07453152e+01], Loss = 0.4557\n",
      "Iteration 2190: Weights = [5.50000000e+01 3.91439339e+00 8.23007495e+00 2.71158384e-02\n",
      " 2.74016997e-01 1.07455648e+01], Loss = 0.4557\n",
      "Iteration 2191: Weights = [5.50000000e+01 3.91428102e+00 8.22983869e+00 2.71150571e-02\n",
      " 2.74009133e-01 1.07458144e+01], Loss = 0.4557\n",
      "Iteration 2192: Weights = [5.50000000e+01 3.91416865e+00 8.22960244e+00 2.71142758e-02\n",
      " 2.74001269e-01 1.07460640e+01], Loss = 0.4556\n",
      "Iteration 2193: Weights = [5.50000000e+01 3.91405629e+00 8.22936620e+00 2.71134945e-02\n",
      " 2.73993405e-01 1.07463135e+01], Loss = 0.4556\n",
      "Iteration 2194: Weights = [5.50000000e+01 3.91394394e+00 8.22912997e+00 2.71127133e-02\n",
      " 2.73985541e-01 1.07465631e+01], Loss = 0.4556\n",
      "Iteration 2195: Weights = [5.50000000e+01 3.91383158e+00 8.22889374e+00 2.71119321e-02\n",
      " 2.73977678e-01 1.07468127e+01], Loss = 0.4556\n",
      "Iteration 2196: Weights = [5.50000000e+01 3.91371923e+00 8.22865752e+00 2.71111510e-02\n",
      " 2.73969815e-01 1.07470623e+01], Loss = 0.4555\n",
      "Iteration 2197: Weights = [5.50000000e+01 3.91360688e+00 8.22842131e+00 2.71103699e-02\n",
      " 2.73961952e-01 1.07473118e+01], Loss = 0.4555\n",
      "Iteration 2198: Weights = [5.50000000e+01 3.91349454e+00 8.22818510e+00 2.71095889e-02\n",
      " 2.73954089e-01 1.07475614e+01], Loss = 0.4555\n",
      "Iteration 2199: Weights = [5.50000000e+01 3.91338220e+00 8.22794890e+00 2.71088079e-02\n",
      " 2.73946226e-01 1.07478109e+01], Loss = 0.4555\n",
      "Iteration 2200: Weights = [5.50000000e+01 3.91326986e+00 8.22771271e+00 2.71080270e-02\n",
      " 2.73938364e-01 1.07480605e+01], Loss = 0.4554\n",
      "Iteration 2201: Weights = [5.50000000e+01 3.91315753e+00 8.22747652e+00 2.71072461e-02\n",
      " 2.73930502e-01 1.07483100e+01], Loss = 0.4554\n",
      "Iteration 2202: Weights = [5.50000000e+01 3.91304519e+00 8.22724034e+00 2.71064652e-02\n",
      " 2.73922640e-01 1.07485595e+01], Loss = 0.4554\n",
      "Iteration 2203: Weights = [5.50000000e+01 3.91293287e+00 8.22700417e+00 2.71056844e-02\n",
      " 2.73914778e-01 1.07488090e+01], Loss = 0.4554\n",
      "Iteration 2204: Weights = [5.50000000e+01 3.91282054e+00 8.22676800e+00 2.71049036e-02\n",
      " 2.73906917e-01 1.07490585e+01], Loss = 0.4553\n",
      "Iteration 2205: Weights = [5.50000000e+01 3.91270822e+00 8.22653184e+00 2.71041229e-02\n",
      " 2.73899055e-01 1.07493080e+01], Loss = 0.4553\n",
      "Iteration 2206: Weights = [5.50000000e+01 3.91259590e+00 8.22629569e+00 2.71033422e-02\n",
      " 2.73891194e-01 1.07495575e+01], Loss = 0.4553\n",
      "Iteration 2207: Weights = [5.50000000e+01 3.91248359e+00 8.22605954e+00 2.71025615e-02\n",
      " 2.73883334e-01 1.07498070e+01], Loss = 0.4552\n",
      "Iteration 2208: Weights = [5.50000000e+01 3.91237127e+00 8.22582340e+00 2.71017809e-02\n",
      " 2.73875473e-01 1.07500565e+01], Loss = 0.4552\n",
      "Iteration 2209: Weights = [5.50000000e+01 3.91225896e+00 8.22558727e+00 2.71010003e-02\n",
      " 2.73867613e-01 1.07503060e+01], Loss = 0.4552\n",
      "Iteration 2210: Weights = [5.50000000e+01 3.91214666e+00 8.22535114e+00 2.71002198e-02\n",
      " 2.73859752e-01 1.07505554e+01], Loss = 0.4552\n",
      "Iteration 2211: Weights = [5.50000000e+01 3.91203436e+00 8.22511502e+00 2.70994393e-02\n",
      " 2.73851892e-01 1.07508049e+01], Loss = 0.4551\n",
      "Iteration 2212: Weights = [5.50000000e+01 3.91192206e+00 8.22487891e+00 2.70986589e-02\n",
      " 2.73844033e-01 1.07510543e+01], Loss = 0.4551\n",
      "Iteration 2213: Weights = [5.50000000e+01 3.91180976e+00 8.22464280e+00 2.70978784e-02\n",
      " 2.73836173e-01 1.07513038e+01], Loss = 0.4551\n",
      "Iteration 2214: Weights = [5.50000000e+01 3.91169747e+00 8.22440671e+00 2.70970981e-02\n",
      " 2.73828314e-01 1.07515532e+01], Loss = 0.4551\n",
      "Iteration 2215: Weights = [5.50000000e+01 3.91158518e+00 8.22417061e+00 2.70963177e-02\n",
      " 2.73820454e-01 1.07518026e+01], Loss = 0.4550\n",
      "Iteration 2216: Weights = [5.50000000e+01 3.91147289e+00 8.22393453e+00 2.70955375e-02\n",
      " 2.73812596e-01 1.07520521e+01], Loss = 0.4550\n",
      "Iteration 2217: Weights = [5.50000000e+01 3.91136061e+00 8.22369845e+00 2.70947572e-02\n",
      " 2.73804737e-01 1.07523015e+01], Loss = 0.4550\n",
      "Iteration 2218: Weights = [5.50000000e+01 3.91124833e+00 8.22346238e+00 2.70939770e-02\n",
      " 2.73796878e-01 1.07525509e+01], Loss = 0.4550\n",
      "Iteration 2219: Weights = [5.50000000e+01 3.91113605e+00 8.22322631e+00 2.70931968e-02\n",
      " 2.73789020e-01 1.07528003e+01], Loss = 0.4549\n",
      "Iteration 2220: Weights = [5.50000000e+01 3.91102378e+00 8.22299026e+00 2.70924167e-02\n",
      " 2.73781162e-01 1.07530497e+01], Loss = 0.4549\n",
      "Iteration 2221: Weights = [5.50000000e+01 3.91091151e+00 8.22275420e+00 2.70916366e-02\n",
      " 2.73773304e-01 1.07532991e+01], Loss = 0.4549\n",
      "Iteration 2222: Weights = [5.50000000e+01 3.91079924e+00 8.22251816e+00 2.70908566e-02\n",
      " 2.73765447e-01 1.07535484e+01], Loss = 0.4549\n",
      "Iteration 2223: Weights = [5.50000000e+01 3.91068698e+00 8.22228212e+00 2.70900766e-02\n",
      " 2.73757589e-01 1.07537978e+01], Loss = 0.4548\n",
      "Iteration 2224: Weights = [5.50000000e+01 3.91057471e+00 8.22204609e+00 2.70892966e-02\n",
      " 2.73749732e-01 1.07540472e+01], Loss = 0.4548\n",
      "Iteration 2225: Weights = [5.50000000e+01 3.91046246e+00 8.22181007e+00 2.70885167e-02\n",
      " 2.73741875e-01 1.07542965e+01], Loss = 0.4548\n",
      "Iteration 2226: Weights = [5.50000000e+01 3.91035020e+00 8.22157405e+00 2.70877368e-02\n",
      " 2.73734018e-01 1.07545459e+01], Loss = 0.4548\n",
      "Iteration 2227: Weights = [5.50000000e+01 3.91023795e+00 8.22133804e+00 2.70869569e-02\n",
      " 2.73726162e-01 1.07547952e+01], Loss = 0.4547\n",
      "Iteration 2228: Weights = [5.50000000e+01 3.91012570e+00 8.22110203e+00 2.70861771e-02\n",
      " 2.73718305e-01 1.07550445e+01], Loss = 0.4547\n",
      "Iteration 2229: Weights = [5.50000000e+01 3.91001346e+00 8.22086604e+00 2.70853973e-02\n",
      " 2.73710449e-01 1.07552939e+01], Loss = 0.4547\n",
      "Iteration 2230: Weights = [5.50000000e+01 3.90990122e+00 8.22063005e+00 2.70846176e-02\n",
      " 2.73702593e-01 1.07555432e+01], Loss = 0.4546\n",
      "Iteration 2231: Weights = [5.50000000e+01 3.90978898e+00 8.22039406e+00 2.70838379e-02\n",
      " 2.73694738e-01 1.07557925e+01], Loss = 0.4546\n",
      "Iteration 2232: Weights = [5.50000000e+01 3.90967674e+00 8.22015809e+00 2.70830583e-02\n",
      " 2.73686882e-01 1.07560418e+01], Loss = 0.4546\n",
      "Iteration 2233: Weights = [5.50000000e+01 3.90956451e+00 8.21992212e+00 2.70822786e-02\n",
      " 2.73679027e-01 1.07562911e+01], Loss = 0.4546\n",
      "Iteration 2234: Weights = [5.50000000e+01 3.90945228e+00 8.21968615e+00 2.70814990e-02\n",
      " 2.73671172e-01 1.07565404e+01], Loss = 0.4545\n",
      "Iteration 2235: Weights = [5.50000000e+01 3.90934006e+00 8.21945020e+00 2.70807195e-02\n",
      " 2.73663317e-01 1.07567897e+01], Loss = 0.4545\n",
      "Iteration 2236: Weights = [5.50000000e+01 3.90922784e+00 8.21921425e+00 2.70799400e-02\n",
      " 2.73655462e-01 1.07570390e+01], Loss = 0.4545\n",
      "Iteration 2237: Weights = [5.50000000e+01 3.90911562e+00 8.21897830e+00 2.70791605e-02\n",
      " 2.73647608e-01 1.07572882e+01], Loss = 0.4545\n",
      "Iteration 2238: Weights = [5.50000000e+01 3.90900340e+00 8.21874237e+00 2.70783811e-02\n",
      " 2.73639754e-01 1.07575375e+01], Loss = 0.4544\n",
      "Iteration 2239: Weights = [5.50000000e+01 3.90889119e+00 8.21850644e+00 2.70776017e-02\n",
      " 2.73631900e-01 1.07577868e+01], Loss = 0.4544\n",
      "Iteration 2240: Weights = [5.50000000e+01 3.90877898e+00 8.21827052e+00 2.70768223e-02\n",
      " 2.73624046e-01 1.07580360e+01], Loss = 0.4544\n",
      "Iteration 2241: Weights = [5.50000000e+01 3.90866677e+00 8.21803460e+00 2.70760430e-02\n",
      " 2.73616193e-01 1.07582853e+01], Loss = 0.4544\n",
      "Iteration 2242: Weights = [5.50000000e+01 3.90855457e+00 8.21779869e+00 2.70752637e-02\n",
      " 2.73608339e-01 1.07585345e+01], Loss = 0.4543\n",
      "Iteration 2243: Weights = [5.50000000e+01 3.90844237e+00 8.21756279e+00 2.70744845e-02\n",
      " 2.73600486e-01 1.07587837e+01], Loss = 0.4543\n",
      "Iteration 2244: Weights = [5.50000000e+01 3.90833018e+00 8.21732689e+00 2.70737053e-02\n",
      " 2.73592633e-01 1.07590329e+01], Loss = 0.4543\n",
      "Iteration 2245: Weights = [5.50000000e+01 3.90821798e+00 8.21709100e+00 2.70729261e-02\n",
      " 2.73584781e-01 1.07592822e+01], Loss = 0.4543\n",
      "Iteration 2246: Weights = [5.50000000e+01 3.90810579e+00 8.21685512e+00 2.70721470e-02\n",
      " 2.73576928e-01 1.07595314e+01], Loss = 0.4542\n",
      "Iteration 2247: Weights = [5.50000000e+01 3.90799361e+00 8.21661925e+00 2.70713679e-02\n",
      " 2.73569076e-01 1.07597806e+01], Loss = 0.4542\n",
      "Iteration 2248: Weights = [5.50000000e+01 3.90788142e+00 8.21638338e+00 2.70705888e-02\n",
      " 2.73561224e-01 1.07600298e+01], Loss = 0.4542\n",
      "Iteration 2249: Weights = [5.50000000e+01 3.90776924e+00 8.21614752e+00 2.70698098e-02\n",
      " 2.73553372e-01 1.07602789e+01], Loss = 0.4542\n",
      "Iteration 2250: Weights = [5.50000000e+01 3.90765706e+00 8.21591166e+00 2.70690308e-02\n",
      " 2.73545521e-01 1.07605281e+01], Loss = 0.4541\n",
      "Iteration 2251: Weights = [5.50000000e+01 3.90754489e+00 8.21567581e+00 2.70682519e-02\n",
      " 2.73537669e-01 1.07607773e+01], Loss = 0.4541\n",
      "Iteration 2252: Weights = [5.50000000e+01 3.90743272e+00 8.21543997e+00 2.70674730e-02\n",
      " 2.73529818e-01 1.07610264e+01], Loss = 0.4541\n",
      "Iteration 2253: Weights = [5.50000000e+01 3.90732055e+00 8.21520414e+00 2.70666941e-02\n",
      " 2.73521967e-01 1.07612756e+01], Loss = 0.4540\n",
      "Iteration 2254: Weights = [5.50000000e+01 3.90720839e+00 8.21496831e+00 2.70659152e-02\n",
      " 2.73514117e-01 1.07615248e+01], Loss = 0.4540\n",
      "Iteration 2255: Weights = [5.50000000e+01 3.90709623e+00 8.21473249e+00 2.70651364e-02\n",
      " 2.73506266e-01 1.07617739e+01], Loss = 0.4540\n",
      "Iteration 2256: Weights = [5.50000000e+01 3.90698407e+00 8.21449667e+00 2.70643577e-02\n",
      " 2.73498416e-01 1.07620230e+01], Loss = 0.4540\n",
      "Iteration 2257: Weights = [5.50000000e+01 3.90687192e+00 8.21426086e+00 2.70635789e-02\n",
      " 2.73490566e-01 1.07622722e+01], Loss = 0.4539\n",
      "Iteration 2258: Weights = [5.50000000e+01 3.90675976e+00 8.21402506e+00 2.70628002e-02\n",
      " 2.73482716e-01 1.07625213e+01], Loss = 0.4539\n",
      "Iteration 2259: Weights = [5.50000000e+01 3.90664762e+00 8.21378927e+00 2.70620216e-02\n",
      " 2.73474866e-01 1.07627704e+01], Loss = 0.4539\n",
      "Iteration 2260: Weights = [5.50000000e+01 3.90653547e+00 8.21355348e+00 2.70612429e-02\n",
      " 2.73467017e-01 1.07630195e+01], Loss = 0.4539\n",
      "Iteration 2261: Weights = [5.50000000e+01 3.90642333e+00 8.21331770e+00 2.70604643e-02\n",
      " 2.73459168e-01 1.07632686e+01], Loss = 0.4538\n",
      "Iteration 2262: Weights = [5.50000000e+01 3.90631119e+00 8.21308193e+00 2.70596858e-02\n",
      " 2.73451319e-01 1.07635177e+01], Loss = 0.4538\n",
      "Iteration 2263: Weights = [5.50000000e+01 3.90619906e+00 8.21284616e+00 2.70589072e-02\n",
      " 2.73443470e-01 1.07637668e+01], Loss = 0.4538\n",
      "Iteration 2264: Weights = [5.50000000e+01 3.90608692e+00 8.21261040e+00 2.70581288e-02\n",
      " 2.73435622e-01 1.07640159e+01], Loss = 0.4538\n",
      "Iteration 2265: Weights = [5.50000000e+01 3.90597479e+00 8.21237465e+00 2.70573503e-02\n",
      " 2.73427773e-01 1.07642649e+01], Loss = 0.4537\n",
      "Iteration 2266: Weights = [5.50000000e+01 3.90586267e+00 8.21213890e+00 2.70565719e-02\n",
      " 2.73419925e-01 1.07645140e+01], Loss = 0.4537\n",
      "Iteration 2267: Weights = [5.50000000e+01 3.90575055e+00 8.21190316e+00 2.70557935e-02\n",
      " 2.73412077e-01 1.07647630e+01], Loss = 0.4537\n",
      "Iteration 2268: Weights = [5.50000000e+01 3.90563843e+00 8.21166743e+00 2.70550152e-02\n",
      " 2.73404230e-01 1.07650121e+01], Loss = 0.4537\n",
      "Iteration 2269: Weights = [5.50000000e+01 3.90552631e+00 8.21143170e+00 2.70542368e-02\n",
      " 2.73396382e-01 1.07652611e+01], Loss = 0.4536\n",
      "Iteration 2270: Weights = [5.50000000e+01 3.90541420e+00 8.21119598e+00 2.70534586e-02\n",
      " 2.73388535e-01 1.07655102e+01], Loss = 0.4536\n",
      "Iteration 2271: Weights = [5.50000000e+01 3.90530209e+00 8.21096027e+00 2.70526803e-02\n",
      " 2.73380688e-01 1.07657592e+01], Loss = 0.4536\n",
      "Iteration 2272: Weights = [5.50000000e+01 3.90518998e+00 8.21072456e+00 2.70519021e-02\n",
      " 2.73372841e-01 1.07660082e+01], Loss = 0.4536\n",
      "Iteration 2273: Weights = [5.50000000e+01 3.90507788e+00 8.21048886e+00 2.70511239e-02\n",
      " 2.73364995e-01 1.07662572e+01], Loss = 0.4535\n",
      "Iteration 2274: Weights = [5.50000000e+01 3.90496578e+00 8.21025317e+00 2.70503458e-02\n",
      " 2.73357148e-01 1.07665062e+01], Loss = 0.4535\n",
      "Iteration 2275: Weights = [5.50000000e+01 3.90485368e+00 8.21001748e+00 2.70495677e-02\n",
      " 2.73349302e-01 1.07667552e+01], Loss = 0.4535\n",
      "Iteration 2276: Weights = [5.50000000e+01 3.90474159e+00 8.20978181e+00 2.70487896e-02\n",
      " 2.73341456e-01 1.07670042e+01], Loss = 0.4534\n",
      "Iteration 2277: Weights = [5.50000000e+01 3.90462950e+00 8.20954613e+00 2.70480115e-02\n",
      " 2.73333611e-01 1.07672532e+01], Loss = 0.4534\n",
      "Iteration 2278: Weights = [5.50000000e+01 3.90451741e+00 8.20931047e+00 2.70472335e-02\n",
      " 2.73325765e-01 1.07675022e+01], Loss = 0.4534\n",
      "Iteration 2279: Weights = [5.50000000e+01 3.90440533e+00 8.20907481e+00 2.70464556e-02\n",
      " 2.73317920e-01 1.07677512e+01], Loss = 0.4534\n",
      "Iteration 2280: Weights = [5.50000000e+01 3.90429325e+00 8.20883916e+00 2.70456776e-02\n",
      " 2.73310075e-01 1.07680001e+01], Loss = 0.4533\n",
      "Iteration 2281: Weights = [5.50000000e+01 3.90418117e+00 8.20860351e+00 2.70448997e-02\n",
      " 2.73302230e-01 1.07682491e+01], Loss = 0.4533\n",
      "Iteration 2282: Weights = [5.50000000e+01 3.90406910e+00 8.20836787e+00 2.70441218e-02\n",
      " 2.73294385e-01 1.07684980e+01], Loss = 0.4533\n",
      "Iteration 2283: Weights = [5.50000000e+01 3.90395702e+00 8.20813224e+00 2.70433440e-02\n",
      " 2.73286541e-01 1.07687470e+01], Loss = 0.4533\n",
      "Iteration 2284: Weights = [5.50000000e+01 3.90384496e+00 8.20789662e+00 2.70425662e-02\n",
      " 2.73278697e-01 1.07689959e+01], Loss = 0.4532\n",
      "Iteration 2285: Weights = [5.50000000e+01 3.90373289e+00 8.20766100e+00 2.70417884e-02\n",
      " 2.73270853e-01 1.07692448e+01], Loss = 0.4532\n",
      "Iteration 2286: Weights = [5.50000000e+01 3.90362083e+00 8.20742539e+00 2.70410107e-02\n",
      " 2.73263009e-01 1.07694938e+01], Loss = 0.4532\n",
      "Iteration 2287: Weights = [5.50000000e+01 3.90350877e+00 8.20718978e+00 2.70402330e-02\n",
      " 2.73255166e-01 1.07697427e+01], Loss = 0.4532\n",
      "Iteration 2288: Weights = [5.50000000e+01 3.90339672e+00 8.20695418e+00 2.70394553e-02\n",
      " 2.73247322e-01 1.07699916e+01], Loss = 0.4531\n",
      "Iteration 2289: Weights = [5.50000000e+01 3.90328467e+00 8.20671859e+00 2.70386776e-02\n",
      " 2.73239479e-01 1.07702405e+01], Loss = 0.4531\n",
      "Iteration 2290: Weights = [5.50000000e+01 3.90317262e+00 8.20648301e+00 2.70379000e-02\n",
      " 2.73231637e-01 1.07704894e+01], Loss = 0.4531\n",
      "Iteration 2291: Weights = [5.50000000e+01 3.90306057e+00 8.20624743e+00 2.70371225e-02\n",
      " 2.73223794e-01 1.07707382e+01], Loss = 0.4531\n",
      "Iteration 2292: Weights = [5.50000000e+01 3.90294853e+00 8.20601186e+00 2.70363449e-02\n",
      " 2.73215951e-01 1.07709871e+01], Loss = 0.4530\n",
      "Iteration 2293: Weights = [5.50000000e+01 3.90283649e+00 8.20577630e+00 2.70355674e-02\n",
      " 2.73208109e-01 1.07712360e+01], Loss = 0.4530\n",
      "Iteration 2294: Weights = [5.50000000e+01 3.90272446e+00 8.20554074e+00 2.70347899e-02\n",
      " 2.73200267e-01 1.07714849e+01], Loss = 0.4530\n",
      "Iteration 2295: Weights = [5.50000000e+01 3.90261242e+00 8.20530519e+00 2.70340125e-02\n",
      " 2.73192426e-01 1.07717337e+01], Loss = 0.4530\n",
      "Iteration 2296: Weights = [5.50000000e+01 3.90250039e+00 8.20506964e+00 2.70332351e-02\n",
      " 2.73184584e-01 1.07719826e+01], Loss = 0.4529\n",
      "Iteration 2297: Weights = [5.50000000e+01 3.90238837e+00 8.20483411e+00 2.70324577e-02\n",
      " 2.73176743e-01 1.07722314e+01], Loss = 0.4529\n",
      "Iteration 2298: Weights = [5.50000000e+01 3.90227635e+00 8.20459858e+00 2.70316803e-02\n",
      " 2.73168902e-01 1.07724802e+01], Loss = 0.4529\n",
      "Iteration 2299: Weights = [5.50000000e+01 3.90216433e+00 8.20436305e+00 2.70309030e-02\n",
      " 2.73161061e-01 1.07727291e+01], Loss = 0.4529\n",
      "Iteration 2300: Weights = [5.50000000e+01 3.90205231e+00 8.20412754e+00 2.70301257e-02\n",
      " 2.73153220e-01 1.07729779e+01], Loss = 0.4528\n",
      "Iteration 2301: Weights = [5.50000000e+01 3.90194030e+00 8.20389203e+00 2.70293485e-02\n",
      " 2.73145380e-01 1.07732267e+01], Loss = 0.4528\n",
      "Iteration 2302: Weights = [5.50000000e+01 3.90182829e+00 8.20365652e+00 2.70285712e-02\n",
      " 2.73137539e-01 1.07734755e+01], Loss = 0.4528\n",
      "Iteration 2303: Weights = [5.50000000e+01 3.90171628e+00 8.20342103e+00 2.70277941e-02\n",
      " 2.73129699e-01 1.07737243e+01], Loss = 0.4527\n",
      "Iteration 2304: Weights = [5.50000000e+01 3.90160428e+00 8.20318554e+00 2.70270169e-02\n",
      " 2.73121860e-01 1.07739731e+01], Loss = 0.4527\n",
      "Iteration 2305: Weights = [5.50000000e+01 3.90149228e+00 8.20295005e+00 2.70262398e-02\n",
      " 2.73114020e-01 1.07742219e+01], Loss = 0.4527\n",
      "Iteration 2306: Weights = [5.50000000e+01 3.90138028e+00 8.20271458e+00 2.70254627e-02\n",
      " 2.73106181e-01 1.07744707e+01], Loss = 0.4527\n",
      "Iteration 2307: Weights = [5.50000000e+01 3.90126828e+00 8.20247911e+00 2.70246856e-02\n",
      " 2.73098342e-01 1.07747194e+01], Loss = 0.4526\n",
      "Iteration 2308: Weights = [5.50000000e+01 3.90115629e+00 8.20224365e+00 2.70239086e-02\n",
      " 2.73090503e-01 1.07749682e+01], Loss = 0.4526\n",
      "Iteration 2309: Weights = [5.50000000e+01 3.90104431e+00 8.20200819e+00 2.70231316e-02\n",
      " 2.73082664e-01 1.07752169e+01], Loss = 0.4526\n",
      "Iteration 2310: Weights = [5.50000000e+01 3.90093232e+00 8.20177274e+00 2.70223546e-02\n",
      " 2.73074826e-01 1.07754657e+01], Loss = 0.4526\n",
      "Iteration 2311: Weights = [5.50000000e+01 3.90082034e+00 8.20153730e+00 2.70215777e-02\n",
      " 2.73066987e-01 1.07757144e+01], Loss = 0.4525\n",
      "Iteration 2312: Weights = [5.50000000e+01 3.90070836e+00 8.20130186e+00 2.70208008e-02\n",
      " 2.73059149e-01 1.07759632e+01], Loss = 0.4525\n",
      "Iteration 2313: Weights = [5.50000000e+01 3.90059639e+00 8.20106643e+00 2.70200239e-02\n",
      " 2.73051312e-01 1.07762119e+01], Loss = 0.4525\n",
      "Iteration 2314: Weights = [5.50000000e+01 3.90048442e+00 8.20083101e+00 2.70192470e-02\n",
      " 2.73043474e-01 1.07764606e+01], Loss = 0.4525\n",
      "Iteration 2315: Weights = [5.50000000e+01 3.90037245e+00 8.20059560e+00 2.70184702e-02\n",
      " 2.73035637e-01 1.07767093e+01], Loss = 0.4524\n",
      "Iteration 2316: Weights = [5.50000000e+01 3.90026048e+00 8.20036019e+00 2.70176934e-02\n",
      " 2.73027799e-01 1.07769580e+01], Loss = 0.4524\n",
      "Iteration 2317: Weights = [5.50000000e+01 3.90014852e+00 8.20012479e+00 2.70169167e-02\n",
      " 2.73019963e-01 1.07772067e+01], Loss = 0.4524\n",
      "Iteration 2318: Weights = [5.50000000e+01 3.90003656e+00 8.19988939e+00 2.70161400e-02\n",
      " 2.73012126e-01 1.07774554e+01], Loss = 0.4524\n",
      "Iteration 2319: Weights = [5.50000000e+01 3.89992461e+00 8.19965400e+00 2.70153633e-02\n",
      " 2.73004289e-01 1.07777041e+01], Loss = 0.4523\n",
      "Iteration 2320: Weights = [5.50000000e+01 3.89981266e+00 8.19941862e+00 2.70145866e-02\n",
      " 2.72996453e-01 1.07779528e+01], Loss = 0.4523\n",
      "Iteration 2321: Weights = [5.50000000e+01 3.89970071e+00 8.19918325e+00 2.70138100e-02\n",
      " 2.72988617e-01 1.07782015e+01], Loss = 0.4523\n",
      "Iteration 2322: Weights = [5.50000000e+01 3.89958876e+00 8.19894788e+00 2.70130334e-02\n",
      " 2.72980781e-01 1.07784501e+01], Loss = 0.4523\n",
      "Iteration 2323: Weights = [5.50000000e+01 3.89947682e+00 8.19871252e+00 2.70122568e-02\n",
      " 2.72972946e-01 1.07786988e+01], Loss = 0.4522\n",
      "Iteration 2324: Weights = [5.50000000e+01 3.89936488e+00 8.19847716e+00 2.70114803e-02\n",
      " 2.72965110e-01 1.07789474e+01], Loss = 0.4522\n",
      "Iteration 2325: Weights = [5.50000000e+01 3.89925294e+00 8.19824181e+00 2.70107038e-02\n",
      " 2.72957275e-01 1.07791961e+01], Loss = 0.4522\n",
      "Iteration 2326: Weights = [5.50000000e+01 3.89914101e+00 8.19800647e+00 2.70099273e-02\n",
      " 2.72949440e-01 1.07794447e+01], Loss = 0.4521\n",
      "Iteration 2327: Weights = [5.50000000e+01 3.89902908e+00 8.19777114e+00 2.70091509e-02\n",
      " 2.72941605e-01 1.07796933e+01], Loss = 0.4521\n",
      "Iteration 2328: Weights = [5.50000000e+01 3.89891716e+00 8.19753581e+00 2.70083744e-02\n",
      " 2.72933771e-01 1.07799420e+01], Loss = 0.4521\n",
      "Iteration 2329: Weights = [5.50000000e+01 3.89880523e+00 8.19730049e+00 2.70075981e-02\n",
      " 2.72925937e-01 1.07801906e+01], Loss = 0.4521\n",
      "Iteration 2330: Weights = [5.50000000e+01 3.89869331e+00 8.19706518e+00 2.70068217e-02\n",
      " 2.72918103e-01 1.07804392e+01], Loss = 0.4520\n",
      "Iteration 2331: Weights = [5.50000000e+01 3.89858140e+00 8.19682987e+00 2.70060454e-02\n",
      " 2.72910269e-01 1.07806878e+01], Loss = 0.4520\n",
      "Iteration 2332: Weights = [5.50000000e+01 3.89846948e+00 8.19659457e+00 2.70052691e-02\n",
      " 2.72902435e-01 1.07809364e+01], Loss = 0.4520\n",
      "Iteration 2333: Weights = [5.50000000e+01 3.89835757e+00 8.19635927e+00 2.70044928e-02\n",
      " 2.72894602e-01 1.07811849e+01], Loss = 0.4520\n",
      "Iteration 2334: Weights = [5.50000000e+01 3.89824566e+00 8.19612399e+00 2.70037166e-02\n",
      " 2.72886769e-01 1.07814335e+01], Loss = 0.4519\n",
      "Iteration 2335: Weights = [5.50000000e+01 3.89813376e+00 8.19588871e+00 2.70029404e-02\n",
      " 2.72878936e-01 1.07816821e+01], Loss = 0.4519\n",
      "Iteration 2336: Weights = [5.50000000e+01 3.89802186e+00 8.19565343e+00 2.70021642e-02\n",
      " 2.72871103e-01 1.07819307e+01], Loss = 0.4519\n",
      "Iteration 2337: Weights = [5.50000000e+01 3.89790996e+00 8.19541817e+00 2.70013880e-02\n",
      " 2.72863270e-01 1.07821792e+01], Loss = 0.4519\n",
      "Iteration 2338: Weights = [5.50000000e+01 3.89779807e+00 8.19518291e+00 2.70006119e-02\n",
      " 2.72855438e-01 1.07824278e+01], Loss = 0.4518\n",
      "Iteration 2339: Weights = [5.50000000e+01 3.89768618e+00 8.19494765e+00 2.69998358e-02\n",
      " 2.72847606e-01 1.07826763e+01], Loss = 0.4518\n",
      "Iteration 2340: Weights = [5.50000000e+01 3.89757429e+00 8.19471241e+00 2.69990598e-02\n",
      " 2.72839774e-01 1.07829248e+01], Loss = 0.4518\n",
      "Iteration 2341: Weights = [5.50000000e+01 3.89746240e+00 8.19447717e+00 2.69982838e-02\n",
      " 2.72831942e-01 1.07831734e+01], Loss = 0.4518\n",
      "Iteration 2342: Weights = [5.50000000e+01 3.89735052e+00 8.19424193e+00 2.69975078e-02\n",
      " 2.72824111e-01 1.07834219e+01], Loss = 0.4517\n",
      "Iteration 2343: Weights = [5.50000000e+01 3.89723864e+00 8.19400671e+00 2.69967318e-02\n",
      " 2.72816280e-01 1.07836704e+01], Loss = 0.4517\n",
      "Iteration 2344: Weights = [5.50000000e+01 3.89712677e+00 8.19377149e+00 2.69959558e-02\n",
      " 2.72808449e-01 1.07839189e+01], Loss = 0.4517\n",
      "Iteration 2345: Weights = [5.50000000e+01 3.89701490e+00 8.19353627e+00 2.69951799e-02\n",
      " 2.72800618e-01 1.07841674e+01], Loss = 0.4517\n",
      "Iteration 2346: Weights = [5.50000000e+01 3.89690303e+00 8.19330107e+00 2.69944041e-02\n",
      " 2.72792788e-01 1.07844159e+01], Loss = 0.4516\n",
      "Iteration 2347: Weights = [5.50000000e+01 3.89679116e+00 8.19306587e+00 2.69936282e-02\n",
      " 2.72784957e-01 1.07846644e+01], Loss = 0.4516\n",
      "Iteration 2348: Weights = [5.50000000e+01 3.89667930e+00 8.19283068e+00 2.69928524e-02\n",
      " 2.72777127e-01 1.07849129e+01], Loss = 0.4516\n",
      "Iteration 2349: Weights = [5.50000000e+01 3.89656744e+00 8.19259549e+00 2.69920766e-02\n",
      " 2.72769297e-01 1.07851613e+01], Loss = 0.4516\n",
      "Iteration 2350: Weights = [5.50000000e+01 3.89645559e+00 8.19236031e+00 2.69913008e-02\n",
      " 2.72761468e-01 1.07854098e+01], Loss = 0.4515\n",
      "Iteration 2351: Weights = [5.50000000e+01 3.89634373e+00 8.19212514e+00 2.69905251e-02\n",
      " 2.72753638e-01 1.07856583e+01], Loss = 0.4515\n",
      "Iteration 2352: Weights = [5.50000000e+01 3.89623188e+00 8.19188997e+00 2.69897494e-02\n",
      " 2.72745809e-01 1.07859067e+01], Loss = 0.4515\n",
      "Iteration 2353: Weights = [5.50000000e+01 3.89612004e+00 8.19165481e+00 2.69889737e-02\n",
      " 2.72737980e-01 1.07861551e+01], Loss = 0.4514\n",
      "Iteration 2354: Weights = [5.50000000e+01 3.89600819e+00 8.19141966e+00 2.69881980e-02\n",
      " 2.72730151e-01 1.07864036e+01], Loss = 0.4514\n",
      "Iteration 2355: Weights = [5.50000000e+01 3.89589635e+00 8.19118452e+00 2.69874224e-02\n",
      " 2.72722323e-01 1.07866520e+01], Loss = 0.4514\n",
      "Iteration 2356: Weights = [5.50000000e+01 3.89578452e+00 8.19094938e+00 2.69866468e-02\n",
      " 2.72714494e-01 1.07869004e+01], Loss = 0.4514\n",
      "Iteration 2357: Weights = [5.50000000e+01 3.89567268e+00 8.19071425e+00 2.69858713e-02\n",
      " 2.72706666e-01 1.07871488e+01], Loss = 0.4513\n",
      "Iteration 2358: Weights = [5.50000000e+01 3.89556085e+00 8.19047912e+00 2.69850957e-02\n",
      " 2.72698838e-01 1.07873972e+01], Loss = 0.4513\n",
      "Iteration 2359: Weights = [5.50000000e+01 3.89544903e+00 8.19024400e+00 2.69843202e-02\n",
      " 2.72691011e-01 1.07876456e+01], Loss = 0.4513\n",
      "Iteration 2360: Weights = [5.50000000e+01 3.89533720e+00 8.19000889e+00 2.69835447e-02\n",
      " 2.72683183e-01 1.07878940e+01], Loss = 0.4513\n",
      "Iteration 2361: Weights = [5.50000000e+01 3.89522538e+00 8.18977379e+00 2.69827693e-02\n",
      " 2.72675356e-01 1.07881424e+01], Loss = 0.4512\n",
      "Iteration 2362: Weights = [5.50000000e+01 3.89511357e+00 8.18953869e+00 2.69819939e-02\n",
      " 2.72667529e-01 1.07883908e+01], Loss = 0.4512\n",
      "Iteration 2363: Weights = [5.50000000e+01 3.89500175e+00 8.18930360e+00 2.69812185e-02\n",
      " 2.72659702e-01 1.07886392e+01], Loss = 0.4512\n",
      "Iteration 2364: Weights = [5.50000000e+01 3.89488994e+00 8.18906851e+00 2.69804431e-02\n",
      " 2.72651876e-01 1.07888875e+01], Loss = 0.4512\n",
      "Iteration 2365: Weights = [5.50000000e+01 3.89477813e+00 8.18883344e+00 2.69796678e-02\n",
      " 2.72644049e-01 1.07891359e+01], Loss = 0.4511\n",
      "Iteration 2366: Weights = [5.50000000e+01 3.89466633e+00 8.18859836e+00 2.69788925e-02\n",
      " 2.72636223e-01 1.07893842e+01], Loss = 0.4511\n",
      "Iteration 2367: Weights = [5.50000000e+01 3.89455453e+00 8.18836330e+00 2.69781172e-02\n",
      " 2.72628397e-01 1.07896326e+01], Loss = 0.4511\n",
      "Iteration 2368: Weights = [5.50000000e+01 3.89444273e+00 8.18812824e+00 2.69773419e-02\n",
      " 2.72620572e-01 1.07898809e+01], Loss = 0.4511\n",
      "Iteration 2369: Weights = [5.50000000e+01 3.89433093e+00 8.18789319e+00 2.69765667e-02\n",
      " 2.72612746e-01 1.07901292e+01], Loss = 0.4510\n",
      "Iteration 2370: Weights = [5.50000000e+01 3.89421914e+00 8.18765815e+00 2.69757915e-02\n",
      " 2.72604921e-01 1.07903776e+01], Loss = 0.4510\n",
      "Iteration 2371: Weights = [5.50000000e+01 3.89410735e+00 8.18742311e+00 2.69750164e-02\n",
      " 2.72597096e-01 1.07906259e+01], Loss = 0.4510\n",
      "Iteration 2372: Weights = [5.50000000e+01 3.89399557e+00 8.18718808e+00 2.69742412e-02\n",
      " 2.72589271e-01 1.07908742e+01], Loss = 0.4510\n",
      "Iteration 2373: Weights = [5.50000000e+01 3.89388379e+00 8.18695306e+00 2.69734661e-02\n",
      " 2.72581447e-01 1.07911225e+01], Loss = 0.4509\n",
      "Iteration 2374: Weights = [5.50000000e+01 3.89377201e+00 8.18671804e+00 2.69726910e-02\n",
      " 2.72573622e-01 1.07913708e+01], Loss = 0.4509\n",
      "Iteration 2375: Weights = [5.50000000e+01 3.89366023e+00 8.18648303e+00 2.69719160e-02\n",
      " 2.72565798e-01 1.07916191e+01], Loss = 0.4509\n",
      "Iteration 2376: Weights = [5.50000000e+01 3.89354846e+00 8.18624802e+00 2.69711409e-02\n",
      " 2.72557974e-01 1.07918673e+01], Loss = 0.4509\n",
      "Iteration 2377: Weights = [5.50000000e+01 3.89343669e+00 8.18601303e+00 2.69703659e-02\n",
      " 2.72550151e-01 1.07921156e+01], Loss = 0.4508\n",
      "Iteration 2378: Weights = [5.50000000e+01 3.89332493e+00 8.18577804e+00 2.69695910e-02\n",
      " 2.72542327e-01 1.07923639e+01], Loss = 0.4508\n",
      "Iteration 2379: Weights = [5.50000000e+01 3.89321316e+00 8.18554305e+00 2.69688160e-02\n",
      " 2.72534504e-01 1.07926121e+01], Loss = 0.4508\n",
      "Iteration 2380: Weights = [5.50000000e+01 3.89310140e+00 8.18530808e+00 2.69680411e-02\n",
      " 2.72526681e-01 1.07928604e+01], Loss = 0.4508\n",
      "Iteration 2381: Weights = [5.50000000e+01 3.89298965e+00 8.18507311e+00 2.69672662e-02\n",
      " 2.72518858e-01 1.07931086e+01], Loss = 0.4507\n",
      "Iteration 2382: Weights = [5.50000000e+01 3.89287789e+00 8.18483814e+00 2.69664914e-02\n",
      " 2.72511036e-01 1.07933569e+01], Loss = 0.4507\n",
      "Iteration 2383: Weights = [5.50000000e+01 3.89276614e+00 8.18460319e+00 2.69657165e-02\n",
      " 2.72503213e-01 1.07936051e+01], Loss = 0.4507\n",
      "Iteration 2384: Weights = [5.50000000e+01 3.89265440e+00 8.18436824e+00 2.69649417e-02\n",
      " 2.72495391e-01 1.07938533e+01], Loss = 0.4506\n",
      "Iteration 2385: Weights = [5.50000000e+01 3.89254265e+00 8.18413330e+00 2.69641669e-02\n",
      " 2.72487569e-01 1.07941015e+01], Loss = 0.4506\n",
      "Iteration 2386: Weights = [5.50000000e+01 3.89243091e+00 8.18389836e+00 2.69633922e-02\n",
      " 2.72479747e-01 1.07943497e+01], Loss = 0.4506\n",
      "Iteration 2387: Weights = [5.50000000e+01 3.89231918e+00 8.18366343e+00 2.69626175e-02\n",
      " 2.72471926e-01 1.07945979e+01], Loss = 0.4506\n",
      "Iteration 2388: Weights = [5.50000000e+01 3.89220744e+00 8.18342851e+00 2.69618428e-02\n",
      " 2.72464105e-01 1.07948461e+01], Loss = 0.4505\n",
      "Iteration 2389: Weights = [5.50000000e+01 3.89209571e+00 8.18319359e+00 2.69610681e-02\n",
      " 2.72456284e-01 1.07950943e+01], Loss = 0.4505\n",
      "Iteration 2390: Weights = [5.50000000e+01 3.89198398e+00 8.18295868e+00 2.69602935e-02\n",
      " 2.72448463e-01 1.07953425e+01], Loss = 0.4505\n",
      "Iteration 2391: Weights = [5.50000000e+01 3.89187226e+00 8.18272378e+00 2.69595188e-02\n",
      " 2.72440642e-01 1.07955907e+01], Loss = 0.4505\n",
      "Iteration 2392: Weights = [5.50000000e+01 3.89176054e+00 8.18248888e+00 2.69587443e-02\n",
      " 2.72432822e-01 1.07958388e+01], Loss = 0.4504\n",
      "Iteration 2393: Weights = [5.50000000e+01 3.89164882e+00 8.18225400e+00 2.69579697e-02\n",
      " 2.72425002e-01 1.07960870e+01], Loss = 0.4504\n",
      "Iteration 2394: Weights = [5.50000000e+01 3.89153711e+00 8.18201911e+00 2.69571952e-02\n",
      " 2.72417182e-01 1.07963351e+01], Loss = 0.4504\n",
      "Iteration 2395: Weights = [5.50000000e+01 3.89142539e+00 8.18178424e+00 2.69564207e-02\n",
      " 2.72409362e-01 1.07965833e+01], Loss = 0.4504\n",
      "Iteration 2396: Weights = [5.50000000e+01 3.89131369e+00 8.18154937e+00 2.69556462e-02\n",
      " 2.72401543e-01 1.07968314e+01], Loss = 0.4503\n",
      "Iteration 2397: Weights = [5.50000000e+01 3.89120198e+00 8.18131451e+00 2.69548717e-02\n",
      " 2.72393723e-01 1.07970795e+01], Loss = 0.4503\n",
      "Iteration 2398: Weights = [5.50000000e+01 3.89109028e+00 8.18107965e+00 2.69540973e-02\n",
      " 2.72385904e-01 1.07973276e+01], Loss = 0.4503\n",
      "Iteration 2399: Weights = [5.50000000e+01 3.89097858e+00 8.18084480e+00 2.69533229e-02\n",
      " 2.72378086e-01 1.07975758e+01], Loss = 0.4503\n",
      "Iteration 2400: Weights = [5.50000000e+01 3.89086689e+00 8.18060996e+00 2.69525485e-02\n",
      " 2.72370267e-01 1.07978239e+01], Loss = 0.4502\n",
      "Iteration 2401: Weights = [5.50000000e+01 3.89075519e+00 8.18037513e+00 2.69517742e-02\n",
      " 2.72362449e-01 1.07980720e+01], Loss = 0.4502\n",
      "Iteration 2402: Weights = [5.50000000e+01 3.89064350e+00 8.18014030e+00 2.69509999e-02\n",
      " 2.72354631e-01 1.07983201e+01], Loss = 0.4502\n",
      "Iteration 2403: Weights = [5.50000000e+01 3.89053182e+00 8.17990548e+00 2.69502256e-02\n",
      " 2.72346813e-01 1.07985681e+01], Loss = 0.4502\n",
      "Iteration 2404: Weights = [5.50000000e+01 3.89042014e+00 8.17967066e+00 2.69494513e-02\n",
      " 2.72338995e-01 1.07988162e+01], Loss = 0.4501\n",
      "Iteration 2405: Weights = [5.50000000e+01 3.89030846e+00 8.17943585e+00 2.69486771e-02\n",
      " 2.72331177e-01 1.07990643e+01], Loss = 0.4501\n",
      "Iteration 2406: Weights = [5.50000000e+01 3.89019678e+00 8.17920105e+00 2.69479029e-02\n",
      " 2.72323360e-01 1.07993124e+01], Loss = 0.4501\n",
      "Iteration 2407: Weights = [5.50000000e+01 3.89008511e+00 8.17896626e+00 2.69471287e-02\n",
      " 2.72315543e-01 1.07995604e+01], Loss = 0.4501\n",
      "Iteration 2408: Weights = [5.50000000e+01 3.88997344e+00 8.17873147e+00 2.69463545e-02\n",
      " 2.72307726e-01 1.07998085e+01], Loss = 0.4500\n",
      "Iteration 2409: Weights = [5.50000000e+01 3.88986177e+00 8.17849669e+00 2.69455804e-02\n",
      " 2.72299910e-01 1.08000565e+01], Loss = 0.4500\n",
      "Iteration 2410: Weights = [5.50000000e+01 3.88975011e+00 8.17826191e+00 2.69448063e-02\n",
      " 2.72292093e-01 1.08003045e+01], Loss = 0.4500\n",
      "Iteration 2411: Weights = [5.50000000e+01 3.88963845e+00 8.17802715e+00 2.69440322e-02\n",
      " 2.72284277e-01 1.08005526e+01], Loss = 0.4499\n",
      "Iteration 2412: Weights = [5.50000000e+01 3.88952679e+00 8.17779239e+00 2.69432582e-02\n",
      " 2.72276461e-01 1.08008006e+01], Loss = 0.4499\n",
      "Iteration 2413: Weights = [5.50000000e+01 3.88941514e+00 8.17755763e+00 2.69424841e-02\n",
      " 2.72268646e-01 1.08010486e+01], Loss = 0.4499\n",
      "Iteration 2414: Weights = [5.50000000e+01 3.88930349e+00 8.17732288e+00 2.69417101e-02\n",
      " 2.72260830e-01 1.08012966e+01], Loss = 0.4499\n",
      "Iteration 2415: Weights = [5.50000000e+01 3.88919184e+00 8.17708814e+00 2.69409362e-02\n",
      " 2.72253015e-01 1.08015446e+01], Loss = 0.4498\n",
      "Iteration 2416: Weights = [5.50000000e+01 3.88908019e+00 8.17685341e+00 2.69401622e-02\n",
      " 2.72245200e-01 1.08017926e+01], Loss = 0.4498\n",
      "Iteration 2417: Weights = [5.50000000e+01 3.88896855e+00 8.17661868e+00 2.69393883e-02\n",
      " 2.72237385e-01 1.08020406e+01], Loss = 0.4498\n",
      "Iteration 2418: Weights = [5.50000000e+01 3.88885691e+00 8.17638396e+00 2.69386144e-02\n",
      " 2.72229570e-01 1.08022886e+01], Loss = 0.4498\n",
      "Iteration 2419: Weights = [5.50000000e+01 3.88874528e+00 8.17614925e+00 2.69378405e-02\n",
      " 2.72221756e-01 1.08025365e+01], Loss = 0.4497\n",
      "Iteration 2420: Weights = [5.50000000e+01 3.88863365e+00 8.17591454e+00 2.69370667e-02\n",
      " 2.72213942e-01 1.08027845e+01], Loss = 0.4497\n",
      "Iteration 2421: Weights = [5.50000000e+01 3.88852202e+00 8.17567984e+00 2.69362929e-02\n",
      " 2.72206128e-01 1.08030325e+01], Loss = 0.4497\n",
      "Iteration 2422: Weights = [5.50000000e+01 3.88841040e+00 8.17544515e+00 2.69355191e-02\n",
      " 2.72198314e-01 1.08032804e+01], Loss = 0.4497\n",
      "Iteration 2423: Weights = [5.50000000e+01 3.88829877e+00 8.17521046e+00 2.69347453e-02\n",
      " 2.72190501e-01 1.08035284e+01], Loss = 0.4496\n",
      "Iteration 2424: Weights = [5.50000000e+01 3.88818716e+00 8.17497578e+00 2.69339716e-02\n",
      " 2.72182687e-01 1.08037763e+01], Loss = 0.4496\n",
      "Iteration 2425: Weights = [5.50000000e+01 3.88807554e+00 8.17474111e+00 2.69331979e-02\n",
      " 2.72174874e-01 1.08040242e+01], Loss = 0.4496\n",
      "Iteration 2426: Weights = [5.50000000e+01 3.88796393e+00 8.17450644e+00 2.69324242e-02\n",
      " 2.72167062e-01 1.08042721e+01], Loss = 0.4496\n",
      "Iteration 2427: Weights = [5.50000000e+01 3.88785232e+00 8.17427178e+00 2.69316506e-02\n",
      " 2.72159249e-01 1.08045201e+01], Loss = 0.4495\n",
      "Iteration 2428: Weights = [5.50000000e+01 3.88774071e+00 8.17403713e+00 2.69308769e-02\n",
      " 2.72151437e-01 1.08047680e+01], Loss = 0.4495\n",
      "Iteration 2429: Weights = [5.50000000e+01 3.88762911e+00 8.17380248e+00 2.69301033e-02\n",
      " 2.72143624e-01 1.08050159e+01], Loss = 0.4495\n",
      "Iteration 2430: Weights = [5.50000000e+01 3.88751751e+00 8.17356784e+00 2.69293297e-02\n",
      " 2.72135813e-01 1.08052638e+01], Loss = 0.4495\n",
      "Iteration 2431: Weights = [5.50000000e+01 3.88740592e+00 8.17333321e+00 2.69285562e-02\n",
      " 2.72128001e-01 1.08055116e+01], Loss = 0.4494\n",
      "Iteration 2432: Weights = [5.50000000e+01 3.88729432e+00 8.17309858e+00 2.69277827e-02\n",
      " 2.72120189e-01 1.08057595e+01], Loss = 0.4494\n",
      "Iteration 2433: Weights = [5.50000000e+01 3.88718273e+00 8.17286396e+00 2.69270092e-02\n",
      " 2.72112378e-01 1.08060074e+01], Loss = 0.4494\n",
      "Iteration 2434: Weights = [5.50000000e+01 3.88707115e+00 8.17262935e+00 2.69262357e-02\n",
      " 2.72104567e-01 1.08062553e+01], Loss = 0.4494\n",
      "Iteration 2435: Weights = [5.50000000e+01 3.88695956e+00 8.17239475e+00 2.69254622e-02\n",
      " 2.72096756e-01 1.08065031e+01], Loss = 0.4493\n",
      "Iteration 2436: Weights = [5.50000000e+01 3.88684798e+00 8.17216015e+00 2.69246888e-02\n",
      " 2.72088946e-01 1.08067510e+01], Loss = 0.4493\n",
      "Iteration 2437: Weights = [5.50000000e+01 3.88673641e+00 8.17192555e+00 2.69239154e-02\n",
      " 2.72081135e-01 1.08069988e+01], Loss = 0.4493\n",
      "Iteration 2438: Weights = [5.50000000e+01 3.88662483e+00 8.17169097e+00 2.69231421e-02\n",
      " 2.72073325e-01 1.08072467e+01], Loss = 0.4493\n",
      "Iteration 2439: Weights = [5.50000000e+01 3.88651326e+00 8.17145639e+00 2.69223687e-02\n",
      " 2.72065515e-01 1.08074945e+01], Loss = 0.4492\n",
      "Iteration 2440: Weights = [5.50000000e+01 3.88640169e+00 8.17122182e+00 2.69215954e-02\n",
      " 2.72057705e-01 1.08077423e+01], Loss = 0.4492\n",
      "Iteration 2441: Weights = [5.50000000e+01 3.88629013e+00 8.17098725e+00 2.69208221e-02\n",
      " 2.72049896e-01 1.08079901e+01], Loss = 0.4492\n",
      "Iteration 2442: Weights = [5.50000000e+01 3.88617857e+00 8.17075269e+00 2.69200488e-02\n",
      " 2.72042087e-01 1.08082379e+01], Loss = 0.4491\n",
      "Iteration 2443: Weights = [5.50000000e+01 3.88606701e+00 8.17051814e+00 2.69192756e-02\n",
      " 2.72034278e-01 1.08084857e+01], Loss = 0.4491\n",
      "Iteration 2444: Weights = [5.50000000e+01 3.88595546e+00 8.17028359e+00 2.69185024e-02\n",
      " 2.72026469e-01 1.08087335e+01], Loss = 0.4491\n",
      "Iteration 2445: Weights = [5.50000000e+01 3.88584391e+00 8.17004906e+00 2.69177292e-02\n",
      " 2.72018660e-01 1.08089813e+01], Loss = 0.4491\n",
      "Iteration 2446: Weights = [5.50000000e+01 3.88573236e+00 8.16981452e+00 2.69169560e-02\n",
      " 2.72010852e-01 1.08092291e+01], Loss = 0.4490\n",
      "Iteration 2447: Weights = [5.50000000e+01 3.88562081e+00 8.16958000e+00 2.69161829e-02\n",
      " 2.72003044e-01 1.08094769e+01], Loss = 0.4490\n",
      "Iteration 2448: Weights = [5.50000000e+01 3.88550927e+00 8.16934548e+00 2.69154097e-02\n",
      " 2.71995236e-01 1.08097246e+01], Loss = 0.4490\n",
      "Iteration 2449: Weights = [5.50000000e+01 3.88539773e+00 8.16911097e+00 2.69146367e-02\n",
      " 2.71987428e-01 1.08099724e+01], Loss = 0.4490\n",
      "Iteration 2450: Weights = [5.50000000e+01 3.88528620e+00 8.16887646e+00 2.69138636e-02\n",
      " 2.71979620e-01 1.08102201e+01], Loss = 0.4489\n",
      "Iteration 2451: Weights = [5.50000000e+01 3.88517466e+00 8.16864197e+00 2.69130905e-02\n",
      " 2.71971813e-01 1.08104679e+01], Loss = 0.4489\n",
      "Iteration 2452: Weights = [5.50000000e+01 3.88506314e+00 8.16840747e+00 2.69123175e-02\n",
      " 2.71964006e-01 1.08107156e+01], Loss = 0.4489\n",
      "Iteration 2453: Weights = [5.50000000e+01 3.88495161e+00 8.16817299e+00 2.69115445e-02\n",
      " 2.71956199e-01 1.08109633e+01], Loss = 0.4489\n",
      "Iteration 2454: Weights = [5.50000000e+01 3.88484009e+00 8.16793851e+00 2.69107716e-02\n",
      " 2.71948393e-01 1.08112111e+01], Loss = 0.4488\n",
      "Iteration 2455: Weights = [5.50000000e+01 3.88472857e+00 8.16770404e+00 2.69099986e-02\n",
      " 2.71940586e-01 1.08114588e+01], Loss = 0.4488\n",
      "Iteration 2456: Weights = [5.50000000e+01 3.88461705e+00 8.16746958e+00 2.69092257e-02\n",
      " 2.71932780e-01 1.08117065e+01], Loss = 0.4488\n",
      "Iteration 2457: Weights = [5.50000000e+01 3.88450554e+00 8.16723512e+00 2.69084528e-02\n",
      " 2.71924974e-01 1.08119542e+01], Loss = 0.4488\n",
      "Iteration 2458: Weights = [5.50000000e+01 3.88439403e+00 8.16700067e+00 2.69076800e-02\n",
      " 2.71917169e-01 1.08122019e+01], Loss = 0.4487\n",
      "Iteration 2459: Weights = [5.50000000e+01 3.88428252e+00 8.16676622e+00 2.69069071e-02\n",
      " 2.71909363e-01 1.08124496e+01], Loss = 0.4487\n",
      "Iteration 2460: Weights = [5.50000000e+01 3.88417102e+00 8.16653178e+00 2.69061343e-02\n",
      " 2.71901558e-01 1.08126973e+01], Loss = 0.4487\n",
      "Iteration 2461: Weights = [5.50000000e+01 3.88405952e+00 8.16629735e+00 2.69053615e-02\n",
      " 2.71893753e-01 1.08129449e+01], Loss = 0.4487\n",
      "Iteration 2462: Weights = [5.50000000e+01 3.88394802e+00 8.16606293e+00 2.69045888e-02\n",
      " 2.71885948e-01 1.08131926e+01], Loss = 0.4486\n",
      "Iteration 2463: Weights = [5.50000000e+01 3.88383653e+00 8.16582851e+00 2.69038160e-02\n",
      " 2.71878143e-01 1.08134402e+01], Loss = 0.4486\n",
      "Iteration 2464: Weights = [5.50000000e+01 3.88372504e+00 8.16559410e+00 2.69030433e-02\n",
      " 2.71870339e-01 1.08136879e+01], Loss = 0.4486\n",
      "Iteration 2465: Weights = [5.50000000e+01 3.88361355e+00 8.16535970e+00 2.69022707e-02\n",
      " 2.71862535e-01 1.08139355e+01], Loss = 0.4486\n",
      "Iteration 2466: Weights = [5.50000000e+01 3.88350207e+00 8.16512530e+00 2.69014980e-02\n",
      " 2.71854731e-01 1.08141832e+01], Loss = 0.4485\n",
      "Iteration 2467: Weights = [5.50000000e+01 3.88339059e+00 8.16489091e+00 2.69007254e-02\n",
      " 2.71846927e-01 1.08144308e+01], Loss = 0.4485\n",
      "Iteration 2468: Weights = [5.50000000e+01 3.88327911e+00 8.16465653e+00 2.68999527e-02\n",
      " 2.71839124e-01 1.08146784e+01], Loss = 0.4485\n",
      "Iteration 2469: Weights = [5.50000000e+01 3.88316763e+00 8.16442215e+00 2.68991802e-02\n",
      " 2.71831320e-01 1.08149261e+01], Loss = 0.4485\n",
      "Iteration 2470: Weights = [5.50000000e+01 3.88305616e+00 8.16418778e+00 2.68984076e-02\n",
      " 2.71823517e-01 1.08151737e+01], Loss = 0.4484\n",
      "Iteration 2471: Weights = [5.50000000e+01 3.88294469e+00 8.16395341e+00 2.68976351e-02\n",
      " 2.71815715e-01 1.08154213e+01], Loss = 0.4484\n",
      "Iteration 2472: Weights = [5.50000000e+01 3.88283323e+00 8.16371906e+00 2.68968626e-02\n",
      " 2.71807912e-01 1.08156689e+01], Loss = 0.4484\n",
      "Iteration 2473: Weights = [5.50000000e+01 3.88272177e+00 8.16348471e+00 2.68960901e-02\n",
      " 2.71800110e-01 1.08159164e+01], Loss = 0.4483\n",
      "Iteration 2474: Weights = [5.50000000e+01 3.88261031e+00 8.16325036e+00 2.68953176e-02\n",
      " 2.71792307e-01 1.08161640e+01], Loss = 0.4483\n",
      "Iteration 2475: Weights = [5.50000000e+01 3.88249885e+00 8.16301603e+00 2.68945452e-02\n",
      " 2.71784505e-01 1.08164116e+01], Loss = 0.4483\n",
      "Iteration 2476: Weights = [5.50000000e+01 3.88238740e+00 8.16278170e+00 2.68937728e-02\n",
      " 2.71776704e-01 1.08166592e+01], Loss = 0.4483\n",
      "Iteration 2477: Weights = [5.50000000e+01 3.88227595e+00 8.16254737e+00 2.68930004e-02\n",
      " 2.71768902e-01 1.08169067e+01], Loss = 0.4482\n",
      "Iteration 2478: Weights = [5.50000000e+01 3.88216451e+00 8.16231306e+00 2.68922280e-02\n",
      " 2.71761101e-01 1.08171543e+01], Loss = 0.4482\n",
      "Iteration 2479: Weights = [5.50000000e+01 3.88205307e+00 8.16207875e+00 2.68914557e-02\n",
      " 2.71753300e-01 1.08174018e+01], Loss = 0.4482\n",
      "Iteration 2480: Weights = [5.50000000e+01 3.88194163e+00 8.16184444e+00 2.68906834e-02\n",
      " 2.71745499e-01 1.08176494e+01], Loss = 0.4482\n",
      "Iteration 2481: Weights = [5.50000000e+01 3.88183019e+00 8.16161015e+00 2.68899111e-02\n",
      " 2.71737699e-01 1.08178969e+01], Loss = 0.4481\n",
      "Iteration 2482: Weights = [5.50000000e+01 3.88171876e+00 8.16137586e+00 2.68891388e-02\n",
      " 2.71729898e-01 1.08181444e+01], Loss = 0.4481\n",
      "Iteration 2483: Weights = [5.50000000e+01 3.88160733e+00 8.16114158e+00 2.68883666e-02\n",
      " 2.71722098e-01 1.08183919e+01], Loss = 0.4481\n",
      "Iteration 2484: Weights = [5.50000000e+01 3.88149590e+00 8.16090730e+00 2.68875944e-02\n",
      " 2.71714298e-01 1.08186394e+01], Loss = 0.4481\n",
      "Iteration 2485: Weights = [5.50000000e+01 3.88138448e+00 8.16067303e+00 2.68868222e-02\n",
      " 2.71706498e-01 1.08188869e+01], Loss = 0.4480\n",
      "Iteration 2486: Weights = [5.50000000e+01 3.88127306e+00 8.16043877e+00 2.68860500e-02\n",
      " 2.71698699e-01 1.08191344e+01], Loss = 0.4480\n",
      "Iteration 2487: Weights = [5.50000000e+01 3.88116164e+00 8.16020451e+00 2.68852779e-02\n",
      " 2.71690900e-01 1.08193819e+01], Loss = 0.4480\n",
      "Iteration 2488: Weights = [5.50000000e+01 3.88105023e+00 8.15997026e+00 2.68845058e-02\n",
      " 2.71683101e-01 1.08196294e+01], Loss = 0.4480\n",
      "Iteration 2489: Weights = [5.50000000e+01 3.88093882e+00 8.15973602e+00 2.68837337e-02\n",
      " 2.71675302e-01 1.08198769e+01], Loss = 0.4479\n",
      "Iteration 2490: Weights = [5.50000000e+01 3.88082741e+00 8.15950178e+00 2.68829616e-02\n",
      " 2.71667503e-01 1.08201243e+01], Loss = 0.4479\n",
      "Iteration 2491: Weights = [5.50000000e+01 3.88071600e+00 8.15926755e+00 2.68821896e-02\n",
      " 2.71659705e-01 1.08203718e+01], Loss = 0.4479\n",
      "Iteration 2492: Weights = [5.50000000e+01 3.88060460e+00 8.15903333e+00 2.68814175e-02\n",
      " 2.71651907e-01 1.08206193e+01], Loss = 0.4479\n",
      "Iteration 2493: Weights = [5.50000000e+01 3.88049321e+00 8.15879912e+00 2.68806456e-02\n",
      " 2.71644109e-01 1.08208667e+01], Loss = 0.4478\n",
      "Iteration 2494: Weights = [5.50000000e+01 3.88038181e+00 8.15856491e+00 2.68798736e-02\n",
      " 2.71636311e-01 1.08211141e+01], Loss = 0.4478\n",
      "Iteration 2495: Weights = [5.50000000e+01 3.88027042e+00 8.15833070e+00 2.68791016e-02\n",
      " 2.71628514e-01 1.08213616e+01], Loss = 0.4478\n",
      "Iteration 2496: Weights = [5.50000000e+01 3.88015903e+00 8.15809651e+00 2.68783297e-02\n",
      " 2.71620716e-01 1.08216090e+01], Loss = 0.4478\n",
      "Iteration 2497: Weights = [5.50000000e+01 3.88004765e+00 8.15786232e+00 2.68775578e-02\n",
      " 2.71612919e-01 1.08218564e+01], Loss = 0.4477\n",
      "Iteration 2498: Weights = [5.50000000e+01 3.87993627e+00 8.15762814e+00 2.68767860e-02\n",
      " 2.71605122e-01 1.08221038e+01], Loss = 0.4477\n",
      "Iteration 2499: Weights = [5.50000000e+01 3.87982489e+00 8.15739396e+00 2.68760141e-02\n",
      " 2.71597326e-01 1.08223512e+01], Loss = 0.4477\n",
      "Iteration 2500: Weights = [5.50000000e+01 3.87971351e+00 8.15715979e+00 2.68752423e-02\n",
      " 2.71589529e-01 1.08225986e+01], Loss = 0.4477\n",
      "Iteration 2501: Weights = [5.50000000e+01 3.87960214e+00 8.15692563e+00 2.68744705e-02\n",
      " 2.71581733e-01 1.08228460e+01], Loss = 0.4476\n",
      "Iteration 2502: Weights = [5.50000000e+01 3.87949077e+00 8.15669148e+00 2.68736987e-02\n",
      " 2.71573937e-01 1.08230934e+01], Loss = 0.4476\n",
      "Iteration 2503: Weights = [5.50000000e+01 3.87937940e+00 8.15645733e+00 2.68729270e-02\n",
      " 2.71566142e-01 1.08233408e+01], Loss = 0.4476\n",
      "Iteration 2504: Weights = [5.50000000e+01 3.87926804e+00 8.15622319e+00 2.68721553e-02\n",
      " 2.71558346e-01 1.08235881e+01], Loss = 0.4476\n",
      "Iteration 2505: Weights = [5.50000000e+01 3.87915668e+00 8.15598905e+00 2.68713836e-02\n",
      " 2.71550551e-01 1.08238355e+01], Loss = 0.4475\n",
      "Iteration 2506: Weights = [5.50000000e+01 3.87904533e+00 8.15575492e+00 2.68706119e-02\n",
      " 2.71542756e-01 1.08240828e+01], Loss = 0.4475\n",
      "Iteration 2507: Weights = [5.50000000e+01 3.87893397e+00 8.15552080e+00 2.68698402e-02\n",
      " 2.71534961e-01 1.08243302e+01], Loss = 0.4475\n",
      "Iteration 2508: Weights = [5.50000000e+01 3.87882262e+00 8.15528669e+00 2.68690686e-02\n",
      " 2.71527166e-01 1.08245775e+01], Loss = 0.4474\n",
      "Iteration 2509: Weights = [5.50000000e+01 3.87871128e+00 8.15505258e+00 2.68682970e-02\n",
      " 2.71519372e-01 1.08248249e+01], Loss = 0.4474\n",
      "Iteration 2510: Weights = [5.50000000e+01 3.87859993e+00 8.15481848e+00 2.68675254e-02\n",
      " 2.71511578e-01 1.08250722e+01], Loss = 0.4474\n",
      "Iteration 2511: Weights = [5.50000000e+01 3.87848859e+00 8.15458438e+00 2.68667539e-02\n",
      " 2.71503784e-01 1.08253195e+01], Loss = 0.4474\n",
      "Iteration 2512: Weights = [5.50000000e+01 3.87837726e+00 8.15435029e+00 2.68659824e-02\n",
      " 2.71495990e-01 1.08255668e+01], Loss = 0.4473\n",
      "Iteration 2513: Weights = [5.50000000e+01 3.87826592e+00 8.15411621e+00 2.68652108e-02\n",
      " 2.71488197e-01 1.08258141e+01], Loss = 0.4473\n",
      "Iteration 2514: Weights = [5.50000000e+01 3.87815459e+00 8.15388214e+00 2.68644394e-02\n",
      " 2.71480404e-01 1.08260614e+01], Loss = 0.4473\n",
      "Iteration 2515: Weights = [5.50000000e+01 3.87804326e+00 8.15364807e+00 2.68636679e-02\n",
      " 2.71472611e-01 1.08263087e+01], Loss = 0.4473\n",
      "Iteration 2516: Weights = [5.50000000e+01 3.87793194e+00 8.15341401e+00 2.68628965e-02\n",
      " 2.71464818e-01 1.08265560e+01], Loss = 0.4472\n",
      "Iteration 2517: Weights = [5.50000000e+01 3.87782062e+00 8.15317996e+00 2.68621251e-02\n",
      " 2.71457025e-01 1.08268033e+01], Loss = 0.4472\n",
      "Iteration 2518: Weights = [5.50000000e+01 3.87770930e+00 8.15294591e+00 2.68613537e-02\n",
      " 2.71449233e-01 1.08270505e+01], Loss = 0.4472\n",
      "Iteration 2519: Weights = [5.50000000e+01 3.87759799e+00 8.15271187e+00 2.68605823e-02\n",
      " 2.71441441e-01 1.08272978e+01], Loss = 0.4472\n",
      "Iteration 2520: Weights = [5.50000000e+01 3.87748668e+00 8.15247783e+00 2.68598110e-02\n",
      " 2.71433649e-01 1.08275450e+01], Loss = 0.4471\n",
      "Iteration 2521: Weights = [5.50000000e+01 3.87737537e+00 8.15224381e+00 2.68590397e-02\n",
      " 2.71425857e-01 1.08277923e+01], Loss = 0.4471\n",
      "Iteration 2522: Weights = [5.50000000e+01 3.87726406e+00 8.15200978e+00 2.68582684e-02\n",
      " 2.71418066e-01 1.08280395e+01], Loss = 0.4471\n",
      "Iteration 2523: Weights = [5.50000000e+01 3.87715276e+00 8.15177577e+00 2.68574971e-02\n",
      " 2.71410274e-01 1.08282868e+01], Loss = 0.4471\n",
      "Iteration 2524: Weights = [5.50000000e+01 3.87704146e+00 8.15154176e+00 2.68567259e-02\n",
      " 2.71402483e-01 1.08285340e+01], Loss = 0.4470\n",
      "Iteration 2525: Weights = [5.50000000e+01 3.87693017e+00 8.15130776e+00 2.68559547e-02\n",
      " 2.71394692e-01 1.08287812e+01], Loss = 0.4470\n",
      "Iteration 2526: Weights = [5.50000000e+01 3.87681887e+00 8.15107377e+00 2.68551835e-02\n",
      " 2.71386902e-01 1.08290284e+01], Loss = 0.4470\n",
      "Iteration 2527: Weights = [5.50000000e+01 3.87670758e+00 8.15083978e+00 2.68544123e-02\n",
      " 2.71379111e-01 1.08292756e+01], Loss = 0.4470\n",
      "Iteration 2528: Weights = [5.50000000e+01 3.87659630e+00 8.15060580e+00 2.68536412e-02\n",
      " 2.71371321e-01 1.08295228e+01], Loss = 0.4469\n",
      "Iteration 2529: Weights = [5.50000000e+01 3.87648502e+00 8.15037183e+00 2.68528701e-02\n",
      " 2.71363531e-01 1.08297700e+01], Loss = 0.4469\n",
      "Iteration 2530: Weights = [5.50000000e+01 3.87637374e+00 8.15013786e+00 2.68520990e-02\n",
      " 2.71355742e-01 1.08300172e+01], Loss = 0.4469\n",
      "Iteration 2531: Weights = [5.50000000e+01 3.87626246e+00 8.14990390e+00 2.68513279e-02\n",
      " 2.71347952e-01 1.08302644e+01], Loss = 0.4469\n",
      "Iteration 2532: Weights = [5.50000000e+01 3.87615119e+00 8.14966995e+00 2.68505568e-02\n",
      " 2.71340163e-01 1.08305115e+01], Loss = 0.4468\n",
      "Iteration 2533: Weights = [5.50000000e+01 3.87603992e+00 8.14943600e+00 2.68497858e-02\n",
      " 2.71332374e-01 1.08307587e+01], Loss = 0.4468\n",
      "Iteration 2534: Weights = [5.50000000e+01 3.87592865e+00 8.14920206e+00 2.68490148e-02\n",
      " 2.71324585e-01 1.08310058e+01], Loss = 0.4468\n",
      "Iteration 2535: Weights = [5.50000000e+01 3.87581739e+00 8.14896813e+00 2.68482438e-02\n",
      " 2.71316797e-01 1.08312530e+01], Loss = 0.4468\n",
      "Iteration 2536: Weights = [5.50000000e+01 3.87570613e+00 8.14873420e+00 2.68474729e-02\n",
      " 2.71309008e-01 1.08315001e+01], Loss = 0.4467\n",
      "Iteration 2537: Weights = [5.50000000e+01 3.87559487e+00 8.14850028e+00 2.68467020e-02\n",
      " 2.71301220e-01 1.08317473e+01], Loss = 0.4467\n",
      "Iteration 2538: Weights = [5.50000000e+01 3.87548362e+00 8.14826637e+00 2.68459311e-02\n",
      " 2.71293432e-01 1.08319944e+01], Loss = 0.4467\n",
      "Iteration 2539: Weights = [5.50000000e+01 3.87537236e+00 8.14803246e+00 2.68451602e-02\n",
      " 2.71285644e-01 1.08322415e+01], Loss = 0.4467\n",
      "Iteration 2540: Weights = [5.50000000e+01 3.87526112e+00 8.14779856e+00 2.68443893e-02\n",
      " 2.71277857e-01 1.08324886e+01], Loss = 0.4466\n",
      "Iteration 2541: Weights = [5.50000000e+01 3.87514987e+00 8.14756467e+00 2.68436185e-02\n",
      " 2.71270070e-01 1.08327357e+01], Loss = 0.4466\n",
      "Iteration 2542: Weights = [5.50000000e+01 3.87503863e+00 8.14733078e+00 2.68428477e-02\n",
      " 2.71262283e-01 1.08329828e+01], Loss = 0.4466\n",
      "Iteration 2543: Weights = [5.50000000e+01 3.87492739e+00 8.14709690e+00 2.68420769e-02\n",
      " 2.71254496e-01 1.08332299e+01], Loss = 0.4466\n",
      "Iteration 2544: Weights = [5.50000000e+01 3.87481616e+00 8.14686303e+00 2.68413061e-02\n",
      " 2.71246709e-01 1.08334770e+01], Loss = 0.4465\n",
      "Iteration 2545: Weights = [5.50000000e+01 3.87470493e+00 8.14662916e+00 2.68405354e-02\n",
      " 2.71238923e-01 1.08337241e+01], Loss = 0.4465\n",
      "Iteration 2546: Weights = [5.50000000e+01 3.87459370e+00 8.14639530e+00 2.68397647e-02\n",
      " 2.71231137e-01 1.08339711e+01], Loss = 0.4465\n",
      "Iteration 2547: Weights = [5.50000000e+01 3.87448247e+00 8.14616145e+00 2.68389940e-02\n",
      " 2.71223351e-01 1.08342182e+01], Loss = 0.4464\n",
      "Iteration 2548: Weights = [5.50000000e+01 3.87437125e+00 8.14592760e+00 2.68382233e-02\n",
      " 2.71215565e-01 1.08344653e+01], Loss = 0.4464\n",
      "Iteration 2549: Weights = [5.50000000e+01 3.87426003e+00 8.14569376e+00 2.68374527e-02\n",
      " 2.71207780e-01 1.08347123e+01], Loss = 0.4464\n",
      "Iteration 2550: Weights = [5.50000000e+01 3.87414882e+00 8.14545993e+00 2.68366821e-02\n",
      " 2.71199994e-01 1.08349593e+01], Loss = 0.4464\n",
      "Iteration 2551: Weights = [5.50000000e+01 3.87403760e+00 8.14522610e+00 2.68359115e-02\n",
      " 2.71192209e-01 1.08352064e+01], Loss = 0.4463\n",
      "Iteration 2552: Weights = [5.50000000e+01 3.87392639e+00 8.14499228e+00 2.68351409e-02\n",
      " 2.71184425e-01 1.08354534e+01], Loss = 0.4463\n",
      "Iteration 2553: Weights = [5.50000000e+01 3.87381519e+00 8.14475847e+00 2.68343704e-02\n",
      " 2.71176640e-01 1.08357004e+01], Loss = 0.4463\n",
      "Iteration 2554: Weights = [5.50000000e+01 3.87370399e+00 8.14452467e+00 2.68335998e-02\n",
      " 2.71168856e-01 1.08359474e+01], Loss = 0.4463\n",
      "Iteration 2555: Weights = [5.50000000e+01 3.87359279e+00 8.14429087e+00 2.68328293e-02\n",
      " 2.71161072e-01 1.08361944e+01], Loss = 0.4462\n",
      "Iteration 2556: Weights = [5.50000000e+01 3.87348159e+00 8.14405707e+00 2.68320589e-02\n",
      " 2.71153288e-01 1.08364414e+01], Loss = 0.4462\n",
      "Iteration 2557: Weights = [5.50000000e+01 3.87337040e+00 8.14382329e+00 2.68312884e-02\n",
      " 2.71145504e-01 1.08366884e+01], Loss = 0.4462\n",
      "Iteration 2558: Weights = [5.50000000e+01 3.87325921e+00 8.14358951e+00 2.68305180e-02\n",
      " 2.71137721e-01 1.08369354e+01], Loss = 0.4462\n",
      "Iteration 2559: Weights = [5.50000000e+01 3.87314802e+00 8.14335574e+00 2.68297476e-02\n",
      " 2.71129937e-01 1.08371824e+01], Loss = 0.4461\n",
      "Iteration 2560: Weights = [5.50000000e+01 3.87303684e+00 8.14312197e+00 2.68289772e-02\n",
      " 2.71122154e-01 1.08374294e+01], Loss = 0.4461\n",
      "Iteration 2561: Weights = [5.50000000e+01 3.87292566e+00 8.14288821e+00 2.68282068e-02\n",
      " 2.71114371e-01 1.08376763e+01], Loss = 0.4461\n",
      "Iteration 2562: Weights = [5.50000000e+01 3.87281448e+00 8.14265446e+00 2.68274365e-02\n",
      " 2.71106589e-01 1.08379233e+01], Loss = 0.4461\n",
      "Iteration 2563: Weights = [5.50000000e+01 3.87270330e+00 8.14242071e+00 2.68266662e-02\n",
      " 2.71098807e-01 1.08381702e+01], Loss = 0.4460\n",
      "Iteration 2564: Weights = [5.50000000e+01 3.87259213e+00 8.14218697e+00 2.68258959e-02\n",
      " 2.71091024e-01 1.08384172e+01], Loss = 0.4460\n",
      "Iteration 2565: Weights = [5.50000000e+01 3.87248097e+00 8.14195324e+00 2.68251256e-02\n",
      " 2.71083242e-01 1.08386641e+01], Loss = 0.4460\n",
      "Iteration 2566: Weights = [5.50000000e+01 3.87236980e+00 8.14171952e+00 2.68243554e-02\n",
      " 2.71075461e-01 1.08389110e+01], Loss = 0.4460\n",
      "Iteration 2567: Weights = [5.50000000e+01 3.87225864e+00 8.14148580e+00 2.68235852e-02\n",
      " 2.71067679e-01 1.08391579e+01], Loss = 0.4459\n",
      "Iteration 2568: Weights = [5.50000000e+01 3.87214748e+00 8.14125209e+00 2.68228150e-02\n",
      " 2.71059898e-01 1.08394049e+01], Loss = 0.4459\n",
      "Iteration 2569: Weights = [5.50000000e+01 3.87203633e+00 8.14101838e+00 2.68220448e-02\n",
      " 2.71052117e-01 1.08396518e+01], Loss = 0.4459\n",
      "Iteration 2570: Weights = [5.50000000e+01 3.87192517e+00 8.14078468e+00 2.68212747e-02\n",
      " 2.71044336e-01 1.08398987e+01], Loss = 0.4459\n",
      "Iteration 2571: Weights = [5.50000000e+01 3.87181403e+00 8.14055099e+00 2.68205045e-02\n",
      " 2.71036556e-01 1.08401456e+01], Loss = 0.4458\n",
      "Iteration 2572: Weights = [5.50000000e+01 3.87170288e+00 8.14031731e+00 2.68197344e-02\n",
      " 2.71028775e-01 1.08403924e+01], Loss = 0.4458\n",
      "Iteration 2573: Weights = [5.50000000e+01 3.87159174e+00 8.14008363e+00 2.68189644e-02\n",
      " 2.71020995e-01 1.08406393e+01], Loss = 0.4458\n",
      "Iteration 2574: Weights = [5.50000000e+01 3.87148060e+00 8.13984996e+00 2.68181943e-02\n",
      " 2.71013215e-01 1.08408862e+01], Loss = 0.4458\n",
      "Iteration 2575: Weights = [5.50000000e+01 3.87136946e+00 8.13961629e+00 2.68174243e-02\n",
      " 2.71005436e-01 1.08411331e+01], Loss = 0.4457\n",
      "Iteration 2576: Weights = [5.50000000e+01 3.87125833e+00 8.13938263e+00 2.68166543e-02\n",
      " 2.70997656e-01 1.08413799e+01], Loss = 0.4457\n",
      "Iteration 2577: Weights = [5.50000000e+01 3.87114720e+00 8.13914898e+00 2.68158843e-02\n",
      " 2.70989877e-01 1.08416268e+01], Loss = 0.4457\n",
      "Iteration 2578: Weights = [5.50000000e+01 3.87103607e+00 8.13891534e+00 2.68151143e-02\n",
      " 2.70982098e-01 1.08418736e+01], Loss = 0.4457\n",
      "Iteration 2579: Weights = [5.50000000e+01 3.87092495e+00 8.13868170e+00 2.68143444e-02\n",
      " 2.70974319e-01 1.08421204e+01], Loss = 0.4456\n",
      "Iteration 2580: Weights = [5.50000000e+01 3.87081383e+00 8.13844807e+00 2.68135745e-02\n",
      " 2.70966541e-01 1.08423673e+01], Loss = 0.4456\n",
      "Iteration 2581: Weights = [5.50000000e+01 3.87070271e+00 8.13821444e+00 2.68128046e-02\n",
      " 2.70958762e-01 1.08426141e+01], Loss = 0.4456\n",
      "Iteration 2582: Weights = [5.50000000e+01 3.87059160e+00 8.13798082e+00 2.68120347e-02\n",
      " 2.70950984e-01 1.08428609e+01], Loss = 0.4456\n",
      "Iteration 2583: Weights = [5.50000000e+01 3.87048049e+00 8.13774721e+00 2.68112649e-02\n",
      " 2.70943206e-01 1.08431077e+01], Loss = 0.4455\n",
      "Iteration 2584: Weights = [5.50000000e+01 3.87036938e+00 8.13751361e+00 2.68104950e-02\n",
      " 2.70935429e-01 1.08433545e+01], Loss = 0.4455\n",
      "Iteration 2585: Weights = [5.50000000e+01 3.87025828e+00 8.13728001e+00 2.68097253e-02\n",
      " 2.70927651e-01 1.08436013e+01], Loss = 0.4455\n",
      "Iteration 2586: Weights = [5.50000000e+01 3.87014718e+00 8.13704642e+00 2.68089555e-02\n",
      " 2.70919874e-01 1.08438481e+01], Loss = 0.4455\n",
      "Iteration 2587: Weights = [5.50000000e+01 3.87003608e+00 8.13681283e+00 2.68081857e-02\n",
      " 2.70912097e-01 1.08440949e+01], Loss = 0.4454\n",
      "Iteration 2588: Weights = [5.50000000e+01 3.86992499e+00 8.13657926e+00 2.68074160e-02\n",
      " 2.70904320e-01 1.08443416e+01], Loss = 0.4454\n",
      "Iteration 2589: Weights = [5.50000000e+01 3.86981390e+00 8.13634568e+00 2.68066463e-02\n",
      " 2.70896543e-01 1.08445884e+01], Loss = 0.4454\n",
      "Iteration 2590: Weights = [5.50000000e+01 3.86970281e+00 8.13611212e+00 2.68058766e-02\n",
      " 2.70888767e-01 1.08448352e+01], Loss = 0.4453\n",
      "Iteration 2591: Weights = [5.50000000e+01 3.86959172e+00 8.13587856e+00 2.68051070e-02\n",
      " 2.70880991e-01 1.08450819e+01], Loss = 0.4453\n",
      "Iteration 2592: Weights = [5.50000000e+01 3.86948064e+00 8.13564501e+00 2.68043373e-02\n",
      " 2.70873215e-01 1.08453286e+01], Loss = 0.4453\n",
      "Iteration 2593: Weights = [5.50000000e+01 3.86936956e+00 8.13541147e+00 2.68035677e-02\n",
      " 2.70865439e-01 1.08455754e+01], Loss = 0.4453\n",
      "Iteration 2594: Weights = [5.50000000e+01 3.86925849e+00 8.13517793e+00 2.68027981e-02\n",
      " 2.70857664e-01 1.08458221e+01], Loss = 0.4452\n",
      "Iteration 2595: Weights = [5.50000000e+01 3.86914742e+00 8.13494440e+00 2.68020286e-02\n",
      " 2.70849889e-01 1.08460688e+01], Loss = 0.4452\n",
      "Iteration 2596: Weights = [5.50000000e+01 3.86903635e+00 8.13471087e+00 2.68012590e-02\n",
      " 2.70842114e-01 1.08463155e+01], Loss = 0.4452\n",
      "Iteration 2597: Weights = [5.50000000e+01 3.86892528e+00 8.13447736e+00 2.68004895e-02\n",
      " 2.70834339e-01 1.08465623e+01], Loss = 0.4452\n",
      "Iteration 2598: Weights = [5.50000000e+01 3.86881422e+00 8.13424385e+00 2.67997200e-02\n",
      " 2.70826564e-01 1.08468090e+01], Loss = 0.4451\n",
      "Iteration 2599: Weights = [5.50000000e+01 3.86870316e+00 8.13401034e+00 2.67989505e-02\n",
      " 2.70818790e-01 1.08470557e+01], Loss = 0.4451\n",
      "Iteration 2600: Weights = [5.50000000e+01 3.86859210e+00 8.13377684e+00 2.67981811e-02\n",
      " 2.70811016e-01 1.08473023e+01], Loss = 0.4451\n",
      "Iteration 2601: Weights = [5.50000000e+01 3.86848105e+00 8.13354335e+00 2.67974117e-02\n",
      " 2.70803242e-01 1.08475490e+01], Loss = 0.4451\n",
      "Iteration 2602: Weights = [5.50000000e+01 3.86837000e+00 8.13330987e+00 2.67966423e-02\n",
      " 2.70795468e-01 1.08477957e+01], Loss = 0.4450\n",
      "Iteration 2603: Weights = [5.50000000e+01 3.86825895e+00 8.13307639e+00 2.67958729e-02\n",
      " 2.70787695e-01 1.08480424e+01], Loss = 0.4450\n",
      "Iteration 2604: Weights = [5.50000000e+01 3.86814791e+00 8.13284292e+00 2.67951035e-02\n",
      " 2.70779922e-01 1.08482890e+01], Loss = 0.4450\n",
      "Iteration 2605: Weights = [5.50000000e+01 3.86803687e+00 8.13260946e+00 2.67943342e-02\n",
      " 2.70772149e-01 1.08485357e+01], Loss = 0.4450\n",
      "Iteration 2606: Weights = [5.50000000e+01 3.86792583e+00 8.13237600e+00 2.67935649e-02\n",
      " 2.70764376e-01 1.08487823e+01], Loss = 0.4449\n",
      "Iteration 2607: Weights = [5.50000000e+01 3.86781480e+00 8.13214255e+00 2.67927956e-02\n",
      " 2.70756603e-01 1.08490289e+01], Loss = 0.4449\n",
      "Iteration 2608: Weights = [5.50000000e+01 3.86770377e+00 8.13190911e+00 2.67920263e-02\n",
      " 2.70748831e-01 1.08492756e+01], Loss = 0.4449\n",
      "Iteration 2609: Weights = [5.50000000e+01 3.86759274e+00 8.13167567e+00 2.67912571e-02\n",
      " 2.70741059e-01 1.08495222e+01], Loss = 0.4449\n",
      "Iteration 2610: Weights = [5.50000000e+01 3.86748172e+00 8.13144224e+00 2.67904879e-02\n",
      " 2.70733287e-01 1.08497688e+01], Loss = 0.4448\n",
      "Iteration 2611: Weights = [5.50000000e+01 3.86737070e+00 8.13120882e+00 2.67897187e-02\n",
      " 2.70725515e-01 1.08500154e+01], Loss = 0.4448\n",
      "Iteration 2612: Weights = [5.50000000e+01 3.86725968e+00 8.13097540e+00 2.67889495e-02\n",
      " 2.70717744e-01 1.08502620e+01], Loss = 0.4448\n",
      "Iteration 2613: Weights = [5.50000000e+01 3.86714866e+00 8.13074199e+00 2.67881804e-02\n",
      " 2.70709973e-01 1.08505086e+01], Loss = 0.4448\n",
      "Iteration 2614: Weights = [5.50000000e+01 3.86703765e+00 8.13050858e+00 2.67874112e-02\n",
      " 2.70702202e-01 1.08507552e+01], Loss = 0.4447\n",
      "Iteration 2615: Weights = [5.50000000e+01 3.86692664e+00 8.13027519e+00 2.67866421e-02\n",
      " 2.70694431e-01 1.08510018e+01], Loss = 0.4447\n",
      "Iteration 2616: Weights = [5.50000000e+01 3.86681564e+00 8.13004180e+00 2.67858731e-02\n",
      " 2.70686660e-01 1.08512484e+01], Loss = 0.4447\n",
      "Iteration 2617: Weights = [5.50000000e+01 3.86670464e+00 8.12980841e+00 2.67851040e-02\n",
      " 2.70678890e-01 1.08514949e+01], Loss = 0.4447\n",
      "Iteration 2618: Weights = [5.50000000e+01 3.86659364e+00 8.12957504e+00 2.67843350e-02\n",
      " 2.70671120e-01 1.08517415e+01], Loss = 0.4446\n",
      "Iteration 2619: Weights = [5.50000000e+01 3.86648264e+00 8.12934167e+00 2.67835660e-02\n",
      " 2.70663350e-01 1.08519880e+01], Loss = 0.4446\n",
      "Iteration 2620: Weights = [5.50000000e+01 3.86637165e+00 8.12910830e+00 2.67827970e-02\n",
      " 2.70655580e-01 1.08522346e+01], Loss = 0.4446\n",
      "Iteration 2621: Weights = [5.50000000e+01 3.86626066e+00 8.12887495e+00 2.67820280e-02\n",
      " 2.70647811e-01 1.08524811e+01], Loss = 0.4446\n",
      "Iteration 2622: Weights = [5.50000000e+01 3.86614967e+00 8.12864160e+00 2.67812591e-02\n",
      " 2.70640042e-01 1.08527276e+01], Loss = 0.4445\n",
      "Iteration 2623: Weights = [5.50000000e+01 3.86603869e+00 8.12840825e+00 2.67804902e-02\n",
      " 2.70632273e-01 1.08529742e+01], Loss = 0.4445\n",
      "Iteration 2624: Weights = [5.50000000e+01 3.86592771e+00 8.12817492e+00 2.67797213e-02\n",
      " 2.70624504e-01 1.08532207e+01], Loss = 0.4445\n",
      "Iteration 2625: Weights = [5.50000000e+01 3.86581673e+00 8.12794159e+00 2.67789524e-02\n",
      " 2.70616735e-01 1.08534672e+01], Loss = 0.4445\n",
      "Iteration 2626: Weights = [5.50000000e+01 3.86570576e+00 8.12770826e+00 2.67781836e-02\n",
      " 2.70608967e-01 1.08537137e+01], Loss = 0.4444\n",
      "Iteration 2627: Weights = [5.50000000e+01 3.86559479e+00 8.12747495e+00 2.67774147e-02\n",
      " 2.70601199e-01 1.08539602e+01], Loss = 0.4444\n",
      "Iteration 2628: Weights = [5.50000000e+01 3.86548382e+00 8.12724164e+00 2.67766459e-02\n",
      " 2.70593431e-01 1.08542067e+01], Loss = 0.4444\n",
      "Iteration 2629: Weights = [5.50000000e+01 3.86537286e+00 8.12700834e+00 2.67758771e-02\n",
      " 2.70585663e-01 1.08544532e+01], Loss = 0.4444\n",
      "Iteration 2630: Weights = [5.50000000e+01 3.86526190e+00 8.12677504e+00 2.67751084e-02\n",
      " 2.70577896e-01 1.08546996e+01], Loss = 0.4443\n",
      "Iteration 2631: Weights = [5.50000000e+01 3.86515094e+00 8.12654175e+00 2.67743397e-02\n",
      " 2.70570129e-01 1.08549461e+01], Loss = 0.4443\n",
      "Iteration 2632: Weights = [5.50000000e+01 3.86503999e+00 8.12630847e+00 2.67735709e-02\n",
      " 2.70562362e-01 1.08551926e+01], Loss = 0.4443\n",
      "Iteration 2633: Weights = [5.50000000e+01 3.86492904e+00 8.12607519e+00 2.67728023e-02\n",
      " 2.70554595e-01 1.08554390e+01], Loss = 0.4443\n",
      "Iteration 2634: Weights = [5.50000000e+01 3.86481809e+00 8.12584192e+00 2.67720336e-02\n",
      " 2.70546828e-01 1.08556855e+01], Loss = 0.4442\n",
      "Iteration 2635: Weights = [5.50000000e+01 3.86470715e+00 8.12560866e+00 2.67712650e-02\n",
      " 2.70539062e-01 1.08559319e+01], Loss = 0.4442\n",
      "Iteration 2636: Weights = [5.50000000e+01 3.86459620e+00 8.12537540e+00 2.67704963e-02\n",
      " 2.70531296e-01 1.08561783e+01], Loss = 0.4442\n",
      "Iteration 2637: Weights = [5.50000000e+01 3.86448527e+00 8.12514215e+00 2.67697277e-02\n",
      " 2.70523530e-01 1.08564248e+01], Loss = 0.4441\n",
      "Iteration 2638: Weights = [5.50000000e+01 3.86437433e+00 8.12490891e+00 2.67689592e-02\n",
      " 2.70515764e-01 1.08566712e+01], Loss = 0.4441\n",
      "Iteration 2639: Weights = [5.50000000e+01 3.86426340e+00 8.12467567e+00 2.67681906e-02\n",
      " 2.70507999e-01 1.08569176e+01], Loss = 0.4441\n",
      "Iteration 2640: Weights = [5.50000000e+01 3.86415247e+00 8.12444244e+00 2.67674221e-02\n",
      " 2.70500234e-01 1.08571640e+01], Loss = 0.4441\n",
      "Iteration 2641: Weights = [5.50000000e+01 3.86404154e+00 8.12420922e+00 2.67666536e-02\n",
      " 2.70492469e-01 1.08574104e+01], Loss = 0.4440\n",
      "Iteration 2642: Weights = [5.50000000e+01 3.86393062e+00 8.12397600e+00 2.67658851e-02\n",
      " 2.70484704e-01 1.08576568e+01], Loss = 0.4440\n",
      "Iteration 2643: Weights = [5.50000000e+01 3.86381970e+00 8.12374279e+00 2.67651166e-02\n",
      " 2.70476939e-01 1.08579032e+01], Loss = 0.4440\n",
      "Iteration 2644: Weights = [5.50000000e+01 3.86370879e+00 8.12350959e+00 2.67643482e-02\n",
      " 2.70469175e-01 1.08581495e+01], Loss = 0.4440\n",
      "Iteration 2645: Weights = [5.50000000e+01 3.86359787e+00 8.12327640e+00 2.67635798e-02\n",
      " 2.70461411e-01 1.08583959e+01], Loss = 0.4439\n",
      "Iteration 2646: Weights = [5.50000000e+01 3.86348696e+00 8.12304321e+00 2.67628114e-02\n",
      " 2.70453647e-01 1.08586423e+01], Loss = 0.4439\n",
      "Iteration 2647: Weights = [5.50000000e+01 3.86337606e+00 8.12281002e+00 2.67620430e-02\n",
      " 2.70445883e-01 1.08588886e+01], Loss = 0.4439\n",
      "Iteration 2648: Weights = [5.50000000e+01 3.86326515e+00 8.12257685e+00 2.67612747e-02\n",
      " 2.70438120e-01 1.08591350e+01], Loss = 0.4439\n",
      "Iteration 2649: Weights = [5.50000000e+01 3.86315425e+00 8.12234368e+00 2.67605064e-02\n",
      " 2.70430357e-01 1.08593813e+01], Loss = 0.4438\n",
      "Iteration 2650: Weights = [5.50000000e+01 3.86304336e+00 8.12211052e+00 2.67597381e-02\n",
      " 2.70422594e-01 1.08596276e+01], Loss = 0.4438\n",
      "Iteration 2651: Weights = [5.50000000e+01 3.86293246e+00 8.12187736e+00 2.67589698e-02\n",
      " 2.70414831e-01 1.08598740e+01], Loss = 0.4438\n",
      "Iteration 2652: Weights = [5.50000000e+01 3.86282157e+00 8.12164421e+00 2.67582015e-02\n",
      " 2.70407068e-01 1.08601203e+01], Loss = 0.4438\n",
      "Iteration 2653: Weights = [5.50000000e+01 3.86271069e+00 8.12141107e+00 2.67574333e-02\n",
      " 2.70399306e-01 1.08603666e+01], Loss = 0.4437\n",
      "Iteration 2654: Weights = [5.50000000e+01 3.86259980e+00 8.12117793e+00 2.67566651e-02\n",
      " 2.70391544e-01 1.08606129e+01], Loss = 0.4437\n",
      "Iteration 2655: Weights = [5.50000000e+01 3.86248892e+00 8.12094480e+00 2.67558969e-02\n",
      " 2.70383782e-01 1.08608592e+01], Loss = 0.4437\n",
      "Iteration 2656: Weights = [5.50000000e+01 3.86237804e+00 8.12071168e+00 2.67551288e-02\n",
      " 2.70376020e-01 1.08611055e+01], Loss = 0.4437\n",
      "Iteration 2657: Weights = [5.50000000e+01 3.86226717e+00 8.12047857e+00 2.67543606e-02\n",
      " 2.70368259e-01 1.08613518e+01], Loss = 0.4436\n",
      "Iteration 2658: Weights = [5.50000000e+01 3.86215630e+00 8.12024546e+00 2.67535925e-02\n",
      " 2.70360498e-01 1.08615980e+01], Loss = 0.4436\n",
      "Iteration 2659: Weights = [5.50000000e+01 3.86204543e+00 8.12001236e+00 2.67528244e-02\n",
      " 2.70352737e-01 1.08618443e+01], Loss = 0.4436\n",
      "Iteration 2660: Weights = [5.50000000e+01 3.86193456e+00 8.11977926e+00 2.67520563e-02\n",
      " 2.70344976e-01 1.08620906e+01], Loss = 0.4436\n",
      "Iteration 2661: Weights = [5.50000000e+01 3.86182370e+00 8.11954617e+00 2.67512883e-02\n",
      " 2.70337215e-01 1.08623368e+01], Loss = 0.4435\n",
      "Iteration 2662: Weights = [5.50000000e+01 3.86171284e+00 8.11931309e+00 2.67505203e-02\n",
      " 2.70329455e-01 1.08625831e+01], Loss = 0.4435\n",
      "Iteration 2663: Weights = [5.50000000e+01 3.86160199e+00 8.11908001e+00 2.67497523e-02\n",
      " 2.70321695e-01 1.08628293e+01], Loss = 0.4435\n",
      "Iteration 2664: Weights = [5.50000000e+01 3.86149114e+00 8.11884694e+00 2.67489843e-02\n",
      " 2.70313935e-01 1.08630755e+01], Loss = 0.4435\n",
      "Iteration 2665: Weights = [5.50000000e+01 3.86138029e+00 8.11861388e+00 2.67482163e-02\n",
      " 2.70306175e-01 1.08633218e+01], Loss = 0.4434\n",
      "Iteration 2666: Weights = [5.50000000e+01 3.86126944e+00 8.11838083e+00 2.67474484e-02\n",
      " 2.70298416e-01 1.08635680e+01], Loss = 0.4434\n",
      "Iteration 2667: Weights = [5.50000000e+01 3.86115860e+00 8.11814778e+00 2.67466805e-02\n",
      " 2.70290657e-01 1.08638142e+01], Loss = 0.4434\n",
      "Iteration 2668: Weights = [5.50000000e+01 3.86104776e+00 8.11791474e+00 2.67459126e-02\n",
      " 2.70282898e-01 1.08640604e+01], Loss = 0.4434\n",
      "Iteration 2669: Weights = [5.50000000e+01 3.86093692e+00 8.11768170e+00 2.67451447e-02\n",
      " 2.70275139e-01 1.08643066e+01], Loss = 0.4433\n",
      "Iteration 2670: Weights = [5.50000000e+01 3.86082609e+00 8.11744867e+00 2.67443769e-02\n",
      " 2.70267380e-01 1.08645528e+01], Loss = 0.4433\n",
      "Iteration 2671: Weights = [5.50000000e+01 3.86071526e+00 8.11721565e+00 2.67436091e-02\n",
      " 2.70259622e-01 1.08647990e+01], Loss = 0.4433\n",
      "Iteration 2672: Weights = [5.50000000e+01 3.86060443e+00 8.11698264e+00 2.67428413e-02\n",
      " 2.70251864e-01 1.08650452e+01], Loss = 0.4433\n",
      "Iteration 2673: Weights = [5.50000000e+01 3.86049361e+00 8.11674963e+00 2.67420735e-02\n",
      " 2.70244106e-01 1.08652913e+01], Loss = 0.4432\n",
      "Iteration 2674: Weights = [5.50000000e+01 3.86038279e+00 8.11651662e+00 2.67413057e-02\n",
      " 2.70236348e-01 1.08655375e+01], Loss = 0.4432\n",
      "Iteration 2675: Weights = [5.50000000e+01 3.86027197e+00 8.11628363e+00 2.67405380e-02\n",
      " 2.70228591e-01 1.08657836e+01], Loss = 0.4432\n",
      "Iteration 2676: Weights = [5.50000000e+01 3.86016116e+00 8.11605064e+00 2.67397703e-02\n",
      " 2.70220834e-01 1.08660298e+01], Loss = 0.4432\n",
      "Iteration 2677: Weights = [5.50000000e+01 3.86005035e+00 8.11581766e+00 2.67390026e-02\n",
      " 2.70213077e-01 1.08662759e+01], Loss = 0.4431\n",
      "Iteration 2678: Weights = [5.50000000e+01 3.85993954e+00 8.11558468e+00 2.67382349e-02\n",
      " 2.70205320e-01 1.08665221e+01], Loss = 0.4431\n",
      "Iteration 2679: Weights = [5.50000000e+01 3.85982873e+00 8.11535172e+00 2.67374673e-02\n",
      " 2.70197563e-01 1.08667682e+01], Loss = 0.4431\n",
      "Iteration 2680: Weights = [5.50000000e+01 3.85971793e+00 8.11511875e+00 2.67366997e-02\n",
      " 2.70189807e-01 1.08670143e+01], Loss = 0.4431\n",
      "Iteration 2681: Weights = [5.50000000e+01 3.85960713e+00 8.11488580e+00 2.67359321e-02\n",
      " 2.70182051e-01 1.08672604e+01], Loss = 0.4430\n",
      "Iteration 2682: Weights = [5.50000000e+01 3.85949634e+00 8.11465285e+00 2.67351645e-02\n",
      " 2.70174295e-01 1.08675065e+01], Loss = 0.4430\n",
      "Iteration 2683: Weights = [5.50000000e+01 3.85938555e+00 8.11441991e+00 2.67343970e-02\n",
      " 2.70166540e-01 1.08677526e+01], Loss = 0.4430\n",
      "Iteration 2684: Weights = [5.50000000e+01 3.85927476e+00 8.11418697e+00 2.67336294e-02\n",
      " 2.70158784e-01 1.08679987e+01], Loss = 0.4430\n",
      "Iteration 2685: Weights = [5.50000000e+01 3.85916397e+00 8.11395404e+00 2.67328619e-02\n",
      " 2.70151029e-01 1.08682448e+01], Loss = 0.4429\n",
      "Iteration 2686: Weights = [5.50000000e+01 3.85905319e+00 8.11372112e+00 2.67320945e-02\n",
      " 2.70143274e-01 1.08684909e+01], Loss = 0.4429\n",
      "Iteration 2687: Weights = [5.50000000e+01 3.85894241e+00 8.11348821e+00 2.67313270e-02\n",
      " 2.70135519e-01 1.08687370e+01], Loss = 0.4429\n",
      "Iteration 2688: Weights = [5.50000000e+01 3.85883163e+00 8.11325530e+00 2.67305596e-02\n",
      " 2.70127765e-01 1.08689830e+01], Loss = 0.4428\n",
      "Iteration 2689: Weights = [5.50000000e+01 3.85872086e+00 8.11302240e+00 2.67297921e-02\n",
      " 2.70120010e-01 1.08692291e+01], Loss = 0.4428\n",
      "Iteration 2690: Weights = [5.50000000e+01 3.85861009e+00 8.11278950e+00 2.67290248e-02\n",
      " 2.70112256e-01 1.08694751e+01], Loss = 0.4428\n",
      "Iteration 2691: Weights = [5.50000000e+01 3.85849933e+00 8.11255662e+00 2.67282574e-02\n",
      " 2.70104502e-01 1.08697212e+01], Loss = 0.4428\n",
      "Iteration 2692: Weights = [5.50000000e+01 3.85838856e+00 8.11232373e+00 2.67274900e-02\n",
      " 2.70096749e-01 1.08699672e+01], Loss = 0.4427\n",
      "Iteration 2693: Weights = [5.50000000e+01 3.85827780e+00 8.11209086e+00 2.67267227e-02\n",
      " 2.70088995e-01 1.08702132e+01], Loss = 0.4427\n",
      "Iteration 2694: Weights = [5.50000000e+01 3.85816705e+00 8.11185799e+00 2.67259554e-02\n",
      " 2.70081242e-01 1.08704593e+01], Loss = 0.4427\n",
      "Iteration 2695: Weights = [5.50000000e+01 3.85805629e+00 8.11162513e+00 2.67251881e-02\n",
      " 2.70073489e-01 1.08707053e+01], Loss = 0.4427\n",
      "Iteration 2696: Weights = [5.50000000e+01 3.85794554e+00 8.11139227e+00 2.67244209e-02\n",
      " 2.70065736e-01 1.08709513e+01], Loss = 0.4426\n",
      "Iteration 2697: Weights = [5.50000000e+01 3.85783479e+00 8.11115943e+00 2.67236537e-02\n",
      " 2.70057984e-01 1.08711973e+01], Loss = 0.4426\n",
      "Iteration 2698: Weights = [5.50000000e+01 3.85772405e+00 8.11092658e+00 2.67228864e-02\n",
      " 2.70050231e-01 1.08714433e+01], Loss = 0.4426\n",
      "Iteration 2699: Weights = [5.50000000e+01 3.85761331e+00 8.11069375e+00 2.67221193e-02\n",
      " 2.70042479e-01 1.08716893e+01], Loss = 0.4426\n",
      "Iteration 2700: Weights = [5.50000000e+01 3.85750257e+00 8.11046092e+00 2.67213521e-02\n",
      " 2.70034727e-01 1.08719352e+01], Loss = 0.4425\n",
      "Iteration 2701: Weights = [5.50000000e+01 3.85739184e+00 8.11022810e+00 2.67205849e-02\n",
      " 2.70026976e-01 1.08721812e+01], Loss = 0.4425\n",
      "Iteration 2702: Weights = [5.50000000e+01 3.85728110e+00 8.10999529e+00 2.67198178e-02\n",
      " 2.70019224e-01 1.08724272e+01], Loss = 0.4425\n",
      "Iteration 2703: Weights = [5.50000000e+01 3.85717038e+00 8.10976248e+00 2.67190507e-02\n",
      " 2.70011473e-01 1.08726731e+01], Loss = 0.4425\n",
      "Iteration 2704: Weights = [5.50000000e+01 3.85705965e+00 8.10952968e+00 2.67182837e-02\n",
      " 2.70003722e-01 1.08729191e+01], Loss = 0.4424\n",
      "Iteration 2705: Weights = [5.50000000e+01 3.85694893e+00 8.10929688e+00 2.67175166e-02\n",
      " 2.69995971e-01 1.08731650e+01], Loss = 0.4424\n",
      "Iteration 2706: Weights = [5.50000000e+01 3.85683821e+00 8.10906409e+00 2.67167496e-02\n",
      " 2.69988221e-01 1.08734110e+01], Loss = 0.4424\n",
      "Iteration 2707: Weights = [5.50000000e+01 3.85672750e+00 8.10883131e+00 2.67159826e-02\n",
      " 2.69980470e-01 1.08736569e+01], Loss = 0.4424\n",
      "Iteration 2708: Weights = [5.50000000e+01 3.85661678e+00 8.10859854e+00 2.67152156e-02\n",
      " 2.69972720e-01 1.08739028e+01], Loss = 0.4423\n",
      "Iteration 2709: Weights = [5.50000000e+01 3.85650607e+00 8.10836577e+00 2.67144486e-02\n",
      " 2.69964970e-01 1.08741487e+01], Loss = 0.4423\n",
      "Iteration 2710: Weights = [5.50000000e+01 3.85639537e+00 8.10813301e+00 2.67136817e-02\n",
      " 2.69957221e-01 1.08743946e+01], Loss = 0.4423\n",
      "Iteration 2711: Weights = [5.50000000e+01 3.85628466e+00 8.10790025e+00 2.67129148e-02\n",
      " 2.69949471e-01 1.08746405e+01], Loss = 0.4423\n",
      "Iteration 2712: Weights = [5.50000000e+01 3.85617396e+00 8.10766751e+00 2.67121479e-02\n",
      " 2.69941722e-01 1.08748864e+01], Loss = 0.4422\n",
      "Iteration 2713: Weights = [5.50000000e+01 3.85606327e+00 8.10743477e+00 2.67113810e-02\n",
      " 2.69933973e-01 1.08751323e+01], Loss = 0.4422\n",
      "Iteration 2714: Weights = [5.50000000e+01 3.85595258e+00 8.10720203e+00 2.67106141e-02\n",
      " 2.69926224e-01 1.08753782e+01], Loss = 0.4422\n",
      "Iteration 2715: Weights = [5.50000000e+01 3.85584188e+00 8.10696930e+00 2.67098473e-02\n",
      " 2.69918476e-01 1.08756241e+01], Loss = 0.4422\n",
      "Iteration 2716: Weights = [5.50000000e+01 3.85573120e+00 8.10673658e+00 2.67090805e-02\n",
      " 2.69910727e-01 1.08758699e+01], Loss = 0.4421\n",
      "Iteration 2717: Weights = [5.50000000e+01 3.85562051e+00 8.10650387e+00 2.67083137e-02\n",
      " 2.69902979e-01 1.08761158e+01], Loss = 0.4421\n",
      "Iteration 2718: Weights = [5.50000000e+01 3.85550983e+00 8.10627116e+00 2.67075470e-02\n",
      " 2.69895231e-01 1.08763617e+01], Loss = 0.4421\n",
      "Iteration 2719: Weights = [5.50000000e+01 3.85539916e+00 8.10603846e+00 2.67067802e-02\n",
      " 2.69887484e-01 1.08766075e+01], Loss = 0.4421\n",
      "Iteration 2720: Weights = [5.50000000e+01 3.85528848e+00 8.10580576e+00 2.67060135e-02\n",
      " 2.69879736e-01 1.08768533e+01], Loss = 0.4420\n",
      "Iteration 2721: Weights = [5.50000000e+01 3.85517781e+00 8.10557308e+00 2.67052468e-02\n",
      " 2.69871989e-01 1.08770992e+01], Loss = 0.4420\n",
      "Iteration 2722: Weights = [5.50000000e+01 3.85506714e+00 8.10534039e+00 2.67044801e-02\n",
      " 2.69864242e-01 1.08773450e+01], Loss = 0.4420\n",
      "Iteration 2723: Weights = [5.50000000e+01 3.85495648e+00 8.10510772e+00 2.67037135e-02\n",
      " 2.69856495e-01 1.08775908e+01], Loss = 0.4420\n",
      "Iteration 2724: Weights = [5.50000000e+01 3.85484582e+00 8.10487505e+00 2.67029469e-02\n",
      " 2.69848749e-01 1.08778366e+01], Loss = 0.4419\n",
      "Iteration 2725: Weights = [5.50000000e+01 3.85473516e+00 8.10464239e+00 2.67021803e-02\n",
      " 2.69841003e-01 1.08780824e+01], Loss = 0.4419\n",
      "Iteration 2726: Weights = [5.50000000e+01 3.85462450e+00 8.10440974e+00 2.67014137e-02\n",
      " 2.69833256e-01 1.08783282e+01], Loss = 0.4419\n",
      "Iteration 2727: Weights = [5.50000000e+01 3.85451385e+00 8.10417709e+00 2.67006471e-02\n",
      " 2.69825511e-01 1.08785740e+01], Loss = 0.4419\n",
      "Iteration 2728: Weights = [5.50000000e+01 3.85440320e+00 8.10394445e+00 2.66998806e-02\n",
      " 2.69817765e-01 1.08788198e+01], Loss = 0.4418\n",
      "Iteration 2729: Weights = [5.50000000e+01 3.85429256e+00 8.10371181e+00 2.66991141e-02\n",
      " 2.69810019e-01 1.08790656e+01], Loss = 0.4418\n",
      "Iteration 2730: Weights = [5.50000000e+01 3.85418191e+00 8.10347919e+00 2.66983476e-02\n",
      " 2.69802274e-01 1.08793113e+01], Loss = 0.4418\n",
      "Iteration 2731: Weights = [5.50000000e+01 3.85407127e+00 8.10324657e+00 2.66975811e-02\n",
      " 2.69794529e-01 1.08795571e+01], Loss = 0.4418\n",
      "Iteration 2732: Weights = [5.50000000e+01 3.85396064e+00 8.10301395e+00 2.66968147e-02\n",
      " 2.69786784e-01 1.08798028e+01], Loss = 0.4417\n",
      "Iteration 2733: Weights = [5.50000000e+01 3.85385001e+00 8.10278134e+00 2.66960483e-02\n",
      " 2.69779040e-01 1.08800486e+01], Loss = 0.4417\n",
      "Iteration 2734: Weights = [5.50000000e+01 3.85373938e+00 8.10254874e+00 2.66952819e-02\n",
      " 2.69771296e-01 1.08802943e+01], Loss = 0.4417\n",
      "Iteration 2735: Weights = [5.50000000e+01 3.85362875e+00 8.10231615e+00 2.66945155e-02\n",
      " 2.69763552e-01 1.08805401e+01], Loss = 0.4417\n",
      "Iteration 2736: Weights = [5.50000000e+01 3.85351813e+00 8.10208356e+00 2.66937491e-02\n",
      " 2.69755808e-01 1.08807858e+01], Loss = 0.4416\n",
      "Iteration 2737: Weights = [5.50000000e+01 3.85340751e+00 8.10185098e+00 2.66929828e-02\n",
      " 2.69748064e-01 1.08810315e+01], Loss = 0.4416\n",
      "Iteration 2738: Weights = [5.50000000e+01 3.85329689e+00 8.10161841e+00 2.66922165e-02\n",
      " 2.69740321e-01 1.08812772e+01], Loss = 0.4416\n",
      "Iteration 2739: Weights = [5.50000000e+01 3.85318627e+00 8.10138584e+00 2.66914502e-02\n",
      " 2.69732577e-01 1.08815229e+01], Loss = 0.4416\n",
      "Iteration 2740: Weights = [5.50000000e+01 3.85307566e+00 8.10115328e+00 2.66906839e-02\n",
      " 2.69724834e-01 1.08817686e+01], Loss = 0.4415\n",
      "Iteration 2741: Weights = [5.50000000e+01 3.85296506e+00 8.10092072e+00 2.66899177e-02\n",
      " 2.69717092e-01 1.08820143e+01], Loss = 0.4415\n",
      "Iteration 2742: Weights = [5.50000000e+01 3.85285445e+00 8.10068818e+00 2.66891515e-02\n",
      " 2.69709349e-01 1.08822600e+01], Loss = 0.4415\n",
      "Iteration 2743: Weights = [5.50000000e+01 3.85274385e+00 8.10045564e+00 2.66883853e-02\n",
      " 2.69701607e-01 1.08825057e+01], Loss = 0.4415\n",
      "Iteration 2744: Weights = [5.50000000e+01 3.85263325e+00 8.10022310e+00 2.66876191e-02\n",
      " 2.69693865e-01 1.08827513e+01], Loss = 0.4414\n",
      "Iteration 2745: Weights = [5.50000000e+01 3.85252266e+00 8.09999057e+00 2.66868529e-02\n",
      " 2.69686123e-01 1.08829970e+01], Loss = 0.4414\n",
      "Iteration 2746: Weights = [5.50000000e+01 3.85241207e+00 8.09975805e+00 2.66860868e-02\n",
      " 2.69678381e-01 1.08832427e+01], Loss = 0.4414\n",
      "Iteration 2747: Weights = [5.50000000e+01 3.85230148e+00 8.09952554e+00 2.66853207e-02\n",
      " 2.69670640e-01 1.08834883e+01], Loss = 0.4414\n",
      "Iteration 2748: Weights = [5.50000000e+01 3.85219089e+00 8.09929303e+00 2.66845546e-02\n",
      " 2.69662898e-01 1.08837339e+01], Loss = 0.4413\n",
      "Iteration 2749: Weights = [5.50000000e+01 3.85208031e+00 8.09906053e+00 2.66837885e-02\n",
      " 2.69655157e-01 1.08839796e+01], Loss = 0.4413\n",
      "Iteration 2750: Weights = [5.50000000e+01 3.85196973e+00 8.09882804e+00 2.66830225e-02\n",
      " 2.69647417e-01 1.08842252e+01], Loss = 0.4413\n",
      "Iteration 2751: Weights = [5.50000000e+01 3.85185916e+00 8.09859555e+00 2.66822565e-02\n",
      " 2.69639676e-01 1.08844708e+01], Loss = 0.4413\n",
      "Iteration 2752: Weights = [5.50000000e+01 3.85174858e+00 8.09836307e+00 2.66814905e-02\n",
      " 2.69631936e-01 1.08847164e+01], Loss = 0.4412\n",
      "Iteration 2753: Weights = [5.50000000e+01 3.85163801e+00 8.09813059e+00 2.66807245e-02\n",
      " 2.69624196e-01 1.08849620e+01], Loss = 0.4412\n",
      "Iteration 2754: Weights = [5.50000000e+01 3.85152745e+00 8.09789813e+00 2.66799585e-02\n",
      " 2.69616456e-01 1.08852076e+01], Loss = 0.4412\n",
      "Iteration 2755: Weights = [5.50000000e+01 3.85141688e+00 8.09766567e+00 2.66791926e-02\n",
      " 2.69608716e-01 1.08854532e+01], Loss = 0.4411\n",
      "Iteration 2756: Weights = [5.50000000e+01 3.85130632e+00 8.09743321e+00 2.66784267e-02\n",
      " 2.69600977e-01 1.08856988e+01], Loss = 0.4411\n",
      "Iteration 2757: Weights = [5.50000000e+01 3.85119577e+00 8.09720076e+00 2.66776608e-02\n",
      " 2.69593237e-01 1.08859444e+01], Loss = 0.4411\n",
      "Iteration 2758: Weights = [5.50000000e+01 3.85108521e+00 8.09696832e+00 2.66768949e-02\n",
      " 2.69585498e-01 1.08861900e+01], Loss = 0.4411\n",
      "Iteration 2759: Weights = [5.50000000e+01 3.85097466e+00 8.09673589e+00 2.66761291e-02\n",
      " 2.69577760e-01 1.08864355e+01], Loss = 0.4410\n",
      "Iteration 2760: Weights = [5.50000000e+01 3.85086412e+00 8.09650346e+00 2.66753633e-02\n",
      " 2.69570021e-01 1.08866811e+01], Loss = 0.4410\n",
      "Iteration 2761: Weights = [5.50000000e+01 3.85075357e+00 8.09627104e+00 2.66745975e-02\n",
      " 2.69562283e-01 1.08869266e+01], Loss = 0.4410\n",
      "Iteration 2762: Weights = [5.50000000e+01 3.85064303e+00 8.09603863e+00 2.66738317e-02\n",
      " 2.69554545e-01 1.08871722e+01], Loss = 0.4410\n",
      "Iteration 2763: Weights = [5.50000000e+01 3.85053249e+00 8.09580622e+00 2.66730660e-02\n",
      " 2.69546807e-01 1.08874177e+01], Loss = 0.4409\n",
      "Iteration 2764: Weights = [5.50000000e+01 3.85042196e+00 8.09557382e+00 2.66723002e-02\n",
      " 2.69539069e-01 1.08876632e+01], Loss = 0.4409\n",
      "Iteration 2765: Weights = [5.50000000e+01 3.85031143e+00 8.09534142e+00 2.66715345e-02\n",
      " 2.69531332e-01 1.08879087e+01], Loss = 0.4409\n",
      "Iteration 2766: Weights = [5.50000000e+01 3.85020090e+00 8.09510904e+00 2.66707688e-02\n",
      " 2.69523594e-01 1.08881543e+01], Loss = 0.4409\n",
      "Iteration 2767: Weights = [5.50000000e+01 3.85009037e+00 8.09487666e+00 2.66700032e-02\n",
      " 2.69515857e-01 1.08883998e+01], Loss = 0.4408\n",
      "Iteration 2768: Weights = [5.50000000e+01 3.84997985e+00 8.09464428e+00 2.66692375e-02\n",
      " 2.69508121e-01 1.08886453e+01], Loss = 0.4408\n",
      "Iteration 2769: Weights = [5.50000000e+01 3.84986933e+00 8.09441192e+00 2.66684719e-02\n",
      " 2.69500384e-01 1.08888908e+01], Loss = 0.4408\n",
      "Iteration 2770: Weights = [5.50000000e+01 3.84975882e+00 8.09417955e+00 2.66677063e-02\n",
      " 2.69492648e-01 1.08891362e+01], Loss = 0.4408\n",
      "Iteration 2771: Weights = [5.50000000e+01 3.84964831e+00 8.09394720e+00 2.66669407e-02\n",
      " 2.69484912e-01 1.08893817e+01], Loss = 0.4407\n",
      "Iteration 2772: Weights = [5.50000000e+01 3.84953780e+00 8.09371485e+00 2.66661752e-02\n",
      " 2.69477176e-01 1.08896272e+01], Loss = 0.4407\n",
      "Iteration 2773: Weights = [5.50000000e+01 3.84942729e+00 8.09348251e+00 2.66654097e-02\n",
      " 2.69469440e-01 1.08898727e+01], Loss = 0.4407\n",
      "Iteration 2774: Weights = [5.50000000e+01 3.84931679e+00 8.09325018e+00 2.66646441e-02\n",
      " 2.69461705e-01 1.08901181e+01], Loss = 0.4407\n",
      "Iteration 2775: Weights = [5.50000000e+01 3.84920629e+00 8.09301785e+00 2.66638787e-02\n",
      " 2.69453969e-01 1.08903636e+01], Loss = 0.4406\n",
      "Iteration 2776: Weights = [5.50000000e+01 3.84909579e+00 8.09278553e+00 2.66631132e-02\n",
      " 2.69446234e-01 1.08906090e+01], Loss = 0.4406\n",
      "Iteration 2777: Weights = [5.50000000e+01 3.84898530e+00 8.09255322e+00 2.66623478e-02\n",
      " 2.69438500e-01 1.08908544e+01], Loss = 0.4406\n",
      "Iteration 2778: Weights = [5.50000000e+01 3.84887481e+00 8.09232091e+00 2.66615823e-02\n",
      " 2.69430765e-01 1.08910999e+01], Loss = 0.4406\n",
      "Iteration 2779: Weights = [5.50000000e+01 3.84876432e+00 8.09208861e+00 2.66608169e-02\n",
      " 2.69423031e-01 1.08913453e+01], Loss = 0.4405\n",
      "Iteration 2780: Weights = [5.50000000e+01 3.84865384e+00 8.09185631e+00 2.66600516e-02\n",
      " 2.69415297e-01 1.08915907e+01], Loss = 0.4405\n",
      "Iteration 2781: Weights = [5.50000000e+01 3.84854336e+00 8.09162403e+00 2.66592862e-02\n",
      " 2.69407563e-01 1.08918361e+01], Loss = 0.4405\n",
      "Iteration 2782: Weights = [5.50000000e+01 3.84843288e+00 8.09139175e+00 2.66585209e-02\n",
      " 2.69399829e-01 1.08920815e+01], Loss = 0.4405\n",
      "Iteration 2783: Weights = [5.50000000e+01 3.84832240e+00 8.09115947e+00 2.66577556e-02\n",
      " 2.69392096e-01 1.08923269e+01], Loss = 0.4404\n",
      "Iteration 2784: Weights = [5.50000000e+01 3.84821193e+00 8.09092721e+00 2.66569903e-02\n",
      " 2.69384362e-01 1.08925723e+01], Loss = 0.4404\n",
      "Iteration 2785: Weights = [5.50000000e+01 3.84810147e+00 8.09069494e+00 2.66562250e-02\n",
      " 2.69376629e-01 1.08928177e+01], Loss = 0.4404\n",
      "Iteration 2786: Weights = [5.50000000e+01 3.84799100e+00 8.09046269e+00 2.66554598e-02\n",
      " 2.69368897e-01 1.08930631e+01], Loss = 0.4404\n",
      "Iteration 2787: Weights = [5.50000000e+01 3.84788054e+00 8.09023044e+00 2.66546946e-02\n",
      " 2.69361164e-01 1.08933084e+01], Loss = 0.4403\n",
      "Iteration 2788: Weights = [5.50000000e+01 3.84777008e+00 8.08999820e+00 2.66539294e-02\n",
      " 2.69353432e-01 1.08935538e+01], Loss = 0.4403\n",
      "Iteration 2789: Weights = [5.50000000e+01 3.84765963e+00 8.08976597e+00 2.66531642e-02\n",
      " 2.69345699e-01 1.08937991e+01], Loss = 0.4403\n",
      "Iteration 2790: Weights = [5.50000000e+01 3.84754917e+00 8.08953374e+00 2.66523991e-02\n",
      " 2.69337968e-01 1.08940445e+01], Loss = 0.4403\n",
      "Iteration 2791: Weights = [5.50000000e+01 3.84743872e+00 8.08930152e+00 2.66516339e-02\n",
      " 2.69330236e-01 1.08942898e+01], Loss = 0.4402\n",
      "Iteration 2792: Weights = [5.50000000e+01 3.84732828e+00 8.08906931e+00 2.66508688e-02\n",
      " 2.69322504e-01 1.08945351e+01], Loss = 0.4402\n",
      "Iteration 2793: Weights = [5.50000000e+01 3.84721784e+00 8.08883710e+00 2.66501037e-02\n",
      " 2.69314773e-01 1.08947805e+01], Loss = 0.4402\n",
      "Iteration 2794: Weights = [5.50000000e+01 3.84710740e+00 8.08860490e+00 2.66493387e-02\n",
      " 2.69307042e-01 1.08950258e+01], Loss = 0.4402\n",
      "Iteration 2795: Weights = [5.50000000e+01 3.84699696e+00 8.08837270e+00 2.66485736e-02\n",
      " 2.69299311e-01 1.08952711e+01], Loss = 0.4401\n",
      "Iteration 2796: Weights = [5.50000000e+01 3.84688653e+00 8.08814052e+00 2.66478086e-02\n",
      " 2.69291581e-01 1.08955164e+01], Loss = 0.4401\n",
      "Iteration 2797: Weights = [5.50000000e+01 3.84677610e+00 8.08790834e+00 2.66470436e-02\n",
      " 2.69283850e-01 1.08957617e+01], Loss = 0.4401\n",
      "Iteration 2798: Weights = [5.50000000e+01 3.84666567e+00 8.08767616e+00 2.66462786e-02\n",
      " 2.69276120e-01 1.08960070e+01], Loss = 0.4401\n",
      "Iteration 2799: Weights = [5.50000000e+01 3.84655525e+00 8.08744400e+00 2.66455137e-02\n",
      " 2.69268390e-01 1.08962523e+01], Loss = 0.4400\n",
      "Iteration 2800: Weights = [5.50000000e+01 3.84644483e+00 8.08721183e+00 2.66447488e-02\n",
      " 2.69260661e-01 1.08964975e+01], Loss = 0.4400\n",
      "Iteration 2801: Weights = [5.50000000e+01 3.84633441e+00 8.08697968e+00 2.66439839e-02\n",
      " 2.69252931e-01 1.08967428e+01], Loss = 0.4400\n",
      "Iteration 2802: Weights = [5.50000000e+01 3.84622400e+00 8.08674753e+00 2.66432190e-02\n",
      " 2.69245202e-01 1.08969881e+01], Loss = 0.4400\n",
      "Iteration 2803: Weights = [5.50000000e+01 3.84611358e+00 8.08651539e+00 2.66424541e-02\n",
      " 2.69237473e-01 1.08972333e+01], Loss = 0.4399\n",
      "Iteration 2804: Weights = [5.50000000e+01 3.84600318e+00 8.08628326e+00 2.66416893e-02\n",
      " 2.69229744e-01 1.08974786e+01], Loss = 0.4399\n",
      "Iteration 2805: Weights = [5.50000000e+01 3.84589277e+00 8.08605113e+00 2.66409245e-02\n",
      " 2.69222016e-01 1.08977238e+01], Loss = 0.4399\n",
      "Iteration 2806: Weights = [5.50000000e+01 3.84578237e+00 8.08581901e+00 2.66401597e-02\n",
      " 2.69214287e-01 1.08979690e+01], Loss = 0.4399\n",
      "Iteration 2807: Weights = [5.50000000e+01 3.84567197e+00 8.08558690e+00 2.66393949e-02\n",
      " 2.69206559e-01 1.08982143e+01], Loss = 0.4398\n",
      "Iteration 2808: Weights = [5.50000000e+01 3.84556158e+00 8.08535479e+00 2.66386301e-02\n",
      " 2.69198831e-01 1.08984595e+01], Loss = 0.4398\n",
      "Iteration 2809: Weights = [5.50000000e+01 3.84545119e+00 8.08512269e+00 2.66378654e-02\n",
      " 2.69191104e-01 1.08987047e+01], Loss = 0.4398\n",
      "Iteration 2810: Weights = [5.50000000e+01 3.84534080e+00 8.08489059e+00 2.66371007e-02\n",
      " 2.69183376e-01 1.08989499e+01], Loss = 0.4398\n",
      "Iteration 2811: Weights = [5.50000000e+01 3.84523041e+00 8.08465851e+00 2.66363360e-02\n",
      " 2.69175649e-01 1.08991951e+01], Loss = 0.4397\n",
      "Iteration 2812: Weights = [5.50000000e+01 3.84512003e+00 8.08442643e+00 2.66355714e-02\n",
      " 2.69167922e-01 1.08994403e+01], Loss = 0.4397\n",
      "Iteration 2813: Weights = [5.50000000e+01 3.84500965e+00 8.08419435e+00 2.66348067e-02\n",
      " 2.69160195e-01 1.08996855e+01], Loss = 0.4397\n",
      "Iteration 2814: Weights = [5.50000000e+01 3.84489927e+00 8.08396229e+00 2.66340421e-02\n",
      " 2.69152469e-01 1.08999306e+01], Loss = 0.4397\n",
      "Iteration 2815: Weights = [5.50000000e+01 3.84478890e+00 8.08373022e+00 2.66332775e-02\n",
      " 2.69144742e-01 1.09001758e+01], Loss = 0.4396\n",
      "Iteration 2816: Weights = [5.50000000e+01 3.84467853e+00 8.08349817e+00 2.66325129e-02\n",
      " 2.69137016e-01 1.09004210e+01], Loss = 0.4396\n",
      "Iteration 2817: Weights = [5.50000000e+01 3.84456816e+00 8.08326612e+00 2.66317484e-02\n",
      " 2.69129290e-01 1.09006661e+01], Loss = 0.4396\n",
      "Iteration 2818: Weights = [5.50000000e+01 3.84445780e+00 8.08303408e+00 2.66309838e-02\n",
      " 2.69121564e-01 1.09009113e+01], Loss = 0.4396\n",
      "Iteration 2819: Weights = [5.50000000e+01 3.84434744e+00 8.08280205e+00 2.66302193e-02\n",
      " 2.69113839e-01 1.09011564e+01], Loss = 0.4395\n",
      "Iteration 2820: Weights = [5.50000000e+01 3.84423708e+00 8.08257002e+00 2.66294548e-02\n",
      " 2.69106114e-01 1.09014015e+01], Loss = 0.4395\n",
      "Iteration 2821: Weights = [5.50000000e+01 3.84412673e+00 8.08233800e+00 2.66286904e-02\n",
      " 2.69098389e-01 1.09016467e+01], Loss = 0.4395\n",
      "Iteration 2822: Weights = [5.50000000e+01 3.84401638e+00 8.08210599e+00 2.66279259e-02\n",
      " 2.69090664e-01 1.09018918e+01], Loss = 0.4395\n",
      "Iteration 2823: Weights = [5.50000000e+01 3.84390603e+00 8.08187398e+00 2.66271615e-02\n",
      " 2.69082939e-01 1.09021369e+01], Loss = 0.4394\n",
      "Iteration 2824: Weights = [5.50000000e+01 3.84379569e+00 8.08164198e+00 2.66263971e-02\n",
      " 2.69075215e-01 1.09023820e+01], Loss = 0.4394\n",
      "Iteration 2825: Weights = [5.50000000e+01 3.84368535e+00 8.08140998e+00 2.66256328e-02\n",
      " 2.69067491e-01 1.09026271e+01], Loss = 0.4394\n",
      "Iteration 2826: Weights = [5.50000000e+01 3.84357501e+00 8.08117800e+00 2.66248684e-02\n",
      " 2.69059767e-01 1.09028722e+01], Loss = 0.4394\n",
      "Iteration 2827: Weights = [5.50000000e+01 3.84346467e+00 8.08094602e+00 2.66241041e-02\n",
      " 2.69052043e-01 1.09031173e+01], Loss = 0.4393\n",
      "Iteration 2828: Weights = [5.50000000e+01 3.84335434e+00 8.08071404e+00 2.66233398e-02\n",
      " 2.69044320e-01 1.09033623e+01], Loss = 0.4393\n",
      "Iteration 2829: Weights = [5.50000000e+01 3.84324401e+00 8.08048207e+00 2.66225755e-02\n",
      " 2.69036596e-01 1.09036074e+01], Loss = 0.4393\n",
      "Iteration 2830: Weights = [5.50000000e+01 3.84313369e+00 8.08025011e+00 2.66218112e-02\n",
      " 2.69028873e-01 1.09038525e+01], Loss = 0.4393\n",
      "Iteration 2831: Weights = [5.50000000e+01 3.84302337e+00 8.08001816e+00 2.66210470e-02\n",
      " 2.69021151e-01 1.09040975e+01], Loss = 0.4392\n",
      "Iteration 2832: Weights = [5.50000000e+01 3.84291305e+00 8.07978621e+00 2.66202828e-02\n",
      " 2.69013428e-01 1.09043426e+01], Loss = 0.4392\n",
      "Iteration 2833: Weights = [5.50000000e+01 3.84280273e+00 8.07955427e+00 2.66195186e-02\n",
      " 2.69005706e-01 1.09045876e+01], Loss = 0.4392\n",
      "Iteration 2834: Weights = [5.50000000e+01 3.84269242e+00 8.07932234e+00 2.66187544e-02\n",
      " 2.68997984e-01 1.09048327e+01], Loss = 0.4392\n",
      "Iteration 2835: Weights = [5.50000000e+01 3.84258211e+00 8.07909041e+00 2.66179902e-02\n",
      " 2.68990262e-01 1.09050777e+01], Loss = 0.4391\n",
      "Iteration 2836: Weights = [5.50000000e+01 3.84247180e+00 8.07885849e+00 2.66172261e-02\n",
      " 2.68982540e-01 1.09053227e+01], Loss = 0.4391\n",
      "Iteration 2837: Weights = [5.50000000e+01 3.84236150e+00 8.07862657e+00 2.66164620e-02\n",
      " 2.68974818e-01 1.09055677e+01], Loss = 0.4391\n",
      "Iteration 2838: Weights = [5.50000000e+01 3.84225120e+00 8.07839467e+00 2.66156979e-02\n",
      " 2.68967097e-01 1.09058127e+01], Loss = 0.4391\n",
      "Iteration 2839: Weights = [5.50000000e+01 3.84214090e+00 8.07816277e+00 2.66149338e-02\n",
      " 2.68959376e-01 1.09060577e+01], Loss = 0.4390\n",
      "Iteration 2840: Weights = [5.50000000e+01 3.84203061e+00 8.07793087e+00 2.66141698e-02\n",
      " 2.68951655e-01 1.09063027e+01], Loss = 0.4390\n",
      "Iteration 2841: Weights = [5.50000000e+01 3.84192032e+00 8.07769898e+00 2.66134058e-02\n",
      " 2.68943935e-01 1.09065477e+01], Loss = 0.4390\n",
      "Iteration 2842: Weights = [5.50000000e+01 3.84181003e+00 8.07746710e+00 2.66126418e-02\n",
      " 2.68936214e-01 1.09067927e+01], Loss = 0.4390\n",
      "Iteration 2843: Weights = [5.50000000e+01 3.84169975e+00 8.07723523e+00 2.66118778e-02\n",
      " 2.68928494e-01 1.09070377e+01], Loss = 0.4389\n",
      "Iteration 2844: Weights = [5.50000000e+01 3.84158947e+00 8.07700336e+00 2.66111138e-02\n",
      " 2.68920774e-01 1.09072826e+01], Loss = 0.4389\n",
      "Iteration 2845: Weights = [5.50000000e+01 3.84147919e+00 8.07677150e+00 2.66103499e-02\n",
      " 2.68913055e-01 1.09075276e+01], Loss = 0.4389\n",
      "Iteration 2846: Weights = [5.50000000e+01 3.84136891e+00 8.07653965e+00 2.66095860e-02\n",
      " 2.68905335e-01 1.09077725e+01], Loss = 0.4389\n",
      "Iteration 2847: Weights = [5.50000000e+01 3.84125864e+00 8.07630780e+00 2.66088221e-02\n",
      " 2.68897616e-01 1.09080175e+01], Loss = 0.4388\n",
      "Iteration 2848: Weights = [5.50000000e+01 3.84114837e+00 8.07607596e+00 2.66080583e-02\n",
      " 2.68889897e-01 1.09082624e+01], Loss = 0.4388\n",
      "Iteration 2849: Weights = [5.50000000e+01 3.84103811e+00 8.07584412e+00 2.66072944e-02\n",
      " 2.68882178e-01 1.09085073e+01], Loss = 0.4388\n",
      "Iteration 2850: Weights = [5.50000000e+01 3.84092785e+00 8.07561230e+00 2.66065306e-02\n",
      " 2.68874459e-01 1.09087523e+01], Loss = 0.4387\n",
      "Iteration 2851: Weights = [5.50000000e+01 3.84081759e+00 8.07538047e+00 2.66057668e-02\n",
      " 2.68866741e-01 1.09089972e+01], Loss = 0.4387\n",
      "Iteration 2852: Weights = [5.50000000e+01 3.84070733e+00 8.07514866e+00 2.66050030e-02\n",
      " 2.68859023e-01 1.09092421e+01], Loss = 0.4387\n",
      "Iteration 2853: Weights = [5.50000000e+01 3.84059708e+00 8.07491685e+00 2.66042393e-02\n",
      " 2.68851305e-01 1.09094870e+01], Loss = 0.4387\n",
      "Iteration 2854: Weights = [5.50000000e+01 3.84048683e+00 8.07468505e+00 2.66034755e-02\n",
      " 2.68843587e-01 1.09097319e+01], Loss = 0.4386\n",
      "Iteration 2855: Weights = [5.50000000e+01 3.84037658e+00 8.07445326e+00 2.66027118e-02\n",
      " 2.68835870e-01 1.09099768e+01], Loss = 0.4386\n",
      "Iteration 2856: Weights = [5.50000000e+01 3.84026634e+00 8.07422147e+00 2.66019481e-02\n",
      " 2.68828152e-01 1.09102216e+01], Loss = 0.4386\n",
      "Iteration 2857: Weights = [5.50000000e+01 3.84015610e+00 8.07398969e+00 2.66011845e-02\n",
      " 2.68820435e-01 1.09104665e+01], Loss = 0.4386\n",
      "Iteration 2858: Weights = [5.50000000e+01 3.84004586e+00 8.07375791e+00 2.66004208e-02\n",
      " 2.68812719e-01 1.09107114e+01], Loss = 0.4385\n",
      "Iteration 2859: Weights = [5.50000000e+01 3.83993563e+00 8.07352615e+00 2.65996572e-02\n",
      " 2.68805002e-01 1.09109562e+01], Loss = 0.4385\n",
      "Iteration 2860: Weights = [5.50000000e+01 3.83982540e+00 8.07329438e+00 2.65988936e-02\n",
      " 2.68797286e-01 1.09112011e+01], Loss = 0.4385\n",
      "Iteration 2861: Weights = [5.50000000e+01 3.83971517e+00 8.07306263e+00 2.65981300e-02\n",
      " 2.68789569e-01 1.09114459e+01], Loss = 0.4385\n",
      "Iteration 2862: Weights = [5.50000000e+01 3.83960495e+00 8.07283088e+00 2.65973665e-02\n",
      " 2.68781853e-01 1.09116908e+01], Loss = 0.4384\n",
      "Iteration 2863: Weights = [5.50000000e+01 3.83949473e+00 8.07259914e+00 2.65966029e-02\n",
      " 2.68774138e-01 1.09119356e+01], Loss = 0.4384\n",
      "Iteration 2864: Weights = [5.50000000e+01 3.83938451e+00 8.07236741e+00 2.65958394e-02\n",
      " 2.68766422e-01 1.09121804e+01], Loss = 0.4384\n",
      "Iteration 2865: Weights = [5.50000000e+01 3.83927430e+00 8.07213568e+00 2.65950759e-02\n",
      " 2.68758707e-01 1.09124253e+01], Loss = 0.4384\n",
      "Iteration 2866: Weights = [5.50000000e+01 3.83916408e+00 8.07190396e+00 2.65943124e-02\n",
      " 2.68750992e-01 1.09126701e+01], Loss = 0.4383\n",
      "Iteration 2867: Weights = [5.50000000e+01 3.83905388e+00 8.07167224e+00 2.65935490e-02\n",
      " 2.68743277e-01 1.09129149e+01], Loss = 0.4383\n",
      "Iteration 2868: Weights = [5.50000000e+01 3.83894367e+00 8.07144053e+00 2.65927856e-02\n",
      " 2.68735562e-01 1.09131597e+01], Loss = 0.4383\n",
      "Iteration 2869: Weights = [5.50000000e+01 3.83883347e+00 8.07120883e+00 2.65920222e-02\n",
      " 2.68727848e-01 1.09134044e+01], Loss = 0.4383\n",
      "Iteration 2870: Weights = [5.50000000e+01 3.83872327e+00 8.07097714e+00 2.65912588e-02\n",
      " 2.68720134e-01 1.09136492e+01], Loss = 0.4382\n",
      "Iteration 2871: Weights = [5.50000000e+01 3.83861307e+00 8.07074545e+00 2.65904954e-02\n",
      " 2.68712420e-01 1.09138940e+01], Loss = 0.4382\n",
      "Iteration 2872: Weights = [5.50000000e+01 3.83850288e+00 8.07051377e+00 2.65897321e-02\n",
      " 2.68704706e-01 1.09141388e+01], Loss = 0.4382\n",
      "Iteration 2873: Weights = [5.50000000e+01 3.83839269e+00 8.07028209e+00 2.65889688e-02\n",
      " 2.68696993e-01 1.09143835e+01], Loss = 0.4382\n",
      "Iteration 2874: Weights = [5.50000000e+01 3.83828251e+00 8.07005043e+00 2.65882055e-02\n",
      " 2.68689279e-01 1.09146283e+01], Loss = 0.4381\n",
      "Iteration 2875: Weights = [5.50000000e+01 3.83817232e+00 8.06981877e+00 2.65874422e-02\n",
      " 2.68681566e-01 1.09148730e+01], Loss = 0.4381\n",
      "Iteration 2876: Weights = [5.50000000e+01 3.83806214e+00 8.06958711e+00 2.65866790e-02\n",
      " 2.68673853e-01 1.09151178e+01], Loss = 0.4381\n",
      "Iteration 2877: Weights = [5.50000000e+01 3.83795197e+00 8.06935546e+00 2.65859158e-02\n",
      " 2.68666141e-01 1.09153625e+01], Loss = 0.4381\n",
      "Iteration 2878: Weights = [5.50000000e+01 3.83784179e+00 8.06912382e+00 2.65851526e-02\n",
      " 2.68658428e-01 1.09156072e+01], Loss = 0.4380\n",
      "Iteration 2879: Weights = [5.50000000e+01 3.83773162e+00 8.06889219e+00 2.65843894e-02\n",
      " 2.68650716e-01 1.09158519e+01], Loss = 0.4380\n",
      "Iteration 2880: Weights = [5.50000000e+01 3.83762146e+00 8.06866056e+00 2.65836262e-02\n",
      " 2.68643004e-01 1.09160967e+01], Loss = 0.4380\n",
      "Iteration 2881: Weights = [5.50000000e+01 3.83751129e+00 8.06842894e+00 2.65828631e-02\n",
      " 2.68635293e-01 1.09163414e+01], Loss = 0.4380\n",
      "Iteration 2882: Weights = [5.50000000e+01 3.83740113e+00 8.06819732e+00 2.65821000e-02\n",
      " 2.68627581e-01 1.09165861e+01], Loss = 0.4379\n",
      "Iteration 2883: Weights = [5.50000000e+01 3.83729097e+00 8.06796571e+00 2.65813369e-02\n",
      " 2.68619870e-01 1.09168308e+01], Loss = 0.4379\n",
      "Iteration 2884: Weights = [5.50000000e+01 3.83718082e+00 8.06773411e+00 2.65805738e-02\n",
      " 2.68612159e-01 1.09170754e+01], Loss = 0.4379\n",
      "Iteration 2885: Weights = [5.50000000e+01 3.83707067e+00 8.06750252e+00 2.65798108e-02\n",
      " 2.68604448e-01 1.09173201e+01], Loss = 0.4379\n",
      "Iteration 2886: Weights = [5.50000000e+01 3.83696052e+00 8.06727093e+00 2.65790477e-02\n",
      " 2.68596737e-01 1.09175648e+01], Loss = 0.4378\n",
      "Iteration 2887: Weights = [5.50000000e+01 3.83685038e+00 8.06703935e+00 2.65782847e-02\n",
      " 2.68589027e-01 1.09178094e+01], Loss = 0.4378\n",
      "Iteration 2888: Weights = [5.50000000e+01 3.83674023e+00 8.06680777e+00 2.65775217e-02\n",
      " 2.68581317e-01 1.09180541e+01], Loss = 0.4378\n",
      "Iteration 2889: Weights = [5.50000000e+01 3.83663010e+00 8.06657620e+00 2.65767588e-02\n",
      " 2.68573607e-01 1.09182987e+01], Loss = 0.4378\n",
      "Iteration 2890: Weights = [5.50000000e+01 3.83651996e+00 8.06634464e+00 2.65759958e-02\n",
      " 2.68565897e-01 1.09185434e+01], Loss = 0.4377\n",
      "Iteration 2891: Weights = [5.50000000e+01 3.83640983e+00 8.06611309e+00 2.65752329e-02\n",
      " 2.68558187e-01 1.09187880e+01], Loss = 0.4377\n",
      "Iteration 2892: Weights = [5.50000000e+01 3.83629970e+00 8.06588154e+00 2.65744700e-02\n",
      " 2.68550478e-01 1.09190326e+01], Loss = 0.4377\n",
      "Iteration 2893: Weights = [5.50000000e+01 3.83618957e+00 8.06565000e+00 2.65737072e-02\n",
      " 2.68542769e-01 1.09192773e+01], Loss = 0.4377\n",
      "Iteration 2894: Weights = [5.50000000e+01 3.83607945e+00 8.06541846e+00 2.65729443e-02\n",
      " 2.68535060e-01 1.09195219e+01], Loss = 0.4376\n",
      "Iteration 2895: Weights = [5.50000000e+01 3.83596933e+00 8.06518693e+00 2.65721815e-02\n",
      " 2.68527351e-01 1.09197665e+01], Loss = 0.4376\n",
      "Iteration 2896: Weights = [5.50000000e+01 3.83585921e+00 8.06495541e+00 2.65714187e-02\n",
      " 2.68519643e-01 1.09200111e+01], Loss = 0.4376\n",
      "Iteration 2897: Weights = [5.50000000e+01 3.83574910e+00 8.06472390e+00 2.65706559e-02\n",
      " 2.68511935e-01 1.09202557e+01], Loss = 0.4376\n",
      "Iteration 2898: Weights = [5.50000000e+01 3.83563899e+00 8.06449239e+00 2.65698931e-02\n",
      " 2.68504227e-01 1.09205003e+01], Loss = 0.4375\n",
      "Iteration 2899: Weights = [5.50000000e+01 3.83552888e+00 8.06426089e+00 2.65691304e-02\n",
      " 2.68496519e-01 1.09207448e+01], Loss = 0.4375\n",
      "Iteration 2900: Weights = [5.50000000e+01 3.83541878e+00 8.06402939e+00 2.65683677e-02\n",
      " 2.68488812e-01 1.09209894e+01], Loss = 0.4375\n",
      "Iteration 2901: Weights = [5.50000000e+01 3.83530868e+00 8.06379790e+00 2.65676050e-02\n",
      " 2.68481104e-01 1.09212340e+01], Loss = 0.4375\n",
      "Iteration 2902: Weights = [5.50000000e+01 3.83519858e+00 8.06356642e+00 2.65668423e-02\n",
      " 2.68473397e-01 1.09214785e+01], Loss = 0.4374\n",
      "Iteration 2903: Weights = [5.50000000e+01 3.83508849e+00 8.06333495e+00 2.65660796e-02\n",
      " 2.68465690e-01 1.09217231e+01], Loss = 0.4374\n",
      "Iteration 2904: Weights = [5.50000000e+01 3.83497840e+00 8.06310348e+00 2.65653170e-02\n",
      " 2.68457984e-01 1.09219676e+01], Loss = 0.4374\n",
      "Iteration 2905: Weights = [5.50000000e+01 3.83486831e+00 8.06287202e+00 2.65645544e-02\n",
      " 2.68450277e-01 1.09222122e+01], Loss = 0.4374\n",
      "Iteration 2906: Weights = [5.50000000e+01 3.83475822e+00 8.06264056e+00 2.65637918e-02\n",
      " 2.68442571e-01 1.09224567e+01], Loss = 0.4373\n",
      "Iteration 2907: Weights = [5.50000000e+01 3.83464814e+00 8.06240911e+00 2.65630293e-02\n",
      " 2.68434865e-01 1.09227012e+01], Loss = 0.4373\n",
      "Iteration 2908: Weights = [5.50000000e+01 3.83453806e+00 8.06217767e+00 2.65622667e-02\n",
      " 2.68427159e-01 1.09229457e+01], Loss = 0.4373\n",
      "Iteration 2909: Weights = [5.50000000e+01 3.83442799e+00 8.06194623e+00 2.65615042e-02\n",
      " 2.68419454e-01 1.09231902e+01], Loss = 0.4373\n",
      "Iteration 2910: Weights = [5.50000000e+01 3.83431791e+00 8.06171481e+00 2.65607417e-02\n",
      " 2.68411748e-01 1.09234347e+01], Loss = 0.4372\n",
      "Iteration 2911: Weights = [5.50000000e+01 3.83420784e+00 8.06148338e+00 2.65599792e-02\n",
      " 2.68404043e-01 1.09236792e+01], Loss = 0.4372\n",
      "Iteration 2912: Weights = [5.50000000e+01 3.83409778e+00 8.06125197e+00 2.65592168e-02\n",
      " 2.68396338e-01 1.09239237e+01], Loss = 0.4372\n",
      "Iteration 2913: Weights = [5.50000000e+01 3.83398772e+00 8.06102056e+00 2.65584543e-02\n",
      " 2.68388634e-01 1.09241682e+01], Loss = 0.4372\n",
      "Iteration 2914: Weights = [5.50000000e+01 3.83387766e+00 8.06078916e+00 2.65576919e-02\n",
      " 2.68380929e-01 1.09244127e+01], Loss = 0.4371\n",
      "Iteration 2915: Weights = [5.50000000e+01 3.83376760e+00 8.06055776e+00 2.65569295e-02\n",
      " 2.68373225e-01 1.09246571e+01], Loss = 0.4371\n",
      "Iteration 2916: Weights = [5.50000000e+01 3.83365755e+00 8.06032637e+00 2.65561672e-02\n",
      " 2.68365521e-01 1.09249016e+01], Loss = 0.4371\n",
      "Iteration 2917: Weights = [5.50000000e+01 3.83354750e+00 8.06009499e+00 2.65554048e-02\n",
      " 2.68357817e-01 1.09251460e+01], Loss = 0.4371\n",
      "Iteration 2918: Weights = [5.50000000e+01 3.83343745e+00 8.05986362e+00 2.65546425e-02\n",
      " 2.68350114e-01 1.09253905e+01], Loss = 0.4370\n",
      "Iteration 2919: Weights = [5.50000000e+01 3.83332741e+00 8.05963225e+00 2.65538802e-02\n",
      " 2.68342410e-01 1.09256349e+01], Loss = 0.4370\n",
      "Iteration 2920: Weights = [5.50000000e+01 3.83321737e+00 8.05940088e+00 2.65531179e-02\n",
      " 2.68334707e-01 1.09258794e+01], Loss = 0.4370\n",
      "Iteration 2921: Weights = [5.50000000e+01 3.83310733e+00 8.05916953e+00 2.65523557e-02\n",
      " 2.68327004e-01 1.09261238e+01], Loss = 0.4370\n",
      "Iteration 2922: Weights = [5.50000000e+01 3.83299729e+00 8.05893818e+00 2.65515934e-02\n",
      " 2.68319302e-01 1.09263682e+01], Loss = 0.4369\n",
      "Iteration 2923: Weights = [5.50000000e+01 3.83288726e+00 8.05870684e+00 2.65508312e-02\n",
      " 2.68311599e-01 1.09266126e+01], Loss = 0.4369\n",
      "Iteration 2924: Weights = [5.50000000e+01 3.83277723e+00 8.05847550e+00 2.65500690e-02\n",
      " 2.68303897e-01 1.09268570e+01], Loss = 0.4369\n",
      "Iteration 2925: Weights = [5.50000000e+01 3.83266721e+00 8.05824417e+00 2.65493069e-02\n",
      " 2.68296195e-01 1.09271014e+01], Loss = 0.4369\n",
      "Iteration 2926: Weights = [5.50000000e+01 3.83255719e+00 8.05801285e+00 2.65485447e-02\n",
      " 2.68288493e-01 1.09273458e+01], Loss = 0.4368\n",
      "Iteration 2927: Weights = [5.50000000e+01 3.83244717e+00 8.05778153e+00 2.65477826e-02\n",
      " 2.68280792e-01 1.09275902e+01], Loss = 0.4368\n",
      "Iteration 2928: Weights = [5.50000000e+01 3.83233715e+00 8.05755023e+00 2.65470205e-02\n",
      " 2.68273090e-01 1.09278345e+01], Loss = 0.4368\n",
      "Iteration 2929: Weights = [5.50000000e+01 3.83222714e+00 8.05731892e+00 2.65462584e-02\n",
      " 2.68265389e-01 1.09280789e+01], Loss = 0.4368\n",
      "Iteration 2930: Weights = [5.50000000e+01 3.83211713e+00 8.05708763e+00 2.65454963e-02\n",
      " 2.68257688e-01 1.09283233e+01], Loss = 0.4367\n",
      "Iteration 2931: Weights = [5.50000000e+01 3.83200713e+00 8.05685634e+00 2.65447343e-02\n",
      " 2.68249988e-01 1.09285676e+01], Loss = 0.4367\n",
      "Iteration 2932: Weights = [5.50000000e+01 3.83189712e+00 8.05662505e+00 2.65439723e-02\n",
      " 2.68242287e-01 1.09288120e+01], Loss = 0.4367\n",
      "Iteration 2933: Weights = [5.50000000e+01 3.83178712e+00 8.05639378e+00 2.65432103e-02\n",
      " 2.68234587e-01 1.09290563e+01], Loss = 0.4367\n",
      "Iteration 2934: Weights = [5.50000000e+01 3.83167713e+00 8.05616251e+00 2.65424483e-02\n",
      " 2.68226887e-01 1.09293006e+01], Loss = 0.4366\n",
      "Iteration 2935: Weights = [5.50000000e+01 3.83156713e+00 8.05593125e+00 2.65416864e-02\n",
      " 2.68219187e-01 1.09295450e+01], Loss = 0.4366\n",
      "Iteration 2936: Weights = [5.50000000e+01 3.83145714e+00 8.05569999e+00 2.65409245e-02\n",
      " 2.68211488e-01 1.09297893e+01], Loss = 0.4366\n",
      "Iteration 2937: Weights = [5.50000000e+01 3.83134716e+00 8.05546874e+00 2.65401625e-02\n",
      " 2.68203788e-01 1.09300336e+01], Loss = 0.4366\n",
      "Iteration 2938: Weights = [5.50000000e+01 3.83123717e+00 8.05523750e+00 2.65394007e-02\n",
      " 2.68196089e-01 1.09302779e+01], Loss = 0.4365\n",
      "Iteration 2939: Weights = [5.50000000e+01 3.83112719e+00 8.05500626e+00 2.65386388e-02\n",
      " 2.68188390e-01 1.09305222e+01], Loss = 0.4365\n",
      "Iteration 2940: Weights = [5.50000000e+01 3.83101721e+00 8.05477503e+00 2.65378770e-02\n",
      " 2.68180692e-01 1.09307665e+01], Loss = 0.4365\n",
      "Iteration 2941: Weights = [5.50000000e+01 3.83090724e+00 8.05454381e+00 2.65371151e-02\n",
      " 2.68172993e-01 1.09310108e+01], Loss = 0.4365\n",
      "Iteration 2942: Weights = [5.50000000e+01 3.83079727e+00 8.05431259e+00 2.65363534e-02\n",
      " 2.68165295e-01 1.09312551e+01], Loss = 0.4364\n",
      "Iteration 2943: Weights = [5.50000000e+01 3.83068730e+00 8.05408138e+00 2.65355916e-02\n",
      " 2.68157597e-01 1.09314993e+01], Loss = 0.4364\n",
      "Iteration 2944: Weights = [5.50000000e+01 3.83057734e+00 8.05385018e+00 2.65348298e-02\n",
      " 2.68149899e-01 1.09317436e+01], Loss = 0.4364\n",
      "Iteration 2945: Weights = [5.50000000e+01 3.83046737e+00 8.05361899e+00 2.65340681e-02\n",
      " 2.68142201e-01 1.09319878e+01], Loss = 0.4364\n",
      "Iteration 2946: Weights = [5.50000000e+01 3.83035742e+00 8.05338780e+00 2.65333064e-02\n",
      " 2.68134504e-01 1.09322321e+01], Loss = 0.4363\n",
      "Iteration 2947: Weights = [5.50000000e+01 3.83024746e+00 8.05315661e+00 2.65325447e-02\n",
      " 2.68126807e-01 1.09324763e+01], Loss = 0.4363\n",
      "Iteration 2948: Weights = [5.50000000e+01 3.83013751e+00 8.05292544e+00 2.65317830e-02\n",
      " 2.68119110e-01 1.09327206e+01], Loss = 0.4363\n",
      "Iteration 2949: Weights = [5.50000000e+01 3.83002756e+00 8.05269427e+00 2.65310214e-02\n",
      " 2.68111413e-01 1.09329648e+01], Loss = 0.4363\n",
      "Iteration 2950: Weights = [5.50000000e+01 3.82991761e+00 8.05246310e+00 2.65302598e-02\n",
      " 2.68103717e-01 1.09332090e+01], Loss = 0.4362\n",
      "Iteration 2951: Weights = [5.50000000e+01 3.82980767e+00 8.05223195e+00 2.65294982e-02\n",
      " 2.68096020e-01 1.09334532e+01], Loss = 0.4362\n",
      "Iteration 2952: Weights = [5.50000000e+01 3.82969773e+00 8.05200080e+00 2.65287366e-02\n",
      " 2.68088324e-01 1.09336974e+01], Loss = 0.4362\n",
      "Iteration 2953: Weights = [5.50000000e+01 3.82958779e+00 8.05176965e+00 2.65279751e-02\n",
      " 2.68080629e-01 1.09339416e+01], Loss = 0.4362\n",
      "Iteration 2954: Weights = [5.50000000e+01 3.82947786e+00 8.05153852e+00 2.65272135e-02\n",
      " 2.68072933e-01 1.09341858e+01], Loss = 0.4361\n",
      "Iteration 2955: Weights = [5.50000000e+01 3.82936793e+00 8.05130739e+00 2.65264520e-02\n",
      " 2.68065238e-01 1.09344300e+01], Loss = 0.4361\n",
      "Iteration 2956: Weights = [5.50000000e+01 3.82925800e+00 8.05107626e+00 2.65256905e-02\n",
      " 2.68057543e-01 1.09346742e+01], Loss = 0.4361\n",
      "Iteration 2957: Weights = [5.50000000e+01 3.82914808e+00 8.05084515e+00 2.65249291e-02\n",
      " 2.68049848e-01 1.09349184e+01], Loss = 0.4361\n",
      "Iteration 2958: Weights = [5.50000000e+01 3.82903816e+00 8.05061404e+00 2.65241676e-02\n",
      " 2.68042153e-01 1.09351625e+01], Loss = 0.4360\n",
      "Iteration 2959: Weights = [5.50000000e+01 3.82892824e+00 8.05038293e+00 2.65234062e-02\n",
      " 2.68034458e-01 1.09354067e+01], Loss = 0.4360\n",
      "Iteration 2960: Weights = [5.50000000e+01 3.82881833e+00 8.05015184e+00 2.65226448e-02\n",
      " 2.68026764e-01 1.09356508e+01], Loss = 0.4360\n",
      "Iteration 2961: Weights = [5.50000000e+01 3.82870842e+00 8.04992075e+00 2.65218834e-02\n",
      " 2.68019070e-01 1.09358950e+01], Loss = 0.4360\n",
      "Iteration 2962: Weights = [5.50000000e+01 3.82859851e+00 8.04968966e+00 2.65211221e-02\n",
      " 2.68011376e-01 1.09361391e+01], Loss = 0.4359\n",
      "Iteration 2963: Weights = [5.50000000e+01 3.82848860e+00 8.04945859e+00 2.65203607e-02\n",
      " 2.68003683e-01 1.09363832e+01], Loss = 0.4359\n",
      "Iteration 2964: Weights = [5.50000000e+01 3.82837870e+00 8.04922752e+00 2.65195994e-02\n",
      " 2.67995989e-01 1.09366274e+01], Loss = 0.4359\n",
      "Iteration 2965: Weights = [5.50000000e+01 3.82826880e+00 8.04899645e+00 2.65188381e-02\n",
      " 2.67988296e-01 1.09368715e+01], Loss = 0.4359\n",
      "Iteration 2966: Weights = [5.50000000e+01 3.82815891e+00 8.04876540e+00 2.65180769e-02\n",
      " 2.67980603e-01 1.09371156e+01], Loss = 0.4358\n",
      "Iteration 2967: Weights = [5.50000000e+01 3.82804901e+00 8.04853435e+00 2.65173156e-02\n",
      " 2.67972910e-01 1.09373597e+01], Loss = 0.4358\n",
      "Iteration 2968: Weights = [5.50000000e+01 3.82793913e+00 8.04830330e+00 2.65165544e-02\n",
      " 2.67965218e-01 1.09376038e+01], Loss = 0.4358\n",
      "Iteration 2969: Weights = [5.50000000e+01 3.82782924e+00 8.04807226e+00 2.65157932e-02\n",
      " 2.67957526e-01 1.09378479e+01], Loss = 0.4358\n",
      "Iteration 2970: Weights = [5.50000000e+01 3.82771936e+00 8.04784123e+00 2.65150320e-02\n",
      " 2.67949833e-01 1.09380919e+01], Loss = 0.4357\n",
      "Iteration 2971: Weights = [5.50000000e+01 3.82760948e+00 8.04761021e+00 2.65142708e-02\n",
      " 2.67942142e-01 1.09383360e+01], Loss = 0.4357\n",
      "Iteration 2972: Weights = [5.50000000e+01 3.82749960e+00 8.04737919e+00 2.65135097e-02\n",
      " 2.67934450e-01 1.09385801e+01], Loss = 0.4357\n",
      "Iteration 2973: Weights = [5.50000000e+01 3.82738973e+00 8.04714818e+00 2.65127486e-02\n",
      " 2.67926759e-01 1.09388241e+01], Loss = 0.4357\n",
      "Iteration 2974: Weights = [5.50000000e+01 3.82727986e+00 8.04691718e+00 2.65119875e-02\n",
      " 2.67919067e-01 1.09390682e+01], Loss = 0.4356\n",
      "Iteration 2975: Weights = [5.50000000e+01 3.82716999e+00 8.04668618e+00 2.65112264e-02\n",
      " 2.67911376e-01 1.09393122e+01], Loss = 0.4356\n",
      "Iteration 2976: Weights = [5.50000000e+01 3.82706013e+00 8.04645519e+00 2.65104654e-02\n",
      " 2.67903686e-01 1.09395563e+01], Loss = 0.4356\n",
      "Iteration 2977: Weights = [5.50000000e+01 3.82695027e+00 8.04622421e+00 2.65097044e-02\n",
      " 2.67895995e-01 1.09398003e+01], Loss = 0.4356\n",
      "Iteration 2978: Weights = [5.50000000e+01 3.82684041e+00 8.04599323e+00 2.65089433e-02\n",
      " 2.67888305e-01 1.09400443e+01], Loss = 0.4355\n",
      "Iteration 2979: Weights = [5.50000000e+01 3.82673055e+00 8.04576226e+00 2.65081824e-02\n",
      " 2.67880615e-01 1.09402883e+01], Loss = 0.4355\n",
      "Iteration 2980: Weights = [5.50000000e+01 3.82662070e+00 8.04553129e+00 2.65074214e-02\n",
      " 2.67872925e-01 1.09405324e+01], Loss = 0.4355\n",
      "Iteration 2981: Weights = [5.50000000e+01 3.82651085e+00 8.04530034e+00 2.65066605e-02\n",
      " 2.67865235e-01 1.09407764e+01], Loss = 0.4355\n",
      "Iteration 2982: Weights = [5.50000000e+01 3.82640101e+00 8.04506939e+00 2.65058995e-02\n",
      " 2.67857546e-01 1.09410204e+01], Loss = 0.4354\n",
      "Iteration 2983: Weights = [5.50000000e+01 3.82629117e+00 8.04483844e+00 2.65051387e-02\n",
      " 2.67849857e-01 1.09412643e+01], Loss = 0.4354\n",
      "Iteration 2984: Weights = [5.50000000e+01 3.82618133e+00 8.04460750e+00 2.65043778e-02\n",
      " 2.67842168e-01 1.09415083e+01], Loss = 0.4354\n",
      "Iteration 2985: Weights = [5.50000000e+01 3.82607149e+00 8.04437657e+00 2.65036169e-02\n",
      " 2.67834479e-01 1.09417523e+01], Loss = 0.4354\n",
      "Iteration 2986: Weights = [5.50000000e+01 3.82596166e+00 8.04414565e+00 2.65028561e-02\n",
      " 2.67826790e-01 1.09419963e+01], Loss = 0.4353\n",
      "Iteration 2987: Weights = [5.50000000e+01 3.82585183e+00 8.04391473e+00 2.65020953e-02\n",
      " 2.67819102e-01 1.09422402e+01], Loss = 0.4353\n",
      "Iteration 2988: Weights = [5.50000000e+01 3.82574200e+00 8.04368382e+00 2.65013345e-02\n",
      " 2.67811414e-01 1.09424842e+01], Loss = 0.4353\n",
      "Iteration 2989: Weights = [5.50000000e+01 3.82563218e+00 8.04345292e+00 2.65005737e-02\n",
      " 2.67803726e-01 1.09427281e+01], Loss = 0.4353\n",
      "Iteration 2990: Weights = [5.50000000e+01 3.82552236e+00 8.04322202e+00 2.64998130e-02\n",
      " 2.67796039e-01 1.09429721e+01], Loss = 0.4352\n",
      "Iteration 2991: Weights = [5.50000000e+01 3.82541255e+00 8.04299113e+00 2.64990523e-02\n",
      " 2.67788351e-01 1.09432160e+01], Loss = 0.4352\n",
      "Iteration 2992: Weights = [5.50000000e+01 3.82530273e+00 8.04276024e+00 2.64982916e-02\n",
      " 2.67780664e-01 1.09434599e+01], Loss = 0.4352\n",
      "Iteration 2993: Weights = [5.50000000e+01 3.82519292e+00 8.04252936e+00 2.64975309e-02\n",
      " 2.67772977e-01 1.09437039e+01], Loss = 0.4352\n",
      "Iteration 2994: Weights = [5.50000000e+01 3.82508311e+00 8.04229849e+00 2.64967702e-02\n",
      " 2.67765290e-01 1.09439478e+01], Loss = 0.4351\n",
      "Iteration 2995: Weights = [5.50000000e+01 3.82497331e+00 8.04206763e+00 2.64960096e-02\n",
      " 2.67757604e-01 1.09441917e+01], Loss = 0.4351\n",
      "Iteration 2996: Weights = [5.50000000e+01 3.82486351e+00 8.04183677e+00 2.64952490e-02\n",
      " 2.67749917e-01 1.09444356e+01], Loss = 0.4351\n",
      "Iteration 2997: Weights = [5.50000000e+01 3.82475371e+00 8.04160592e+00 2.64944884e-02\n",
      " 2.67742231e-01 1.09446795e+01], Loss = 0.4351\n",
      "Iteration 2998: Weights = [5.50000000e+01 3.82464392e+00 8.04137507e+00 2.64937278e-02\n",
      " 2.67734545e-01 1.09449233e+01], Loss = 0.4350\n",
      "Iteration 2999: Weights = [5.50000000e+01 3.82453413e+00 8.04114423e+00 2.64929673e-02\n",
      " 2.67726860e-01 1.09451672e+01], Loss = 0.4350\n",
      "Iteration 3000: Weights = [5.50000000e+01 3.82442434e+00 8.04091340e+00 2.64922068e-02\n",
      " 2.67719174e-01 1.09454111e+01], Loss = 0.4350\n",
      "Iteration 3001: Weights = [5.50000000e+01 3.82431455e+00 8.04068258e+00 2.64914463e-02\n",
      " 2.67711489e-01 1.09456549e+01], Loss = 0.4350\n",
      "Iteration 3002: Weights = [5.50000000e+01 3.82420477e+00 8.04045176e+00 2.64906858e-02\n",
      " 2.67703804e-01 1.09458988e+01], Loss = 0.4349\n",
      "Iteration 3003: Weights = [5.50000000e+01 3.82409499e+00 8.04022095e+00 2.64899253e-02\n",
      " 2.67696119e-01 1.09461427e+01], Loss = 0.4349\n",
      "Iteration 3004: Weights = [5.50000000e+01 3.82398522e+00 8.03999014e+00 2.64891649e-02\n",
      " 2.67688435e-01 1.09463865e+01], Loss = 0.4349\n",
      "Iteration 3005: Weights = [5.50000000e+01 3.82387544e+00 8.03975934e+00 2.64884045e-02\n",
      " 2.67680750e-01 1.09466303e+01], Loss = 0.4349\n",
      "Iteration 3006: Weights = [5.50000000e+01 3.82376567e+00 8.03952855e+00 2.64876441e-02\n",
      " 2.67673066e-01 1.09468742e+01], Loss = 0.4348\n",
      "Iteration 3007: Weights = [5.50000000e+01 3.82365591e+00 8.03929777e+00 2.64868837e-02\n",
      " 2.67665382e-01 1.09471180e+01], Loss = 0.4348\n",
      "Iteration 3008: Weights = [5.50000000e+01 3.82354615e+00 8.03906699e+00 2.64861234e-02\n",
      " 2.67657699e-01 1.09473618e+01], Loss = 0.4348\n",
      "Iteration 3009: Weights = [5.50000000e+01 3.82343639e+00 8.03883622e+00 2.64853631e-02\n",
      " 2.67650015e-01 1.09476056e+01], Loss = 0.4348\n",
      "Iteration 3010: Weights = [5.50000000e+01 3.82332663e+00 8.03860545e+00 2.64846027e-02\n",
      " 2.67642332e-01 1.09478494e+01], Loss = 0.4347\n",
      "Iteration 3011: Weights = [5.50000000e+01 3.82321687e+00 8.03837469e+00 2.64838425e-02\n",
      " 2.67634649e-01 1.09480932e+01], Loss = 0.4347\n",
      "Iteration 3012: Weights = [5.50000000e+01 3.82310712e+00 8.03814394e+00 2.64830822e-02\n",
      " 2.67626966e-01 1.09483370e+01], Loss = 0.4347\n",
      "Iteration 3013: Weights = [5.50000000e+01 3.82299738e+00 8.03791320e+00 2.64823220e-02\n",
      " 2.67619283e-01 1.09485808e+01], Loss = 0.4347\n",
      "Iteration 3014: Weights = [5.50000000e+01 3.82288763e+00 8.03768246e+00 2.64815617e-02\n",
      " 2.67611601e-01 1.09488245e+01], Loss = 0.4346\n",
      "Iteration 3015: Weights = [5.50000000e+01 3.82277789e+00 8.03745172e+00 2.64808016e-02\n",
      " 2.67603919e-01 1.09490683e+01], Loss = 0.4346\n",
      "Iteration 3016: Weights = [5.50000000e+01 3.82266815e+00 8.03722100e+00 2.64800414e-02\n",
      " 2.67596237e-01 1.09493121e+01], Loss = 0.4346\n",
      "Iteration 3017: Weights = [5.50000000e+01 3.82255842e+00 8.03699028e+00 2.64792812e-02\n",
      " 2.67588555e-01 1.09495558e+01], Loss = 0.4346\n",
      "Iteration 3018: Weights = [5.50000000e+01 3.82244869e+00 8.03675957e+00 2.64785211e-02\n",
      " 2.67580874e-01 1.09497995e+01], Loss = 0.4345\n",
      "Iteration 3019: Weights = [5.50000000e+01 3.82233896e+00 8.03652886e+00 2.64777610e-02\n",
      " 2.67573193e-01 1.09500433e+01], Loss = 0.4345\n",
      "Iteration 3020: Weights = [5.50000000e+01 3.82222923e+00 8.03629816e+00 2.64770009e-02\n",
      " 2.67565512e-01 1.09502870e+01], Loss = 0.4345\n",
      "Iteration 3021: Weights = [5.50000000e+01 3.82211951e+00 8.03606747e+00 2.64762408e-02\n",
      " 2.67557831e-01 1.09505307e+01], Loss = 0.4345\n",
      "Iteration 3022: Weights = [5.50000000e+01 3.82200979e+00 8.03583678e+00 2.64754808e-02\n",
      " 2.67550150e-01 1.09507745e+01], Loss = 0.4344\n",
      "Iteration 3023: Weights = [5.50000000e+01 3.82190008e+00 8.03560611e+00 2.64747208e-02\n",
      " 2.67542470e-01 1.09510182e+01], Loss = 0.4344\n",
      "Iteration 3024: Weights = [5.50000000e+01 3.82179036e+00 8.03537543e+00 2.64739608e-02\n",
      " 2.67534790e-01 1.09512619e+01], Loss = 0.4344\n",
      "Iteration 3025: Weights = [5.50000000e+01 3.82168066e+00 8.03514477e+00 2.64732008e-02\n",
      " 2.67527110e-01 1.09515056e+01], Loss = 0.4344\n",
      "Iteration 3026: Weights = [5.50000000e+01 3.82157095e+00 8.03491411e+00 2.64724408e-02\n",
      " 2.67519430e-01 1.09517492e+01], Loss = 0.4343\n",
      "Iteration 3027: Weights = [5.50000000e+01 3.82146125e+00 8.03468346e+00 2.64716809e-02\n",
      " 2.67511750e-01 1.09519929e+01], Loss = 0.4343\n",
      "Iteration 3028: Weights = [5.50000000e+01 3.82135155e+00 8.03445281e+00 2.64709210e-02\n",
      " 2.67504071e-01 1.09522366e+01], Loss = 0.4343\n",
      "Iteration 3029: Weights = [5.50000000e+01 3.82124185e+00 8.03422217e+00 2.64701611e-02\n",
      " 2.67496392e-01 1.09524803e+01], Loss = 0.4343\n",
      "Iteration 3030: Weights = [5.50000000e+01 3.82113216e+00 8.03399154e+00 2.64694013e-02\n",
      " 2.67488713e-01 1.09527239e+01], Loss = 0.4342\n",
      "Iteration 3031: Weights = [5.50000000e+01 3.82102246e+00 8.03376091e+00 2.64686414e-02\n",
      " 2.67481035e-01 1.09529676e+01], Loss = 0.4342\n",
      "Iteration 3032: Weights = [5.50000000e+01 3.82091278e+00 8.03353029e+00 2.64678816e-02\n",
      " 2.67473356e-01 1.09532112e+01], Loss = 0.4342\n",
      "Iteration 3033: Weights = [5.50000000e+01 3.82080309e+00 8.03329968e+00 2.64671218e-02\n",
      " 2.67465678e-01 1.09534549e+01], Loss = 0.4342\n",
      "Iteration 3034: Weights = [5.50000000e+01 3.82069341e+00 8.03306907e+00 2.64663620e-02\n",
      " 2.67458000e-01 1.09536985e+01], Loss = 0.4341\n",
      "Iteration 3035: Weights = [5.50000000e+01 3.82058373e+00 8.03283847e+00 2.64656022e-02\n",
      " 2.67450323e-01 1.09539421e+01], Loss = 0.4341\n",
      "Iteration 3036: Weights = [5.50000000e+01 3.82047406e+00 8.03260788e+00 2.64648425e-02\n",
      " 2.67442645e-01 1.09541857e+01], Loss = 0.4341\n",
      "Iteration 3037: Weights = [5.50000000e+01 3.82036439e+00 8.03237729e+00 2.64640828e-02\n",
      " 2.67434968e-01 1.09544294e+01], Loss = 0.4341\n",
      "Iteration 3038: Weights = [5.50000000e+01 3.82025472e+00 8.03214671e+00 2.64633231e-02\n",
      " 2.67427291e-01 1.09546730e+01], Loss = 0.4340\n",
      "Iteration 3039: Weights = [5.50000000e+01 3.82014505e+00 8.03191614e+00 2.64625634e-02\n",
      " 2.67419614e-01 1.09549166e+01], Loss = 0.4340\n",
      "Iteration 3040: Weights = [5.50000000e+01 3.82003539e+00 8.03168557e+00 2.64618038e-02\n",
      " 2.67411937e-01 1.09551601e+01], Loss = 0.4340\n",
      "Iteration 3041: Weights = [5.50000000e+01 3.81992573e+00 8.03145501e+00 2.64610442e-02\n",
      " 2.67404261e-01 1.09554037e+01], Loss = 0.4340\n",
      "Iteration 3042: Weights = [5.50000000e+01 3.81981608e+00 8.03122446e+00 2.64602845e-02\n",
      " 2.67396585e-01 1.09556473e+01], Loss = 0.4339\n",
      "Iteration 3043: Weights = [5.50000000e+01 3.81970642e+00 8.03099391e+00 2.64595250e-02\n",
      " 2.67388909e-01 1.09558909e+01], Loss = 0.4339\n",
      "Iteration 3044: Weights = [5.50000000e+01 3.81959677e+00 8.03076337e+00 2.64587654e-02\n",
      " 2.67381233e-01 1.09561344e+01], Loss = 0.4339\n",
      "Iteration 3045: Weights = [5.50000000e+01 3.81948713e+00 8.03053284e+00 2.64580059e-02\n",
      " 2.67373557e-01 1.09563780e+01], Loss = 0.4339\n",
      "Iteration 3046: Weights = [5.50000000e+01 3.81937748e+00 8.03030231e+00 2.64572463e-02\n",
      " 2.67365882e-01 1.09566215e+01], Loss = 0.4338\n",
      "Iteration 3047: Weights = [5.50000000e+01 3.81926784e+00 8.03007179e+00 2.64564869e-02\n",
      " 2.67358207e-01 1.09568651e+01], Loss = 0.4338\n",
      "Iteration 3048: Weights = [5.50000000e+01 3.81915821e+00 8.02984128e+00 2.64557274e-02\n",
      " 2.67350532e-01 1.09571086e+01], Loss = 0.4338\n",
      "Iteration 3049: Weights = [5.50000000e+01 3.81904857e+00 8.02961077e+00 2.64549679e-02\n",
      " 2.67342857e-01 1.09573521e+01], Loss = 0.4338\n",
      "Iteration 3050: Weights = [5.50000000e+01 3.81893894e+00 8.02938027e+00 2.64542085e-02\n",
      " 2.67335183e-01 1.09575957e+01], Loss = 0.4337\n",
      "Iteration 3051: Weights = [5.50000000e+01 3.81882931e+00 8.02914978e+00 2.64534491e-02\n",
      " 2.67327509e-01 1.09578392e+01], Loss = 0.4337\n",
      "Iteration 3052: Weights = [5.50000000e+01 3.81871969e+00 8.02891929e+00 2.64526897e-02\n",
      " 2.67319835e-01 1.09580827e+01], Loss = 0.4337\n",
      "Iteration 3053: Weights = [5.50000000e+01 3.81861007e+00 8.02868881e+00 2.64519303e-02\n",
      " 2.67312161e-01 1.09583262e+01], Loss = 0.4337\n",
      "Iteration 3054: Weights = [5.50000000e+01 3.81850045e+00 8.02845833e+00 2.64511710e-02\n",
      " 2.67304488e-01 1.09585697e+01], Loss = 0.4336\n",
      "Iteration 3055: Weights = [5.50000000e+01 3.81839083e+00 8.02822787e+00 2.64504117e-02\n",
      " 2.67296814e-01 1.09588132e+01], Loss = 0.4336\n",
      "Iteration 3056: Weights = [5.50000000e+01 3.81828122e+00 8.02799741e+00 2.64496524e-02\n",
      " 2.67289141e-01 1.09590566e+01], Loss = 0.4336\n",
      "Iteration 3057: Weights = [5.50000000e+01 3.81817161e+00 8.02776695e+00 2.64488931e-02\n",
      " 2.67281468e-01 1.09593001e+01], Loss = 0.4336\n",
      "Iteration 3058: Weights = [5.50000000e+01 3.81806201e+00 8.02753650e+00 2.64481338e-02\n",
      " 2.67273796e-01 1.09595436e+01], Loss = 0.4335\n",
      "Iteration 3059: Weights = [5.50000000e+01 3.81795241e+00 8.02730606e+00 2.64473746e-02\n",
      " 2.67266123e-01 1.09597870e+01], Loss = 0.4335\n",
      "Iteration 3060: Weights = [5.50000000e+01 3.81784281e+00 8.02707563e+00 2.64466154e-02\n",
      " 2.67258451e-01 1.09600305e+01], Loss = 0.4335\n",
      "Iteration 3061: Weights = [5.50000000e+01 3.81773321e+00 8.02684520e+00 2.64458562e-02\n",
      " 2.67250779e-01 1.09602739e+01], Loss = 0.4335\n",
      "Iteration 3062: Weights = [5.50000000e+01 3.81762362e+00 8.02661478e+00 2.64450970e-02\n",
      " 2.67243107e-01 1.09605174e+01], Loss = 0.4334\n",
      "Iteration 3063: Weights = [5.50000000e+01 3.81751403e+00 8.02638437e+00 2.64443379e-02\n",
      " 2.67235436e-01 1.09607608e+01], Loss = 0.4334\n",
      "Iteration 3064: Weights = [5.50000000e+01 3.81740444e+00 8.02615396e+00 2.64435788e-02\n",
      " 2.67227764e-01 1.09610042e+01], Loss = 0.4334\n",
      "Iteration 3065: Weights = [5.50000000e+01 3.81729486e+00 8.02592356e+00 2.64428197e-02\n",
      " 2.67220093e-01 1.09612476e+01], Loss = 0.4334\n",
      "Iteration 3066: Weights = [5.50000000e+01 3.81718528e+00 8.02569316e+00 2.64420606e-02\n",
      " 2.67212422e-01 1.09614910e+01], Loss = 0.4333\n",
      "Iteration 3067: Weights = [5.50000000e+01 3.81707570e+00 8.02546277e+00 2.64413015e-02\n",
      " 2.67204752e-01 1.09617344e+01], Loss = 0.4333\n",
      "Iteration 3068: Weights = [5.50000000e+01 3.81696613e+00 8.02523239e+00 2.64405425e-02\n",
      " 2.67197081e-01 1.09619778e+01], Loss = 0.4333\n",
      "Iteration 3069: Weights = [5.50000000e+01 3.81685655e+00 8.02500202e+00 2.64397835e-02\n",
      " 2.67189411e-01 1.09622212e+01], Loss = 0.4333\n",
      "Iteration 3070: Weights = [5.50000000e+01 3.81674699e+00 8.02477165e+00 2.64390245e-02\n",
      " 2.67181741e-01 1.09624646e+01], Loss = 0.4332\n",
      "Iteration 3071: Weights = [5.50000000e+01 3.81663742e+00 8.02454129e+00 2.64382655e-02\n",
      " 2.67174071e-01 1.09627080e+01], Loss = 0.4332\n",
      "Iteration 3072: Weights = [5.50000000e+01 3.81652786e+00 8.02431093e+00 2.64375066e-02\n",
      " 2.67166401e-01 1.09629513e+01], Loss = 0.4332\n",
      "Iteration 3073: Weights = [5.50000000e+01 3.81641830e+00 8.02408058e+00 2.64367476e-02\n",
      " 2.67158732e-01 1.09631947e+01], Loss = 0.4332\n",
      "Iteration 3074: Weights = [5.50000000e+01 3.81630875e+00 8.02385024e+00 2.64359887e-02\n",
      " 2.67151063e-01 1.09634380e+01], Loss = 0.4331\n",
      "Iteration 3075: Weights = [5.50000000e+01 3.81619919e+00 8.02361991e+00 2.64352298e-02\n",
      " 2.67143394e-01 1.09636814e+01], Loss = 0.4331\n",
      "Iteration 3076: Weights = [5.50000000e+01 3.81608965e+00 8.02338958e+00 2.64344710e-02\n",
      " 2.67135725e-01 1.09639247e+01], Loss = 0.4331\n",
      "Iteration 3077: Weights = [5.50000000e+01 3.81598010e+00 8.02315926e+00 2.64337121e-02\n",
      " 2.67128057e-01 1.09641681e+01], Loss = 0.4331\n",
      "Iteration 3078: Weights = [5.50000000e+01 3.81587056e+00 8.02292894e+00 2.64329533e-02\n",
      " 2.67120389e-01 1.09644114e+01], Loss = 0.4330\n",
      "Iteration 3079: Weights = [5.50000000e+01 3.81576102e+00 8.02269863e+00 2.64321945e-02\n",
      " 2.67112721e-01 1.09646547e+01], Loss = 0.4330\n",
      "Iteration 3080: Weights = [5.50000000e+01 3.81565148e+00 8.02246833e+00 2.64314357e-02\n",
      " 2.67105053e-01 1.09648980e+01], Loss = 0.4330\n",
      "Iteration 3081: Weights = [5.50000000e+01 3.81554195e+00 8.02223804e+00 2.64306770e-02\n",
      " 2.67097385e-01 1.09651413e+01], Loss = 0.4330\n",
      "Iteration 3082: Weights = [5.50000000e+01 3.81543242e+00 8.02200775e+00 2.64299183e-02\n",
      " 2.67089718e-01 1.09653846e+01], Loss = 0.4329\n",
      "Iteration 3083: Weights = [5.50000000e+01 3.81532289e+00 8.02177746e+00 2.64291596e-02\n",
      " 2.67082051e-01 1.09656279e+01], Loss = 0.4329\n",
      "Iteration 3084: Weights = [5.50000000e+01 3.81521337e+00 8.02154719e+00 2.64284009e-02\n",
      " 2.67074384e-01 1.09658712e+01], Loss = 0.4329\n",
      "Iteration 3085: Weights = [5.50000000e+01 3.81510385e+00 8.02131692e+00 2.64276422e-02\n",
      " 2.67066717e-01 1.09661145e+01], Loss = 0.4329\n",
      "Iteration 3086: Weights = [5.50000000e+01 3.81499433e+00 8.02108666e+00 2.64268836e-02\n",
      " 2.67059050e-01 1.09663577e+01], Loss = 0.4328\n",
      "Iteration 3087: Weights = [5.50000000e+01 3.81488481e+00 8.02085640e+00 2.64261249e-02\n",
      " 2.67051384e-01 1.09666010e+01], Loss = 0.4328\n",
      "Iteration 3088: Weights = [5.50000000e+01 3.81477530e+00 8.02062615e+00 2.64253663e-02\n",
      " 2.67043718e-01 1.09668442e+01], Loss = 0.4328\n",
      "Iteration 3089: Weights = [5.50000000e+01 3.81466579e+00 8.02039591e+00 2.64246078e-02\n",
      " 2.67036052e-01 1.09670875e+01], Loss = 0.4328\n",
      "Iteration 3090: Weights = [5.50000000e+01 3.81455629e+00 8.02016567e+00 2.64238492e-02\n",
      " 2.67028387e-01 1.09673307e+01], Loss = 0.4327\n",
      "Iteration 3091: Weights = [5.50000000e+01 3.81444679e+00 8.01993544e+00 2.64230907e-02\n",
      " 2.67020721e-01 1.09675740e+01], Loss = 0.4327\n",
      "Iteration 3092: Weights = [5.50000000e+01 3.81433729e+00 8.01970522e+00 2.64223321e-02\n",
      " 2.67013056e-01 1.09678172e+01], Loss = 0.4327\n",
      "Iteration 3093: Weights = [5.50000000e+01 3.81422779e+00 8.01947501e+00 2.64215737e-02\n",
      " 2.67005391e-01 1.09680604e+01], Loss = 0.4327\n",
      "Iteration 3094: Weights = [5.50000000e+01 3.81411830e+00 8.01924480e+00 2.64208152e-02\n",
      " 2.66997726e-01 1.09683036e+01], Loss = 0.4326\n",
      "Iteration 3095: Weights = [5.50000000e+01 3.81400881e+00 8.01901459e+00 2.64200567e-02\n",
      " 2.66990062e-01 1.09685468e+01], Loss = 0.4326\n",
      "Iteration 3096: Weights = [5.50000000e+01 3.81389933e+00 8.01878440e+00 2.64192983e-02\n",
      " 2.66982398e-01 1.09687900e+01], Loss = 0.4326\n",
      "Iteration 3097: Weights = [5.50000000e+01 3.81378984e+00 8.01855421e+00 2.64185399e-02\n",
      " 2.66974733e-01 1.09690332e+01], Loss = 0.4326\n",
      "Iteration 3098: Weights = [5.50000000e+01 3.81368036e+00 8.01832402e+00 2.64177815e-02\n",
      " 2.66967070e-01 1.09692764e+01], Loss = 0.4325\n",
      "Iteration 3099: Weights = [5.50000000e+01 3.81357089e+00 8.01809385e+00 2.64170232e-02\n",
      " 2.66959406e-01 1.09695196e+01], Loss = 0.4325\n",
      "Iteration 3100: Weights = [5.50000000e+01 3.81346141e+00 8.01786368e+00 2.64162648e-02\n",
      " 2.66951743e-01 1.09697628e+01], Loss = 0.4325\n",
      "Iteration 3101: Weights = [5.50000000e+01 3.81335194e+00 8.01763351e+00 2.64155065e-02\n",
      " 2.66944079e-01 1.09700059e+01], Loss = 0.4325\n",
      "Iteration 3102: Weights = [5.50000000e+01 3.81324248e+00 8.01740336e+00 2.64147482e-02\n",
      " 2.66936416e-01 1.09702491e+01], Loss = 0.4324\n",
      "Iteration 3103: Weights = [5.50000000e+01 3.81313301e+00 8.01717321e+00 2.64139899e-02\n",
      " 2.66928754e-01 1.09704922e+01], Loss = 0.4324\n",
      "Iteration 3104: Weights = [5.50000000e+01 3.81302355e+00 8.01694306e+00 2.64132317e-02\n",
      " 2.66921091e-01 1.09707354e+01], Loss = 0.4324\n",
      "Iteration 3105: Weights = [5.50000000e+01 3.81291409e+00 8.01671293e+00 2.64124735e-02\n",
      " 2.66913429e-01 1.09709785e+01], Loss = 0.4324\n",
      "Iteration 3106: Weights = [5.50000000e+01 3.81280464e+00 8.01648280e+00 2.64117152e-02\n",
      " 2.66905767e-01 1.09712216e+01], Loss = 0.4323\n",
      "Iteration 3107: Weights = [5.50000000e+01 3.81269519e+00 8.01625267e+00 2.64109571e-02\n",
      " 2.66898105e-01 1.09714648e+01], Loss = 0.4323\n",
      "Iteration 3108: Weights = [5.50000000e+01 3.81258574e+00 8.01602256e+00 2.64101989e-02\n",
      " 2.66890443e-01 1.09717079e+01], Loss = 0.4323\n",
      "Iteration 3109: Weights = [5.50000000e+01 3.81247629e+00 8.01579245e+00 2.64094408e-02\n",
      " 2.66882782e-01 1.09719510e+01], Loss = 0.4323\n",
      "Iteration 3110: Weights = [5.50000000e+01 3.81236685e+00 8.01556234e+00 2.64086826e-02\n",
      " 2.66875121e-01 1.09721941e+01], Loss = 0.4322\n",
      "Iteration 3111: Weights = [5.50000000e+01 3.81225741e+00 8.01533224e+00 2.64079245e-02\n",
      " 2.66867460e-01 1.09724372e+01], Loss = 0.4322\n",
      "Iteration 3112: Weights = [5.50000000e+01 3.81214798e+00 8.01510215e+00 2.64071665e-02\n",
      " 2.66859799e-01 1.09726803e+01], Loss = 0.4322\n",
      "Iteration 3113: Weights = [5.50000000e+01 3.81203854e+00 8.01487207e+00 2.64064084e-02\n",
      " 2.66852138e-01 1.09729233e+01], Loss = 0.4322\n",
      "Iteration 3114: Weights = [5.50000000e+01 3.81192911e+00 8.01464199e+00 2.64056504e-02\n",
      " 2.66844478e-01 1.09731664e+01], Loss = 0.4321\n",
      "Iteration 3115: Weights = [5.50000000e+01 3.81181969e+00 8.01441192e+00 2.64048924e-02\n",
      " 2.66836818e-01 1.09734095e+01], Loss = 0.4321\n",
      "Iteration 3116: Weights = [5.50000000e+01 3.81171026e+00 8.01418186e+00 2.64041344e-02\n",
      " 2.66829158e-01 1.09736525e+01], Loss = 0.4321\n",
      "Iteration 3117: Weights = [5.50000000e+01 3.81160084e+00 8.01395180e+00 2.64033764e-02\n",
      " 2.66821498e-01 1.09738956e+01], Loss = 0.4321\n",
      "Iteration 3118: Weights = [5.50000000e+01 3.81149143e+00 8.01372175e+00 2.64026184e-02\n",
      " 2.66813839e-01 1.09741386e+01], Loss = 0.4321\n",
      "Iteration 3119: Weights = [5.50000000e+01 3.81138201e+00 8.01349171e+00 2.64018605e-02\n",
      " 2.66806179e-01 1.09743817e+01], Loss = 0.4320\n",
      "Iteration 3120: Weights = [5.50000000e+01 3.81127260e+00 8.01326167e+00 2.64011026e-02\n",
      " 2.66798520e-01 1.09746247e+01], Loss = 0.4320\n",
      "Iteration 3121: Weights = [5.50000000e+01 3.81116319e+00 8.01303164e+00 2.64003447e-02\n",
      " 2.66790862e-01 1.09748677e+01], Loss = 0.4320\n",
      "Iteration 3122: Weights = [5.50000000e+01 3.81105379e+00 8.01280161e+00 2.63995869e-02\n",
      " 2.66783203e-01 1.09751107e+01], Loss = 0.4320\n",
      "Iteration 3123: Weights = [5.50000000e+01 3.81094439e+00 8.01257159e+00 2.63988290e-02\n",
      " 2.66775545e-01 1.09753538e+01], Loss = 0.4319\n",
      "Iteration 3124: Weights = [5.50000000e+01 3.81083499e+00 8.01234158e+00 2.63980712e-02\n",
      " 2.66767887e-01 1.09755968e+01], Loss = 0.4319\n",
      "Iteration 3125: Weights = [5.50000000e+01 3.81072560e+00 8.01211158e+00 2.63973134e-02\n",
      " 2.66760229e-01 1.09758398e+01], Loss = 0.4319\n",
      "Iteration 3126: Weights = [5.50000000e+01 3.81061620e+00 8.01188158e+00 2.63965557e-02\n",
      " 2.66752571e-01 1.09760827e+01], Loss = 0.4319\n",
      "Iteration 3127: Weights = [5.50000000e+01 3.81050681e+00 8.01165159e+00 2.63957979e-02\n",
      " 2.66744913e-01 1.09763257e+01], Loss = 0.4318\n",
      "Iteration 3128: Weights = [5.50000000e+01 3.81039743e+00 8.01142160e+00 2.63950402e-02\n",
      " 2.66737256e-01 1.09765687e+01], Loss = 0.4318\n",
      "Iteration 3129: Weights = [5.50000000e+01 3.81028805e+00 8.01119162e+00 2.63942825e-02\n",
      " 2.66729599e-01 1.09768117e+01], Loss = 0.4318\n",
      "Iteration 3130: Weights = [5.50000000e+01 3.81017867e+00 8.01096165e+00 2.63935248e-02\n",
      " 2.66721942e-01 1.09770546e+01], Loss = 0.4318\n",
      "Iteration 3131: Weights = [5.50000000e+01 3.81006929e+00 8.01073169e+00 2.63927671e-02\n",
      " 2.66714286e-01 1.09772976e+01], Loss = 0.4317\n",
      "Iteration 3132: Weights = [5.50000000e+01 3.80995992e+00 8.01050173e+00 2.63920095e-02\n",
      " 2.66706629e-01 1.09775405e+01], Loss = 0.4317\n",
      "Iteration 3133: Weights = [5.50000000e+01 3.80985055e+00 8.01027178e+00 2.63912519e-02\n",
      " 2.66698973e-01 1.09777835e+01], Loss = 0.4317\n",
      "Iteration 3134: Weights = [5.50000000e+01 3.80974118e+00 8.01004183e+00 2.63904943e-02\n",
      " 2.66691317e-01 1.09780264e+01], Loss = 0.4317\n",
      "Iteration 3135: Weights = [5.50000000e+01 3.80963182e+00 8.00981189e+00 2.63897367e-02\n",
      " 2.66683662e-01 1.09782693e+01], Loss = 0.4316\n",
      "Iteration 3136: Weights = [5.50000000e+01 3.80952246e+00 8.00958196e+00 2.63889791e-02\n",
      " 2.66676006e-01 1.09785123e+01], Loss = 0.4316\n",
      "Iteration 3137: Weights = [5.50000000e+01 3.80941310e+00 8.00935204e+00 2.63882216e-02\n",
      " 2.66668351e-01 1.09787552e+01], Loss = 0.4316\n",
      "Iteration 3138: Weights = [5.50000000e+01 3.80930375e+00 8.00912212e+00 2.63874641e-02\n",
      " 2.66660696e-01 1.09789981e+01], Loss = 0.4316\n",
      "Iteration 3139: Weights = [5.50000000e+01 3.80919439e+00 8.00889220e+00 2.63867066e-02\n",
      " 2.66653041e-01 1.09792410e+01], Loss = 0.4315\n",
      "Iteration 3140: Weights = [5.50000000e+01 3.80908505e+00 8.00866230e+00 2.63859491e-02\n",
      " 2.66645386e-01 1.09794839e+01], Loss = 0.4315\n",
      "Iteration 3141: Weights = [5.50000000e+01 3.80897570e+00 8.00843240e+00 2.63851917e-02\n",
      " 2.66637732e-01 1.09797267e+01], Loss = 0.4315\n",
      "Iteration 3142: Weights = [5.50000000e+01 3.80886636e+00 8.00820251e+00 2.63844343e-02\n",
      " 2.66630078e-01 1.09799696e+01], Loss = 0.4315\n",
      "Iteration 3143: Weights = [5.50000000e+01 3.80875702e+00 8.00797262e+00 2.63836768e-02\n",
      " 2.66622424e-01 1.09802125e+01], Loss = 0.4314\n",
      "Iteration 3144: Weights = [5.50000000e+01 3.80864769e+00 8.00774274e+00 2.63829195e-02\n",
      " 2.66614770e-01 1.09804554e+01], Loss = 0.4314\n",
      "Iteration 3145: Weights = [5.50000000e+01 3.80853835e+00 8.00751287e+00 2.63821621e-02\n",
      " 2.66607116e-01 1.09806982e+01], Loss = 0.4314\n",
      "Iteration 3146: Weights = [5.50000000e+01 3.80842903e+00 8.00728300e+00 2.63814048e-02\n",
      " 2.66599463e-01 1.09809411e+01], Loss = 0.4314\n",
      "Iteration 3147: Weights = [5.50000000e+01 3.80831970e+00 8.00705314e+00 2.63806475e-02\n",
      " 2.66591810e-01 1.09811839e+01], Loss = 0.4313\n",
      "Iteration 3148: Weights = [5.50000000e+01 3.80821038e+00 8.00682329e+00 2.63798902e-02\n",
      " 2.66584157e-01 1.09814267e+01], Loss = 0.4313\n",
      "Iteration 3149: Weights = [5.50000000e+01 3.80810106e+00 8.00659344e+00 2.63791329e-02\n",
      " 2.66576504e-01 1.09816696e+01], Loss = 0.4313\n",
      "Iteration 3150: Weights = [5.50000000e+01 3.80799174e+00 8.00636360e+00 2.63783756e-02\n",
      " 2.66568852e-01 1.09819124e+01], Loss = 0.4313\n",
      "Iteration 3151: Weights = [5.50000000e+01 3.80788243e+00 8.00613377e+00 2.63776184e-02\n",
      " 2.66561200e-01 1.09821552e+01], Loss = 0.4312\n",
      "Iteration 3152: Weights = [5.50000000e+01 3.80777312e+00 8.00590394e+00 2.63768612e-02\n",
      " 2.66553548e-01 1.09823980e+01], Loss = 0.4312\n",
      "Iteration 3153: Weights = [5.50000000e+01 3.80766381e+00 8.00567412e+00 2.63761040e-02\n",
      " 2.66545896e-01 1.09826408e+01], Loss = 0.4312\n",
      "Iteration 3154: Weights = [5.50000000e+01 3.80755451e+00 8.00544431e+00 2.63753469e-02\n",
      " 2.66538245e-01 1.09828836e+01], Loss = 0.4312\n",
      "Iteration 3155: Weights = [5.50000000e+01 3.80744520e+00 8.00521450e+00 2.63745897e-02\n",
      " 2.66530593e-01 1.09831264e+01], Loss = 0.4311\n",
      "Iteration 3156: Weights = [5.50000000e+01 3.80733591e+00 8.00498470e+00 2.63738326e-02\n",
      " 2.66522942e-01 1.09833692e+01], Loss = 0.4311\n",
      "Iteration 3157: Weights = [5.50000000e+01 3.80722661e+00 8.00475491e+00 2.63730755e-02\n",
      " 2.66515291e-01 1.09836120e+01], Loss = 0.4311\n",
      "Iteration 3158: Weights = [5.50000000e+01 3.80711732e+00 8.00452512e+00 2.63723184e-02\n",
      " 2.66507641e-01 1.09838547e+01], Loss = 0.4311\n",
      "Iteration 3159: Weights = [5.50000000e+01 3.80700803e+00 8.00429534e+00 2.63715614e-02\n",
      " 2.66499990e-01 1.09840975e+01], Loss = 0.4310\n",
      "Iteration 3160: Weights = [5.50000000e+01 3.80689875e+00 8.00406557e+00 2.63708043e-02\n",
      " 2.66492340e-01 1.09843402e+01], Loss = 0.4310\n",
      "Iteration 3161: Weights = [5.50000000e+01 3.80678947e+00 8.00383580e+00 2.63700473e-02\n",
      " 2.66484690e-01 1.09845830e+01], Loss = 0.4310\n",
      "Iteration 3162: Weights = [5.50000000e+01 3.80668019e+00 8.00360604e+00 2.63692903e-02\n",
      " 2.66477040e-01 1.09848257e+01], Loss = 0.4310\n",
      "Iteration 3163: Weights = [5.50000000e+01 3.80657091e+00 8.00337629e+00 2.63685334e-02\n",
      " 2.66469391e-01 1.09850684e+01], Loss = 0.4309\n",
      "Iteration 3164: Weights = [5.50000000e+01 3.80646164e+00 8.00314654e+00 2.63677764e-02\n",
      " 2.66461741e-01 1.09853112e+01], Loss = 0.4309\n",
      "Iteration 3165: Weights = [5.50000000e+01 3.80635237e+00 8.00291680e+00 2.63670195e-02\n",
      " 2.66454092e-01 1.09855539e+01], Loss = 0.4309\n",
      "Iteration 3166: Weights = [5.50000000e+01 3.80624310e+00 8.00268707e+00 2.63662626e-02\n",
      " 2.66446443e-01 1.09857966e+01], Loss = 0.4309\n",
      "Iteration 3167: Weights = [5.50000000e+01 3.80613384e+00 8.00245734e+00 2.63655057e-02\n",
      " 2.66438794e-01 1.09860393e+01], Loss = 0.4308\n",
      "Iteration 3168: Weights = [5.50000000e+01 3.80602458e+00 8.00222762e+00 2.63647489e-02\n",
      " 2.66431146e-01 1.09862820e+01], Loss = 0.4308\n",
      "Iteration 3169: Weights = [5.50000000e+01 3.80591532e+00 8.00199790e+00 2.63639920e-02\n",
      " 2.66423498e-01 1.09865247e+01], Loss = 0.4308\n",
      "Iteration 3170: Weights = [5.50000000e+01 3.80580607e+00 8.00176819e+00 2.63632352e-02\n",
      " 2.66415850e-01 1.09867674e+01], Loss = 0.4308\n",
      "Iteration 3171: Weights = [5.50000000e+01 3.80569682e+00 8.00153849e+00 2.63624784e-02\n",
      " 2.66408202e-01 1.09870100e+01], Loss = 0.4307\n",
      "Iteration 3172: Weights = [5.50000000e+01 3.80558757e+00 8.00130880e+00 2.63617216e-02\n",
      " 2.66400554e-01 1.09872527e+01], Loss = 0.4307\n",
      "Iteration 3173: Weights = [5.50000000e+01 3.80547833e+00 8.00107911e+00 2.63609649e-02\n",
      " 2.66392907e-01 1.09874954e+01], Loss = 0.4307\n",
      "Iteration 3174: Weights = [5.50000000e+01 3.80536909e+00 8.00084943e+00 2.63602082e-02\n",
      " 2.66385260e-01 1.09877380e+01], Loss = 0.4307\n",
      "Iteration 3175: Weights = [5.50000000e+01 3.80525985e+00 8.00061975e+00 2.63594515e-02\n",
      " 2.66377613e-01 1.09879807e+01], Loss = 0.4306\n",
      "Iteration 3176: Weights = [5.50000000e+01 3.80515061e+00 8.00039009e+00 2.63586948e-02\n",
      " 2.66369966e-01 1.09882233e+01], Loss = 0.4306\n",
      "Iteration 3177: Weights = [5.50000000e+01 3.80504138e+00 8.00016042e+00 2.63579381e-02\n",
      " 2.66362320e-01 1.09884660e+01], Loss = 0.4306\n",
      "Iteration 3178: Weights = [5.50000000e+01 3.80493215e+00 7.99993077e+00 2.63571815e-02\n",
      " 2.66354673e-01 1.09887086e+01], Loss = 0.4306\n",
      "Iteration 3179: Weights = [5.50000000e+01 3.80482293e+00 7.99970112e+00 2.63564248e-02\n",
      " 2.66347027e-01 1.09889512e+01], Loss = 0.4305\n",
      "Iteration 3180: Weights = [5.50000000e+01 3.80471370e+00 7.99947148e+00 2.63556682e-02\n",
      " 2.66339381e-01 1.09891938e+01], Loss = 0.4305\n",
      "Iteration 3181: Weights = [5.50000000e+01 3.80460448e+00 7.99924184e+00 2.63549117e-02\n",
      " 2.66331736e-01 1.09894364e+01], Loss = 0.4305\n",
      "Iteration 3182: Weights = [5.50000000e+01 3.80449527e+00 7.99901221e+00 2.63541551e-02\n",
      " 2.66324090e-01 1.09896790e+01], Loss = 0.4305\n",
      "Iteration 3183: Weights = [5.50000000e+01 3.80438606e+00 7.99878259e+00 2.63533986e-02\n",
      " 2.66316445e-01 1.09899216e+01], Loss = 0.4304\n",
      "Iteration 3184: Weights = [5.50000000e+01 3.80427685e+00 7.99855298e+00 2.63526421e-02\n",
      " 2.66308800e-01 1.09901642e+01], Loss = 0.4304\n",
      "Iteration 3185: Weights = [5.50000000e+01 3.80416764e+00 7.99832337e+00 2.63518856e-02\n",
      " 2.66301156e-01 1.09904068e+01], Loss = 0.4304\n",
      "Iteration 3186: Weights = [5.50000000e+01 3.80405843e+00 7.99809377e+00 2.63511291e-02\n",
      " 2.66293511e-01 1.09906493e+01], Loss = 0.4304\n",
      "Iteration 3187: Weights = [5.50000000e+01 3.80394923e+00 7.99786417e+00 2.63503727e-02\n",
      " 2.66285867e-01 1.09908919e+01], Loss = 0.4303\n",
      "Iteration 3188: Weights = [5.50000000e+01 3.80384004e+00 7.99763458e+00 2.63496162e-02\n",
      " 2.66278223e-01 1.09911345e+01], Loss = 0.4303\n",
      "Iteration 3189: Weights = [5.50000000e+01 3.80373084e+00 7.99740500e+00 2.63488598e-02\n",
      " 2.66270579e-01 1.09913770e+01], Loss = 0.4303\n",
      "Iteration 3190: Weights = [5.50000000e+01 3.80362165e+00 7.99717542e+00 2.63481035e-02\n",
      " 2.66262935e-01 1.09916196e+01], Loss = 0.4303\n",
      "Iteration 3191: Weights = [5.50000000e+01 3.80351246e+00 7.99694585e+00 2.63473471e-02\n",
      " 2.66255292e-01 1.09918621e+01], Loss = 0.4302\n",
      "Iteration 3192: Weights = [5.50000000e+01 3.80340328e+00 7.99671629e+00 2.63465908e-02\n",
      " 2.66247648e-01 1.09921046e+01], Loss = 0.4302\n",
      "Iteration 3193: Weights = [5.50000000e+01 3.80329410e+00 7.99648673e+00 2.63458345e-02\n",
      " 2.66240005e-01 1.09923472e+01], Loss = 0.4302\n",
      "Iteration 3194: Weights = [5.50000000e+01 3.80318492e+00 7.99625718e+00 2.63450782e-02\n",
      " 2.66232363e-01 1.09925897e+01], Loss = 0.4302\n",
      "Iteration 3195: Weights = [5.50000000e+01 3.80307574e+00 7.99602764e+00 2.63443219e-02\n",
      " 2.66224720e-01 1.09928322e+01], Loss = 0.4301\n",
      "Iteration 3196: Weights = [5.50000000e+01 3.80296657e+00 7.99579810e+00 2.63435656e-02\n",
      " 2.66217078e-01 1.09930747e+01], Loss = 0.4301\n",
      "Iteration 3197: Weights = [5.50000000e+01 3.80285740e+00 7.99556858e+00 2.63428094e-02\n",
      " 2.66209436e-01 1.09933172e+01], Loss = 0.4301\n",
      "Iteration 3198: Weights = [5.50000000e+01 3.80274824e+00 7.99533905e+00 2.63420532e-02\n",
      " 2.66201794e-01 1.09935597e+01], Loss = 0.4301\n",
      "Iteration 3199: Weights = [5.50000000e+01 3.80263907e+00 7.99510954e+00 2.63412970e-02\n",
      " 2.66194152e-01 1.09938021e+01], Loss = 0.4300\n",
      "Iteration 3200: Weights = [5.50000000e+01 3.80252991e+00 7.99488003e+00 2.63405409e-02\n",
      " 2.66186511e-01 1.09940446e+01], Loss = 0.4300\n",
      "Iteration 3201: Weights = [5.50000000e+01 3.80242076e+00 7.99465052e+00 2.63397847e-02\n",
      " 2.66178869e-01 1.09942871e+01], Loss = 0.4300\n",
      "Iteration 3202: Weights = [5.50000000e+01 3.80231160e+00 7.99442102e+00 2.63390286e-02\n",
      " 2.66171228e-01 1.09945295e+01], Loss = 0.4300\n",
      "Iteration 3203: Weights = [5.50000000e+01 3.80220245e+00 7.99419153e+00 2.63382725e-02\n",
      " 2.66163588e-01 1.09947720e+01], Loss = 0.4299\n",
      "Iteration 3204: Weights = [5.50000000e+01 3.80209331e+00 7.99396205e+00 2.63375164e-02\n",
      " 2.66155947e-01 1.09950144e+01], Loss = 0.4299\n",
      "Iteration 3205: Weights = [5.50000000e+01 3.80198416e+00 7.99373257e+00 2.63367604e-02\n",
      " 2.66148307e-01 1.09952569e+01], Loss = 0.4299\n",
      "Iteration 3206: Weights = [5.50000000e+01 3.80187502e+00 7.99350310e+00 2.63360043e-02\n",
      " 2.66140667e-01 1.09954993e+01], Loss = 0.4299\n",
      "Iteration 3207: Weights = [5.50000000e+01 3.80176588e+00 7.99327364e+00 2.63352483e-02\n",
      " 2.66133027e-01 1.09957417e+01], Loss = 0.4298\n",
      "Iteration 3208: Weights = [5.50000000e+01 3.80165675e+00 7.99304418e+00 2.63344923e-02\n",
      " 2.66125387e-01 1.09959842e+01], Loss = 0.4298\n",
      "Iteration 3209: Weights = [5.50000000e+01 3.80154762e+00 7.99281473e+00 2.63337364e-02\n",
      " 2.66117748e-01 1.09962266e+01], Loss = 0.4298\n",
      "Iteration 3210: Weights = [5.50000000e+01 3.80143849e+00 7.99258529e+00 2.63329804e-02\n",
      " 2.66110108e-01 1.09964690e+01], Loss = 0.4298\n",
      "Iteration 3211: Weights = [5.50000000e+01 3.80132936e+00 7.99235585e+00 2.63322245e-02\n",
      " 2.66102469e-01 1.09967114e+01], Loss = 0.4297\n",
      "Iteration 3212: Weights = [5.50000000e+01 3.80122024e+00 7.99212642e+00 2.63314686e-02\n",
      " 2.66094830e-01 1.09969538e+01], Loss = 0.4297\n",
      "Iteration 3213: Weights = [5.50000000e+01 3.80111112e+00 7.99189699e+00 2.63307127e-02\n",
      " 2.66087192e-01 1.09971961e+01], Loss = 0.4297\n",
      "Iteration 3214: Weights = [5.50000000e+01 3.80100201e+00 7.99166758e+00 2.63299568e-02\n",
      " 2.66079553e-01 1.09974385e+01], Loss = 0.4297\n",
      "Iteration 3215: Weights = [5.50000000e+01 3.80089289e+00 7.99143816e+00 2.63292010e-02\n",
      " 2.66071915e-01 1.09976809e+01], Loss = 0.4297\n",
      "Iteration 3216: Weights = [5.50000000e+01 3.80078378e+00 7.99120876e+00 2.63284452e-02\n",
      " 2.66064277e-01 1.09979232e+01], Loss = 0.4296\n",
      "Iteration 3217: Weights = [5.50000000e+01 3.80067468e+00 7.99097936e+00 2.63276894e-02\n",
      " 2.66056640e-01 1.09981656e+01], Loss = 0.4296\n",
      "Iteration 3218: Weights = [5.50000000e+01 3.80056557e+00 7.99074997e+00 2.63269336e-02\n",
      " 2.66049002e-01 1.09984080e+01], Loss = 0.4296\n",
      "Iteration 3219: Weights = [5.50000000e+01 3.80045647e+00 7.99052059e+00 2.63261779e-02\n",
      " 2.66041365e-01 1.09986503e+01], Loss = 0.4296\n",
      "Iteration 3220: Weights = [5.50000000e+01 3.80034738e+00 7.99029121e+00 2.63254221e-02\n",
      " 2.66033728e-01 1.09988926e+01], Loss = 0.4295\n",
      "Iteration 3221: Weights = [5.50000000e+01 3.80023828e+00 7.99006183e+00 2.63246664e-02\n",
      " 2.66026091e-01 1.09991350e+01], Loss = 0.4295\n",
      "Iteration 3222: Weights = [5.50000000e+01 3.80012919e+00 7.98983247e+00 2.63239108e-02\n",
      " 2.66018454e-01 1.09993773e+01], Loss = 0.4295\n",
      "Iteration 3223: Weights = [5.50000000e+01 3.80002010e+00 7.98960311e+00 2.63231551e-02\n",
      " 2.66010818e-01 1.09996196e+01], Loss = 0.4295\n",
      "Iteration 3224: Weights = [5.50000000e+01 3.79991102e+00 7.98937376e+00 2.63223994e-02\n",
      " 2.66003182e-01 1.09998619e+01], Loss = 0.4294\n",
      "Iteration 3225: Weights = [5.50000000e+01 3.79980194e+00 7.98914441e+00 2.63216438e-02\n",
      " 2.65995546e-01 1.10001042e+01], Loss = 0.4294\n",
      "Iteration 3226: Weights = [5.50000000e+01 3.79969286e+00 7.98891507e+00 2.63208882e-02\n",
      " 2.65987910e-01 1.10003465e+01], Loss = 0.4294\n",
      "Iteration 3227: Weights = [5.50000000e+01 3.79958378e+00 7.98868574e+00 2.63201327e-02\n",
      " 2.65980274e-01 1.10005888e+01], Loss = 0.4294\n",
      "Iteration 3228: Weights = [5.50000000e+01 3.79947471e+00 7.98845642e+00 2.63193771e-02\n",
      " 2.65972639e-01 1.10008311e+01], Loss = 0.4293\n",
      "Iteration 3229: Weights = [5.50000000e+01 3.79936564e+00 7.98822710e+00 2.63186216e-02\n",
      " 2.65965004e-01 1.10010733e+01], Loss = 0.4293\n",
      "Iteration 3230: Weights = [5.50000000e+01 3.79925658e+00 7.98799779e+00 2.63178661e-02\n",
      " 2.65957369e-01 1.10013156e+01], Loss = 0.4293\n",
      "Iteration 3231: Weights = [5.50000000e+01 3.79914752e+00 7.98776848e+00 2.63171106e-02\n",
      " 2.65949735e-01 1.10015578e+01], Loss = 0.4293\n",
      "Iteration 3232: Weights = [5.50000000e+01 3.79903846e+00 7.98753918e+00 2.63163551e-02\n",
      " 2.65942100e-01 1.10018001e+01], Loss = 0.4292\n",
      "Iteration 3233: Weights = [5.50000000e+01 3.79892940e+00 7.98730989e+00 2.63155996e-02\n",
      " 2.65934466e-01 1.10020423e+01], Loss = 0.4292\n",
      "Iteration 3234: Weights = [5.50000000e+01 3.79882035e+00 7.98708060e+00 2.63148442e-02\n",
      " 2.65926832e-01 1.10022846e+01], Loss = 0.4292\n",
      "Iteration 3235: Weights = [5.50000000e+01 3.79871130e+00 7.98685132e+00 2.63140888e-02\n",
      " 2.65919198e-01 1.10025268e+01], Loss = 0.4292\n",
      "Iteration 3236: Weights = [5.50000000e+01 3.79860225e+00 7.98662205e+00 2.63133334e-02\n",
      " 2.65911565e-01 1.10027690e+01], Loss = 0.4291\n",
      "Iteration 3237: Weights = [5.50000000e+01 3.79849321e+00 7.98639278e+00 2.63125781e-02\n",
      " 2.65903931e-01 1.10030113e+01], Loss = 0.4291\n",
      "Iteration 3238: Weights = [5.50000000e+01 3.79838416e+00 7.98616352e+00 2.63118227e-02\n",
      " 2.65896298e-01 1.10032535e+01], Loss = 0.4291\n",
      "Iteration 3239: Weights = [5.50000000e+01 3.79827513e+00 7.98593427e+00 2.63110674e-02\n",
      " 2.65888665e-01 1.10034957e+01], Loss = 0.4291\n",
      "Iteration 3240: Weights = [5.50000000e+01 3.79816609e+00 7.98570502e+00 2.63103121e-02\n",
      " 2.65881032e-01 1.10037379e+01], Loss = 0.4290\n",
      "Iteration 3241: Weights = [5.50000000e+01 3.79805706e+00 7.98547578e+00 2.63095569e-02\n",
      " 2.65873400e-01 1.10039800e+01], Loss = 0.4290\n",
      "Iteration 3242: Weights = [5.50000000e+01 3.79794803e+00 7.98524655e+00 2.63088016e-02\n",
      " 2.65865768e-01 1.10042222e+01], Loss = 0.4290\n",
      "Iteration 3243: Weights = [5.50000000e+01 3.79783901e+00 7.98501732e+00 2.63080464e-02\n",
      " 2.65858136e-01 1.10044644e+01], Loss = 0.4290\n",
      "Iteration 3244: Weights = [5.50000000e+01 3.79772999e+00 7.98478810e+00 2.63072912e-02\n",
      " 2.65850504e-01 1.10047066e+01], Loss = 0.4289\n",
      "Iteration 3245: Weights = [5.50000000e+01 3.79762097e+00 7.98455889e+00 2.63065360e-02\n",
      " 2.65842872e-01 1.10049487e+01], Loss = 0.4289\n",
      "Iteration 3246: Weights = [5.50000000e+01 3.79751195e+00 7.98432968e+00 2.63057808e-02\n",
      " 2.65835241e-01 1.10051909e+01], Loss = 0.4289\n",
      "Iteration 3247: Weights = [5.50000000e+01 3.79740294e+00 7.98410048e+00 2.63050257e-02\n",
      " 2.65827610e-01 1.10054330e+01], Loss = 0.4289\n",
      "Iteration 3248: Weights = [5.50000000e+01 3.79729393e+00 7.98387129e+00 2.63042705e-02\n",
      " 2.65819979e-01 1.10056752e+01], Loss = 0.4288\n",
      "Iteration 3249: Weights = [5.50000000e+01 3.79718492e+00 7.98364210e+00 2.63035154e-02\n",
      " 2.65812348e-01 1.10059173e+01], Loss = 0.4288\n",
      "Iteration 3250: Weights = [5.50000000e+01 3.79707592e+00 7.98341292e+00 2.63027604e-02\n",
      " 2.65804718e-01 1.10061594e+01], Loss = 0.4288\n",
      "Iteration 3251: Weights = [5.50000000e+01 3.79696692e+00 7.98318374e+00 2.63020053e-02\n",
      " 2.65797087e-01 1.10064016e+01], Loss = 0.4288\n",
      "Iteration 3252: Weights = [5.50000000e+01 3.79685792e+00 7.98295458e+00 2.63012503e-02\n",
      " 2.65789457e-01 1.10066437e+01], Loss = 0.4287\n",
      "Iteration 3253: Weights = [5.50000000e+01 3.79674893e+00 7.98272541e+00 2.63004953e-02\n",
      " 2.65781828e-01 1.10068858e+01], Loss = 0.4287\n",
      "Iteration 3254: Weights = [5.50000000e+01 3.79663994e+00 7.98249626e+00 2.62997403e-02\n",
      " 2.65774198e-01 1.10071279e+01], Loss = 0.4287\n",
      "Iteration 3255: Weights = [5.50000000e+01 3.79653095e+00 7.98226711e+00 2.62989853e-02\n",
      " 2.65766569e-01 1.10073700e+01], Loss = 0.4287\n",
      "Iteration 3256: Weights = [5.50000000e+01 3.79642197e+00 7.98203797e+00 2.62982304e-02\n",
      " 2.65758939e-01 1.10076120e+01], Loss = 0.4286\n",
      "Iteration 3257: Weights = [5.50000000e+01 3.79631299e+00 7.98180884e+00 2.62974754e-02\n",
      " 2.65751310e-01 1.10078541e+01], Loss = 0.4286\n",
      "Iteration 3258: Weights = [5.50000000e+01 3.79620401e+00 7.98157971e+00 2.62967205e-02\n",
      " 2.65743682e-01 1.10080962e+01], Loss = 0.4286\n",
      "Iteration 3259: Weights = [5.50000000e+01 3.79609503e+00 7.98135059e+00 2.62959656e-02\n",
      " 2.65736053e-01 1.10083383e+01], Loss = 0.4286\n",
      "Iteration 3260: Weights = [5.50000000e+01 3.79598606e+00 7.98112147e+00 2.62952108e-02\n",
      " 2.65728425e-01 1.10085803e+01], Loss = 0.4285\n",
      "Iteration 3261: Weights = [5.50000000e+01 3.79587709e+00 7.98089236e+00 2.62944559e-02\n",
      " 2.65720797e-01 1.10088224e+01], Loss = 0.4285\n",
      "Iteration 3262: Weights = [5.50000000e+01 3.79576813e+00 7.98066326e+00 2.62937011e-02\n",
      " 2.65713169e-01 1.10090644e+01], Loss = 0.4285\n",
      "Iteration 3263: Weights = [5.50000000e+01 3.79565916e+00 7.98043416e+00 2.62929463e-02\n",
      " 2.65705541e-01 1.10093064e+01], Loss = 0.4285\n",
      "Iteration 3264: Weights = [5.50000000e+01 3.79555020e+00 7.98020508e+00 2.62921915e-02\n",
      " 2.65697914e-01 1.10095485e+01], Loss = 0.4284\n",
      "Iteration 3265: Weights = [5.50000000e+01 3.79544125e+00 7.97997599e+00 2.62914368e-02\n",
      " 2.65690287e-01 1.10097905e+01], Loss = 0.4284\n",
      "Iteration 3266: Weights = [5.50000000e+01 3.79533230e+00 7.97974692e+00 2.62906821e-02\n",
      " 2.65682660e-01 1.10100325e+01], Loss = 0.4284\n",
      "Iteration 3267: Weights = [5.50000000e+01 3.79522335e+00 7.97951785e+00 2.62899274e-02\n",
      " 2.65675033e-01 1.10102745e+01], Loss = 0.4284\n",
      "Iteration 3268: Weights = [5.50000000e+01 3.79511440e+00 7.97928879e+00 2.62891727e-02\n",
      " 2.65667406e-01 1.10105165e+01], Loss = 0.4283\n",
      "Iteration 3269: Weights = [5.50000000e+01 3.79500545e+00 7.97905973e+00 2.62884180e-02\n",
      " 2.65659780e-01 1.10107585e+01], Loss = 0.4283\n",
      "Iteration 3270: Weights = [5.50000000e+01 3.79489651e+00 7.97883068e+00 2.62876634e-02\n",
      " 2.65652154e-01 1.10110005e+01], Loss = 0.4283\n",
      "Iteration 3271: Weights = [5.50000000e+01 3.79478758e+00 7.97860164e+00 2.62869087e-02\n",
      " 2.65644528e-01 1.10112425e+01], Loss = 0.4283\n",
      "Iteration 3272: Weights = [5.50000000e+01 3.79467864e+00 7.97837260e+00 2.62861541e-02\n",
      " 2.65636902e-01 1.10114844e+01], Loss = 0.4282\n",
      "Iteration 3273: Weights = [5.50000000e+01 3.79456971e+00 7.97814357e+00 2.62853996e-02\n",
      " 2.65629277e-01 1.10117264e+01], Loss = 0.4282\n",
      "Iteration 3274: Weights = [5.50000000e+01 3.79446078e+00 7.97791455e+00 2.62846450e-02\n",
      " 2.65621652e-01 1.10119684e+01], Loss = 0.4282\n",
      "Iteration 3275: Weights = [5.50000000e+01 3.79435186e+00 7.97768553e+00 2.62838905e-02\n",
      " 2.65614027e-01 1.10122103e+01], Loss = 0.4282\n",
      "Iteration 3276: Weights = [5.50000000e+01 3.79424294e+00 7.97745652e+00 2.62831359e-02\n",
      " 2.65606402e-01 1.10124523e+01], Loss = 0.4281\n",
      "Iteration 3277: Weights = [5.50000000e+01 3.79413402e+00 7.97722752e+00 2.62823815e-02\n",
      " 2.65598777e-01 1.10126942e+01], Loss = 0.4281\n",
      "Iteration 3278: Weights = [5.50000000e+01 3.79402510e+00 7.97699852e+00 2.62816270e-02\n",
      " 2.65591153e-01 1.10129361e+01], Loss = 0.4281\n",
      "Iteration 3279: Weights = [5.50000000e+01 3.79391619e+00 7.97676953e+00 2.62808725e-02\n",
      " 2.65583529e-01 1.10131781e+01], Loss = 0.4281\n",
      "Iteration 3280: Weights = [5.50000000e+01 3.79380728e+00 7.97654055e+00 2.62801181e-02\n",
      " 2.65575905e-01 1.10134200e+01], Loss = 0.4281\n",
      "Iteration 3281: Weights = [5.50000000e+01 3.79369837e+00 7.97631157e+00 2.62793637e-02\n",
      " 2.65568281e-01 1.10136619e+01], Loss = 0.4280\n",
      "Iteration 3282: Weights = [5.50000000e+01 3.79358947e+00 7.97608260e+00 2.62786093e-02\n",
      " 2.65560658e-01 1.10139038e+01], Loss = 0.4280\n",
      "Iteration 3283: Weights = [5.50000000e+01 3.79348057e+00 7.97585364e+00 2.62778549e-02\n",
      " 2.65553034e-01 1.10141457e+01], Loss = 0.4280\n",
      "Iteration 3284: Weights = [5.50000000e+01 3.79337167e+00 7.97562468e+00 2.62771006e-02\n",
      " 2.65545411e-01 1.10143876e+01], Loss = 0.4280\n",
      "Iteration 3285: Weights = [5.50000000e+01 3.79326278e+00 7.97539573e+00 2.62763463e-02\n",
      " 2.65537789e-01 1.10146295e+01], Loss = 0.4279\n",
      "Iteration 3286: Weights = [5.50000000e+01 3.79315389e+00 7.97516678e+00 2.62755920e-02\n",
      " 2.65530166e-01 1.10148713e+01], Loss = 0.4279\n",
      "Iteration 3287: Weights = [5.50000000e+01 3.79304500e+00 7.97493785e+00 2.62748377e-02\n",
      " 2.65522544e-01 1.10151132e+01], Loss = 0.4279\n",
      "Iteration 3288: Weights = [5.50000000e+01 3.79293612e+00 7.97470892e+00 2.62740835e-02\n",
      " 2.65514921e-01 1.10153551e+01], Loss = 0.4279\n",
      "Iteration 3289: Weights = [5.50000000e+01 3.79282724e+00 7.97447999e+00 2.62733292e-02\n",
      " 2.65507299e-01 1.10155969e+01], Loss = 0.4278\n",
      "Iteration 3290: Weights = [5.50000000e+01 3.79271836e+00 7.97425107e+00 2.62725750e-02\n",
      " 2.65499678e-01 1.10158388e+01], Loss = 0.4278\n",
      "Iteration 3291: Weights = [5.50000000e+01 3.79260948e+00 7.97402216e+00 2.62718208e-02\n",
      " 2.65492056e-01 1.10160806e+01], Loss = 0.4278\n",
      "Iteration 3292: Weights = [5.50000000e+01 3.79250061e+00 7.97379326e+00 2.62710667e-02\n",
      " 2.65484435e-01 1.10163224e+01], Loss = 0.4278\n",
      "Iteration 3293: Weights = [5.50000000e+01 3.79239174e+00 7.97356436e+00 2.62703125e-02\n",
      " 2.65476814e-01 1.10165643e+01], Loss = 0.4277\n",
      "Iteration 3294: Weights = [5.50000000e+01 3.79228288e+00 7.97333547e+00 2.62695584e-02\n",
      " 2.65469193e-01 1.10168061e+01], Loss = 0.4277\n",
      "Iteration 3295: Weights = [5.50000000e+01 3.79217402e+00 7.97310658e+00 2.62688043e-02\n",
      " 2.65461572e-01 1.10170479e+01], Loss = 0.4277\n",
      "Iteration 3296: Weights = [5.50000000e+01 3.79206516e+00 7.97287770e+00 2.62680502e-02\n",
      " 2.65453952e-01 1.10172897e+01], Loss = 0.4277\n",
      "Iteration 3297: Weights = [5.50000000e+01 3.79195630e+00 7.97264883e+00 2.62672961e-02\n",
      " 2.65446332e-01 1.10175315e+01], Loss = 0.4276\n",
      "Iteration 3298: Weights = [5.50000000e+01 3.79184745e+00 7.97241997e+00 2.62665421e-02\n",
      " 2.65438712e-01 1.10177733e+01], Loss = 0.4276\n",
      "Iteration 3299: Weights = [5.50000000e+01 3.79173860e+00 7.97219111e+00 2.62657881e-02\n",
      " 2.65431092e-01 1.10180151e+01], Loss = 0.4276\n",
      "Iteration 3300: Weights = [5.50000000e+01 3.79162975e+00 7.97196226e+00 2.62650341e-02\n",
      " 2.65423472e-01 1.10182569e+01], Loss = 0.4276\n",
      "Iteration 3301: Weights = [5.50000000e+01 3.79152091e+00 7.97173341e+00 2.62642801e-02\n",
      " 2.65415853e-01 1.10184986e+01], Loss = 0.4275\n",
      "Iteration 3302: Weights = [5.50000000e+01 3.79141207e+00 7.97150457e+00 2.62635262e-02\n",
      " 2.65408234e-01 1.10187404e+01], Loss = 0.4275\n",
      "Iteration 3303: Weights = [5.50000000e+01 3.79130323e+00 7.97127574e+00 2.62627722e-02\n",
      " 2.65400615e-01 1.10189822e+01], Loss = 0.4275\n",
      "Iteration 3304: Weights = [5.50000000e+01 3.79119439e+00 7.97104691e+00 2.62620183e-02\n",
      " 2.65392996e-01 1.10192239e+01], Loss = 0.4275\n",
      "Iteration 3305: Weights = [5.50000000e+01 3.79108556e+00 7.97081809e+00 2.62612644e-02\n",
      " 2.65385378e-01 1.10194657e+01], Loss = 0.4274\n",
      "Iteration 3306: Weights = [5.50000000e+01 3.79097673e+00 7.97058928e+00 2.62605106e-02\n",
      " 2.65377760e-01 1.10197074e+01], Loss = 0.4274\n",
      "Iteration 3307: Weights = [5.50000000e+01 3.79086791e+00 7.97036048e+00 2.62597567e-02\n",
      " 2.65370142e-01 1.10199491e+01], Loss = 0.4274\n",
      "Iteration 3308: Weights = [5.50000000e+01 3.79075909e+00 7.97013168e+00 2.62590029e-02\n",
      " 2.65362524e-01 1.10201909e+01], Loss = 0.4274\n",
      "Iteration 3309: Weights = [5.50000000e+01 3.79065027e+00 7.96990288e+00 2.62582491e-02\n",
      " 2.65354906e-01 1.10204326e+01], Loss = 0.4273\n",
      "Iteration 3310: Weights = [5.50000000e+01 3.79054145e+00 7.96967410e+00 2.62574953e-02\n",
      " 2.65347289e-01 1.10206743e+01], Loss = 0.4273\n",
      "Iteration 3311: Weights = [5.50000000e+01 3.79043264e+00 7.96944532e+00 2.62567416e-02\n",
      " 2.65339672e-01 1.10209160e+01], Loss = 0.4273\n",
      "Iteration 3312: Weights = [5.50000000e+01 3.79032383e+00 7.96921654e+00 2.62559878e-02\n",
      " 2.65332055e-01 1.10211577e+01], Loss = 0.4273\n",
      "Iteration 3313: Weights = [5.50000000e+01 3.79021503e+00 7.96898778e+00 2.62552341e-02\n",
      " 2.65324438e-01 1.10213994e+01], Loss = 0.4272\n",
      "Iteration 3314: Weights = [5.50000000e+01 3.79010622e+00 7.96875902e+00 2.62544804e-02\n",
      " 2.65316822e-01 1.10216410e+01], Loss = 0.4272\n",
      "Iteration 3315: Weights = [5.50000000e+01 3.78999742e+00 7.96853026e+00 2.62537268e-02\n",
      " 2.65309205e-01 1.10218827e+01], Loss = 0.4272\n",
      "Iteration 3316: Weights = [5.50000000e+01 3.78988863e+00 7.96830151e+00 2.62529731e-02\n",
      " 2.65301589e-01 1.10221244e+01], Loss = 0.4272\n",
      "Iteration 3317: Weights = [5.50000000e+01 3.78977983e+00 7.96807277e+00 2.62522195e-02\n",
      " 2.65293974e-01 1.10223660e+01], Loss = 0.4271\n",
      "Iteration 3318: Weights = [5.50000000e+01 3.78967104e+00 7.96784404e+00 2.62514659e-02\n",
      " 2.65286358e-01 1.10226077e+01], Loss = 0.4271\n",
      "Iteration 3319: Weights = [5.50000000e+01 3.78956225e+00 7.96761531e+00 2.62507123e-02\n",
      " 2.65278743e-01 1.10228493e+01], Loss = 0.4271\n",
      "Iteration 3320: Weights = [5.50000000e+01 3.78945347e+00 7.96738659e+00 2.62499587e-02\n",
      " 2.65271127e-01 1.10230910e+01], Loss = 0.4271\n",
      "Iteration 3321: Weights = [5.50000000e+01 3.78934469e+00 7.96715788e+00 2.62492052e-02\n",
      " 2.65263512e-01 1.10233326e+01], Loss = 0.4270\n",
      "Iteration 3322: Weights = [5.50000000e+01 3.78923591e+00 7.96692917e+00 2.62484517e-02\n",
      " 2.65255898e-01 1.10235742e+01], Loss = 0.4270\n",
      "Iteration 3323: Weights = [5.50000000e+01 3.78912714e+00 7.96670047e+00 2.62476982e-02\n",
      " 2.65248283e-01 1.10238159e+01], Loss = 0.4270\n",
      "Iteration 3324: Weights = [5.50000000e+01 3.78901836e+00 7.96647177e+00 2.62469447e-02\n",
      " 2.65240669e-01 1.10240575e+01], Loss = 0.4270\n",
      "Iteration 3325: Weights = [5.50000000e+01 3.78890959e+00 7.96624309e+00 2.62461913e-02\n",
      " 2.65233055e-01 1.10242991e+01], Loss = 0.4269\n",
      "Iteration 3326: Weights = [5.50000000e+01 3.78880083e+00 7.96601441e+00 2.62454378e-02\n",
      " 2.65225441e-01 1.10245407e+01], Loss = 0.4269\n",
      "Iteration 3327: Weights = [5.50000000e+01 3.78869207e+00 7.96578573e+00 2.62446844e-02\n",
      " 2.65217827e-01 1.10247823e+01], Loss = 0.4269\n",
      "Iteration 3328: Weights = [5.50000000e+01 3.78858331e+00 7.96555706e+00 2.62439310e-02\n",
      " 2.65210214e-01 1.10250239e+01], Loss = 0.4269\n",
      "Iteration 3329: Weights = [5.50000000e+01 3.78847455e+00 7.96532840e+00 2.62431777e-02\n",
      " 2.65202601e-01 1.10252654e+01], Loss = 0.4268\n",
      "Iteration 3330: Weights = [5.50000000e+01 3.78836580e+00 7.96509975e+00 2.62424243e-02\n",
      " 2.65194988e-01 1.10255070e+01], Loss = 0.4268\n",
      "Iteration 3331: Weights = [5.50000000e+01 3.78825705e+00 7.96487110e+00 2.62416710e-02\n",
      " 2.65187375e-01 1.10257486e+01], Loss = 0.4268\n",
      "Iteration 3332: Weights = [5.50000000e+01 3.78814830e+00 7.96464245e+00 2.62409177e-02\n",
      " 2.65179762e-01 1.10259901e+01], Loss = 0.4268\n",
      "Iteration 3333: Weights = [5.50000000e+01 3.78803956e+00 7.96441382e+00 2.62401644e-02\n",
      " 2.65172150e-01 1.10262317e+01], Loss = 0.4268\n",
      "Iteration 3334: Weights = [5.50000000e+01 3.78793082e+00 7.96418519e+00 2.62394112e-02\n",
      " 2.65164538e-01 1.10264732e+01], Loss = 0.4267\n",
      "Iteration 3335: Weights = [5.50000000e+01 3.78782208e+00 7.96395657e+00 2.62386579e-02\n",
      " 2.65156926e-01 1.10267148e+01], Loss = 0.4267\n",
      "Iteration 3336: Weights = [5.50000000e+01 3.78771334e+00 7.96372795e+00 2.62379047e-02\n",
      " 2.65149314e-01 1.10269563e+01], Loss = 0.4267\n",
      "Iteration 3337: Weights = [5.50000000e+01 3.78760461e+00 7.96349934e+00 2.62371515e-02\n",
      " 2.65141703e-01 1.10271978e+01], Loss = 0.4267\n",
      "Iteration 3338: Weights = [5.50000000e+01 3.78749589e+00 7.96327074e+00 2.62363983e-02\n",
      " 2.65134092e-01 1.10274393e+01], Loss = 0.4266\n",
      "Iteration 3339: Weights = [5.50000000e+01 3.78738716e+00 7.96304214e+00 2.62356452e-02\n",
      " 2.65126481e-01 1.10276808e+01], Loss = 0.4266\n",
      "Iteration 3340: Weights = [5.50000000e+01 3.78727844e+00 7.96281355e+00 2.62348921e-02\n",
      " 2.65118870e-01 1.10279223e+01], Loss = 0.4266\n",
      "Iteration 3341: Weights = [5.50000000e+01 3.78716972e+00 7.96258497e+00 2.62341389e-02\n",
      " 2.65111259e-01 1.10281638e+01], Loss = 0.4266\n",
      "Iteration 3342: Weights = [5.50000000e+01 3.78706100e+00 7.96235639e+00 2.62333859e-02\n",
      " 2.65103649e-01 1.10284053e+01], Loss = 0.4265\n",
      "Iteration 3343: Weights = [5.50000000e+01 3.78695229e+00 7.96212782e+00 2.62326328e-02\n",
      " 2.65096039e-01 1.10286468e+01], Loss = 0.4265\n",
      "Iteration 3344: Weights = [5.50000000e+01 3.78684358e+00 7.96189926e+00 2.62318798e-02\n",
      " 2.65088429e-01 1.10288883e+01], Loss = 0.4265\n",
      "Iteration 3345: Weights = [5.50000000e+01 3.78673488e+00 7.96167070e+00 2.62311267e-02\n",
      " 2.65080819e-01 1.10291297e+01], Loss = 0.4265\n",
      "Iteration 3346: Weights = [5.50000000e+01 3.78662617e+00 7.96144215e+00 2.62303737e-02\n",
      " 2.65073210e-01 1.10293712e+01], Loss = 0.4264\n",
      "Iteration 3347: Weights = [5.50000000e+01 3.78651747e+00 7.96121361e+00 2.62296208e-02\n",
      " 2.65065600e-01 1.10296126e+01], Loss = 0.4264\n",
      "Iteration 3348: Weights = [5.50000000e+01 3.78640878e+00 7.96098507e+00 2.62288678e-02\n",
      " 2.65057991e-01 1.10298541e+01], Loss = 0.4264\n",
      "Iteration 3349: Weights = [5.50000000e+01 3.78630008e+00 7.96075654e+00 2.62281149e-02\n",
      " 2.65050382e-01 1.10300955e+01], Loss = 0.4264\n",
      "Iteration 3350: Weights = [5.50000000e+01 3.78619139e+00 7.96052802e+00 2.62273619e-02\n",
      " 2.65042774e-01 1.10303370e+01], Loss = 0.4263\n",
      "Iteration 3351: Weights = [5.50000000e+01 3.78608270e+00 7.96029950e+00 2.62266091e-02\n",
      " 2.65035165e-01 1.10305784e+01], Loss = 0.4263\n",
      "Iteration 3352: Weights = [5.50000000e+01 3.78597402e+00 7.96007099e+00 2.62258562e-02\n",
      " 2.65027557e-01 1.10308198e+01], Loss = 0.4263\n",
      "Iteration 3353: Weights = [5.50000000e+01 3.78586534e+00 7.95984249e+00 2.62251033e-02\n",
      " 2.65019949e-01 1.10310612e+01], Loss = 0.4263\n",
      "Iteration 3354: Weights = [5.50000000e+01 3.78575666e+00 7.95961399e+00 2.62243505e-02\n",
      " 2.65012341e-01 1.10313026e+01], Loss = 0.4262\n",
      "Iteration 3355: Weights = [5.50000000e+01 3.78564798e+00 7.95938550e+00 2.62235977e-02\n",
      " 2.65004734e-01 1.10315440e+01], Loss = 0.4262\n",
      "Iteration 3356: Weights = [5.50000000e+01 3.78553931e+00 7.95915701e+00 2.62228449e-02\n",
      " 2.64997127e-01 1.10317854e+01], Loss = 0.4262\n",
      "Iteration 3357: Weights = [5.50000000e+01 3.78543064e+00 7.95892854e+00 2.62220922e-02\n",
      " 2.64989520e-01 1.10320268e+01], Loss = 0.4262\n",
      "Iteration 3358: Weights = [5.50000000e+01 3.78532198e+00 7.95870006e+00 2.62213394e-02\n",
      " 2.64981913e-01 1.10322682e+01], Loss = 0.4261\n",
      "Iteration 3359: Weights = [5.50000000e+01 3.78521331e+00 7.95847160e+00 2.62205867e-02\n",
      " 2.64974306e-01 1.10325095e+01], Loss = 0.4261\n",
      "Iteration 3360: Weights = [5.50000000e+01 3.78510466e+00 7.95824314e+00 2.62198340e-02\n",
      " 2.64966700e-01 1.10327509e+01], Loss = 0.4261\n",
      "Iteration 3361: Weights = [5.50000000e+01 3.78499600e+00 7.95801469e+00 2.62190813e-02\n",
      " 2.64959093e-01 1.10329923e+01], Loss = 0.4261\n",
      "Iteration 3362: Weights = [5.50000000e+01 3.78488735e+00 7.95778624e+00 2.62183287e-02\n",
      " 2.64951487e-01 1.10332336e+01], Loss = 0.4260\n",
      "Iteration 3363: Weights = [5.50000000e+01 3.78477870e+00 7.95755781e+00 2.62175760e-02\n",
      " 2.64943882e-01 1.10334749e+01], Loss = 0.4260\n",
      "Iteration 3364: Weights = [5.50000000e+01 3.78467005e+00 7.95732937e+00 2.62168234e-02\n",
      " 2.64936276e-01 1.10337163e+01], Loss = 0.4260\n",
      "Iteration 3365: Weights = [5.50000000e+01 3.78456140e+00 7.95710095e+00 2.62160708e-02\n",
      " 2.64928671e-01 1.10339576e+01], Loss = 0.4260\n",
      "Iteration 3366: Weights = [5.50000000e+01 3.78445276e+00 7.95687253e+00 2.62153183e-02\n",
      " 2.64921066e-01 1.10341989e+01], Loss = 0.4259\n",
      "Iteration 3367: Weights = [5.50000000e+01 3.78434413e+00 7.95664412e+00 2.62145657e-02\n",
      " 2.64913461e-01 1.10344402e+01], Loss = 0.4259\n",
      "Iteration 3368: Weights = [5.50000000e+01 3.78423549e+00 7.95641571e+00 2.62138132e-02\n",
      " 2.64905856e-01 1.10346815e+01], Loss = 0.4259\n",
      "Iteration 3369: Weights = [5.50000000e+01 3.78412686e+00 7.95618731e+00 2.62130607e-02\n",
      " 2.64898252e-01 1.10349228e+01], Loss = 0.4259\n",
      "Iteration 3370: Weights = [5.50000000e+01 3.78401823e+00 7.95595892e+00 2.62123082e-02\n",
      " 2.64890647e-01 1.10351641e+01], Loss = 0.4258\n",
      "Iteration 3371: Weights = [5.50000000e+01 3.78390961e+00 7.95573053e+00 2.62115558e-02\n",
      " 2.64883043e-01 1.10354054e+01], Loss = 0.4258\n",
      "Iteration 3372: Weights = [5.50000000e+01 3.78380098e+00 7.95550215e+00 2.62108033e-02\n",
      " 2.64875439e-01 1.10356467e+01], Loss = 0.4258\n",
      "Iteration 3373: Weights = [5.50000000e+01 3.78369237e+00 7.95527378e+00 2.62100509e-02\n",
      " 2.64867836e-01 1.10358880e+01], Loss = 0.4258\n",
      "Iteration 3374: Weights = [5.50000000e+01 3.78358375e+00 7.95504541e+00 2.62092985e-02\n",
      " 2.64860232e-01 1.10361292e+01], Loss = 0.4257\n",
      "Iteration 3375: Weights = [5.50000000e+01 3.78347514e+00 7.95481705e+00 2.62085461e-02\n",
      " 2.64852629e-01 1.10363705e+01], Loss = 0.4257\n",
      "Iteration 3376: Weights = [5.50000000e+01 3.78336653e+00 7.95458870e+00 2.62077938e-02\n",
      " 2.64845026e-01 1.10366118e+01], Loss = 0.4257\n",
      "Iteration 3377: Weights = [5.50000000e+01 3.78325792e+00 7.95436035e+00 2.62070415e-02\n",
      " 2.64837424e-01 1.10368530e+01], Loss = 0.4257\n",
      "Iteration 3378: Weights = [5.50000000e+01 3.78314932e+00 7.95413201e+00 2.62062892e-02\n",
      " 2.64829821e-01 1.10370942e+01], Loss = 0.4256\n",
      "Iteration 3379: Weights = [5.50000000e+01 3.78304072e+00 7.95390368e+00 2.62055369e-02\n",
      " 2.64822219e-01 1.10373355e+01], Loss = 0.4256\n",
      "Iteration 3380: Weights = [5.50000000e+01 3.78293212e+00 7.95367535e+00 2.62047846e-02\n",
      " 2.64814617e-01 1.10375767e+01], Loss = 0.4256\n",
      "Iteration 3381: Weights = [5.50000000e+01 3.78282353e+00 7.95344703e+00 2.62040324e-02\n",
      " 2.64807015e-01 1.10378179e+01], Loss = 0.4256\n",
      "Iteration 3382: Weights = [5.50000000e+01 3.78271494e+00 7.95321872e+00 2.62032801e-02\n",
      " 2.64799413e-01 1.10380591e+01], Loss = 0.4256\n",
      "Iteration 3383: Weights = [5.50000000e+01 3.78260635e+00 7.95299041e+00 2.62025279e-02\n",
      " 2.64791812e-01 1.10383003e+01], Loss = 0.4255\n",
      "Iteration 3384: Weights = [5.50000000e+01 3.78249776e+00 7.95276211e+00 2.62017758e-02\n",
      " 2.64784211e-01 1.10385415e+01], Loss = 0.4255\n",
      "Iteration 3385: Weights = [5.50000000e+01 3.78238918e+00 7.95253381e+00 2.62010236e-02\n",
      " 2.64776610e-01 1.10387827e+01], Loss = 0.4255\n",
      "Iteration 3386: Weights = [5.50000000e+01 3.78228060e+00 7.95230553e+00 2.62002715e-02\n",
      " 2.64769009e-01 1.10390239e+01], Loss = 0.4255\n",
      "Iteration 3387: Weights = [5.50000000e+01 3.78217203e+00 7.95207724e+00 2.61995194e-02\n",
      " 2.64761408e-01 1.10392651e+01], Loss = 0.4254\n",
      "Iteration 3388: Weights = [5.50000000e+01 3.78206346e+00 7.95184897e+00 2.61987673e-02\n",
      " 2.64753808e-01 1.10395062e+01], Loss = 0.4254\n",
      "Iteration 3389: Weights = [5.50000000e+01 3.78195489e+00 7.95162070e+00 2.61980152e-02\n",
      " 2.64746208e-01 1.10397474e+01], Loss = 0.4254\n",
      "Iteration 3390: Weights = [5.50000000e+01 3.78184632e+00 7.95139244e+00 2.61972631e-02\n",
      " 2.64738608e-01 1.10399886e+01], Loss = 0.4254\n",
      "Iteration 3391: Weights = [5.50000000e+01 3.78173776e+00 7.95116418e+00 2.61965111e-02\n",
      " 2.64731008e-01 1.10402297e+01], Loss = 0.4253\n",
      "Iteration 3392: Weights = [5.50000000e+01 3.78162920e+00 7.95093594e+00 2.61957591e-02\n",
      " 2.64723409e-01 1.10404708e+01], Loss = 0.4253\n",
      "Iteration 3393: Weights = [5.50000000e+01 3.78152064e+00 7.95070769e+00 2.61950071e-02\n",
      " 2.64715810e-01 1.10407120e+01], Loss = 0.4253\n",
      "Iteration 3394: Weights = [5.50000000e+01 3.78141209e+00 7.95047946e+00 2.61942552e-02\n",
      " 2.64708211e-01 1.10409531e+01], Loss = 0.4253\n",
      "Iteration 3395: Weights = [5.50000000e+01 3.78130354e+00 7.95025123e+00 2.61935032e-02\n",
      " 2.64700612e-01 1.10411942e+01], Loss = 0.4252\n",
      "Iteration 3396: Weights = [5.50000000e+01 3.78119499e+00 7.95002301e+00 2.61927513e-02\n",
      " 2.64693013e-01 1.10414353e+01], Loss = 0.4252\n",
      "Iteration 3397: Weights = [5.50000000e+01 3.78108645e+00 7.94979479e+00 2.61919994e-02\n",
      " 2.64685415e-01 1.10416764e+01], Loss = 0.4252\n",
      "Iteration 3398: Weights = [5.50000000e+01 3.78097790e+00 7.94956658e+00 2.61912475e-02\n",
      " 2.64677817e-01 1.10419175e+01], Loss = 0.4252\n",
      "Iteration 3399: Weights = [5.50000000e+01 3.78086937e+00 7.94933838e+00 2.61904957e-02\n",
      " 2.64670219e-01 1.10421586e+01], Loss = 0.4251\n",
      "Iteration 3400: Weights = [5.50000000e+01 3.78076083e+00 7.94911018e+00 2.61897438e-02\n",
      " 2.64662621e-01 1.10423997e+01], Loss = 0.4251\n",
      "Iteration 3401: Weights = [5.50000000e+01 3.78065230e+00 7.94888199e+00 2.61889920e-02\n",
      " 2.64655024e-01 1.10426408e+01], Loss = 0.4251\n",
      "Iteration 3402: Weights = [5.50000000e+01 3.78054377e+00 7.94865381e+00 2.61882402e-02\n",
      " 2.64647426e-01 1.10428819e+01], Loss = 0.4251\n",
      "Iteration 3403: Weights = [5.50000000e+01 3.78043525e+00 7.94842563e+00 2.61874885e-02\n",
      " 2.64639829e-01 1.10431229e+01], Loss = 0.4250\n",
      "Iteration 3404: Weights = [5.50000000e+01 3.78032672e+00 7.94819746e+00 2.61867367e-02\n",
      " 2.64632233e-01 1.10433640e+01], Loss = 0.4250\n",
      "Iteration 3405: Weights = [5.50000000e+01 3.78021820e+00 7.94796930e+00 2.61859850e-02\n",
      " 2.64624636e-01 1.10436050e+01], Loss = 0.4250\n",
      "Iteration 3406: Weights = [5.50000000e+01 3.78010969e+00 7.94774114e+00 2.61852333e-02\n",
      " 2.64617040e-01 1.10438461e+01], Loss = 0.4250\n",
      "Iteration 3407: Weights = [5.50000000e+01 3.78000118e+00 7.94751299e+00 2.61844816e-02\n",
      " 2.64609443e-01 1.10440871e+01], Loss = 0.4249\n",
      "Iteration 3408: Weights = [5.50000000e+01 3.77989267e+00 7.94728485e+00 2.61837300e-02\n",
      " 2.64601847e-01 1.10443282e+01], Loss = 0.4249\n",
      "Iteration 3409: Weights = [5.50000000e+01 3.77978416e+00 7.94705671e+00 2.61829783e-02\n",
      " 2.64594252e-01 1.10445692e+01], Loss = 0.4249\n",
      "Iteration 3410: Weights = [5.50000000e+01 3.77967566e+00 7.94682858e+00 2.61822267e-02\n",
      " 2.64586656e-01 1.10448102e+01], Loss = 0.4249\n",
      "Iteration 3411: Weights = [5.50000000e+01 3.77956715e+00 7.94660046e+00 2.61814751e-02\n",
      " 2.64579061e-01 1.10450512e+01], Loss = 0.4248\n",
      "Iteration 3412: Weights = [5.50000000e+01 3.77945866e+00 7.94637234e+00 2.61807235e-02\n",
      " 2.64571466e-01 1.10452922e+01], Loss = 0.4248\n",
      "Iteration 3413: Weights = [5.50000000e+01 3.77935016e+00 7.94614423e+00 2.61799720e-02\n",
      " 2.64563871e-01 1.10455332e+01], Loss = 0.4248\n",
      "Iteration 3414: Weights = [5.50000000e+01 3.77924167e+00 7.94591612e+00 2.61792205e-02\n",
      " 2.64556276e-01 1.10457742e+01], Loss = 0.4248\n",
      "Iteration 3415: Weights = [5.50000000e+01 3.77913318e+00 7.94568803e+00 2.61784689e-02\n",
      " 2.64548682e-01 1.10460152e+01], Loss = 0.4247\n",
      "Iteration 3416: Weights = [5.50000000e+01 3.77902470e+00 7.94545994e+00 2.61777175e-02\n",
      " 2.64541088e-01 1.10462561e+01], Loss = 0.4247\n",
      "Iteration 3417: Weights = [5.50000000e+01 3.77891622e+00 7.94523185e+00 2.61769660e-02\n",
      " 2.64533494e-01 1.10464971e+01], Loss = 0.4247\n",
      "Iteration 3418: Weights = [5.50000000e+01 3.77880774e+00 7.94500377e+00 2.61762145e-02\n",
      " 2.64525900e-01 1.10467381e+01], Loss = 0.4247\n",
      "Iteration 3419: Weights = [5.50000000e+01 3.77869926e+00 7.94477570e+00 2.61754631e-02\n",
      " 2.64518306e-01 1.10469790e+01], Loss = 0.4246\n",
      "Iteration 3420: Weights = [5.50000000e+01 3.77859079e+00 7.94454764e+00 2.61747117e-02\n",
      " 2.64510713e-01 1.10472200e+01], Loss = 0.4246\n",
      "Iteration 3421: Weights = [5.50000000e+01 3.77848232e+00 7.94431958e+00 2.61739603e-02\n",
      " 2.64503120e-01 1.10474609e+01], Loss = 0.4246\n",
      "Iteration 3422: Weights = [5.50000000e+01 3.77837385e+00 7.94409152e+00 2.61732090e-02\n",
      " 2.64495527e-01 1.10477019e+01], Loss = 0.4246\n",
      "Iteration 3423: Weights = [5.50000000e+01 3.77826539e+00 7.94386348e+00 2.61724576e-02\n",
      " 2.64487934e-01 1.10479428e+01], Loss = 0.4246\n",
      "Iteration 3424: Weights = [5.50000000e+01 3.77815693e+00 7.94363544e+00 2.61717063e-02\n",
      " 2.64480342e-01 1.10481837e+01], Loss = 0.4245\n",
      "Iteration 3425: Weights = [5.50000000e+01 3.77804847e+00 7.94340741e+00 2.61709550e-02\n",
      " 2.64472749e-01 1.10484246e+01], Loss = 0.4245\n",
      "Iteration 3426: Weights = [5.50000000e+01 3.77794002e+00 7.94317938e+00 2.61702038e-02\n",
      " 2.64465157e-01 1.10486655e+01], Loss = 0.4245\n",
      "Iteration 3427: Weights = [5.50000000e+01 3.77783157e+00 7.94295136e+00 2.61694525e-02\n",
      " 2.64457566e-01 1.10489064e+01], Loss = 0.4245\n",
      "Iteration 3428: Weights = [5.50000000e+01 3.77772312e+00 7.94272335e+00 2.61687013e-02\n",
      " 2.64449974e-01 1.10491473e+01], Loss = 0.4244\n",
      "Iteration 3429: Weights = [5.50000000e+01 3.77761468e+00 7.94249534e+00 2.61679501e-02\n",
      " 2.64442383e-01 1.10493882e+01], Loss = 0.4244\n",
      "Iteration 3430: Weights = [5.50000000e+01 3.77750624e+00 7.94226734e+00 2.61671989e-02\n",
      " 2.64434791e-01 1.10496291e+01], Loss = 0.4244\n",
      "Iteration 3431: Weights = [5.50000000e+01 3.77739780e+00 7.94203935e+00 2.61664477e-02\n",
      " 2.64427201e-01 1.10498699e+01], Loss = 0.4244\n",
      "Iteration 3432: Weights = [5.50000000e+01 3.77728936e+00 7.94181136e+00 2.61656966e-02\n",
      " 2.64419610e-01 1.10501108e+01], Loss = 0.4243\n",
      "Iteration 3433: Weights = [5.50000000e+01 3.77718093e+00 7.94158338e+00 2.61649455e-02\n",
      " 2.64412019e-01 1.10503517e+01], Loss = 0.4243\n",
      "Iteration 3434: Weights = [5.50000000e+01 3.77707250e+00 7.94135541e+00 2.61641944e-02\n",
      " 2.64404429e-01 1.10505925e+01], Loss = 0.4243\n",
      "Iteration 3435: Weights = [5.50000000e+01 3.77696408e+00 7.94112744e+00 2.61634433e-02\n",
      " 2.64396839e-01 1.10508334e+01], Loss = 0.4243\n",
      "Iteration 3436: Weights = [5.50000000e+01 3.77685565e+00 7.94089948e+00 2.61626922e-02\n",
      " 2.64389249e-01 1.10510742e+01], Loss = 0.4242\n",
      "Iteration 3437: Weights = [5.50000000e+01 3.77674723e+00 7.94067153e+00 2.61619412e-02\n",
      " 2.64381659e-01 1.10513150e+01], Loss = 0.4242\n",
      "Iteration 3438: Weights = [5.50000000e+01 3.77663882e+00 7.94044358e+00 2.61611902e-02\n",
      " 2.64374070e-01 1.10515558e+01], Loss = 0.4242\n",
      "Iteration 3439: Weights = [5.50000000e+01 3.77653040e+00 7.94021564e+00 2.61604392e-02\n",
      " 2.64366481e-01 1.10517967e+01], Loss = 0.4242\n",
      "Iteration 3440: Weights = [5.50000000e+01 3.77642199e+00 7.93998771e+00 2.61596882e-02\n",
      " 2.64358892e-01 1.10520375e+01], Loss = 0.4241\n",
      "Iteration 3441: Weights = [5.50000000e+01 3.77631359e+00 7.93975978e+00 2.61589373e-02\n",
      " 2.64351303e-01 1.10522783e+01], Loss = 0.4241\n",
      "Iteration 3442: Weights = [5.50000000e+01 3.77620518e+00 7.93953186e+00 2.61581863e-02\n",
      " 2.64343714e-01 1.10525191e+01], Loss = 0.4241\n",
      "Iteration 3443: Weights = [5.50000000e+01 3.77609678e+00 7.93930394e+00 2.61574354e-02\n",
      " 2.64336126e-01 1.10527599e+01], Loss = 0.4241\n",
      "Iteration 3444: Weights = [5.50000000e+01 3.77598838e+00 7.93907603e+00 2.61566846e-02\n",
      " 2.64328538e-01 1.10530006e+01], Loss = 0.4240\n",
      "Iteration 3445: Weights = [5.50000000e+01 3.77587999e+00 7.93884813e+00 2.61559337e-02\n",
      " 2.64320950e-01 1.10532414e+01], Loss = 0.4240\n",
      "Iteration 3446: Weights = [5.50000000e+01 3.77577160e+00 7.93862024e+00 2.61551829e-02\n",
      " 2.64313362e-01 1.10534822e+01], Loss = 0.4240\n",
      "Iteration 3447: Weights = [5.50000000e+01 3.77566321e+00 7.93839235e+00 2.61544320e-02\n",
      " 2.64305775e-01 1.10537229e+01], Loss = 0.4240\n",
      "Iteration 3448: Weights = [5.50000000e+01 3.77555482e+00 7.93816447e+00 2.61536812e-02\n",
      " 2.64298188e-01 1.10539637e+01], Loss = 0.4239\n",
      "Iteration 3449: Weights = [5.50000000e+01 3.77544644e+00 7.93793659e+00 2.61529305e-02\n",
      " 2.64290601e-01 1.10542044e+01], Loss = 0.4239\n",
      "Iteration 3450: Weights = [5.50000000e+01 3.77533806e+00 7.93770872e+00 2.61521797e-02\n",
      " 2.64283014e-01 1.10544452e+01], Loss = 0.4239\n",
      "Iteration 3451: Weights = [5.50000000e+01 3.77522969e+00 7.93748086e+00 2.61514290e-02\n",
      " 2.64275427e-01 1.10546859e+01], Loss = 0.4239\n",
      "Iteration 3452: Weights = [5.50000000e+01 3.77512131e+00 7.93725300e+00 2.61506783e-02\n",
      " 2.64267841e-01 1.10549266e+01], Loss = 0.4238\n",
      "Iteration 3453: Weights = [5.50000000e+01 3.77501294e+00 7.93702516e+00 2.61499276e-02\n",
      " 2.64260255e-01 1.10551674e+01], Loss = 0.4238\n",
      "Iteration 3454: Weights = [5.50000000e+01 3.77490458e+00 7.93679731e+00 2.61491769e-02\n",
      " 2.64252669e-01 1.10554081e+01], Loss = 0.4238\n",
      "Iteration 3455: Weights = [5.50000000e+01 3.77479621e+00 7.93656948e+00 2.61484263e-02\n",
      " 2.64245083e-01 1.10556488e+01], Loss = 0.4238\n",
      "Iteration 3456: Weights = [5.50000000e+01 3.77468785e+00 7.93634165e+00 2.61476756e-02\n",
      " 2.64237498e-01 1.10558895e+01], Loss = 0.4237\n",
      "Iteration 3457: Weights = [5.50000000e+01 3.77457950e+00 7.93611382e+00 2.61469250e-02\n",
      " 2.64229912e-01 1.10561302e+01], Loss = 0.4237\n",
      "Iteration 3458: Weights = [5.50000000e+01 3.77447114e+00 7.93588601e+00 2.61461745e-02\n",
      " 2.64222327e-01 1.10563709e+01], Loss = 0.4237\n",
      "Iteration 3459: Weights = [5.50000000e+01 3.77436279e+00 7.93565820e+00 2.61454239e-02\n",
      " 2.64214742e-01 1.10566115e+01], Loss = 0.4237\n",
      "Iteration 3460: Weights = [5.50000000e+01 3.77425444e+00 7.93543039e+00 2.61446734e-02\n",
      " 2.64207158e-01 1.10568522e+01], Loss = 0.4236\n",
      "Iteration 3461: Weights = [5.50000000e+01 3.77414610e+00 7.93520260e+00 2.61439228e-02\n",
      " 2.64199573e-01 1.10570929e+01], Loss = 0.4236\n",
      "Iteration 3462: Weights = [5.50000000e+01 3.77403776e+00 7.93497481e+00 2.61431723e-02\n",
      " 2.64191989e-01 1.10573335e+01], Loss = 0.4236\n",
      "Iteration 3463: Weights = [5.50000000e+01 3.77392942e+00 7.93474702e+00 2.61424219e-02\n",
      " 2.64184405e-01 1.10575742e+01], Loss = 0.4236\n",
      "Iteration 3464: Weights = [5.50000000e+01 3.77382108e+00 7.93451925e+00 2.61416714e-02\n",
      " 2.64176821e-01 1.10578148e+01], Loss = 0.4236\n",
      "Iteration 3465: Weights = [5.50000000e+01 3.77371275e+00 7.93429147e+00 2.61409210e-02\n",
      " 2.64169238e-01 1.10580554e+01], Loss = 0.4235\n",
      "Iteration 3466: Weights = [5.50000000e+01 3.77360442e+00 7.93406371e+00 2.61401706e-02\n",
      " 2.64161655e-01 1.10582961e+01], Loss = 0.4235\n",
      "Iteration 3467: Weights = [5.50000000e+01 3.77349609e+00 7.93383595e+00 2.61394202e-02\n",
      " 2.64154072e-01 1.10585367e+01], Loss = 0.4235\n",
      "Iteration 3468: Weights = [5.50000000e+01 3.77338777e+00 7.93360820e+00 2.61386698e-02\n",
      " 2.64146489e-01 1.10587773e+01], Loss = 0.4235\n",
      "Iteration 3469: Weights = [5.50000000e+01 3.77327945e+00 7.93338046e+00 2.61379195e-02\n",
      " 2.64138906e-01 1.10590179e+01], Loss = 0.4234\n",
      "Iteration 3470: Weights = [5.50000000e+01 3.77317113e+00 7.93315272e+00 2.61371691e-02\n",
      " 2.64131324e-01 1.10592585e+01], Loss = 0.4234\n",
      "Iteration 3471: Weights = [5.50000000e+01 3.77306282e+00 7.93292499e+00 2.61364188e-02\n",
      " 2.64123741e-01 1.10594991e+01], Loss = 0.4234\n",
      "Iteration 3472: Weights = [5.50000000e+01 3.77295451e+00 7.93269726e+00 2.61356686e-02\n",
      " 2.64116159e-01 1.10597397e+01], Loss = 0.4234\n",
      "Iteration 3473: Weights = [5.50000000e+01 3.77284620e+00 7.93246954e+00 2.61349183e-02\n",
      " 2.64108577e-01 1.10599803e+01], Loss = 0.4233\n",
      "Iteration 3474: Weights = [5.50000000e+01 3.77273790e+00 7.93224183e+00 2.61341681e-02\n",
      " 2.64100996e-01 1.10602209e+01], Loss = 0.4233\n",
      "Iteration 3475: Weights = [5.50000000e+01 3.77262959e+00 7.93201413e+00 2.61334179e-02\n",
      " 2.64093415e-01 1.10604614e+01], Loss = 0.4233\n",
      "Iteration 3476: Weights = [5.50000000e+01 3.77252130e+00 7.93178643e+00 2.61326677e-02\n",
      " 2.64085833e-01 1.10607020e+01], Loss = 0.4233\n",
      "Iteration 3477: Weights = [5.50000000e+01 3.77241300e+00 7.93155874e+00 2.61319175e-02\n",
      " 2.64078252e-01 1.10609425e+01], Loss = 0.4232\n",
      "Iteration 3478: Weights = [5.50000000e+01 3.77230471e+00 7.93133105e+00 2.61311673e-02\n",
      " 2.64070672e-01 1.10611831e+01], Loss = 0.4232\n",
      "Iteration 3479: Weights = [5.50000000e+01 3.77219642e+00 7.93110337e+00 2.61304172e-02\n",
      " 2.64063091e-01 1.10614236e+01], Loss = 0.4232\n",
      "Iteration 3480: Weights = [5.50000000e+01 3.77208813e+00 7.93087570e+00 2.61296671e-02\n",
      " 2.64055511e-01 1.10616642e+01], Loss = 0.4232\n",
      "Iteration 3481: Weights = [5.50000000e+01 3.77197985e+00 7.93064803e+00 2.61289170e-02\n",
      " 2.64047931e-01 1.10619047e+01], Loss = 0.4231\n",
      "Iteration 3482: Weights = [5.50000000e+01 3.77187157e+00 7.93042037e+00 2.61281669e-02\n",
      " 2.64040351e-01 1.10621452e+01], Loss = 0.4231\n",
      "Iteration 3483: Weights = [5.50000000e+01 3.77176330e+00 7.93019272e+00 2.61274169e-02\n",
      " 2.64032771e-01 1.10623857e+01], Loss = 0.4231\n",
      "Iteration 3484: Weights = [5.50000000e+01 3.77165502e+00 7.92996507e+00 2.61266669e-02\n",
      " 2.64025192e-01 1.10626262e+01], Loss = 0.4231\n",
      "Iteration 3485: Weights = [5.50000000e+01 3.77154675e+00 7.92973743e+00 2.61259169e-02\n",
      " 2.64017613e-01 1.10628667e+01], Loss = 0.4230\n",
      "Iteration 3486: Weights = [5.50000000e+01 3.77143848e+00 7.92950980e+00 2.61251669e-02\n",
      " 2.64010034e-01 1.10631072e+01], Loss = 0.4230\n",
      "Iteration 3487: Weights = [5.50000000e+01 3.77133022e+00 7.92928217e+00 2.61244169e-02\n",
      " 2.64002455e-01 1.10633477e+01], Loss = 0.4230\n",
      "Iteration 3488: Weights = [5.50000000e+01 3.77122196e+00 7.92905455e+00 2.61236670e-02\n",
      " 2.63994877e-01 1.10635882e+01], Loss = 0.4230\n",
      "Iteration 3489: Weights = [5.50000000e+01 3.77111370e+00 7.92882694e+00 2.61229171e-02\n",
      " 2.63987298e-01 1.10638286e+01], Loss = 0.4229\n",
      "Iteration 3490: Weights = [5.50000000e+01 3.77100545e+00 7.92859933e+00 2.61221672e-02\n",
      " 2.63979720e-01 1.10640691e+01], Loss = 0.4229\n",
      "Iteration 3491: Weights = [5.50000000e+01 3.77089720e+00 7.92837173e+00 2.61214173e-02\n",
      " 2.63972142e-01 1.10643096e+01], Loss = 0.4229\n",
      "Iteration 3492: Weights = [5.50000000e+01 3.77078895e+00 7.92814414e+00 2.61206675e-02\n",
      " 2.63964565e-01 1.10645500e+01], Loss = 0.4229\n",
      "Iteration 3493: Weights = [5.50000000e+01 3.77068070e+00 7.92791655e+00 2.61199177e-02\n",
      " 2.63956987e-01 1.10647905e+01], Loss = 0.4228\n",
      "Iteration 3494: Weights = [5.50000000e+01 3.77057246e+00 7.92768897e+00 2.61191678e-02\n",
      " 2.63949410e-01 1.10650309e+01], Loss = 0.4228\n",
      "Iteration 3495: Weights = [5.50000000e+01 3.77046422e+00 7.92746139e+00 2.61184181e-02\n",
      " 2.63941833e-01 1.10652713e+01], Loss = 0.4228\n",
      "Iteration 3496: Weights = [5.50000000e+01 3.77035598e+00 7.92723382e+00 2.61176683e-02\n",
      " 2.63934256e-01 1.10655117e+01], Loss = 0.4228\n",
      "Iteration 3497: Weights = [5.50000000e+01 3.77024775e+00 7.92700626e+00 2.61169186e-02\n",
      " 2.63926680e-01 1.10657522e+01], Loss = 0.4228\n",
      "Iteration 3498: Weights = [5.50000000e+01 3.77013952e+00 7.92677871e+00 2.61161688e-02\n",
      " 2.63919103e-01 1.10659926e+01], Loss = 0.4227\n",
      "Iteration 3499: Weights = [5.50000000e+01 3.77003129e+00 7.92655116e+00 2.61154191e-02\n",
      " 2.63911527e-01 1.10662330e+01], Loss = 0.4227\n",
      "Iteration 3500: Weights = [5.50000000e+01 3.76992307e+00 7.92632362e+00 2.61146695e-02\n",
      " 2.63903951e-01 1.10664734e+01], Loss = 0.4227\n",
      "Iteration 3501: Weights = [5.50000000e+01 3.76981485e+00 7.92609608e+00 2.61139198e-02\n",
      " 2.63896375e-01 1.10667138e+01], Loss = 0.4227\n",
      "Iteration 3502: Weights = [5.50000000e+01 3.76970663e+00 7.92586855e+00 2.61131702e-02\n",
      " 2.63888800e-01 1.10669541e+01], Loss = 0.4226\n",
      "Iteration 3503: Weights = [5.50000000e+01 3.76959842e+00 7.92564103e+00 2.61124206e-02\n",
      " 2.63881225e-01 1.10671945e+01], Loss = 0.4226\n",
      "Iteration 3504: Weights = [5.50000000e+01 3.76949021e+00 7.92541351e+00 2.61116710e-02\n",
      " 2.63873650e-01 1.10674349e+01], Loss = 0.4226\n",
      "Iteration 3505: Weights = [5.50000000e+01 3.76938200e+00 7.92518600e+00 2.61109214e-02\n",
      " 2.63866075e-01 1.10676752e+01], Loss = 0.4226\n",
      "Iteration 3506: Weights = [5.50000000e+01 3.76927379e+00 7.92495850e+00 2.61101718e-02\n",
      " 2.63858500e-01 1.10679156e+01], Loss = 0.4225\n",
      "Iteration 3507: Weights = [5.50000000e+01 3.76916559e+00 7.92473100e+00 2.61094223e-02\n",
      " 2.63850926e-01 1.10681559e+01], Loss = 0.4225\n",
      "Iteration 3508: Weights = [5.50000000e+01 3.76905739e+00 7.92450352e+00 2.61086728e-02\n",
      " 2.63843352e-01 1.10683963e+01], Loss = 0.4225\n",
      "Iteration 3509: Weights = [5.50000000e+01 3.76894920e+00 7.92427603e+00 2.61079233e-02\n",
      " 2.63835778e-01 1.10686366e+01], Loss = 0.4225\n",
      "Iteration 3510: Weights = [5.50000000e+01 3.76884100e+00 7.92404856e+00 2.61071739e-02\n",
      " 2.63828204e-01 1.10688769e+01], Loss = 0.4224\n",
      "Iteration 3511: Weights = [5.50000000e+01 3.76873282e+00 7.92382108e+00 2.61064244e-02\n",
      " 2.63820630e-01 1.10691172e+01], Loss = 0.4224\n",
      "Iteration 3512: Weights = [5.50000000e+01 3.76862463e+00 7.92359362e+00 2.61056750e-02\n",
      " 2.63813057e-01 1.10693576e+01], Loss = 0.4224\n",
      "Iteration 3513: Weights = [5.50000000e+01 3.76851645e+00 7.92336616e+00 2.61049256e-02\n",
      " 2.63805484e-01 1.10695979e+01], Loss = 0.4224\n",
      "Iteration 3514: Weights = [5.50000000e+01 3.76840827e+00 7.92313871e+00 2.61041762e-02\n",
      " 2.63797911e-01 1.10698382e+01], Loss = 0.4223\n",
      "Iteration 3515: Weights = [5.50000000e+01 3.76830009e+00 7.92291127e+00 2.61034269e-02\n",
      " 2.63790338e-01 1.10700785e+01], Loss = 0.4223\n",
      "Iteration 3516: Weights = [5.50000000e+01 3.76819191e+00 7.92268383e+00 2.61026775e-02\n",
      " 2.63782766e-01 1.10703187e+01], Loss = 0.4223\n",
      "Iteration 3517: Weights = [5.50000000e+01 3.76808374e+00 7.92245640e+00 2.61019282e-02\n",
      " 2.63775194e-01 1.10705590e+01], Loss = 0.4223\n",
      "Iteration 3518: Weights = [5.50000000e+01 3.76797558e+00 7.92222898e+00 2.61011789e-02\n",
      " 2.63767622e-01 1.10707993e+01], Loss = 0.4222\n",
      "Iteration 3519: Weights = [5.50000000e+01 3.76786741e+00 7.92200156e+00 2.61004297e-02\n",
      " 2.63760050e-01 1.10710395e+01], Loss = 0.4222\n",
      "Iteration 3520: Weights = [5.50000000e+01 3.76775925e+00 7.92177415e+00 2.60996804e-02\n",
      " 2.63752478e-01 1.10712798e+01], Loss = 0.4222\n",
      "Iteration 3521: Weights = [5.50000000e+01 3.76765109e+00 7.92154674e+00 2.60989312e-02\n",
      " 2.63744907e-01 1.10715201e+01], Loss = 0.4222\n",
      "Iteration 3522: Weights = [5.50000000e+01 3.76754294e+00 7.92131934e+00 2.60981820e-02\n",
      " 2.63737336e-01 1.10717603e+01], Loss = 0.4221\n",
      "Iteration 3523: Weights = [5.50000000e+01 3.76743478e+00 7.92109195e+00 2.60974328e-02\n",
      " 2.63729765e-01 1.10720005e+01], Loss = 0.4221\n",
      "Iteration 3524: Weights = [5.50000000e+01 3.76732663e+00 7.92086457e+00 2.60966837e-02\n",
      " 2.63722194e-01 1.10722408e+01], Loss = 0.4221\n",
      "Iteration 3525: Weights = [5.50000000e+01 3.76721849e+00 7.92063719e+00 2.60959345e-02\n",
      " 2.63714624e-01 1.10724810e+01], Loss = 0.4221\n",
      "Iteration 3526: Weights = [5.50000000e+01 3.76711035e+00 7.92040982e+00 2.60951854e-02\n",
      " 2.63707053e-01 1.10727212e+01], Loss = 0.4220\n",
      "Iteration 3527: Weights = [5.50000000e+01 3.76700221e+00 7.92018245e+00 2.60944363e-02\n",
      " 2.63699483e-01 1.10729614e+01], Loss = 0.4220\n",
      "Iteration 3528: Weights = [5.50000000e+01 3.76689407e+00 7.91995509e+00 2.60936872e-02\n",
      " 2.63691913e-01 1.10732016e+01], Loss = 0.4220\n",
      "Iteration 3529: Weights = [5.50000000e+01 3.76678593e+00 7.91972774e+00 2.60929382e-02\n",
      " 2.63684344e-01 1.10734418e+01], Loss = 0.4220\n",
      "Iteration 3530: Weights = [5.50000000e+01 3.76667780e+00 7.91950039e+00 2.60921891e-02\n",
      " 2.63676774e-01 1.10736820e+01], Loss = 0.4220\n",
      "Iteration 3531: Weights = [5.50000000e+01 3.76656968e+00 7.91927305e+00 2.60914401e-02\n",
      " 2.63669205e-01 1.10739222e+01], Loss = 0.4219\n",
      "Iteration 3532: Weights = [5.50000000e+01 3.76646155e+00 7.91904572e+00 2.60906911e-02\n",
      " 2.63661636e-01 1.10741623e+01], Loss = 0.4219\n",
      "Iteration 3533: Weights = [5.50000000e+01 3.76635343e+00 7.91881839e+00 2.60899422e-02\n",
      " 2.63654068e-01 1.10744025e+01], Loss = 0.4219\n",
      "Iteration 3534: Weights = [5.50000000e+01 3.76624531e+00 7.91859107e+00 2.60891932e-02\n",
      " 2.63646499e-01 1.10746427e+01], Loss = 0.4219\n",
      "Iteration 3535: Weights = [5.50000000e+01 3.76613720e+00 7.91836376e+00 2.60884443e-02\n",
      " 2.63638931e-01 1.10748828e+01], Loss = 0.4218\n",
      "Iteration 3536: Weights = [5.50000000e+01 3.76602909e+00 7.91813645e+00 2.60876954e-02\n",
      " 2.63631363e-01 1.10751230e+01], Loss = 0.4218\n",
      "Iteration 3537: Weights = [5.50000000e+01 3.76592098e+00 7.91790915e+00 2.60869465e-02\n",
      " 2.63623795e-01 1.10753631e+01], Loss = 0.4218\n",
      "Iteration 3538: Weights = [5.50000000e+01 3.76581287e+00 7.91768186e+00 2.60861977e-02\n",
      " 2.63616227e-01 1.10756032e+01], Loss = 0.4218\n",
      "Iteration 3539: Weights = [5.50000000e+01 3.76570477e+00 7.91745457e+00 2.60854488e-02\n",
      " 2.63608660e-01 1.10758434e+01], Loss = 0.4217\n",
      "Iteration 3540: Weights = [5.50000000e+01 3.76559667e+00 7.91722729e+00 2.60847000e-02\n",
      " 2.63601092e-01 1.10760835e+01], Loss = 0.4217\n",
      "Iteration 3541: Weights = [5.50000000e+01 3.76548857e+00 7.91700001e+00 2.60839512e-02\n",
      " 2.63593525e-01 1.10763236e+01], Loss = 0.4217\n",
      "Iteration 3542: Weights = [5.50000000e+01 3.76538048e+00 7.91677275e+00 2.60832024e-02\n",
      " 2.63585959e-01 1.10765637e+01], Loss = 0.4217\n",
      "Iteration 3543: Weights = [5.50000000e+01 3.76527239e+00 7.91654549e+00 2.60824537e-02\n",
      " 2.63578392e-01 1.10768038e+01], Loss = 0.4216\n",
      "Iteration 3544: Weights = [5.50000000e+01 3.76516430e+00 7.91631823e+00 2.60817049e-02\n",
      " 2.63570826e-01 1.10770439e+01], Loss = 0.4216\n",
      "Iteration 3545: Weights = [5.50000000e+01 3.76505622e+00 7.91609098e+00 2.60809562e-02\n",
      " 2.63563259e-01 1.10772840e+01], Loss = 0.4216\n",
      "Iteration 3546: Weights = [5.50000000e+01 3.76494814e+00 7.91586374e+00 2.60802075e-02\n",
      " 2.63555694e-01 1.10775241e+01], Loss = 0.4216\n",
      "Iteration 3547: Weights = [5.50000000e+01 3.76484006e+00 7.91563651e+00 2.60794589e-02\n",
      " 2.63548128e-01 1.10777641e+01], Loss = 0.4215\n",
      "Iteration 3548: Weights = [5.50000000e+01 3.76473199e+00 7.91540928e+00 2.60787102e-02\n",
      " 2.63540562e-01 1.10780042e+01], Loss = 0.4215\n",
      "Iteration 3549: Weights = [5.50000000e+01 3.76462391e+00 7.91518205e+00 2.60779616e-02\n",
      " 2.63532997e-01 1.10782442e+01], Loss = 0.4215\n",
      "Iteration 3550: Weights = [5.50000000e+01 3.76451585e+00 7.91495484e+00 2.60772130e-02\n",
      " 2.63525432e-01 1.10784843e+01], Loss = 0.4215\n",
      "Iteration 3551: Weights = [5.50000000e+01 3.76440778e+00 7.91472763e+00 2.60764644e-02\n",
      " 2.63517867e-01 1.10787243e+01], Loss = 0.4214\n",
      "Iteration 3552: Weights = [5.50000000e+01 3.76429972e+00 7.91450043e+00 2.60757159e-02\n",
      " 2.63510303e-01 1.10789644e+01], Loss = 0.4214\n",
      "Iteration 3553: Weights = [5.50000000e+01 3.76419166e+00 7.91427323e+00 2.60749673e-02\n",
      " 2.63502738e-01 1.10792044e+01], Loss = 0.4214\n",
      "Iteration 3554: Weights = [5.50000000e+01 3.76408360e+00 7.91404604e+00 2.60742188e-02\n",
      " 2.63495174e-01 1.10794444e+01], Loss = 0.4214\n",
      "Iteration 3555: Weights = [5.50000000e+01 3.76397555e+00 7.91381886e+00 2.60734703e-02\n",
      " 2.63487610e-01 1.10796844e+01], Loss = 0.4213\n",
      "Iteration 3556: Weights = [5.50000000e+01 3.76386750e+00 7.91359168e+00 2.60727218e-02\n",
      " 2.63480046e-01 1.10799244e+01], Loss = 0.4213\n",
      "Iteration 3557: Weights = [5.50000000e+01 3.76375945e+00 7.91336451e+00 2.60719734e-02\n",
      " 2.63472483e-01 1.10801645e+01], Loss = 0.4213\n",
      "Iteration 3558: Weights = [5.50000000e+01 3.76365141e+00 7.91313735e+00 2.60712250e-02\n",
      " 2.63464919e-01 1.10804044e+01], Loss = 0.4213\n",
      "Iteration 3559: Weights = [5.50000000e+01 3.76354337e+00 7.91291019e+00 2.60704766e-02\n",
      " 2.63457356e-01 1.10806444e+01], Loss = 0.4212\n",
      "Iteration 3560: Weights = [5.50000000e+01 3.76343533e+00 7.91268304e+00 2.60697282e-02\n",
      " 2.63449793e-01 1.10808844e+01], Loss = 0.4212\n",
      "Iteration 3561: Weights = [5.50000000e+01 3.76332730e+00 7.91245590e+00 2.60689798e-02\n",
      " 2.63442231e-01 1.10811244e+01], Loss = 0.4212\n",
      "Iteration 3562: Weights = [5.50000000e+01 3.76321927e+00 7.91222876e+00 2.60682315e-02\n",
      " 2.63434668e-01 1.10813644e+01], Loss = 0.4212\n",
      "Iteration 3563: Weights = [5.50000000e+01 3.76311124e+00 7.91200163e+00 2.60674831e-02\n",
      " 2.63427106e-01 1.10816043e+01], Loss = 0.4212\n",
      "Iteration 3564: Weights = [5.50000000e+01 3.76300321e+00 7.91177450e+00 2.60667348e-02\n",
      " 2.63419544e-01 1.10818443e+01], Loss = 0.4211\n",
      "Iteration 3565: Weights = [5.50000000e+01 3.76289519e+00 7.91154739e+00 2.60659866e-02\n",
      " 2.63411982e-01 1.10820842e+01], Loss = 0.4211\n",
      "Iteration 3566: Weights = [5.50000000e+01 3.76278717e+00 7.91132028e+00 2.60652383e-02\n",
      " 2.63404421e-01 1.10823242e+01], Loss = 0.4211\n",
      "Iteration 3567: Weights = [5.50000000e+01 3.76267916e+00 7.91109317e+00 2.60644901e-02\n",
      " 2.63396859e-01 1.10825641e+01], Loss = 0.4211\n",
      "Iteration 3568: Weights = [5.50000000e+01 3.76257114e+00 7.91086607e+00 2.60637418e-02\n",
      " 2.63389298e-01 1.10828040e+01], Loss = 0.4210\n",
      "Iteration 3569: Weights = [5.50000000e+01 3.76246313e+00 7.91063898e+00 2.60629937e-02\n",
      " 2.63381737e-01 1.10830439e+01], Loss = 0.4210\n",
      "Iteration 3570: Weights = [5.50000000e+01 3.76235513e+00 7.91041190e+00 2.60622455e-02\n",
      " 2.63374176e-01 1.10832838e+01], Loss = 0.4210\n",
      "Iteration 3571: Weights = [5.50000000e+01 3.76224712e+00 7.91018482e+00 2.60614973e-02\n",
      " 2.63366616e-01 1.10835237e+01], Loss = 0.4210\n",
      "Iteration 3572: Weights = [5.50000000e+01 3.76213912e+00 7.90995774e+00 2.60607492e-02\n",
      " 2.63359056e-01 1.10837636e+01], Loss = 0.4209\n",
      "Iteration 3573: Weights = [5.50000000e+01 3.76203113e+00 7.90973068e+00 2.60600011e-02\n",
      " 2.63351496e-01 1.10840035e+01], Loss = 0.4209\n",
      "Iteration 3574: Weights = [5.50000000e+01 3.76192313e+00 7.90950362e+00 2.60592530e-02\n",
      " 2.63343936e-01 1.10842434e+01], Loss = 0.4209\n",
      "Iteration 3575: Weights = [5.50000000e+01 3.76181514e+00 7.90927657e+00 2.60585049e-02\n",
      " 2.63336376e-01 1.10844833e+01], Loss = 0.4209\n",
      "Iteration 3576: Weights = [5.50000000e+01 3.76170715e+00 7.90904952e+00 2.60577569e-02\n",
      " 2.63328817e-01 1.10847232e+01], Loss = 0.4208\n",
      "Iteration 3577: Weights = [5.50000000e+01 3.76159917e+00 7.90882248e+00 2.60570089e-02\n",
      " 2.63321257e-01 1.10849630e+01], Loss = 0.4208\n",
      "Iteration 3578: Weights = [5.50000000e+01 3.76149119e+00 7.90859545e+00 2.60562609e-02\n",
      " 2.63313698e-01 1.10852029e+01], Loss = 0.4208\n",
      "Iteration 3579: Weights = [5.50000000e+01 3.76138321e+00 7.90836842e+00 2.60555129e-02\n",
      " 2.63306140e-01 1.10854427e+01], Loss = 0.4208\n",
      "Iteration 3580: Weights = [5.50000000e+01 3.76127523e+00 7.90814140e+00 2.60547649e-02\n",
      " 2.63298581e-01 1.10856826e+01], Loss = 0.4207\n",
      "Iteration 3581: Weights = [5.50000000e+01 3.76116726e+00 7.90791439e+00 2.60540170e-02\n",
      " 2.63291023e-01 1.10859224e+01], Loss = 0.4207\n",
      "Iteration 3582: Weights = [5.50000000e+01 3.76105929e+00 7.90768738e+00 2.60532691e-02\n",
      " 2.63283465e-01 1.10861622e+01], Loss = 0.4207\n",
      "Iteration 3583: Weights = [5.50000000e+01 3.76095133e+00 7.90746038e+00 2.60525212e-02\n",
      " 2.63275907e-01 1.10864021e+01], Loss = 0.4207\n",
      "Iteration 3584: Weights = [5.50000000e+01 3.76084336e+00 7.90723339e+00 2.60517733e-02\n",
      " 2.63268349e-01 1.10866419e+01], Loss = 0.4206\n",
      "Iteration 3585: Weights = [5.50000000e+01 3.76073540e+00 7.90700640e+00 2.60510255e-02\n",
      " 2.63260792e-01 1.10868817e+01], Loss = 0.4206\n",
      "Iteration 3586: Weights = [5.50000000e+01 3.76062745e+00 7.90677942e+00 2.60502776e-02\n",
      " 2.63253234e-01 1.10871215e+01], Loss = 0.4206\n",
      "Iteration 3587: Weights = [5.50000000e+01 3.76051949e+00 7.90655244e+00 2.60495298e-02\n",
      " 2.63245677e-01 1.10873613e+01], Loss = 0.4206\n",
      "Iteration 3588: Weights = [5.50000000e+01 3.76041154e+00 7.90632548e+00 2.60487820e-02\n",
      " 2.63238121e-01 1.10876011e+01], Loss = 0.4205\n",
      "Iteration 3589: Weights = [5.50000000e+01 3.76030359e+00 7.90609851e+00 2.60480343e-02\n",
      " 2.63230564e-01 1.10878409e+01], Loss = 0.4205\n",
      "Iteration 3590: Weights = [5.50000000e+01 3.76019565e+00 7.90587156e+00 2.60472865e-02\n",
      " 2.63223008e-01 1.10880806e+01], Loss = 0.4205\n",
      "Iteration 3591: Weights = [5.50000000e+01 3.76008771e+00 7.90564461e+00 2.60465388e-02\n",
      " 2.63215451e-01 1.10883204e+01], Loss = 0.4205\n",
      "Iteration 3592: Weights = [5.50000000e+01 3.75997977e+00 7.90541767e+00 2.60457911e-02\n",
      " 2.63207895e-01 1.10885602e+01], Loss = 0.4205\n",
      "Iteration 3593: Weights = [5.50000000e+01 3.75987184e+00 7.90519073e+00 2.60450434e-02\n",
      " 2.63200340e-01 1.10887999e+01], Loss = 0.4204\n",
      "Iteration 3594: Weights = [5.50000000e+01 3.75976390e+00 7.90496380e+00 2.60442958e-02\n",
      " 2.63192784e-01 1.10890397e+01], Loss = 0.4204\n",
      "Iteration 3595: Weights = [5.50000000e+01 3.75965597e+00 7.90473688e+00 2.60435481e-02\n",
      " 2.63185229e-01 1.10892794e+01], Loss = 0.4204\n",
      "Iteration 3596: Weights = [5.50000000e+01 3.75954805e+00 7.90450997e+00 2.60428005e-02\n",
      " 2.63177674e-01 1.10895191e+01], Loss = 0.4204\n",
      "Iteration 3597: Weights = [5.50000000e+01 3.75944013e+00 7.90428306e+00 2.60420529e-02\n",
      " 2.63170119e-01 1.10897589e+01], Loss = 0.4203\n",
      "Iteration 3598: Weights = [5.50000000e+01 3.75933221e+00 7.90405615e+00 2.60413054e-02\n",
      " 2.63162564e-01 1.10899986e+01], Loss = 0.4203\n",
      "Iteration 3599: Weights = [5.50000000e+01 3.75922429e+00 7.90382926e+00 2.60405578e-02\n",
      " 2.63155010e-01 1.10902383e+01], Loss = 0.4203\n",
      "Iteration 3600: Weights = [5.50000000e+01 3.75911638e+00 7.90360237e+00 2.60398103e-02\n",
      " 2.63147456e-01 1.10904780e+01], Loss = 0.4203\n",
      "Iteration 3601: Weights = [5.50000000e+01 3.75900847e+00 7.90337548e+00 2.60390628e-02\n",
      " 2.63139902e-01 1.10907177e+01], Loss = 0.4202\n",
      "Iteration 3602: Weights = [5.50000000e+01 3.75890056e+00 7.90314861e+00 2.60383153e-02\n",
      " 2.63132348e-01 1.10909574e+01], Loss = 0.4202\n",
      "Iteration 3603: Weights = [5.50000000e+01 3.75879265e+00 7.90292174e+00 2.60375678e-02\n",
      " 2.63124794e-01 1.10911971e+01], Loss = 0.4202\n",
      "Iteration 3604: Weights = [5.50000000e+01 3.75868475e+00 7.90269487e+00 2.60368204e-02\n",
      " 2.63117241e-01 1.10914368e+01], Loss = 0.4202\n",
      "Iteration 3605: Weights = [5.50000000e+01 3.75857686e+00 7.90246802e+00 2.60360730e-02\n",
      " 2.63109688e-01 1.10916764e+01], Loss = 0.4201\n",
      "Iteration 3606: Weights = [5.50000000e+01 3.75846896e+00 7.90224117e+00 2.60353256e-02\n",
      " 2.63102135e-01 1.10919161e+01], Loss = 0.4201\n",
      "Iteration 3607: Weights = [5.50000000e+01 3.75836107e+00 7.90201432e+00 2.60345782e-02\n",
      " 2.63094582e-01 1.10921557e+01], Loss = 0.4201\n",
      "Iteration 3608: Weights = [5.50000000e+01 3.75825318e+00 7.90178748e+00 2.60338308e-02\n",
      " 2.63087030e-01 1.10923954e+01], Loss = 0.4201\n",
      "Iteration 3609: Weights = [5.50000000e+01 3.75814529e+00 7.90156065e+00 2.60330835e-02\n",
      " 2.63079478e-01 1.10926350e+01], Loss = 0.4200\n",
      "Iteration 3610: Weights = [5.50000000e+01 3.75803741e+00 7.90133383e+00 2.60323362e-02\n",
      " 2.63071926e-01 1.10928747e+01], Loss = 0.4200\n",
      "Iteration 3611: Weights = [5.50000000e+01 3.75792953e+00 7.90110701e+00 2.60315889e-02\n",
      " 2.63064374e-01 1.10931143e+01], Loss = 0.4200\n",
      "Iteration 3612: Weights = [5.50000000e+01 3.75782166e+00 7.90088020e+00 2.60308416e-02\n",
      " 2.63056822e-01 1.10933539e+01], Loss = 0.4200\n",
      "Iteration 3613: Weights = [5.50000000e+01 3.75771378e+00 7.90065339e+00 2.60300944e-02\n",
      " 2.63049271e-01 1.10935935e+01], Loss = 0.4199\n",
      "Iteration 3614: Weights = [5.50000000e+01 3.75760591e+00 7.90042660e+00 2.60293471e-02\n",
      " 2.63041720e-01 1.10938332e+01], Loss = 0.4199\n",
      "Iteration 3615: Weights = [5.50000000e+01 3.75749805e+00 7.90019980e+00 2.60285999e-02\n",
      " 2.63034169e-01 1.10940728e+01], Loss = 0.4199\n",
      "Iteration 3616: Weights = [5.50000000e+01 3.75739018e+00 7.89997302e+00 2.60278528e-02\n",
      " 2.63026618e-01 1.10943124e+01], Loss = 0.4199\n",
      "Iteration 3617: Weights = [5.50000000e+01 3.75728232e+00 7.89974624e+00 2.60271056e-02\n",
      " 2.63019067e-01 1.10945519e+01], Loss = 0.4198\n",
      "Iteration 3618: Weights = [5.50000000e+01 3.75717446e+00 7.89951947e+00 2.60263584e-02\n",
      " 2.63011517e-01 1.10947915e+01], Loss = 0.4198\n",
      "Iteration 3619: Weights = [5.50000000e+01 3.75706661e+00 7.89929270e+00 2.60256113e-02\n",
      " 2.63003967e-01 1.10950311e+01], Loss = 0.4198\n",
      "Iteration 3620: Weights = [5.50000000e+01 3.75695876e+00 7.89906594e+00 2.60248642e-02\n",
      " 2.62996417e-01 1.10952707e+01], Loss = 0.4198\n",
      "Iteration 3621: Weights = [5.50000000e+01 3.75685091e+00 7.89883919e+00 2.60241171e-02\n",
      " 2.62988867e-01 1.10955102e+01], Loss = 0.4198\n",
      "Iteration 3622: Weights = [5.50000000e+01 3.75674306e+00 7.89861244e+00 2.60233701e-02\n",
      " 2.62981318e-01 1.10957498e+01], Loss = 0.4197\n",
      "Iteration 3623: Weights = [5.50000000e+01 3.75663522e+00 7.89838570e+00 2.60226231e-02\n",
      " 2.62973769e-01 1.10959893e+01], Loss = 0.4197\n",
      "Iteration 3624: Weights = [5.50000000e+01 3.75652738e+00 7.89815897e+00 2.60218760e-02\n",
      " 2.62966220e-01 1.10962289e+01], Loss = 0.4197\n",
      "Iteration 3625: Weights = [5.50000000e+01 3.75641955e+00 7.89793224e+00 2.60211291e-02\n",
      " 2.62958671e-01 1.10964684e+01], Loss = 0.4197\n",
      "Iteration 3626: Weights = [5.50000000e+01 3.75631171e+00 7.89770552e+00 2.60203821e-02\n",
      " 2.62951122e-01 1.10967079e+01], Loss = 0.4196\n",
      "Iteration 3627: Weights = [5.50000000e+01 3.75620388e+00 7.89747881e+00 2.60196351e-02\n",
      " 2.62943574e-01 1.10969474e+01], Loss = 0.4196\n",
      "Iteration 3628: Weights = [5.50000000e+01 3.75609606e+00 7.89725210e+00 2.60188882e-02\n",
      " 2.62936026e-01 1.10971870e+01], Loss = 0.4196\n",
      "Iteration 3629: Weights = [5.50000000e+01 3.75598823e+00 7.89702540e+00 2.60181413e-02\n",
      " 2.62928478e-01 1.10974265e+01], Loss = 0.4196\n",
      "Iteration 3630: Weights = [5.50000000e+01 3.75588041e+00 7.89679870e+00 2.60173944e-02\n",
      " 2.62920930e-01 1.10976660e+01], Loss = 0.4195\n",
      "Iteration 3631: Weights = [5.50000000e+01 3.75577260e+00 7.89657202e+00 2.60166476e-02\n",
      " 2.62913383e-01 1.10979055e+01], Loss = 0.4195\n",
      "Iteration 3632: Weights = [5.50000000e+01 3.75566478e+00 7.89634533e+00 2.60159007e-02\n",
      " 2.62905836e-01 1.10981449e+01], Loss = 0.4195\n",
      "Iteration 3633: Weights = [5.50000000e+01 3.75555697e+00 7.89611866e+00 2.60151539e-02\n",
      " 2.62898288e-01 1.10983844e+01], Loss = 0.4195\n",
      "Iteration 3634: Weights = [5.50000000e+01 3.75544916e+00 7.89589199e+00 2.60144071e-02\n",
      " 2.62890742e-01 1.10986239e+01], Loss = 0.4194\n",
      "Iteration 3635: Weights = [5.50000000e+01 3.75534136e+00 7.89566533e+00 2.60136603e-02\n",
      " 2.62883195e-01 1.10988634e+01], Loss = 0.4194\n",
      "Iteration 3636: Weights = [5.50000000e+01 3.75523355e+00 7.89543867e+00 2.60129136e-02\n",
      " 2.62875649e-01 1.10991028e+01], Loss = 0.4194\n",
      "Iteration 3637: Weights = [5.50000000e+01 3.75512576e+00 7.89521202e+00 2.60121668e-02\n",
      " 2.62868102e-01 1.10993423e+01], Loss = 0.4194\n",
      "Iteration 3638: Weights = [5.50000000e+01 3.75501796e+00 7.89498538e+00 2.60114201e-02\n",
      " 2.62860556e-01 1.10995817e+01], Loss = 0.4193\n",
      "Iteration 3639: Weights = [5.50000000e+01 3.75491017e+00 7.89475875e+00 2.60106734e-02\n",
      " 2.62853011e-01 1.10998211e+01], Loss = 0.4193\n",
      "Iteration 3640: Weights = [5.50000000e+01 3.75480238e+00 7.89453212e+00 2.60099267e-02\n",
      " 2.62845465e-01 1.11000606e+01], Loss = 0.4193\n",
      "Iteration 3641: Weights = [5.50000000e+01 3.75469459e+00 7.89430549e+00 2.60091801e-02\n",
      " 2.62837920e-01 1.11003000e+01], Loss = 0.4193\n",
      "Iteration 3642: Weights = [5.50000000e+01 3.75458681e+00 7.89407888e+00 2.60084335e-02\n",
      " 2.62830375e-01 1.11005394e+01], Loss = 0.4192\n",
      "Iteration 3643: Weights = [5.50000000e+01 3.75447903e+00 7.89385227e+00 2.60076869e-02\n",
      " 2.62822830e-01 1.11007788e+01], Loss = 0.4192\n",
      "Iteration 3644: Weights = [5.50000000e+01 3.75437125e+00 7.89362566e+00 2.60069403e-02\n",
      " 2.62815285e-01 1.11010182e+01], Loss = 0.4192\n",
      "Iteration 3645: Weights = [5.50000000e+01 3.75426348e+00 7.89339907e+00 2.60061937e-02\n",
      " 2.62807741e-01 1.11012576e+01], Loss = 0.4192\n",
      "Iteration 3646: Weights = [5.50000000e+01 3.75415570e+00 7.89317248e+00 2.60054472e-02\n",
      " 2.62800196e-01 1.11014970e+01], Loss = 0.4191\n",
      "Iteration 3647: Weights = [5.50000000e+01 3.75404794e+00 7.89294589e+00 2.60047007e-02\n",
      " 2.62792652e-01 1.11017364e+01], Loss = 0.4191\n",
      "Iteration 3648: Weights = [5.50000000e+01 3.75394017e+00 7.89271932e+00 2.60039542e-02\n",
      " 2.62785109e-01 1.11019758e+01], Loss = 0.4191\n",
      "Iteration 3649: Weights = [5.50000000e+01 3.75383241e+00 7.89249274e+00 2.60032077e-02\n",
      " 2.62777565e-01 1.11022151e+01], Loss = 0.4191\n",
      "Iteration 3650: Weights = [5.50000000e+01 3.75372465e+00 7.89226618e+00 2.60024612e-02\n",
      " 2.62770022e-01 1.11024545e+01], Loss = 0.4191\n",
      "Iteration 3651: Weights = [5.50000000e+01 3.75361690e+00 7.89203962e+00 2.60017148e-02\n",
      " 2.62762478e-01 1.11026939e+01], Loss = 0.4190\n",
      "Iteration 3652: Weights = [5.50000000e+01 3.75350914e+00 7.89181307e+00 2.60009684e-02\n",
      " 2.62754936e-01 1.11029332e+01], Loss = 0.4190\n",
      "Iteration 3653: Weights = [5.50000000e+01 3.75340139e+00 7.89158653e+00 2.60002220e-02\n",
      " 2.62747393e-01 1.11031725e+01], Loss = 0.4190\n",
      "Iteration 3654: Weights = [5.50000000e+01 3.75329365e+00 7.89135999e+00 2.59994756e-02\n",
      " 2.62739850e-01 1.11034119e+01], Loss = 0.4190\n",
      "Iteration 3655: Weights = [5.50000000e+01 3.75318590e+00 7.89113346e+00 2.59987293e-02\n",
      " 2.62732308e-01 1.11036512e+01], Loss = 0.4189\n",
      "Iteration 3656: Weights = [5.50000000e+01 3.75307816e+00 7.89090693e+00 2.59979829e-02\n",
      " 2.62724766e-01 1.11038905e+01], Loss = 0.4189\n",
      "Iteration 3657: Weights = [5.50000000e+01 3.75297043e+00 7.89068041e+00 2.59972366e-02\n",
      " 2.62717224e-01 1.11041298e+01], Loss = 0.4189\n",
      "Iteration 3658: Weights = [5.50000000e+01 3.75286269e+00 7.89045390e+00 2.59964903e-02\n",
      " 2.62709682e-01 1.11043691e+01], Loss = 0.4189\n",
      "Iteration 3659: Weights = [5.50000000e+01 3.75275496e+00 7.89022739e+00 2.59957441e-02\n",
      " 2.62702141e-01 1.11046084e+01], Loss = 0.4188\n",
      "Iteration 3660: Weights = [5.50000000e+01 3.75264723e+00 7.89000089e+00 2.59949978e-02\n",
      " 2.62694600e-01 1.11048477e+01], Loss = 0.4188\n",
      "Iteration 3661: Weights = [5.50000000e+01 3.75253951e+00 7.88977440e+00 2.59942516e-02\n",
      " 2.62687059e-01 1.11050870e+01], Loss = 0.4188\n",
      "Iteration 3662: Weights = [5.50000000e+01 3.75243179e+00 7.88954792e+00 2.59935054e-02\n",
      " 2.62679518e-01 1.11053263e+01], Loss = 0.4188\n",
      "Iteration 3663: Weights = [5.50000000e+01 3.75232407e+00 7.88932144e+00 2.59927592e-02\n",
      " 2.62671977e-01 1.11055656e+01], Loss = 0.4187\n",
      "Iteration 3664: Weights = [5.50000000e+01 3.75221635e+00 7.88909496e+00 2.59920131e-02\n",
      " 2.62664437e-01 1.11058048e+01], Loss = 0.4187\n",
      "Iteration 3665: Weights = [5.50000000e+01 3.75210864e+00 7.88886850e+00 2.59912669e-02\n",
      " 2.62656897e-01 1.11060441e+01], Loss = 0.4187\n",
      "Iteration 3666: Weights = [5.50000000e+01 3.75200093e+00 7.88864204e+00 2.59905208e-02\n",
      " 2.62649357e-01 1.11062834e+01], Loss = 0.4187\n",
      "Iteration 3667: Weights = [5.50000000e+01 3.75189323e+00 7.88841558e+00 2.59897747e-02\n",
      " 2.62641817e-01 1.11065226e+01], Loss = 0.4186\n",
      "Iteration 3668: Weights = [5.50000000e+01 3.75178552e+00 7.88818913e+00 2.59890287e-02\n",
      " 2.62634278e-01 1.11067618e+01], Loss = 0.4186\n",
      "Iteration 3669: Weights = [5.50000000e+01 3.75167782e+00 7.88796269e+00 2.59882826e-02\n",
      " 2.62626739e-01 1.11070011e+01], Loss = 0.4186\n",
      "Iteration 3670: Weights = [5.50000000e+01 3.75157013e+00 7.88773626e+00 2.59875366e-02\n",
      " 2.62619200e-01 1.11072403e+01], Loss = 0.4186\n",
      "Iteration 3671: Weights = [5.50000000e+01 3.75146243e+00 7.88750983e+00 2.59867906e-02\n",
      " 2.62611661e-01 1.11074795e+01], Loss = 0.4185\n",
      "Iteration 3672: Weights = [5.50000000e+01 3.75135474e+00 7.88728341e+00 2.59860446e-02\n",
      " 2.62604122e-01 1.11077187e+01], Loss = 0.4185\n",
      "Iteration 3673: Weights = [5.50000000e+01 3.75124706e+00 7.88705700e+00 2.59852986e-02\n",
      " 2.62596584e-01 1.11079579e+01], Loss = 0.4185\n",
      "Iteration 3674: Weights = [5.50000000e+01 3.75113937e+00 7.88683059e+00 2.59845527e-02\n",
      " 2.62589046e-01 1.11081971e+01], Loss = 0.4185\n",
      "Iteration 3675: Weights = [5.50000000e+01 3.75103169e+00 7.88660419e+00 2.59838068e-02\n",
      " 2.62581508e-01 1.11084363e+01], Loss = 0.4185\n",
      "Iteration 3676: Weights = [5.50000000e+01 3.75092401e+00 7.88637779e+00 2.59830609e-02\n",
      " 2.62573970e-01 1.11086755e+01], Loss = 0.4184\n",
      "Iteration 3677: Weights = [5.50000000e+01 3.75081634e+00 7.88615140e+00 2.59823150e-02\n",
      " 2.62566432e-01 1.11089147e+01], Loss = 0.4184\n",
      "Iteration 3678: Weights = [5.50000000e+01 3.75070866e+00 7.88592502e+00 2.59815691e-02\n",
      " 2.62558895e-01 1.11091538e+01], Loss = 0.4184\n",
      "Iteration 3679: Weights = [5.50000000e+01 3.75060100e+00 7.88569864e+00 2.59808233e-02\n",
      " 2.62551358e-01 1.11093930e+01], Loss = 0.4184\n",
      "Iteration 3680: Weights = [5.50000000e+01 3.75049333e+00 7.88547227e+00 2.59800775e-02\n",
      " 2.62543821e-01 1.11096322e+01], Loss = 0.4183\n",
      "Iteration 3681: Weights = [5.50000000e+01 3.75038567e+00 7.88524591e+00 2.59793317e-02\n",
      " 2.62536284e-01 1.11098713e+01], Loss = 0.4183\n",
      "Iteration 3682: Weights = [5.50000000e+01 3.75027801e+00 7.88501955e+00 2.59785859e-02\n",
      " 2.62528748e-01 1.11101104e+01], Loss = 0.4183\n",
      "Iteration 3683: Weights = [5.50000000e+01 3.75017035e+00 7.88479320e+00 2.59778402e-02\n",
      " 2.62521212e-01 1.11103496e+01], Loss = 0.4183\n",
      "Iteration 3684: Weights = [5.50000000e+01 3.75006270e+00 7.88456686e+00 2.59770945e-02\n",
      " 2.62513676e-01 1.11105887e+01], Loss = 0.4182\n",
      "Iteration 3685: Weights = [5.50000000e+01 3.74995505e+00 7.88434052e+00 2.59763487e-02\n",
      " 2.62506140e-01 1.11108278e+01], Loss = 0.4182\n",
      "Iteration 3686: Weights = [5.50000000e+01 3.74984740e+00 7.88411419e+00 2.59756031e-02\n",
      " 2.62498604e-01 1.11110669e+01], Loss = 0.4182\n",
      "Iteration 3687: Weights = [5.50000000e+01 3.74973975e+00 7.88388787e+00 2.59748574e-02\n",
      " 2.62491069e-01 1.11113061e+01], Loss = 0.4182\n",
      "Iteration 3688: Weights = [5.50000000e+01 3.74963211e+00 7.88366155e+00 2.59741118e-02\n",
      " 2.62483534e-01 1.11115452e+01], Loss = 0.4181\n",
      "Iteration 3689: Weights = [5.50000000e+01 3.74952448e+00 7.88343524e+00 2.59733661e-02\n",
      " 2.62475999e-01 1.11117842e+01], Loss = 0.4181\n",
      "Iteration 3690: Weights = [5.50000000e+01 3.74941684e+00 7.88320894e+00 2.59726205e-02\n",
      " 2.62468464e-01 1.11120233e+01], Loss = 0.4181\n",
      "Iteration 3691: Weights = [5.50000000e+01 3.74930921e+00 7.88298264e+00 2.59718750e-02\n",
      " 2.62460930e-01 1.11122624e+01], Loss = 0.4181\n",
      "Iteration 3692: Weights = [5.50000000e+01 3.74920158e+00 7.88275635e+00 2.59711294e-02\n",
      " 2.62453395e-01 1.11125015e+01], Loss = 0.4180\n",
      "Iteration 3693: Weights = [5.50000000e+01 3.74909395e+00 7.88253006e+00 2.59703839e-02\n",
      " 2.62445861e-01 1.11127406e+01], Loss = 0.4180\n",
      "Iteration 3694: Weights = [5.50000000e+01 3.74898633e+00 7.88230379e+00 2.59696384e-02\n",
      " 2.62438327e-01 1.11129796e+01], Loss = 0.4180\n",
      "Iteration 3695: Weights = [5.50000000e+01 3.74887871e+00 7.88207751e+00 2.59688929e-02\n",
      " 2.62430794e-01 1.11132187e+01], Loss = 0.4180\n",
      "Iteration 3696: Weights = [5.50000000e+01 3.74877109e+00 7.88185125e+00 2.59681474e-02\n",
      " 2.62423260e-01 1.11134577e+01], Loss = 0.4179\n",
      "Iteration 3697: Weights = [5.50000000e+01 3.74866348e+00 7.88162499e+00 2.59674019e-02\n",
      " 2.62415727e-01 1.11136967e+01], Loss = 0.4179\n",
      "Iteration 3698: Weights = [5.50000000e+01 3.74855587e+00 7.88139874e+00 2.59666565e-02\n",
      " 2.62408194e-01 1.11139358e+01], Loss = 0.4179\n",
      "Iteration 3699: Weights = [5.50000000e+01 3.74844826e+00 7.88117249e+00 2.59659111e-02\n",
      " 2.62400661e-01 1.11141748e+01], Loss = 0.4179\n",
      "Iteration 3700: Weights = [5.50000000e+01 3.74834066e+00 7.88094625e+00 2.59651657e-02\n",
      " 2.62393129e-01 1.11144138e+01], Loss = 0.4179\n",
      "Iteration 3701: Weights = [5.50000000e+01 3.74823306e+00 7.88072002e+00 2.59644204e-02\n",
      " 2.62385597e-01 1.11146528e+01], Loss = 0.4178\n",
      "Iteration 3702: Weights = [5.50000000e+01 3.74812546e+00 7.88049379e+00 2.59636750e-02\n",
      " 2.62378064e-01 1.11148918e+01], Loss = 0.4178\n",
      "Iteration 3703: Weights = [5.50000000e+01 3.74801787e+00 7.88026757e+00 2.59629297e-02\n",
      " 2.62370533e-01 1.11151308e+01], Loss = 0.4178\n",
      "Iteration 3704: Weights = [5.50000000e+01 3.74791027e+00 7.88004136e+00 2.59621844e-02\n",
      " 2.62363001e-01 1.11153698e+01], Loss = 0.4178\n",
      "Iteration 3705: Weights = [5.50000000e+01 3.74780269e+00 7.87981515e+00 2.59614391e-02\n",
      " 2.62355469e-01 1.11156088e+01], Loss = 0.4177\n",
      "Iteration 3706: Weights = [5.50000000e+01 3.74769510e+00 7.87958895e+00 2.59606939e-02\n",
      " 2.62347938e-01 1.11158478e+01], Loss = 0.4177\n",
      "Iteration 3707: Weights = [5.50000000e+01 3.74758752e+00 7.87936276e+00 2.59599486e-02\n",
      " 2.62340407e-01 1.11160868e+01], Loss = 0.4177\n",
      "Iteration 3708: Weights = [5.50000000e+01 3.74747994e+00 7.87913657e+00 2.59592034e-02\n",
      " 2.62332876e-01 1.11163257e+01], Loss = 0.4177\n",
      "Iteration 3709: Weights = [5.50000000e+01 3.74737236e+00 7.87891039e+00 2.59584582e-02\n",
      " 2.62325346e-01 1.11165647e+01], Loss = 0.4176\n",
      "Iteration 3710: Weights = [5.50000000e+01 3.74726479e+00 7.87868422e+00 2.59577130e-02\n",
      " 2.62317815e-01 1.11168036e+01], Loss = 0.4176\n",
      "Iteration 3711: Weights = [5.50000000e+01 3.74715722e+00 7.87845805e+00 2.59569679e-02\n",
      " 2.62310285e-01 1.11170426e+01], Loss = 0.4176\n",
      "Iteration 3712: Weights = [5.50000000e+01 3.74704965e+00 7.87823189e+00 2.59562228e-02\n",
      " 2.62302755e-01 1.11172815e+01], Loss = 0.4176\n",
      "Iteration 3713: Weights = [5.50000000e+01 3.74694209e+00 7.87800573e+00 2.59554777e-02\n",
      " 2.62295225e-01 1.11175204e+01], Loss = 0.4175\n",
      "Iteration 3714: Weights = [5.50000000e+01 3.74683453e+00 7.87777958e+00 2.59547326e-02\n",
      " 2.62287696e-01 1.11177594e+01], Loss = 0.4175\n",
      "Iteration 3715: Weights = [5.50000000e+01 3.74672697e+00 7.87755344e+00 2.59539875e-02\n",
      " 2.62280167e-01 1.11179983e+01], Loss = 0.4175\n",
      "Iteration 3716: Weights = [5.50000000e+01 3.74661941e+00 7.87732731e+00 2.59532425e-02\n",
      " 2.62272637e-01 1.11182372e+01], Loss = 0.4175\n",
      "Iteration 3717: Weights = [5.50000000e+01 3.74651186e+00 7.87710118e+00 2.59524974e-02\n",
      " 2.62265109e-01 1.11184761e+01], Loss = 0.4174\n",
      "Iteration 3718: Weights = [5.50000000e+01 3.74640431e+00 7.87687505e+00 2.59517524e-02\n",
      " 2.62257580e-01 1.11187150e+01], Loss = 0.4174\n",
      "Iteration 3719: Weights = [5.50000000e+01 3.74629677e+00 7.87664894e+00 2.59510075e-02\n",
      " 2.62250051e-01 1.11189539e+01], Loss = 0.4174\n",
      "Iteration 3720: Weights = [5.50000000e+01 3.74618923e+00 7.87642283e+00 2.59502625e-02\n",
      " 2.62242523e-01 1.11191927e+01], Loss = 0.4174\n",
      "Iteration 3721: Weights = [5.50000000e+01 3.74608169e+00 7.87619673e+00 2.59495176e-02\n",
      " 2.62234995e-01 1.11194316e+01], Loss = 0.4173\n",
      "Iteration 3722: Weights = [5.50000000e+01 3.74597415e+00 7.87597063e+00 2.59487726e-02\n",
      " 2.62227467e-01 1.11196705e+01], Loss = 0.4173\n",
      "Iteration 3723: Weights = [5.50000000e+01 3.74586662e+00 7.87574454e+00 2.59480278e-02\n",
      " 2.62219940e-01 1.11199094e+01], Loss = 0.4173\n",
      "Iteration 3724: Weights = [5.50000000e+01 3.74575909e+00 7.87551846e+00 2.59472829e-02\n",
      " 2.62212412e-01 1.11201482e+01], Loss = 0.4173\n",
      "Iteration 3725: Weights = [5.50000000e+01 3.74565156e+00 7.87529238e+00 2.59465380e-02\n",
      " 2.62204885e-01 1.11203871e+01], Loss = 0.4173\n",
      "Iteration 3726: Weights = [5.50000000e+01 3.74554404e+00 7.87506631e+00 2.59457932e-02\n",
      " 2.62197358e-01 1.11206259e+01], Loss = 0.4172\n",
      "Iteration 3727: Weights = [5.50000000e+01 3.74543652e+00 7.87484024e+00 2.59450484e-02\n",
      " 2.62189832e-01 1.11208647e+01], Loss = 0.4172\n",
      "Iteration 3728: Weights = [5.50000000e+01 3.74532900e+00 7.87461419e+00 2.59443036e-02\n",
      " 2.62182305e-01 1.11211036e+01], Loss = 0.4172\n",
      "Iteration 3729: Weights = [5.50000000e+01 3.74522148e+00 7.87438813e+00 2.59435588e-02\n",
      " 2.62174779e-01 1.11213424e+01], Loss = 0.4172\n",
      "Iteration 3730: Weights = [5.50000000e+01 3.74511397e+00 7.87416209e+00 2.59428141e-02\n",
      " 2.62167253e-01 1.11215812e+01], Loss = 0.4171\n",
      "Iteration 3731: Weights = [5.50000000e+01 3.74500646e+00 7.87393605e+00 2.59420694e-02\n",
      " 2.62159727e-01 1.11218200e+01], Loss = 0.4171\n",
      "Iteration 3732: Weights = [5.50000000e+01 3.74489896e+00 7.87371002e+00 2.59413247e-02\n",
      " 2.62152201e-01 1.11220588e+01], Loss = 0.4171\n",
      "Iteration 3733: Weights = [5.50000000e+01 3.74479146e+00 7.87348400e+00 2.59405800e-02\n",
      " 2.62144676e-01 1.11222976e+01], Loss = 0.4171\n",
      "Iteration 3734: Weights = [5.50000000e+01 3.74468396e+00 7.87325798e+00 2.59398353e-02\n",
      " 2.62137151e-01 1.11225364e+01], Loss = 0.4170\n",
      "Iteration 3735: Weights = [5.50000000e+01 3.74457646e+00 7.87303196e+00 2.59390907e-02\n",
      " 2.62129626e-01 1.11227751e+01], Loss = 0.4170\n",
      "Iteration 3736: Weights = [5.50000000e+01 3.74446897e+00 7.87280596e+00 2.59383461e-02\n",
      " 2.62122101e-01 1.11230139e+01], Loss = 0.4170\n",
      "Iteration 3737: Weights = [5.50000000e+01 3.74436148e+00 7.87257996e+00 2.59376015e-02\n",
      " 2.62114576e-01 1.11232527e+01], Loss = 0.4170\n",
      "Iteration 3738: Weights = [5.50000000e+01 3.74425399e+00 7.87235397e+00 2.59368569e-02\n",
      " 2.62107052e-01 1.11234914e+01], Loss = 0.4169\n",
      "Iteration 3739: Weights = [5.50000000e+01 3.74414651e+00 7.87212798e+00 2.59361124e-02\n",
      " 2.62099528e-01 1.11237302e+01], Loss = 0.4169\n",
      "Iteration 3740: Weights = [5.50000000e+01 3.74403903e+00 7.87190200e+00 2.59353678e-02\n",
      " 2.62092004e-01 1.11239689e+01], Loss = 0.4169\n",
      "Iteration 3741: Weights = [5.50000000e+01 3.74393155e+00 7.87167603e+00 2.59346233e-02\n",
      " 2.62084480e-01 1.11242077e+01], Loss = 0.4169\n",
      "Iteration 3742: Weights = [5.50000000e+01 3.74382408e+00 7.87145006e+00 2.59338788e-02\n",
      " 2.62076957e-01 1.11244464e+01], Loss = 0.4168\n",
      "Iteration 3743: Weights = [5.50000000e+01 3.74371660e+00 7.87122410e+00 2.59331344e-02\n",
      " 2.62069434e-01 1.11246851e+01], Loss = 0.4168\n",
      "Iteration 3744: Weights = [5.50000000e+01 3.74360914e+00 7.87099815e+00 2.59323899e-02\n",
      " 2.62061911e-01 1.11249238e+01], Loss = 0.4168\n",
      "Iteration 3745: Weights = [5.50000000e+01 3.74350167e+00 7.87077220e+00 2.59316455e-02\n",
      " 2.62054388e-01 1.11251625e+01], Loss = 0.4168\n",
      "Iteration 3746: Weights = [5.50000000e+01 3.74339421e+00 7.87054626e+00 2.59309011e-02\n",
      " 2.62046865e-01 1.11254013e+01], Loss = 0.4168\n",
      "Iteration 3747: Weights = [5.50000000e+01 3.74328675e+00 7.87032032e+00 2.59301567e-02\n",
      " 2.62039343e-01 1.11256399e+01], Loss = 0.4167\n",
      "Iteration 3748: Weights = [5.50000000e+01 3.74317929e+00 7.87009440e+00 2.59294124e-02\n",
      " 2.62031820e-01 1.11258786e+01], Loss = 0.4167\n",
      "Iteration 3749: Weights = [5.50000000e+01 3.74307184e+00 7.86986847e+00 2.59286680e-02\n",
      " 2.62024299e-01 1.11261173e+01], Loss = 0.4167\n",
      "Iteration 3750: Weights = [5.50000000e+01 3.74296439e+00 7.86964256e+00 2.59279237e-02\n",
      " 2.62016777e-01 1.11263560e+01], Loss = 0.4167\n",
      "Iteration 3751: Weights = [5.50000000e+01 3.74285694e+00 7.86941665e+00 2.59271794e-02\n",
      " 2.62009255e-01 1.11265947e+01], Loss = 0.4166\n",
      "Iteration 3752: Weights = [5.50000000e+01 3.74274950e+00 7.86919075e+00 2.59264351e-02\n",
      " 2.62001734e-01 1.11268333e+01], Loss = 0.4166\n",
      "Iteration 3753: Weights = [5.50000000e+01 3.74264206e+00 7.86896485e+00 2.59256909e-02\n",
      " 2.61994213e-01 1.11270720e+01], Loss = 0.4166\n",
      "Iteration 3754: Weights = [5.50000000e+01 3.74253462e+00 7.86873897e+00 2.59249467e-02\n",
      " 2.61986692e-01 1.11273106e+01], Loss = 0.4166\n",
      "Iteration 3755: Weights = [5.50000000e+01 3.74242719e+00 7.86851308e+00 2.59242024e-02\n",
      " 2.61979171e-01 1.11275493e+01], Loss = 0.4165\n",
      "Iteration 3756: Weights = [5.50000000e+01 3.74231976e+00 7.86828721e+00 2.59234583e-02\n",
      " 2.61971651e-01 1.11277879e+01], Loss = 0.4165\n",
      "Iteration 3757: Weights = [5.50000000e+01 3.74221233e+00 7.86806134e+00 2.59227141e-02\n",
      " 2.61964131e-01 1.11280265e+01], Loss = 0.4165\n",
      "Iteration 3758: Weights = [5.50000000e+01 3.74210490e+00 7.86783547e+00 2.59219699e-02\n",
      " 2.61956611e-01 1.11282652e+01], Loss = 0.4165\n",
      "Iteration 3759: Weights = [5.50000000e+01 3.74199748e+00 7.86760962e+00 2.59212258e-02\n",
      " 2.61949091e-01 1.11285038e+01], Loss = 0.4164\n",
      "Iteration 3760: Weights = [5.50000000e+01 3.74189006e+00 7.86738377e+00 2.59204817e-02\n",
      " 2.61941571e-01 1.11287424e+01], Loss = 0.4164\n",
      "Iteration 3761: Weights = [5.50000000e+01 3.74178265e+00 7.86715792e+00 2.59197376e-02\n",
      " 2.61934052e-01 1.11289810e+01], Loss = 0.4164\n",
      "Iteration 3762: Weights = [5.50000000e+01 3.74167523e+00 7.86693209e+00 2.59189936e-02\n",
      " 2.61926533e-01 1.11292196e+01], Loss = 0.4164\n",
      "Iteration 3763: Weights = [5.50000000e+01 3.74156782e+00 7.86670626e+00 2.59182495e-02\n",
      " 2.61919014e-01 1.11294582e+01], Loss = 0.4163\n",
      "Iteration 3764: Weights = [5.50000000e+01 3.74146042e+00 7.86648043e+00 2.59175055e-02\n",
      " 2.61911495e-01 1.11296967e+01], Loss = 0.4163\n",
      "Iteration 3765: Weights = [5.50000000e+01 3.74135301e+00 7.86625461e+00 2.59167615e-02\n",
      " 2.61903976e-01 1.11299353e+01], Loss = 0.4163\n",
      "Iteration 3766: Weights = [5.50000000e+01 3.74124561e+00 7.86602880e+00 2.59160176e-02\n",
      " 2.61896458e-01 1.11301739e+01], Loss = 0.4163\n",
      "Iteration 3767: Weights = [5.50000000e+01 3.74113822e+00 7.86580300e+00 2.59152736e-02\n",
      " 2.61888940e-01 1.11304124e+01], Loss = 0.4162\n",
      "Iteration 3768: Weights = [5.50000000e+01 3.74103082e+00 7.86557720e+00 2.59145297e-02\n",
      " 2.61881422e-01 1.11306510e+01], Loss = 0.4162\n",
      "Iteration 3769: Weights = [5.50000000e+01 3.74092343e+00 7.86535141e+00 2.59137858e-02\n",
      " 2.61873905e-01 1.11308895e+01], Loss = 0.4162\n",
      "Iteration 3770: Weights = [5.50000000e+01 3.74081604e+00 7.86512562e+00 2.59130419e-02\n",
      " 2.61866387e-01 1.11311281e+01], Loss = 0.4162\n",
      "Iteration 3771: Weights = [5.50000000e+01 3.74070866e+00 7.86489985e+00 2.59122980e-02\n",
      " 2.61858870e-01 1.11313666e+01], Loss = 0.4162\n",
      "Iteration 3772: Weights = [5.50000000e+01 3.74060128e+00 7.86467407e+00 2.59115542e-02\n",
      " 2.61851353e-01 1.11316051e+01], Loss = 0.4161\n",
      "Iteration 3773: Weights = [5.50000000e+01 3.74049390e+00 7.86444831e+00 2.59108103e-02\n",
      " 2.61843836e-01 1.11318436e+01], Loss = 0.4161\n",
      "Iteration 3774: Weights = [5.50000000e+01 3.74038652e+00 7.86422255e+00 2.59100665e-02\n",
      " 2.61836320e-01 1.11320822e+01], Loss = 0.4161\n",
      "Iteration 3775: Weights = [5.50000000e+01 3.74027915e+00 7.86399680e+00 2.59093227e-02\n",
      " 2.61828803e-01 1.11323207e+01], Loss = 0.4161\n",
      "Iteration 3776: Weights = [5.50000000e+01 3.74017178e+00 7.86377105e+00 2.59085790e-02\n",
      " 2.61821287e-01 1.11325592e+01], Loss = 0.4160\n",
      "Iteration 3777: Weights = [5.50000000e+01 3.74006441e+00 7.86354531e+00 2.59078352e-02\n",
      " 2.61813771e-01 1.11327976e+01], Loss = 0.4160\n",
      "Iteration 3778: Weights = [5.50000000e+01 3.73995705e+00 7.86331958e+00 2.59070915e-02\n",
      " 2.61806255e-01 1.11330361e+01], Loss = 0.4160\n",
      "Iteration 3779: Weights = [5.50000000e+01 3.73984969e+00 7.86309385e+00 2.59063478e-02\n",
      " 2.61798740e-01 1.11332746e+01], Loss = 0.4160\n",
      "Iteration 3780: Weights = [5.50000000e+01 3.73974233e+00 7.86286813e+00 2.59056042e-02\n",
      " 2.61791225e-01 1.11335131e+01], Loss = 0.4159\n",
      "Iteration 3781: Weights = [5.50000000e+01 3.73963498e+00 7.86264241e+00 2.59048605e-02\n",
      " 2.61783710e-01 1.11337515e+01], Loss = 0.4159\n",
      "Iteration 3782: Weights = [5.50000000e+01 3.73952763e+00 7.86241671e+00 2.59041169e-02\n",
      " 2.61776195e-01 1.11339900e+01], Loss = 0.4159\n",
      "Iteration 3783: Weights = [5.50000000e+01 3.73942028e+00 7.86219101e+00 2.59033733e-02\n",
      " 2.61768680e-01 1.11342284e+01], Loss = 0.4159\n",
      "Iteration 3784: Weights = [5.50000000e+01 3.73931293e+00 7.86196531e+00 2.59026297e-02\n",
      " 2.61761166e-01 1.11344669e+01], Loss = 0.4158\n",
      "Iteration 3785: Weights = [5.50000000e+01 3.73920559e+00 7.86173962e+00 2.59018861e-02\n",
      " 2.61753651e-01 1.11347053e+01], Loss = 0.4158\n",
      "Iteration 3786: Weights = [5.50000000e+01 3.73909825e+00 7.86151394e+00 2.59011425e-02\n",
      " 2.61746138e-01 1.11349437e+01], Loss = 0.4158\n",
      "Iteration 3787: Weights = [5.50000000e+01 3.73899092e+00 7.86128827e+00 2.59003990e-02\n",
      " 2.61738624e-01 1.11351822e+01], Loss = 0.4158\n",
      "Iteration 3788: Weights = [5.50000000e+01 3.73888358e+00 7.86106260e+00 2.58996555e-02\n",
      " 2.61731110e-01 1.11354206e+01], Loss = 0.4157\n",
      "Iteration 3789: Weights = [5.50000000e+01 3.73877625e+00 7.86083694e+00 2.58989120e-02\n",
      " 2.61723597e-01 1.11356590e+01], Loss = 0.4157\n",
      "Iteration 3790: Weights = [5.50000000e+01 3.73866893e+00 7.86061128e+00 2.58981686e-02\n",
      " 2.61716084e-01 1.11358974e+01], Loss = 0.4157\n",
      "Iteration 3791: Weights = [5.50000000e+01 3.73856160e+00 7.86038563e+00 2.58974251e-02\n",
      " 2.61708571e-01 1.11361358e+01], Loss = 0.4157\n",
      "Iteration 3792: Weights = [5.50000000e+01 3.73845428e+00 7.86015999e+00 2.58966817e-02\n",
      " 2.61701058e-01 1.11363742e+01], Loss = 0.4157\n",
      "Iteration 3793: Weights = [5.50000000e+01 3.73834697e+00 7.85993435e+00 2.58959383e-02\n",
      " 2.61693546e-01 1.11366126e+01], Loss = 0.4156\n",
      "Iteration 3794: Weights = [5.50000000e+01 3.73823965e+00 7.85970872e+00 2.58951949e-02\n",
      " 2.61686033e-01 1.11368509e+01], Loss = 0.4156\n",
      "Iteration 3795: Weights = [5.50000000e+01 3.73813234e+00 7.85948310e+00 2.58944516e-02\n",
      " 2.61678521e-01 1.11370893e+01], Loss = 0.4156\n",
      "Iteration 3796: Weights = [5.50000000e+01 3.73802503e+00 7.85925748e+00 2.58937082e-02\n",
      " 2.61671010e-01 1.11373277e+01], Loss = 0.4156\n",
      "Iteration 3797: Weights = [5.50000000e+01 3.73791773e+00 7.85903187e+00 2.58929649e-02\n",
      " 2.61663498e-01 1.11375660e+01], Loss = 0.4155\n",
      "Iteration 3798: Weights = [5.50000000e+01 3.73781043e+00 7.85880627e+00 2.58922216e-02\n",
      " 2.61655987e-01 1.11378044e+01], Loss = 0.4155\n",
      "Iteration 3799: Weights = [5.50000000e+01 3.73770313e+00 7.85858067e+00 2.58914784e-02\n",
      " 2.61648475e-01 1.11380427e+01], Loss = 0.4155\n",
      "Iteration 3800: Weights = [5.50000000e+01 3.73759583e+00 7.85835508e+00 2.58907351e-02\n",
      " 2.61640964e-01 1.11382810e+01], Loss = 0.4155\n",
      "Iteration 3801: Weights = [5.50000000e+01 3.73748854e+00 7.85812950e+00 2.58899919e-02\n",
      " 2.61633454e-01 1.11385194e+01], Loss = 0.4154\n",
      "Iteration 3802: Weights = [5.50000000e+01 3.73738125e+00 7.85790392e+00 2.58892487e-02\n",
      " 2.61625943e-01 1.11387577e+01], Loss = 0.4154\n",
      "Iteration 3803: Weights = [5.50000000e+01 3.73727396e+00 7.85767835e+00 2.58885055e-02\n",
      " 2.61618433e-01 1.11389960e+01], Loss = 0.4154\n",
      "Iteration 3804: Weights = [5.50000000e+01 3.73716668e+00 7.85745278e+00 2.58877623e-02\n",
      " 2.61610923e-01 1.11392343e+01], Loss = 0.4154\n",
      "Iteration 3805: Weights = [5.50000000e+01 3.73705940e+00 7.85722722e+00 2.58870192e-02\n",
      " 2.61603413e-01 1.11394726e+01], Loss = 0.4153\n",
      "Iteration 3806: Weights = [5.50000000e+01 3.73695212e+00 7.85700167e+00 2.58862761e-02\n",
      " 2.61595903e-01 1.11397109e+01], Loss = 0.4153\n",
      "Iteration 3807: Weights = [5.50000000e+01 3.73684485e+00 7.85677613e+00 2.58855330e-02\n",
      " 2.61588394e-01 1.11399492e+01], Loss = 0.4153\n",
      "Iteration 3808: Weights = [5.50000000e+01 3.73673758e+00 7.85655059e+00 2.58847899e-02\n",
      " 2.61580884e-01 1.11401875e+01], Loss = 0.4153\n",
      "Iteration 3809: Weights = [5.50000000e+01 3.73663031e+00 7.85632505e+00 2.58840468e-02\n",
      " 2.61573375e-01 1.11404257e+01], Loss = 0.4152\n",
      "Iteration 3810: Weights = [5.50000000e+01 3.73652305e+00 7.85609953e+00 2.58833038e-02\n",
      " 2.61565867e-01 1.11406640e+01], Loss = 0.4152\n",
      "Iteration 3811: Weights = [5.50000000e+01 3.73641578e+00 7.85587401e+00 2.58825608e-02\n",
      " 2.61558358e-01 1.11409022e+01], Loss = 0.4152\n",
      "Iteration 3812: Weights = [5.50000000e+01 3.73630853e+00 7.85564850e+00 2.58818178e-02\n",
      " 2.61550850e-01 1.11411405e+01], Loss = 0.4152\n",
      "Iteration 3813: Weights = [5.50000000e+01 3.73620127e+00 7.85542299e+00 2.58810748e-02\n",
      " 2.61543342e-01 1.11413787e+01], Loss = 0.4152\n",
      "Iteration 3814: Weights = [5.50000000e+01 3.73609402e+00 7.85519749e+00 2.58803319e-02\n",
      " 2.61535834e-01 1.11416170e+01], Loss = 0.4151\n",
      "Iteration 3815: Weights = [5.50000000e+01 3.73598677e+00 7.85497200e+00 2.58795889e-02\n",
      " 2.61528326e-01 1.11418552e+01], Loss = 0.4151\n",
      "Iteration 3816: Weights = [5.50000000e+01 3.73587952e+00 7.85474651e+00 2.58788460e-02\n",
      " 2.61520818e-01 1.11420934e+01], Loss = 0.4151\n",
      "Iteration 3817: Weights = [5.50000000e+01 3.73577228e+00 7.85452103e+00 2.58781032e-02\n",
      " 2.61513311e-01 1.11423317e+01], Loss = 0.4151\n",
      "Iteration 3818: Weights = [5.50000000e+01 3.73566504e+00 7.85429555e+00 2.58773603e-02\n",
      " 2.61505804e-01 1.11425699e+01], Loss = 0.4150\n",
      "Iteration 3819: Weights = [5.50000000e+01 3.73555780e+00 7.85407009e+00 2.58766174e-02\n",
      " 2.61498297e-01 1.11428081e+01], Loss = 0.4150\n",
      "Iteration 3820: Weights = [5.50000000e+01 3.73545057e+00 7.85384462e+00 2.58758746e-02\n",
      " 2.61490790e-01 1.11430463e+01], Loss = 0.4150\n",
      "Iteration 3821: Weights = [5.50000000e+01 3.73534334e+00 7.85361917e+00 2.58751318e-02\n",
      " 2.61483284e-01 1.11432845e+01], Loss = 0.4150\n",
      "Iteration 3822: Weights = [5.50000000e+01 3.73523611e+00 7.85339372e+00 2.58743890e-02\n",
      " 2.61475778e-01 1.11435226e+01], Loss = 0.4149\n",
      "Iteration 3823: Weights = [5.50000000e+01 3.73512888e+00 7.85316828e+00 2.58736463e-02\n",
      " 2.61468272e-01 1.11437608e+01], Loss = 0.4149\n",
      "Iteration 3824: Weights = [5.50000000e+01 3.73502166e+00 7.85294284e+00 2.58729035e-02\n",
      " 2.61460766e-01 1.11439990e+01], Loss = 0.4149\n",
      "Iteration 3825: Weights = [5.50000000e+01 3.73491444e+00 7.85271741e+00 2.58721608e-02\n",
      " 2.61453260e-01 1.11442371e+01], Loss = 0.4149\n",
      "Iteration 3826: Weights = [5.50000000e+01 3.73480723e+00 7.85249199e+00 2.58714181e-02\n",
      " 2.61445755e-01 1.11444753e+01], Loss = 0.4148\n",
      "Iteration 3827: Weights = [5.50000000e+01 3.73470001e+00 7.85226658e+00 2.58706755e-02\n",
      " 2.61438250e-01 1.11447134e+01], Loss = 0.4148\n",
      "Iteration 3828: Weights = [5.50000000e+01 3.73459280e+00 7.85204117e+00 2.58699328e-02\n",
      " 2.61430745e-01 1.11449516e+01], Loss = 0.4148\n",
      "Iteration 3829: Weights = [5.50000000e+01 3.73448560e+00 7.85181576e+00 2.58691902e-02\n",
      " 2.61423240e-01 1.11451897e+01], Loss = 0.4148\n",
      "Iteration 3830: Weights = [5.50000000e+01 3.73437839e+00 7.85159037e+00 2.58684476e-02\n",
      " 2.61415736e-01 1.11454278e+01], Loss = 0.4147\n",
      "Iteration 3831: Weights = [5.50000000e+01 3.73427119e+00 7.85136498e+00 2.58677050e-02\n",
      " 2.61408232e-01 1.11456660e+01], Loss = 0.4147\n",
      "Iteration 3832: Weights = [5.50000000e+01 3.73416400e+00 7.85113959e+00 2.58669624e-02\n",
      " 2.61400727e-01 1.11459041e+01], Loss = 0.4147\n",
      "Iteration 3833: Weights = [5.50000000e+01 3.73405680e+00 7.85091421e+00 2.58662199e-02\n",
      " 2.61393224e-01 1.11461422e+01], Loss = 0.4147\n",
      "Iteration 3834: Weights = [5.50000000e+01 3.73394961e+00 7.85068884e+00 2.58654774e-02\n",
      " 2.61385720e-01 1.11463803e+01], Loss = 0.4146\n",
      "Iteration 3835: Weights = [5.50000000e+01 3.73384242e+00 7.85046348e+00 2.58647348e-02\n",
      " 2.61378217e-01 1.11466184e+01], Loss = 0.4146\n",
      "Iteration 3836: Weights = [5.50000000e+01 3.73373524e+00 7.85023812e+00 2.58639924e-02\n",
      " 2.61370713e-01 1.11468565e+01], Loss = 0.4146\n",
      "Iteration 3837: Weights = [5.50000000e+01 3.73362806e+00 7.85001277e+00 2.58632499e-02\n",
      " 2.61363210e-01 1.11470946e+01], Loss = 0.4146\n",
      "Iteration 3838: Weights = [5.50000000e+01 3.73352088e+00 7.84978743e+00 2.58625075e-02\n",
      " 2.61355708e-01 1.11473326e+01], Loss = 0.4146\n",
      "Iteration 3839: Weights = [5.50000000e+01 3.73341370e+00 7.84956209e+00 2.58617651e-02\n",
      " 2.61348205e-01 1.11475707e+01], Loss = 0.4145\n",
      "Iteration 3840: Weights = [5.50000000e+01 3.73330653e+00 7.84933676e+00 2.58610227e-02\n",
      " 2.61340703e-01 1.11478088e+01], Loss = 0.4145\n",
      "Iteration 3841: Weights = [5.50000000e+01 3.73319936e+00 7.84911143e+00 2.58602803e-02\n",
      " 2.61333201e-01 1.11480468e+01], Loss = 0.4145\n",
      "Iteration 3842: Weights = [5.50000000e+01 3.73309220e+00 7.84888611e+00 2.58595379e-02\n",
      " 2.61325699e-01 1.11482849e+01], Loss = 0.4145\n",
      "Iteration 3843: Weights = [5.50000000e+01 3.73298503e+00 7.84866080e+00 2.58587956e-02\n",
      " 2.61318197e-01 1.11485229e+01], Loss = 0.4144\n",
      "Iteration 3844: Weights = [5.50000000e+01 3.73287787e+00 7.84843549e+00 2.58580533e-02\n",
      " 2.61310695e-01 1.11487609e+01], Loss = 0.4144\n",
      "Iteration 3845: Weights = [5.50000000e+01 3.73277071e+00 7.84821019e+00 2.58573110e-02\n",
      " 2.61303194e-01 1.11489989e+01], Loss = 0.4144\n",
      "Iteration 3846: Weights = [5.50000000e+01 3.73266356e+00 7.84798490e+00 2.58565687e-02\n",
      " 2.61295693e-01 1.11492370e+01], Loss = 0.4144\n",
      "Iteration 3847: Weights = [5.50000000e+01 3.73255641e+00 7.84775961e+00 2.58558265e-02\n",
      " 2.61288192e-01 1.11494750e+01], Loss = 0.4143\n",
      "Iteration 3848: Weights = [5.50000000e+01 3.73244926e+00 7.84753433e+00 2.58550843e-02\n",
      " 2.61280692e-01 1.11497130e+01], Loss = 0.4143\n",
      "Iteration 3849: Weights = [5.50000000e+01 3.73234212e+00 7.84730906e+00 2.58543421e-02\n",
      " 2.61273191e-01 1.11499510e+01], Loss = 0.4143\n",
      "Iteration 3850: Weights = [5.50000000e+01 3.73223497e+00 7.84708379e+00 2.58535999e-02\n",
      " 2.61265691e-01 1.11501890e+01], Loss = 0.4143\n",
      "Iteration 3851: Weights = [5.50000000e+01 3.73212784e+00 7.84685853e+00 2.58528577e-02\n",
      " 2.61258191e-01 1.11504270e+01], Loss = 0.4142\n",
      "Iteration 3852: Weights = [5.50000000e+01 3.73202070e+00 7.84663328e+00 2.58521156e-02\n",
      " 2.61250691e-01 1.11506649e+01], Loss = 0.4142\n",
      "Iteration 3853: Weights = [5.50000000e+01 3.73191357e+00 7.84640803e+00 2.58513735e-02\n",
      " 2.61243192e-01 1.11509029e+01], Loss = 0.4142\n",
      "Iteration 3854: Weights = [5.50000000e+01 3.73180644e+00 7.84618279e+00 2.58506314e-02\n",
      " 2.61235692e-01 1.11511409e+01], Loss = 0.4142\n",
      "Iteration 3855: Weights = [5.50000000e+01 3.73169931e+00 7.84595755e+00 2.58498893e-02\n",
      " 2.61228193e-01 1.11513788e+01], Loss = 0.4142\n",
      "Iteration 3856: Weights = [5.50000000e+01 3.73159219e+00 7.84573232e+00 2.58491472e-02\n",
      " 2.61220694e-01 1.11516168e+01], Loss = 0.4141\n",
      "Iteration 3857: Weights = [5.50000000e+01 3.73148507e+00 7.84550710e+00 2.58484052e-02\n",
      " 2.61213196e-01 1.11518547e+01], Loss = 0.4141\n",
      "Iteration 3858: Weights = [5.50000000e+01 3.73137795e+00 7.84528189e+00 2.58476632e-02\n",
      " 2.61205697e-01 1.11520927e+01], Loss = 0.4141\n",
      "Iteration 3859: Weights = [5.50000000e+01 3.73127084e+00 7.84505668e+00 2.58469212e-02\n",
      " 2.61198199e-01 1.11523306e+01], Loss = 0.4141\n",
      "Iteration 3860: Weights = [5.50000000e+01 3.73116373e+00 7.84483147e+00 2.58461792e-02\n",
      " 2.61190701e-01 1.11525685e+01], Loss = 0.4140\n",
      "Iteration 3861: Weights = [5.50000000e+01 3.73105662e+00 7.84460628e+00 2.58454373e-02\n",
      " 2.61183203e-01 1.11528064e+01], Loss = 0.4140\n",
      "Iteration 3862: Weights = [5.50000000e+01 3.73094951e+00 7.84438109e+00 2.58446953e-02\n",
      " 2.61175706e-01 1.11530443e+01], Loss = 0.4140\n",
      "Iteration 3863: Weights = [5.50000000e+01 3.73084241e+00 7.84415591e+00 2.58439534e-02\n",
      " 2.61168208e-01 1.11532822e+01], Loss = 0.4140\n",
      "Iteration 3864: Weights = [5.50000000e+01 3.73073531e+00 7.84393073e+00 2.58432115e-02\n",
      " 2.61160711e-01 1.11535201e+01], Loss = 0.4139\n",
      "Iteration 3865: Weights = [5.50000000e+01 3.73062822e+00 7.84370556e+00 2.58424697e-02\n",
      " 2.61153214e-01 1.11537580e+01], Loss = 0.4139\n",
      "Iteration 3866: Weights = [5.50000000e+01 3.73052112e+00 7.84348039e+00 2.58417278e-02\n",
      " 2.61145717e-01 1.11539959e+01], Loss = 0.4139\n",
      "Iteration 3867: Weights = [5.50000000e+01 3.73041404e+00 7.84325524e+00 2.58409860e-02\n",
      " 2.61138221e-01 1.11542338e+01], Loss = 0.4139\n",
      "Iteration 3868: Weights = [5.50000000e+01 3.73030695e+00 7.84303009e+00 2.58402442e-02\n",
      " 2.61130725e-01 1.11544716e+01], Loss = 0.4138\n",
      "Iteration 3869: Weights = [5.50000000e+01 3.73019987e+00 7.84280494e+00 2.58395024e-02\n",
      " 2.61123228e-01 1.11547095e+01], Loss = 0.4138\n",
      "Iteration 3870: Weights = [5.50000000e+01 3.73009279e+00 7.84257980e+00 2.58387607e-02\n",
      " 2.61115733e-01 1.11549474e+01], Loss = 0.4138\n",
      "Iteration 3871: Weights = [5.50000000e+01 3.72998571e+00 7.84235467e+00 2.58380190e-02\n",
      " 2.61108237e-01 1.11551852e+01], Loss = 0.4138\n",
      "Iteration 3872: Weights = [5.50000000e+01 3.72987863e+00 7.84212955e+00 2.58372772e-02\n",
      " 2.61100741e-01 1.11554231e+01], Loss = 0.4137\n",
      "Iteration 3873: Weights = [5.50000000e+01 3.72977156e+00 7.84190443e+00 2.58365355e-02\n",
      " 2.61093246e-01 1.11556609e+01], Loss = 0.4137\n",
      "Iteration 3874: Weights = [5.50000000e+01 3.72966450e+00 7.84167932e+00 2.58357939e-02\n",
      " 2.61085751e-01 1.11558987e+01], Loss = 0.4137\n",
      "Iteration 3875: Weights = [5.50000000e+01 3.72955743e+00 7.84145421e+00 2.58350522e-02\n",
      " 2.61078256e-01 1.11561365e+01], Loss = 0.4137\n",
      "Iteration 3876: Weights = [5.50000000e+01 3.72945037e+00 7.84122911e+00 2.58343106e-02\n",
      " 2.61070762e-01 1.11563743e+01], Loss = 0.4137\n",
      "Iteration 3877: Weights = [5.50000000e+01 3.72934331e+00 7.84100402e+00 2.58335690e-02\n",
      " 2.61063267e-01 1.11566122e+01], Loss = 0.4136\n",
      "Iteration 3878: Weights = [5.50000000e+01 3.72923625e+00 7.84077893e+00 2.58328274e-02\n",
      " 2.61055773e-01 1.11568500e+01], Loss = 0.4136\n",
      "Iteration 3879: Weights = [5.50000000e+01 3.72912920e+00 7.84055385e+00 2.58320858e-02\n",
      " 2.61048279e-01 1.11570877e+01], Loss = 0.4136\n",
      "Iteration 3880: Weights = [5.50000000e+01 3.72902215e+00 7.84032878e+00 2.58313443e-02\n",
      " 2.61040786e-01 1.11573255e+01], Loss = 0.4136\n",
      "Iteration 3881: Weights = [5.50000000e+01 3.72891511e+00 7.84010371e+00 2.58306028e-02\n",
      " 2.61033292e-01 1.11575633e+01], Loss = 0.4135\n",
      "Iteration 3882: Weights = [5.50000000e+01 3.72880806e+00 7.83987865e+00 2.58298613e-02\n",
      " 2.61025799e-01 1.11578011e+01], Loss = 0.4135\n",
      "Iteration 3883: Weights = [5.50000000e+01 3.72870102e+00 7.83965360e+00 2.58291198e-02\n",
      " 2.61018306e-01 1.11580389e+01], Loss = 0.4135\n",
      "Iteration 3884: Weights = [5.50000000e+01 3.72859398e+00 7.83942855e+00 2.58283783e-02\n",
      " 2.61010813e-01 1.11582766e+01], Loss = 0.4135\n",
      "Iteration 3885: Weights = [5.50000000e+01 3.72848695e+00 7.83920351e+00 2.58276369e-02\n",
      " 2.61003320e-01 1.11585144e+01], Loss = 0.4134\n",
      "Iteration 3886: Weights = [5.50000000e+01 3.72837992e+00 7.83897847e+00 2.58268955e-02\n",
      " 2.60995828e-01 1.11587521e+01], Loss = 0.4134\n",
      "Iteration 3887: Weights = [5.50000000e+01 3.72827289e+00 7.83875345e+00 2.58261541e-02\n",
      " 2.60988335e-01 1.11589898e+01], Loss = 0.4134\n",
      "Iteration 3888: Weights = [5.50000000e+01 3.72816587e+00 7.83852843e+00 2.58254127e-02\n",
      " 2.60980843e-01 1.11592276e+01], Loss = 0.4134\n",
      "Iteration 3889: Weights = [5.50000000e+01 3.72805884e+00 7.83830341e+00 2.58246714e-02\n",
      " 2.60973352e-01 1.11594653e+01], Loss = 0.4133\n",
      "Iteration 3890: Weights = [5.50000000e+01 3.72795183e+00 7.83807840e+00 2.58239300e-02\n",
      " 2.60965860e-01 1.11597030e+01], Loss = 0.4133\n",
      "Iteration 3891: Weights = [5.50000000e+01 3.72784481e+00 7.83785340e+00 2.58231887e-02\n",
      " 2.60958369e-01 1.11599407e+01], Loss = 0.4133\n",
      "Iteration 3892: Weights = [5.50000000e+01 3.72773780e+00 7.83762840e+00 2.58224474e-02\n",
      " 2.60950877e-01 1.11601784e+01], Loss = 0.4133\n",
      "Iteration 3893: Weights = [5.50000000e+01 3.72763079e+00 7.83740341e+00 2.58217062e-02\n",
      " 2.60943387e-01 1.11604161e+01], Loss = 0.4132\n",
      "Iteration 3894: Weights = [5.50000000e+01 3.72752378e+00 7.83717843e+00 2.58209649e-02\n",
      " 2.60935896e-01 1.11606538e+01], Loss = 0.4132\n",
      "Iteration 3895: Weights = [5.50000000e+01 3.72741678e+00 7.83695345e+00 2.58202237e-02\n",
      " 2.60928405e-01 1.11608915e+01], Loss = 0.4132\n",
      "Iteration 3896: Weights = [5.50000000e+01 3.72730978e+00 7.83672848e+00 2.58194825e-02\n",
      " 2.60920915e-01 1.11611292e+01], Loss = 0.4132\n",
      "Iteration 3897: Weights = [5.50000000e+01 3.72720278e+00 7.83650352e+00 2.58187413e-02\n",
      " 2.60913425e-01 1.11613669e+01], Loss = 0.4132\n",
      "Iteration 3898: Weights = [5.50000000e+01 3.72709579e+00 7.83627856e+00 2.58180001e-02\n",
      " 2.60905935e-01 1.11616045e+01], Loss = 0.4131\n",
      "Iteration 3899: Weights = [5.50000000e+01 3.72698879e+00 7.83605361e+00 2.58172590e-02\n",
      " 2.60898445e-01 1.11618422e+01], Loss = 0.4131\n",
      "Iteration 3900: Weights = [5.50000000e+01 3.72688181e+00 7.83582867e+00 2.58165179e-02\n",
      " 2.60890956e-01 1.11620798e+01], Loss = 0.4131\n",
      "Iteration 3901: Weights = [5.50000000e+01 3.72677482e+00 7.83560373e+00 2.58157768e-02\n",
      " 2.60883467e-01 1.11623175e+01], Loss = 0.4131\n",
      "Iteration 3902: Weights = [5.50000000e+01 3.72666784e+00 7.83537880e+00 2.58150357e-02\n",
      " 2.60875978e-01 1.11625551e+01], Loss = 0.4130\n",
      "Iteration 3903: Weights = [5.50000000e+01 3.72656086e+00 7.83515387e+00 2.58142947e-02\n",
      " 2.60868489e-01 1.11627927e+01], Loss = 0.4130\n",
      "Iteration 3904: Weights = [5.50000000e+01 3.72645388e+00 7.83492896e+00 2.58135536e-02\n",
      " 2.60861000e-01 1.11630304e+01], Loss = 0.4130\n",
      "Iteration 3905: Weights = [5.50000000e+01 3.72634691e+00 7.83470404e+00 2.58128126e-02\n",
      " 2.60853512e-01 1.11632680e+01], Loss = 0.4130\n",
      "Iteration 3906: Weights = [5.50000000e+01 3.72623994e+00 7.83447914e+00 2.58120716e-02\n",
      " 2.60846024e-01 1.11635056e+01], Loss = 0.4129\n",
      "Iteration 3907: Weights = [5.50000000e+01 3.72613298e+00 7.83425424e+00 2.58113307e-02\n",
      " 2.60838536e-01 1.11637432e+01], Loss = 0.4129\n",
      "Iteration 3908: Weights = [5.50000000e+01 3.72602601e+00 7.83402935e+00 2.58105897e-02\n",
      " 2.60831048e-01 1.11639808e+01], Loss = 0.4129\n",
      "Iteration 3909: Weights = [5.50000000e+01 3.72591905e+00 7.83380446e+00 2.58098488e-02\n",
      " 2.60823561e-01 1.11642184e+01], Loss = 0.4129\n",
      "Iteration 3910: Weights = [5.50000000e+01 3.72581209e+00 7.83357958e+00 2.58091079e-02\n",
      " 2.60816074e-01 1.11644560e+01], Loss = 0.4128\n",
      "Iteration 3911: Weights = [5.50000000e+01 3.72570514e+00 7.83335471e+00 2.58083670e-02\n",
      " 2.60808586e-01 1.11646935e+01], Loss = 0.4128\n",
      "Iteration 3912: Weights = [5.50000000e+01 3.72559819e+00 7.83312984e+00 2.58076261e-02\n",
      " 2.60801100e-01 1.11649311e+01], Loss = 0.4128\n",
      "Iteration 3913: Weights = [5.50000000e+01 3.72549124e+00 7.83290498e+00 2.58068853e-02\n",
      " 2.60793613e-01 1.11651687e+01], Loss = 0.4128\n",
      "Iteration 3914: Weights = [5.50000000e+01 3.72538430e+00 7.83268013e+00 2.58061445e-02\n",
      " 2.60786127e-01 1.11654062e+01], Loss = 0.4127\n",
      "Iteration 3915: Weights = [5.50000000e+01 3.72527735e+00 7.83245528e+00 2.58054037e-02\n",
      " 2.60778640e-01 1.11656438e+01], Loss = 0.4127\n",
      "Iteration 3916: Weights = [5.50000000e+01 3.72517041e+00 7.83223044e+00 2.58046629e-02\n",
      " 2.60771154e-01 1.11658813e+01], Loss = 0.4127\n",
      "Iteration 3917: Weights = [5.50000000e+01 3.72506348e+00 7.83200561e+00 2.58039221e-02\n",
      " 2.60763669e-01 1.11661188e+01], Loss = 0.4127\n",
      "Iteration 3918: Weights = [5.50000000e+01 3.72495655e+00 7.83178078e+00 2.58031814e-02\n",
      " 2.60756183e-01 1.11663564e+01], Loss = 0.4127\n",
      "Iteration 3919: Weights = [5.50000000e+01 3.72484962e+00 7.83155596e+00 2.58024407e-02\n",
      " 2.60748698e-01 1.11665939e+01], Loss = 0.4126\n",
      "Iteration 3920: Weights = [5.50000000e+01 3.72474269e+00 7.83133114e+00 2.58017000e-02\n",
      " 2.60741213e-01 1.11668314e+01], Loss = 0.4126\n",
      "Iteration 3921: Weights = [5.50000000e+01 3.72463577e+00 7.83110633e+00 2.58009593e-02\n",
      " 2.60733728e-01 1.11670689e+01], Loss = 0.4126\n",
      "Iteration 3922: Weights = [5.50000000e+01 3.72452885e+00 7.83088153e+00 2.58002187e-02\n",
      " 2.60726243e-01 1.11673064e+01], Loss = 0.4126\n",
      "Iteration 3923: Weights = [5.50000000e+01 3.72442193e+00 7.83065673e+00 2.57994780e-02\n",
      " 2.60718758e-01 1.11675439e+01], Loss = 0.4125\n",
      "Iteration 3924: Weights = [5.50000000e+01 3.72431501e+00 7.83043195e+00 2.57987374e-02\n",
      " 2.60711274e-01 1.11677814e+01], Loss = 0.4125\n",
      "Iteration 3925: Weights = [5.50000000e+01 3.72420810e+00 7.83020716e+00 2.57979968e-02\n",
      " 2.60703790e-01 1.11680189e+01], Loss = 0.4125\n",
      "Iteration 3926: Weights = [5.50000000e+01 3.72410119e+00 7.82998239e+00 2.57972563e-02\n",
      " 2.60696306e-01 1.11682563e+01], Loss = 0.4125\n",
      "Iteration 3927: Weights = [5.50000000e+01 3.72399429e+00 7.82975762e+00 2.57965157e-02\n",
      " 2.60688823e-01 1.11684938e+01], Loss = 0.4124\n",
      "Iteration 3928: Weights = [5.50000000e+01 3.72388739e+00 7.82953285e+00 2.57957752e-02\n",
      " 2.60681339e-01 1.11687313e+01], Loss = 0.4124\n",
      "Iteration 3929: Weights = [5.50000000e+01 3.72378049e+00 7.82930810e+00 2.57950347e-02\n",
      " 2.60673856e-01 1.11689687e+01], Loss = 0.4124\n",
      "Iteration 3930: Weights = [5.50000000e+01 3.72367359e+00 7.82908335e+00 2.57942942e-02\n",
      " 2.60666373e-01 1.11692062e+01], Loss = 0.4124\n",
      "Iteration 3931: Weights = [5.50000000e+01 3.72356670e+00 7.82885860e+00 2.57935538e-02\n",
      " 2.60658890e-01 1.11694436e+01], Loss = 0.4123\n",
      "Iteration 3932: Weights = [5.50000000e+01 3.72345981e+00 7.82863386e+00 2.57928133e-02\n",
      " 2.60651408e-01 1.11696810e+01], Loss = 0.4123\n",
      "Iteration 3933: Weights = [5.50000000e+01 3.72335292e+00 7.82840913e+00 2.57920729e-02\n",
      " 2.60643925e-01 1.11699185e+01], Loss = 0.4123\n",
      "Iteration 3934: Weights = [5.50000000e+01 3.72324604e+00 7.82818441e+00 2.57913325e-02\n",
      " 2.60636443e-01 1.11701559e+01], Loss = 0.4123\n",
      "Iteration 3935: Weights = [5.50000000e+01 3.72313916e+00 7.82795969e+00 2.57905921e-02\n",
      " 2.60628961e-01 1.11703933e+01], Loss = 0.4123\n",
      "Iteration 3936: Weights = [5.50000000e+01 3.72303228e+00 7.82773498e+00 2.57898518e-02\n",
      " 2.60621480e-01 1.11706307e+01], Loss = 0.4122\n",
      "Iteration 3937: Weights = [5.50000000e+01 3.72292541e+00 7.82751027e+00 2.57891115e-02\n",
      " 2.60613998e-01 1.11708681e+01], Loss = 0.4122\n",
      "Iteration 3938: Weights = [5.50000000e+01 3.72281853e+00 7.82728557e+00 2.57883712e-02\n",
      " 2.60606517e-01 1.11711055e+01], Loss = 0.4122\n",
      "Iteration 3939: Weights = [5.50000000e+01 3.72271167e+00 7.82706088e+00 2.57876309e-02\n",
      " 2.60599036e-01 1.11713429e+01], Loss = 0.4122\n",
      "Iteration 3940: Weights = [5.50000000e+01 3.72260480e+00 7.82683619e+00 2.57868906e-02\n",
      " 2.60591555e-01 1.11715802e+01], Loss = 0.4121\n",
      "Iteration 3941: Weights = [5.50000000e+01 3.72249794e+00 7.82661152e+00 2.57861503e-02\n",
      " 2.60584074e-01 1.11718176e+01], Loss = 0.4121\n",
      "Iteration 3942: Weights = [5.50000000e+01 3.72239108e+00 7.82638684e+00 2.57854101e-02\n",
      " 2.60576594e-01 1.11720550e+01], Loss = 0.4121\n",
      "Iteration 3943: Weights = [5.50000000e+01 3.72228422e+00 7.82616218e+00 2.57846699e-02\n",
      " 2.60569114e-01 1.11722923e+01], Loss = 0.4121\n",
      "Iteration 3944: Weights = [5.50000000e+01 3.72217737e+00 7.82593752e+00 2.57839297e-02\n",
      " 2.60561634e-01 1.11725297e+01], Loss = 0.4120\n",
      "Iteration 3945: Weights = [5.50000000e+01 3.72207052e+00 7.82571286e+00 2.57831896e-02\n",
      " 2.60554154e-01 1.11727670e+01], Loss = 0.4120\n",
      "Iteration 3946: Weights = [5.50000000e+01 3.72196367e+00 7.82548821e+00 2.57824494e-02\n",
      " 2.60546674e-01 1.11730044e+01], Loss = 0.4120\n",
      "Iteration 3947: Weights = [5.50000000e+01 3.72185683e+00 7.82526357e+00 2.57817093e-02\n",
      " 2.60539195e-01 1.11732417e+01], Loss = 0.4120\n",
      "Iteration 3948: Weights = [5.50000000e+01 3.72174999e+00 7.82503894e+00 2.57809692e-02\n",
      " 2.60531716e-01 1.11734790e+01], Loss = 0.4119\n",
      "Iteration 3949: Weights = [5.50000000e+01 3.72164315e+00 7.82481431e+00 2.57802291e-02\n",
      " 2.60524237e-01 1.11737163e+01], Loss = 0.4119\n",
      "Iteration 3950: Weights = [5.50000000e+01 3.72153632e+00 7.82458969e+00 2.57794891e-02\n",
      " 2.60516758e-01 1.11739536e+01], Loss = 0.4119\n",
      "Iteration 3951: Weights = [5.50000000e+01 3.72142948e+00 7.82436507e+00 2.57787491e-02\n",
      " 2.60509280e-01 1.11741909e+01], Loss = 0.4119\n",
      "Iteration 3952: Weights = [5.50000000e+01 3.72132266e+00 7.82414047e+00 2.57780090e-02\n",
      " 2.60501802e-01 1.11744282e+01], Loss = 0.4119\n",
      "Iteration 3953: Weights = [5.50000000e+01 3.72121583e+00 7.82391586e+00 2.57772690e-02\n",
      " 2.60494324e-01 1.11746655e+01], Loss = 0.4118\n",
      "Iteration 3954: Weights = [5.50000000e+01 3.72110901e+00 7.82369127e+00 2.57765291e-02\n",
      " 2.60486846e-01 1.11749028e+01], Loss = 0.4118\n",
      "Iteration 3955: Weights = [5.50000000e+01 3.72100219e+00 7.82346668e+00 2.57757891e-02\n",
      " 2.60479368e-01 1.11751401e+01], Loss = 0.4118\n",
      "Iteration 3956: Weights = [5.50000000e+01 3.72089537e+00 7.82324210e+00 2.57750492e-02\n",
      " 2.60471891e-01 1.11753773e+01], Loss = 0.4118\n",
      "Iteration 3957: Weights = [5.50000000e+01 3.72078856e+00 7.82301752e+00 2.57743093e-02\n",
      " 2.60464414e-01 1.11756146e+01], Loss = 0.4117\n",
      "Iteration 3958: Weights = [5.50000000e+01 3.72068175e+00 7.82279295e+00 2.57735694e-02\n",
      " 2.60456937e-01 1.11758519e+01], Loss = 0.4117\n",
      "Iteration 3959: Weights = [5.50000000e+01 3.72057494e+00 7.82256839e+00 2.57728295e-02\n",
      " 2.60449460e-01 1.11760891e+01], Loss = 0.4117\n",
      "Iteration 3960: Weights = [5.50000000e+01 3.72046814e+00 7.82234383e+00 2.57720897e-02\n",
      " 2.60441983e-01 1.11763263e+01], Loss = 0.4117\n",
      "Iteration 3961: Weights = [5.50000000e+01 3.72036134e+00 7.82211928e+00 2.57713499e-02\n",
      " 2.60434507e-01 1.11765636e+01], Loss = 0.4116\n",
      "Iteration 3962: Weights = [5.50000000e+01 3.72025454e+00 7.82189473e+00 2.57706101e-02\n",
      " 2.60427031e-01 1.11768008e+01], Loss = 0.4116\n",
      "Iteration 3963: Weights = [5.50000000e+01 3.72014774e+00 7.82167020e+00 2.57698703e-02\n",
      " 2.60419555e-01 1.11770380e+01], Loss = 0.4116\n",
      "Iteration 3964: Weights = [5.50000000e+01 3.72004095e+00 7.82144566e+00 2.57691305e-02\n",
      " 2.60412079e-01 1.11772752e+01], Loss = 0.4116\n",
      "Iteration 3965: Weights = [5.50000000e+01 3.71993416e+00 7.82122114e+00 2.57683908e-02\n",
      " 2.60404604e-01 1.11775125e+01], Loss = 0.4115\n",
      "Iteration 3966: Weights = [5.50000000e+01 3.71982738e+00 7.82099662e+00 2.57676511e-02\n",
      " 2.60397129e-01 1.11777497e+01], Loss = 0.4115\n",
      "Iteration 3967: Weights = [5.50000000e+01 3.71972060e+00 7.82077211e+00 2.57669114e-02\n",
      " 2.60389654e-01 1.11779868e+01], Loss = 0.4115\n",
      "Iteration 3968: Weights = [5.50000000e+01 3.71961382e+00 7.82054760e+00 2.57661717e-02\n",
      " 2.60382179e-01 1.11782240e+01], Loss = 0.4115\n",
      "Iteration 3969: Weights = [5.50000000e+01 3.71950704e+00 7.82032310e+00 2.57654321e-02\n",
      " 2.60374704e-01 1.11784612e+01], Loss = 0.4114\n",
      "Iteration 3970: Weights = [5.50000000e+01 3.71940027e+00 7.82009861e+00 2.57646924e-02\n",
      " 2.60367230e-01 1.11786984e+01], Loss = 0.4114\n",
      "Iteration 3971: Weights = [5.50000000e+01 3.71929350e+00 7.81987413e+00 2.57639528e-02\n",
      " 2.60359756e-01 1.11789355e+01], Loss = 0.4114\n",
      "Iteration 3972: Weights = [5.50000000e+01 3.71918673e+00 7.81964965e+00 2.57632132e-02\n",
      " 2.60352282e-01 1.11791727e+01], Loss = 0.4114\n",
      "Iteration 3973: Weights = [5.50000000e+01 3.71907997e+00 7.81942517e+00 2.57624737e-02\n",
      " 2.60344808e-01 1.11794099e+01], Loss = 0.4114\n",
      "Iteration 3974: Weights = [5.50000000e+01 3.71897320e+00 7.81920071e+00 2.57617341e-02\n",
      " 2.60337334e-01 1.11796470e+01], Loss = 0.4113\n",
      "Iteration 3975: Weights = [5.50000000e+01 3.71886645e+00 7.81897625e+00 2.57609946e-02\n",
      " 2.60329861e-01 1.11798841e+01], Loss = 0.4113\n",
      "Iteration 3976: Weights = [5.50000000e+01 3.71875969e+00 7.81875179e+00 2.57602551e-02\n",
      " 2.60322388e-01 1.11801213e+01], Loss = 0.4113\n",
      "Iteration 3977: Weights = [5.50000000e+01 3.71865294e+00 7.81852734e+00 2.57595156e-02\n",
      " 2.60314915e-01 1.11803584e+01], Loss = 0.4113\n",
      "Iteration 3978: Weights = [5.50000000e+01 3.71854619e+00 7.81830290e+00 2.57587762e-02\n",
      " 2.60307442e-01 1.11805955e+01], Loss = 0.4112\n",
      "Iteration 3979: Weights = [5.50000000e+01 3.71843944e+00 7.81807847e+00 2.57580367e-02\n",
      " 2.60299970e-01 1.11808326e+01], Loss = 0.4112\n",
      "Iteration 3980: Weights = [5.50000000e+01 3.71833270e+00 7.81785404e+00 2.57572973e-02\n",
      " 2.60292498e-01 1.11810697e+01], Loss = 0.4112\n",
      "Iteration 3981: Weights = [5.50000000e+01 3.71822596e+00 7.81762962e+00 2.57565579e-02\n",
      " 2.60285026e-01 1.11813068e+01], Loss = 0.4112\n",
      "Iteration 3982: Weights = [5.50000000e+01 3.71811923e+00 7.81740520e+00 2.57558185e-02\n",
      " 2.60277554e-01 1.11815439e+01], Loss = 0.4111\n",
      "Iteration 3983: Weights = [5.50000000e+01 3.71801249e+00 7.81718079e+00 2.57550792e-02\n",
      " 2.60270082e-01 1.11817810e+01], Loss = 0.4111\n",
      "Iteration 3984: Weights = [5.50000000e+01 3.71790576e+00 7.81695639e+00 2.57543398e-02\n",
      " 2.60262611e-01 1.11820181e+01], Loss = 0.4111\n",
      "Iteration 3985: Weights = [5.50000000e+01 3.71779903e+00 7.81673200e+00 2.57536005e-02\n",
      " 2.60255140e-01 1.11822552e+01], Loss = 0.4111\n",
      "Iteration 3986: Weights = [5.50000000e+01 3.71769231e+00 7.81650761e+00 2.57528612e-02\n",
      " 2.60247669e-01 1.11824922e+01], Loss = 0.4110\n",
      "Iteration 3987: Weights = [5.50000000e+01 3.71758559e+00 7.81628322e+00 2.57521220e-02\n",
      " 2.60240198e-01 1.11827293e+01], Loss = 0.4110\n",
      "Iteration 3988: Weights = [5.50000000e+01 3.71747887e+00 7.81605885e+00 2.57513827e-02\n",
      " 2.60232727e-01 1.11829663e+01], Loss = 0.4110\n",
      "Iteration 3989: Weights = [5.50000000e+01 3.71737216e+00 7.81583448e+00 2.57506435e-02\n",
      " 2.60225257e-01 1.11832034e+01], Loss = 0.4110\n",
      "Iteration 3990: Weights = [5.50000000e+01 3.71726544e+00 7.81561011e+00 2.57499043e-02\n",
      " 2.60217787e-01 1.11834404e+01], Loss = 0.4110\n",
      "Iteration 3991: Weights = [5.50000000e+01 3.71715874e+00 7.81538576e+00 2.57491651e-02\n",
      " 2.60210317e-01 1.11836774e+01], Loss = 0.4109\n",
      "Iteration 3992: Weights = [5.50000000e+01 3.71705203e+00 7.81516140e+00 2.57484259e-02\n",
      " 2.60202847e-01 1.11839145e+01], Loss = 0.4109\n",
      "Iteration 3993: Weights = [5.50000000e+01 3.71694533e+00 7.81493706e+00 2.57476868e-02\n",
      " 2.60195378e-01 1.11841515e+01], Loss = 0.4109\n",
      "Iteration 3994: Weights = [5.50000000e+01 3.71683863e+00 7.81471272e+00 2.57469477e-02\n",
      " 2.60187909e-01 1.11843885e+01], Loss = 0.4109\n",
      "Iteration 3995: Weights = [5.50000000e+01 3.71673193e+00 7.81448839e+00 2.57462086e-02\n",
      " 2.60180440e-01 1.11846255e+01], Loss = 0.4108\n",
      "Iteration 3996: Weights = [5.50000000e+01 3.71662524e+00 7.81426407e+00 2.57454695e-02\n",
      " 2.60172971e-01 1.11848625e+01], Loss = 0.4108\n",
      "Iteration 3997: Weights = [5.50000000e+01 3.71651855e+00 7.81403975e+00 2.57447304e-02\n",
      " 2.60165502e-01 1.11850995e+01], Loss = 0.4108\n",
      "Iteration 3998: Weights = [5.50000000e+01 3.71641186e+00 7.81381543e+00 2.57439914e-02\n",
      " 2.60158034e-01 1.11853365e+01], Loss = 0.4108\n",
      "Iteration 3999: Weights = [5.50000000e+01 3.71630517e+00 7.81359113e+00 2.57432524e-02\n",
      " 2.60150566e-01 1.11855734e+01], Loss = 0.4107\n",
      "Iteration 4000: Weights = [5.50000000e+01 3.71619849e+00 7.81336683e+00 2.57425134e-02\n",
      " 2.60143098e-01 1.11858104e+01], Loss = 0.4107\n",
      "Iteration 4001: Weights = [5.50000000e+01 3.71609181e+00 7.81314254e+00 2.57417744e-02\n",
      " 2.60135630e-01 1.11860474e+01], Loss = 0.4107\n",
      "Iteration 4002: Weights = [5.50000000e+01 3.71598514e+00 7.81291825e+00 2.57410355e-02\n",
      " 2.60128162e-01 1.11862843e+01], Loss = 0.4107\n",
      "Iteration 4003: Weights = [5.50000000e+01 3.71587847e+00 7.81269397e+00 2.57402965e-02\n",
      " 2.60120695e-01 1.11865213e+01], Loss = 0.4106\n",
      "Iteration 4004: Weights = [5.50000000e+01 3.71577180e+00 7.81246970e+00 2.57395576e-02\n",
      " 2.60113228e-01 1.11867582e+01], Loss = 0.4106\n",
      "Iteration 4005: Weights = [5.50000000e+01 3.71566513e+00 7.81224543e+00 2.57388187e-02\n",
      " 2.60105761e-01 1.11869951e+01], Loss = 0.4106\n",
      "Iteration 4006: Weights = [5.50000000e+01 3.71555847e+00 7.81202117e+00 2.57380799e-02\n",
      " 2.60098294e-01 1.11872321e+01], Loss = 0.4106\n",
      "Iteration 4007: Weights = [5.50000000e+01 3.71545181e+00 7.81179691e+00 2.57373410e-02\n",
      " 2.60090828e-01 1.11874690e+01], Loss = 0.4106\n",
      "Iteration 4008: Weights = [5.50000000e+01 3.71534515e+00 7.81157267e+00 2.57366022e-02\n",
      " 2.60083362e-01 1.11877059e+01], Loss = 0.4105\n",
      "Iteration 4009: Weights = [5.50000000e+01 3.71523850e+00 7.81134843e+00 2.57358634e-02\n",
      " 2.60075896e-01 1.11879428e+01], Loss = 0.4105\n",
      "Iteration 4010: Weights = [5.50000000e+01 3.71513185e+00 7.81112419e+00 2.57351246e-02\n",
      " 2.60068430e-01 1.11881797e+01], Loss = 0.4105\n",
      "Iteration 4011: Weights = [5.50000000e+01 3.71502520e+00 7.81089996e+00 2.57343859e-02\n",
      " 2.60060964e-01 1.11884166e+01], Loss = 0.4105\n",
      "Iteration 4012: Weights = [5.50000000e+01 3.71491855e+00 7.81067574e+00 2.57336471e-02\n",
      " 2.60053499e-01 1.11886535e+01], Loss = 0.4104\n",
      "Iteration 4013: Weights = [5.50000000e+01 3.71481191e+00 7.81045152e+00 2.57329084e-02\n",
      " 2.60046034e-01 1.11888904e+01], Loss = 0.4104\n",
      "Iteration 4014: Weights = [5.50000000e+01 3.71470527e+00 7.81022731e+00 2.57321697e-02\n",
      " 2.60038569e-01 1.11891273e+01], Loss = 0.4104\n",
      "Iteration 4015: Weights = [5.50000000e+01 3.71459864e+00 7.81000311e+00 2.57314310e-02\n",
      " 2.60031104e-01 1.11893641e+01], Loss = 0.4104\n",
      "Iteration 4016: Weights = [5.50000000e+01 3.71449201e+00 7.80977892e+00 2.57306924e-02\n",
      " 2.60023639e-01 1.11896010e+01], Loss = 0.4103\n",
      "Iteration 4017: Weights = [5.50000000e+01 3.71438538e+00 7.80955473e+00 2.57299538e-02\n",
      " 2.60016175e-01 1.11898378e+01], Loss = 0.4103\n",
      "Iteration 4018: Weights = [5.50000000e+01 3.71427875e+00 7.80933054e+00 2.57292151e-02\n",
      " 2.60008711e-01 1.11900747e+01], Loss = 0.4103\n",
      "Iteration 4019: Weights = [5.50000000e+01 3.71417213e+00 7.80910636e+00 2.57284765e-02\n",
      " 2.60001247e-01 1.11903115e+01], Loss = 0.4103\n",
      "Iteration 4020: Weights = [5.50000000e+01 3.71406551e+00 7.80888219e+00 2.57277380e-02\n",
      " 2.59993783e-01 1.11905483e+01], Loss = 0.4102\n",
      "Iteration 4021: Weights = [5.50000000e+01 3.71395889e+00 7.80865803e+00 2.57269994e-02\n",
      " 2.59986320e-01 1.11907852e+01], Loss = 0.4102\n",
      "Iteration 4022: Weights = [5.50000000e+01 3.71385228e+00 7.80843387e+00 2.57262609e-02\n",
      " 2.59978857e-01 1.11910220e+01], Loss = 0.4102\n",
      "Iteration 4023: Weights = [5.50000000e+01 3.71374566e+00 7.80820972e+00 2.57255224e-02\n",
      " 2.59971394e-01 1.11912588e+01], Loss = 0.4102\n",
      "Iteration 4024: Weights = [5.50000000e+01 3.71363906e+00 7.80798558e+00 2.57247839e-02\n",
      " 2.59963931e-01 1.11914956e+01], Loss = 0.4102\n",
      "Iteration 4025: Weights = [5.50000000e+01 3.71353245e+00 7.80776144e+00 2.57240454e-02\n",
      " 2.59956468e-01 1.11917324e+01], Loss = 0.4101\n",
      "Iteration 4026: Weights = [5.50000000e+01 3.71342585e+00 7.80753731e+00 2.57233070e-02\n",
      " 2.59949006e-01 1.11919692e+01], Loss = 0.4101\n",
      "Iteration 4027: Weights = [5.50000000e+01 3.71331925e+00 7.80731318e+00 2.57225686e-02\n",
      " 2.59941544e-01 1.11922060e+01], Loss = 0.4101\n",
      "Iteration 4028: Weights = [5.50000000e+01 3.71321266e+00 7.80708906e+00 2.57218302e-02\n",
      " 2.59934082e-01 1.11924428e+01], Loss = 0.4101\n",
      "Iteration 4029: Weights = [5.50000000e+01 3.71310606e+00 7.80686495e+00 2.57210918e-02\n",
      " 2.59926620e-01 1.11926795e+01], Loss = 0.4100\n",
      "Iteration 4030: Weights = [5.50000000e+01 3.71299947e+00 7.80664084e+00 2.57203534e-02\n",
      " 2.59919158e-01 1.11929163e+01], Loss = 0.4100\n",
      "Iteration 4031: Weights = [5.50000000e+01 3.71289289e+00 7.80641674e+00 2.57196151e-02\n",
      " 2.59911697e-01 1.11931531e+01], Loss = 0.4100\n",
      "Iteration 4032: Weights = [5.50000000e+01 3.71278630e+00 7.80619265e+00 2.57188768e-02\n",
      " 2.59904236e-01 1.11933898e+01], Loss = 0.4100\n",
      "Iteration 4033: Weights = [5.50000000e+01 3.71267972e+00 7.80596856e+00 2.57181385e-02\n",
      " 2.59896775e-01 1.11936266e+01], Loss = 0.4099\n",
      "Iteration 4034: Weights = [5.50000000e+01 3.71257315e+00 7.80574448e+00 2.57174002e-02\n",
      " 2.59889314e-01 1.11938633e+01], Loss = 0.4099\n",
      "Iteration 4035: Weights = [5.50000000e+01 3.71246657e+00 7.80552041e+00 2.57166620e-02\n",
      " 2.59881854e-01 1.11941000e+01], Loss = 0.4099\n",
      "Iteration 4036: Weights = [5.50000000e+01 3.71236000e+00 7.80529634e+00 2.57159237e-02\n",
      " 2.59874394e-01 1.11943367e+01], Loss = 0.4099\n",
      "Iteration 4037: Weights = [5.50000000e+01 3.71225343e+00 7.80507228e+00 2.57151855e-02\n",
      " 2.59866934e-01 1.11945735e+01], Loss = 0.4098\n",
      "Iteration 4038: Weights = [5.50000000e+01 3.71214687e+00 7.80484822e+00 2.57144473e-02\n",
      " 2.59859474e-01 1.11948102e+01], Loss = 0.4098\n",
      "Iteration 4039: Weights = [5.50000000e+01 3.71204031e+00 7.80462417e+00 2.57137092e-02\n",
      " 2.59852014e-01 1.11950469e+01], Loss = 0.4098\n",
      "Iteration 4040: Weights = [5.50000000e+01 3.71193375e+00 7.80440013e+00 2.57129710e-02\n",
      " 2.59844555e-01 1.11952836e+01], Loss = 0.4098\n",
      "Iteration 4041: Weights = [5.50000000e+01 3.71182719e+00 7.80417610e+00 2.57122329e-02\n",
      " 2.59837096e-01 1.11955203e+01], Loss = 0.4098\n",
      "Iteration 4042: Weights = [5.50000000e+01 3.71172064e+00 7.80395207e+00 2.57114948e-02\n",
      " 2.59829637e-01 1.11957569e+01], Loss = 0.4097\n",
      "Iteration 4043: Weights = [5.50000000e+01 3.71161409e+00 7.80372805e+00 2.57107567e-02\n",
      " 2.59822178e-01 1.11959936e+01], Loss = 0.4097\n",
      "Iteration 4044: Weights = [5.50000000e+01 3.71150754e+00 7.80350403e+00 2.57100187e-02\n",
      " 2.59814719e-01 1.11962303e+01], Loss = 0.4097\n",
      "Iteration 4045: Weights = [5.50000000e+01 3.71140100e+00 7.80328002e+00 2.57092806e-02\n",
      " 2.59807261e-01 1.11964670e+01], Loss = 0.4097\n",
      "Iteration 4046: Weights = [5.50000000e+01 3.71129446e+00 7.80305602e+00 2.57085426e-02\n",
      " 2.59799803e-01 1.11967036e+01], Loss = 0.4096\n",
      "Iteration 4047: Weights = [5.50000000e+01 3.71118792e+00 7.80283202e+00 2.57078046e-02\n",
      " 2.59792345e-01 1.11969403e+01], Loss = 0.4096\n",
      "Iteration 4048: Weights = [5.50000000e+01 3.71108138e+00 7.80260803e+00 2.57070666e-02\n",
      " 2.59784887e-01 1.11971769e+01], Loss = 0.4096\n",
      "Iteration 4049: Weights = [5.50000000e+01 3.71097485e+00 7.80238404e+00 2.57063287e-02\n",
      " 2.59777430e-01 1.11974135e+01], Loss = 0.4096\n",
      "Iteration 4050: Weights = [5.50000000e+01 3.71086832e+00 7.80216007e+00 2.57055907e-02\n",
      " 2.59769973e-01 1.11976502e+01], Loss = 0.4095\n",
      "Iteration 4051: Weights = [5.50000000e+01 3.71076180e+00 7.80193610e+00 2.57048528e-02\n",
      " 2.59762516e-01 1.11978868e+01], Loss = 0.4095\n",
      "Iteration 4052: Weights = [5.50000000e+01 3.71065528e+00 7.80171213e+00 2.57041149e-02\n",
      " 2.59755059e-01 1.11981234e+01], Loss = 0.4095\n",
      "Iteration 4053: Weights = [5.50000000e+01 3.71054876e+00 7.80148817e+00 2.57033771e-02\n",
      " 2.59747602e-01 1.11983600e+01], Loss = 0.4095\n",
      "Iteration 4054: Weights = [5.50000000e+01 3.71044224e+00 7.80126422e+00 2.57026392e-02\n",
      " 2.59740146e-01 1.11985966e+01], Loss = 0.4094\n",
      "Iteration 4055: Weights = [5.50000000e+01 3.71033573e+00 7.80104028e+00 2.57019014e-02\n",
      " 2.59732690e-01 1.11988332e+01], Loss = 0.4094\n",
      "Iteration 4056: Weights = [5.50000000e+01 3.71022922e+00 7.80081634e+00 2.57011636e-02\n",
      " 2.59725234e-01 1.11990698e+01], Loss = 0.4094\n",
      "Iteration 4057: Weights = [5.50000000e+01 3.71012271e+00 7.80059240e+00 2.57004258e-02\n",
      " 2.59717778e-01 1.11993064e+01], Loss = 0.4094\n",
      "Iteration 4058: Weights = [5.50000000e+01 3.71001621e+00 7.80036848e+00 2.56996880e-02\n",
      " 2.59710322e-01 1.11995430e+01], Loss = 0.4094\n",
      "Iteration 4059: Weights = [5.50000000e+01 3.70990971e+00 7.80014456e+00 2.56989503e-02\n",
      " 2.59702867e-01 1.11997795e+01], Loss = 0.4093\n",
      "Iteration 4060: Weights = [5.50000000e+01 3.70980321e+00 7.79992064e+00 2.56982126e-02\n",
      " 2.59695412e-01 1.12000161e+01], Loss = 0.4093\n",
      "Iteration 4061: Weights = [5.50000000e+01 3.70969671e+00 7.79969674e+00 2.56974749e-02\n",
      " 2.59687957e-01 1.12002526e+01], Loss = 0.4093\n",
      "Iteration 4062: Weights = [5.50000000e+01 3.70959022e+00 7.79947284e+00 2.56967372e-02\n",
      " 2.59680502e-01 1.12004892e+01], Loss = 0.4093\n",
      "Iteration 4063: Weights = [5.50000000e+01 3.70948373e+00 7.79924894e+00 2.56959995e-02\n",
      " 2.59673048e-01 1.12007257e+01], Loss = 0.4092\n",
      "Iteration 4064: Weights = [5.50000000e+01 3.70937725e+00 7.79902506e+00 2.56952619e-02\n",
      " 2.59665594e-01 1.12009623e+01], Loss = 0.4092\n",
      "Iteration 4065: Weights = [5.50000000e+01 3.70927077e+00 7.79880117e+00 2.56945243e-02\n",
      " 2.59658140e-01 1.12011988e+01], Loss = 0.4092\n",
      "Iteration 4066: Weights = [5.50000000e+01 3.70916429e+00 7.79857730e+00 2.56937867e-02\n",
      " 2.59650686e-01 1.12014353e+01], Loss = 0.4092\n",
      "Iteration 4067: Weights = [5.50000000e+01 3.70905781e+00 7.79835343e+00 2.56930491e-02\n",
      " 2.59643232e-01 1.12016718e+01], Loss = 0.4091\n",
      "Iteration 4068: Weights = [5.50000000e+01 3.70895134e+00 7.79812957e+00 2.56923116e-02\n",
      " 2.59635779e-01 1.12019083e+01], Loss = 0.4091\n",
      "Iteration 4069: Weights = [5.50000000e+01 3.70884487e+00 7.79790571e+00 2.56915740e-02\n",
      " 2.59628326e-01 1.12021448e+01], Loss = 0.4091\n",
      "Iteration 4070: Weights = [5.50000000e+01 3.70873840e+00 7.79768186e+00 2.56908365e-02\n",
      " 2.59620873e-01 1.12023813e+01], Loss = 0.4091\n",
      "Iteration 4071: Weights = [5.50000000e+01 3.70863193e+00 7.79745802e+00 2.56900990e-02\n",
      " 2.59613420e-01 1.12026178e+01], Loss = 0.4090\n",
      "Iteration 4072: Weights = [5.50000000e+01 3.70852547e+00 7.79723419e+00 2.56893616e-02\n",
      " 2.59605967e-01 1.12028543e+01], Loss = 0.4090\n",
      "Iteration 4073: Weights = [5.50000000e+01 3.70841902e+00 7.79701036e+00 2.56886241e-02\n",
      " 2.59598515e-01 1.12030908e+01], Loss = 0.4090\n",
      "Iteration 4074: Weights = [5.50000000e+01 3.70831256e+00 7.79678653e+00 2.56878867e-02\n",
      " 2.59591063e-01 1.12033272e+01], Loss = 0.4090\n",
      "Iteration 4075: Weights = [5.50000000e+01 3.70820611e+00 7.79656272e+00 2.56871493e-02\n",
      " 2.59583611e-01 1.12035637e+01], Loss = 0.4090\n",
      "Iteration 4076: Weights = [5.50000000e+01 3.70809966e+00 7.79633890e+00 2.56864119e-02\n",
      " 2.59576159e-01 1.12038001e+01], Loss = 0.4089\n",
      "Iteration 4077: Weights = [5.50000000e+01 3.70799321e+00 7.79611510e+00 2.56856745e-02\n",
      " 2.59568708e-01 1.12040366e+01], Loss = 0.4089\n",
      "Iteration 4078: Weights = [5.50000000e+01 3.70788677e+00 7.79589130e+00 2.56849372e-02\n",
      " 2.59561257e-01 1.12042730e+01], Loss = 0.4089\n",
      "Iteration 4079: Weights = [5.50000000e+01 3.70778033e+00 7.79566751e+00 2.56841999e-02\n",
      " 2.59553805e-01 1.12045095e+01], Loss = 0.4089\n",
      "Iteration 4080: Weights = [5.50000000e+01 3.70767389e+00 7.79544373e+00 2.56834626e-02\n",
      " 2.59546355e-01 1.12047459e+01], Loss = 0.4088\n",
      "Iteration 4081: Weights = [5.50000000e+01 3.70756746e+00 7.79521995e+00 2.56827253e-02\n",
      " 2.59538904e-01 1.12049823e+01], Loss = 0.4088\n",
      "Iteration 4082: Weights = [5.50000000e+01 3.70746103e+00 7.79499618e+00 2.56819880e-02\n",
      " 2.59531454e-01 1.12052187e+01], Loss = 0.4088\n",
      "Iteration 4083: Weights = [5.50000000e+01 3.70735460e+00 7.79477241e+00 2.56812508e-02\n",
      " 2.59524003e-01 1.12054551e+01], Loss = 0.4088\n",
      "Iteration 4084: Weights = [5.50000000e+01 3.70724818e+00 7.79454865e+00 2.56805136e-02\n",
      " 2.59516553e-01 1.12056915e+01], Loss = 0.4087\n",
      "Iteration 4085: Weights = [5.50000000e+01 3.70714176e+00 7.79432490e+00 2.56797764e-02\n",
      " 2.59509104e-01 1.12059279e+01], Loss = 0.4087\n",
      "Iteration 4086: Weights = [5.50000000e+01 3.70703534e+00 7.79410115e+00 2.56790392e-02\n",
      " 2.59501654e-01 1.12061643e+01], Loss = 0.4087\n",
      "Iteration 4087: Weights = [5.50000000e+01 3.70692892e+00 7.79387741e+00 2.56783021e-02\n",
      " 2.59494205e-01 1.12064007e+01], Loss = 0.4087\n",
      "Iteration 4088: Weights = [5.50000000e+01 3.70682251e+00 7.79365368e+00 2.56775650e-02\n",
      " 2.59486756e-01 1.12066370e+01], Loss = 0.4086\n",
      "Iteration 4089: Weights = [5.50000000e+01 3.70671610e+00 7.79342995e+00 2.56768278e-02\n",
      " 2.59479307e-01 1.12068734e+01], Loss = 0.4086\n",
      "Iteration 4090: Weights = [5.50000000e+01 3.70660970e+00 7.79320623e+00 2.56760908e-02\n",
      " 2.59471858e-01 1.12071098e+01], Loss = 0.4086\n",
      "Iteration 4091: Weights = [5.50000000e+01 3.70650329e+00 7.79298252e+00 2.56753537e-02\n",
      " 2.59464410e-01 1.12073461e+01], Loss = 0.4086\n",
      "Iteration 4092: Weights = [5.50000000e+01 3.70639689e+00 7.79275881e+00 2.56746166e-02\n",
      " 2.59456961e-01 1.12075824e+01], Loss = 0.4086\n",
      "Iteration 4093: Weights = [5.50000000e+01 3.70629050e+00 7.79253511e+00 2.56738796e-02\n",
      " 2.59449513e-01 1.12078188e+01], Loss = 0.4085\n",
      "Iteration 4094: Weights = [5.50000000e+01 3.70618410e+00 7.79231141e+00 2.56731426e-02\n",
      " 2.59442065e-01 1.12080551e+01], Loss = 0.4085\n",
      "Iteration 4095: Weights = [5.50000000e+01 3.70607771e+00 7.79208772e+00 2.56724056e-02\n",
      " 2.59434618e-01 1.12082914e+01], Loss = 0.4085\n",
      "Iteration 4096: Weights = [5.50000000e+01 3.70597132e+00 7.79186404e+00 2.56716687e-02\n",
      " 2.59427170e-01 1.12085278e+01], Loss = 0.4085\n",
      "Iteration 4097: Weights = [5.50000000e+01 3.70586494e+00 7.79164037e+00 2.56709317e-02\n",
      " 2.59419723e-01 1.12087641e+01], Loss = 0.4084\n",
      "Iteration 4098: Weights = [5.50000000e+01 3.70575856e+00 7.79141670e+00 2.56701948e-02\n",
      " 2.59412276e-01 1.12090004e+01], Loss = 0.4084\n",
      "Iteration 4099: Weights = [5.50000000e+01 3.70565218e+00 7.79119304e+00 2.56694579e-02\n",
      " 2.59404829e-01 1.12092367e+01], Loss = 0.4084\n",
      "Iteration 4100: Weights = [5.50000000e+01 3.70554580e+00 7.79096938e+00 2.56687211e-02\n",
      " 2.59397383e-01 1.12094730e+01], Loss = 0.4084\n",
      "Iteration 4101: Weights = [5.50000000e+01 3.70543943e+00 7.79074573e+00 2.56679842e-02\n",
      " 2.59389937e-01 1.12097092e+01], Loss = 0.4083\n",
      "Iteration 4102: Weights = [5.50000000e+01 3.70533306e+00 7.79052209e+00 2.56672474e-02\n",
      " 2.59382490e-01 1.12099455e+01], Loss = 0.4083\n",
      "Iteration 4103: Weights = [5.50000000e+01 3.70522669e+00 7.79029845e+00 2.56665106e-02\n",
      " 2.59375045e-01 1.12101818e+01], Loss = 0.4083\n",
      "Iteration 4104: Weights = [5.50000000e+01 3.70512033e+00 7.79007482e+00 2.56657738e-02\n",
      " 2.59367599e-01 1.12104180e+01], Loss = 0.4083\n",
      "Iteration 4105: Weights = [5.50000000e+01 3.70501397e+00 7.78985119e+00 2.56650370e-02\n",
      " 2.59360153e-01 1.12106543e+01], Loss = 0.4082\n",
      "Iteration 4106: Weights = [5.50000000e+01 3.70490761e+00 7.78962758e+00 2.56643002e-02\n",
      " 2.59352708e-01 1.12108905e+01], Loss = 0.4082\n",
      "Iteration 4107: Weights = [5.50000000e+01 3.70480126e+00 7.78940396e+00 2.56635635e-02\n",
      " 2.59345263e-01 1.12111268e+01], Loss = 0.4082\n",
      "Iteration 4108: Weights = [5.50000000e+01 3.70469491e+00 7.78918036e+00 2.56628268e-02\n",
      " 2.59337818e-01 1.12113630e+01], Loss = 0.4082\n",
      "Iteration 4109: Weights = [5.50000000e+01 3.70458856e+00 7.78895676e+00 2.56620901e-02\n",
      " 2.59330374e-01 1.12115993e+01], Loss = 0.4082\n",
      "Iteration 4110: Weights = [5.50000000e+01 3.70448221e+00 7.78873317e+00 2.56613535e-02\n",
      " 2.59322929e-01 1.12118355e+01], Loss = 0.4081\n",
      "Iteration 4111: Weights = [5.50000000e+01 3.70437587e+00 7.78850958e+00 2.56606168e-02\n",
      " 2.59315485e-01 1.12120717e+01], Loss = 0.4081\n",
      "Iteration 4112: Weights = [5.50000000e+01 3.70426953e+00 7.78828600e+00 2.56598802e-02\n",
      " 2.59308041e-01 1.12123079e+01], Loss = 0.4081\n",
      "Iteration 4113: Weights = [5.50000000e+01 3.70416320e+00 7.78806243e+00 2.56591436e-02\n",
      " 2.59300597e-01 1.12125441e+01], Loss = 0.4081\n",
      "Iteration 4114: Weights = [5.50000000e+01 3.70405686e+00 7.78783886e+00 2.56584070e-02\n",
      " 2.59293154e-01 1.12127803e+01], Loss = 0.4080\n",
      "Iteration 4115: Weights = [5.50000000e+01 3.70395053e+00 7.78761530e+00 2.56576705e-02\n",
      " 2.59285710e-01 1.12130165e+01], Loss = 0.4080\n",
      "Iteration 4116: Weights = [5.50000000e+01 3.70384421e+00 7.78739175e+00 2.56569339e-02\n",
      " 2.59278267e-01 1.12132527e+01], Loss = 0.4080\n",
      "Iteration 4117: Weights = [5.50000000e+01 3.70373788e+00 7.78716820e+00 2.56561974e-02\n",
      " 2.59270824e-01 1.12134888e+01], Loss = 0.4080\n",
      "Iteration 4118: Weights = [5.50000000e+01 3.70363156e+00 7.78694466e+00 2.56554609e-02\n",
      " 2.59263381e-01 1.12137250e+01], Loss = 0.4079\n",
      "Iteration 4119: Weights = [5.50000000e+01 3.70352525e+00 7.78672113e+00 2.56547244e-02\n",
      " 2.59255939e-01 1.12139612e+01], Loss = 0.4079\n",
      "Iteration 4120: Weights = [5.50000000e+01 3.70341893e+00 7.78649760e+00 2.56539880e-02\n",
      " 2.59248497e-01 1.12141973e+01], Loss = 0.4079\n",
      "Iteration 4121: Weights = [5.50000000e+01 3.70331262e+00 7.78627408e+00 2.56532516e-02\n",
      " 2.59241055e-01 1.12144335e+01], Loss = 0.4079\n",
      "Iteration 4122: Weights = [5.50000000e+01 3.70320631e+00 7.78605056e+00 2.56525151e-02\n",
      " 2.59233613e-01 1.12146696e+01], Loss = 0.4078\n",
      "Iteration 4123: Weights = [5.50000000e+01 3.70310001e+00 7.78582705e+00 2.56517788e-02\n",
      " 2.59226171e-01 1.12149057e+01], Loss = 0.4078\n",
      "Iteration 4124: Weights = [5.50000000e+01 3.70299370e+00 7.78560355e+00 2.56510424e-02\n",
      " 2.59218730e-01 1.12151419e+01], Loss = 0.4078\n",
      "Iteration 4125: Weights = [5.50000000e+01 3.70288740e+00 7.78538005e+00 2.56503060e-02\n",
      " 2.59211288e-01 1.12153780e+01], Loss = 0.4078\n",
      "Iteration 4126: Weights = [5.50000000e+01 3.70278111e+00 7.78515657e+00 2.56495697e-02\n",
      " 2.59203847e-01 1.12156141e+01], Loss = 0.4078\n",
      "Iteration 4127: Weights = [5.50000000e+01 3.70267482e+00 7.78493308e+00 2.56488334e-02\n",
      " 2.59196407e-01 1.12158502e+01], Loss = 0.4077\n",
      "Iteration 4128: Weights = [5.50000000e+01 3.70256853e+00 7.78470961e+00 2.56480971e-02\n",
      " 2.59188966e-01 1.12160863e+01], Loss = 0.4077\n",
      "Iteration 4129: Weights = [5.50000000e+01 3.70246224e+00 7.78448614e+00 2.56473609e-02\n",
      " 2.59181526e-01 1.12163224e+01], Loss = 0.4077\n",
      "Iteration 4130: Weights = [5.50000000e+01 3.70235595e+00 7.78426267e+00 2.56466246e-02\n",
      " 2.59174086e-01 1.12165585e+01], Loss = 0.4077\n",
      "Iteration 4131: Weights = [5.50000000e+01 3.70224967e+00 7.78403921e+00 2.56458884e-02\n",
      " 2.59166646e-01 1.12167946e+01], Loss = 0.4076\n",
      "Iteration 4132: Weights = [5.50000000e+01 3.70214340e+00 7.78381576e+00 2.56451522e-02\n",
      " 2.59159206e-01 1.12170306e+01], Loss = 0.4076\n",
      "Iteration 4133: Weights = [5.50000000e+01 3.70203712e+00 7.78359232e+00 2.56444160e-02\n",
      " 2.59151766e-01 1.12172667e+01], Loss = 0.4076\n",
      "Iteration 4134: Weights = [5.50000000e+01 3.70193085e+00 7.78336888e+00 2.56436799e-02\n",
      " 2.59144327e-01 1.12175028e+01], Loss = 0.4076\n",
      "Iteration 4135: Weights = [5.50000000e+01 3.70182458e+00 7.78314545e+00 2.56429437e-02\n",
      " 2.59136888e-01 1.12177388e+01], Loss = 0.4075\n",
      "Iteration 4136: Weights = [5.50000000e+01 3.70171831e+00 7.78292202e+00 2.56422076e-02\n",
      " 2.59129449e-01 1.12179749e+01], Loss = 0.4075\n",
      "Iteration 4137: Weights = [5.50000000e+01 3.70161205e+00 7.78269860e+00 2.56414715e-02\n",
      " 2.59122011e-01 1.12182109e+01], Loss = 0.4075\n",
      "Iteration 4138: Weights = [5.50000000e+01 3.70150579e+00 7.78247519e+00 2.56407355e-02\n",
      " 2.59114572e-01 1.12184469e+01], Loss = 0.4075\n",
      "Iteration 4139: Weights = [5.50000000e+01 3.70139954e+00 7.78225179e+00 2.56399994e-02\n",
      " 2.59107134e-01 1.12186830e+01], Loss = 0.4075\n",
      "Iteration 4140: Weights = [5.50000000e+01 3.70129328e+00 7.78202839e+00 2.56392634e-02\n",
      " 2.59099696e-01 1.12189190e+01], Loss = 0.4074\n",
      "Iteration 4141: Weights = [5.50000000e+01 3.70118703e+00 7.78180499e+00 2.56385274e-02\n",
      " 2.59092258e-01 1.12191550e+01], Loss = 0.4074\n",
      "Iteration 4142: Weights = [5.50000000e+01 3.70108078e+00 7.78158161e+00 2.56377914e-02\n",
      " 2.59084821e-01 1.12193910e+01], Loss = 0.4074\n",
      "Iteration 4143: Weights = [5.50000000e+01 3.70097454e+00 7.78135822e+00 2.56370554e-02\n",
      " 2.59077383e-01 1.12196270e+01], Loss = 0.4074\n",
      "Iteration 4144: Weights = [5.50000000e+01 3.70086830e+00 7.78113485e+00 2.56363195e-02\n",
      " 2.59069946e-01 1.12198630e+01], Loss = 0.4073\n",
      "Iteration 4145: Weights = [5.50000000e+01 3.70076206e+00 7.78091148e+00 2.56355835e-02\n",
      " 2.59062509e-01 1.12200990e+01], Loss = 0.4073\n",
      "Iteration 4146: Weights = [5.50000000e+01 3.70065582e+00 7.78068812e+00 2.56348476e-02\n",
      " 2.59055072e-01 1.12203349e+01], Loss = 0.4073\n",
      "Iteration 4147: Weights = [5.50000000e+01 3.70054959e+00 7.78046477e+00 2.56341118e-02\n",
      " 2.59047636e-01 1.12205709e+01], Loss = 0.4073\n",
      "Iteration 4148: Weights = [5.50000000e+01 3.70044336e+00 7.78024142e+00 2.56333759e-02\n",
      " 2.59040200e-01 1.12208069e+01], Loss = 0.4072\n",
      "Iteration 4149: Weights = [5.50000000e+01 3.70033714e+00 7.78001808e+00 2.56326401e-02\n",
      " 2.59032763e-01 1.12210428e+01], Loss = 0.4072\n",
      "Iteration 4150: Weights = [5.50000000e+01 3.70023091e+00 7.77979474e+00 2.56319042e-02\n",
      " 2.59025328e-01 1.12212788e+01], Loss = 0.4072\n",
      "Iteration 4151: Weights = [5.50000000e+01 3.70012469e+00 7.77957141e+00 2.56311684e-02\n",
      " 2.59017892e-01 1.12215147e+01], Loss = 0.4072\n",
      "Iteration 4152: Weights = [5.50000000e+01 3.70001848e+00 7.77934809e+00 2.56304327e-02\n",
      " 2.59010456e-01 1.12217507e+01], Loss = 0.4071\n",
      "Iteration 4153: Weights = [5.50000000e+01 3.69991226e+00 7.77912477e+00 2.56296969e-02\n",
      " 2.59003021e-01 1.12219866e+01], Loss = 0.4071\n",
      "Iteration 4154: Weights = [5.50000000e+01 3.69980605e+00 7.77890146e+00 2.56289612e-02\n",
      " 2.58995586e-01 1.12222225e+01], Loss = 0.4071\n",
      "Iteration 4155: Weights = [5.50000000e+01 3.69969984e+00 7.77867816e+00 2.56282255e-02\n",
      " 2.58988151e-01 1.12224584e+01], Loss = 0.4071\n",
      "Iteration 4156: Weights = [5.50000000e+01 3.69959364e+00 7.77845486e+00 2.56274898e-02\n",
      " 2.58980717e-01 1.12226943e+01], Loss = 0.4071\n",
      "Iteration 4157: Weights = [5.50000000e+01 3.69948744e+00 7.77823157e+00 2.56267541e-02\n",
      " 2.58973282e-01 1.12229302e+01], Loss = 0.4070\n",
      "Iteration 4158: Weights = [5.50000000e+01 3.69938124e+00 7.77800829e+00 2.56260185e-02\n",
      " 2.58965848e-01 1.12231661e+01], Loss = 0.4070\n",
      "Iteration 4159: Weights = [5.50000000e+01 3.69927504e+00 7.77778501e+00 2.56252828e-02\n",
      " 2.58958414e-01 1.12234020e+01], Loss = 0.4070\n",
      "Iteration 4160: Weights = [5.50000000e+01 3.69916885e+00 7.77756174e+00 2.56245472e-02\n",
      " 2.58950981e-01 1.12236379e+01], Loss = 0.4070\n",
      "Iteration 4161: Weights = [5.50000000e+01 3.69906266e+00 7.77733847e+00 2.56238116e-02\n",
      " 2.58943547e-01 1.12238738e+01], Loss = 0.4069\n",
      "Iteration 4162: Weights = [5.50000000e+01 3.69895648e+00 7.77711521e+00 2.56230761e-02\n",
      " 2.58936114e-01 1.12241097e+01], Loss = 0.4069\n",
      "Iteration 4163: Weights = [5.50000000e+01 3.69885029e+00 7.77689196e+00 2.56223405e-02\n",
      " 2.58928681e-01 1.12243455e+01], Loss = 0.4069\n",
      "Iteration 4164: Weights = [5.50000000e+01 3.69874411e+00 7.77666872e+00 2.56216050e-02\n",
      " 2.58921248e-01 1.12245814e+01], Loss = 0.4069\n",
      "Iteration 4165: Weights = [5.50000000e+01 3.69863793e+00 7.77644548e+00 2.56208695e-02\n",
      " 2.58913815e-01 1.12248172e+01], Loss = 0.4068\n",
      "Iteration 4166: Weights = [5.50000000e+01 3.69853176e+00 7.77622224e+00 2.56201340e-02\n",
      " 2.58906383e-01 1.12250531e+01], Loss = 0.4068\n",
      "Iteration 4167: Weights = [5.50000000e+01 3.69842559e+00 7.77599902e+00 2.56193986e-02\n",
      " 2.58898950e-01 1.12252889e+01], Loss = 0.4068\n",
      "Iteration 4168: Weights = [5.50000000e+01 3.69831942e+00 7.77577580e+00 2.56186631e-02\n",
      " 2.58891518e-01 1.12255247e+01], Loss = 0.4068\n",
      "Iteration 4169: Weights = [5.50000000e+01 3.69821326e+00 7.77555258e+00 2.56179277e-02\n",
      " 2.58884087e-01 1.12257606e+01], Loss = 0.4068\n",
      "Iteration 4170: Weights = [5.50000000e+01 3.69810709e+00 7.77532938e+00 2.56171923e-02\n",
      " 2.58876655e-01 1.12259964e+01], Loss = 0.4067\n",
      "Iteration 4171: Weights = [5.50000000e+01 3.69800093e+00 7.77510617e+00 2.56164569e-02\n",
      " 2.58869224e-01 1.12262322e+01], Loss = 0.4067\n",
      "Iteration 4172: Weights = [5.50000000e+01 3.69789478e+00 7.77488298e+00 2.56157216e-02\n",
      " 2.58861792e-01 1.12264680e+01], Loss = 0.4067\n",
      "Iteration 4173: Weights = [5.50000000e+01 3.69778863e+00 7.77465979e+00 2.56149862e-02\n",
      " 2.58854361e-01 1.12267038e+01], Loss = 0.4067\n",
      "Iteration 4174: Weights = [5.50000000e+01 3.69768248e+00 7.77443661e+00 2.56142509e-02\n",
      " 2.58846931e-01 1.12269396e+01], Loss = 0.4066\n",
      "Iteration 4175: Weights = [5.50000000e+01 3.69757633e+00 7.77421343e+00 2.56135156e-02\n",
      " 2.58839500e-01 1.12271753e+01], Loss = 0.4066\n",
      "Iteration 4176: Weights = [5.50000000e+01 3.69747019e+00 7.77399027e+00 2.56127804e-02\n",
      " 2.58832070e-01 1.12274111e+01], Loss = 0.4066\n",
      "Iteration 4177: Weights = [5.50000000e+01 3.69736404e+00 7.77376710e+00 2.56120451e-02\n",
      " 2.58824640e-01 1.12276469e+01], Loss = 0.4066\n",
      "Iteration 4178: Weights = [5.50000000e+01 3.69725791e+00 7.77354395e+00 2.56113099e-02\n",
      " 2.58817210e-01 1.12278826e+01], Loss = 0.4065\n",
      "Iteration 4179: Weights = [5.50000000e+01 3.69715177e+00 7.77332080e+00 2.56105747e-02\n",
      " 2.58809780e-01 1.12281184e+01], Loss = 0.4065\n",
      "Iteration 4180: Weights = [5.50000000e+01 3.69704564e+00 7.77309765e+00 2.56098395e-02\n",
      " 2.58802351e-01 1.12283541e+01], Loss = 0.4065\n",
      "Iteration 4181: Weights = [5.50000000e+01 3.69693951e+00 7.77287452e+00 2.56091043e-02\n",
      " 2.58794921e-01 1.12285899e+01], Loss = 0.4065\n",
      "Iteration 4182: Weights = [5.50000000e+01 3.69683339e+00 7.77265139e+00 2.56083692e-02\n",
      " 2.58787492e-01 1.12288256e+01], Loss = 0.4064\n",
      "Iteration 4183: Weights = [5.50000000e+01 3.69672726e+00 7.77242826e+00 2.56076341e-02\n",
      " 2.58780063e-01 1.12290613e+01], Loss = 0.4064\n",
      "Iteration 4184: Weights = [5.50000000e+01 3.69662115e+00 7.77220514e+00 2.56068990e-02\n",
      " 2.58772635e-01 1.12292971e+01], Loss = 0.4064\n",
      "Iteration 4185: Weights = [5.50000000e+01 3.69651503e+00 7.77198203e+00 2.56061639e-02\n",
      " 2.58765206e-01 1.12295328e+01], Loss = 0.4064\n",
      "Iteration 4186: Weights = [5.50000000e+01 3.69640892e+00 7.77175893e+00 2.56054288e-02\n",
      " 2.58757778e-01 1.12297685e+01], Loss = 0.4064\n",
      "Iteration 4187: Weights = [5.50000000e+01 3.69630281e+00 7.77153583e+00 2.56046938e-02\n",
      " 2.58750350e-01 1.12300042e+01], Loss = 0.4063\n",
      "Iteration 4188: Weights = [5.50000000e+01 3.69619670e+00 7.77131274e+00 2.56039588e-02\n",
      " 2.58742922e-01 1.12302399e+01], Loss = 0.4063\n",
      "Iteration 4189: Weights = [5.50000000e+01 3.69609059e+00 7.77108965e+00 2.56032238e-02\n",
      " 2.58735495e-01 1.12304756e+01], Loss = 0.4063\n",
      "Iteration 4190: Weights = [5.50000000e+01 3.69598449e+00 7.77086657e+00 2.56024888e-02\n",
      " 2.58728068e-01 1.12307112e+01], Loss = 0.4063\n",
      "Iteration 4191: Weights = [5.50000000e+01 3.69587839e+00 7.77064350e+00 2.56017539e-02\n",
      " 2.58720640e-01 1.12309469e+01], Loss = 0.4062\n",
      "Iteration 4192: Weights = [5.50000000e+01 3.69577230e+00 7.77042043e+00 2.56010189e-02\n",
      " 2.58713214e-01 1.12311826e+01], Loss = 0.4062\n",
      "Iteration 4193: Weights = [5.50000000e+01 3.69566621e+00 7.77019737e+00 2.56002840e-02\n",
      " 2.58705787e-01 1.12314182e+01], Loss = 0.4062\n",
      "Iteration 4194: Weights = [5.50000000e+01 3.69556012e+00 7.76997432e+00 2.55995491e-02\n",
      " 2.58698360e-01 1.12316539e+01], Loss = 0.4062\n",
      "Iteration 4195: Weights = [5.50000000e+01 3.69545403e+00 7.76975127e+00 2.55988143e-02\n",
      " 2.58690934e-01 1.12318895e+01], Loss = 0.4061\n",
      "Iteration 4196: Weights = [5.50000000e+01 3.69534795e+00 7.76952823e+00 2.55980794e-02\n",
      " 2.58683508e-01 1.12321252e+01], Loss = 0.4061\n",
      "Iteration 4197: Weights = [5.50000000e+01 3.69524187e+00 7.76930520e+00 2.55973446e-02\n",
      " 2.58676082e-01 1.12323608e+01], Loss = 0.4061\n",
      "Iteration 4198: Weights = [5.50000000e+01 3.69513579e+00 7.76908217e+00 2.55966098e-02\n",
      " 2.58668657e-01 1.12325964e+01], Loss = 0.4061\n",
      "Iteration 4199: Weights = [5.50000000e+01 3.69502972e+00 7.76885915e+00 2.55958750e-02\n",
      " 2.58661231e-01 1.12328321e+01], Loss = 0.4061\n",
      "Iteration 4200: Weights = [5.50000000e+01 3.69492365e+00 7.76863613e+00 2.55951402e-02\n",
      " 2.58653806e-01 1.12330677e+01], Loss = 0.4060\n",
      "Iteration 4201: Weights = [5.50000000e+01 3.69481758e+00 7.76841312e+00 2.55944055e-02\n",
      " 2.58646381e-01 1.12333033e+01], Loss = 0.4060\n",
      "Iteration 4202: Weights = [5.50000000e+01 3.69471152e+00 7.76819012e+00 2.55936708e-02\n",
      " 2.58638956e-01 1.12335389e+01], Loss = 0.4060\n",
      "Iteration 4203: Weights = [5.50000000e+01 3.69460546e+00 7.76796712e+00 2.55929361e-02\n",
      " 2.58631532e-01 1.12337745e+01], Loss = 0.4060\n",
      "Iteration 4204: Weights = [5.50000000e+01 3.69449940e+00 7.76774413e+00 2.55922014e-02\n",
      " 2.58624107e-01 1.12340101e+01], Loss = 0.4059\n",
      "Iteration 4205: Weights = [5.50000000e+01 3.69439334e+00 7.76752115e+00 2.55914667e-02\n",
      " 2.58616683e-01 1.12342456e+01], Loss = 0.4059\n",
      "Iteration 4206: Weights = [5.50000000e+01 3.69428729e+00 7.76729817e+00 2.55907321e-02\n",
      " 2.58609259e-01 1.12344812e+01], Loss = 0.4059\n",
      "Iteration 4207: Weights = [5.50000000e+01 3.69418124e+00 7.76707520e+00 2.55899975e-02\n",
      " 2.58601835e-01 1.12347168e+01], Loss = 0.4059\n",
      "Iteration 4208: Weights = [5.50000000e+01 3.69407519e+00 7.76685224e+00 2.55892629e-02\n",
      " 2.58594412e-01 1.12349523e+01], Loss = 0.4058\n",
      "Iteration 4209: Weights = [5.50000000e+01 3.69396915e+00 7.76662928e+00 2.55885283e-02\n",
      " 2.58586989e-01 1.12351879e+01], Loss = 0.4058\n",
      "Iteration 4210: Weights = [5.50000000e+01 3.69386311e+00 7.76640633e+00 2.55877938e-02\n",
      " 2.58579565e-01 1.12354234e+01], Loss = 0.4058\n",
      "Iteration 4211: Weights = [5.50000000e+01 3.69375707e+00 7.76618339e+00 2.55870592e-02\n",
      " 2.58572143e-01 1.12356590e+01], Loss = 0.4058\n",
      "Iteration 4212: Weights = [5.50000000e+01 3.69365104e+00 7.76596045e+00 2.55863247e-02\n",
      " 2.58564720e-01 1.12358945e+01], Loss = 0.4057\n",
      "Iteration 4213: Weights = [5.50000000e+01 3.69354501e+00 7.76573752e+00 2.55855902e-02\n",
      " 2.58557298e-01 1.12361300e+01], Loss = 0.4057\n",
      "Iteration 4214: Weights = [5.50000000e+01 3.69343898e+00 7.76551459e+00 2.55848558e-02\n",
      " 2.58549875e-01 1.12363655e+01], Loss = 0.4057\n",
      "Iteration 4215: Weights = [5.50000000e+01 3.69333295e+00 7.76529167e+00 2.55841213e-02\n",
      " 2.58542453e-01 1.12366010e+01], Loss = 0.4057\n",
      "Iteration 4216: Weights = [5.50000000e+01 3.69322693e+00 7.76506876e+00 2.55833869e-02\n",
      " 2.58535032e-01 1.12368365e+01], Loss = 0.4057\n",
      "Iteration 4217: Weights = [5.50000000e+01 3.69312091e+00 7.76484585e+00 2.55826525e-02\n",
      " 2.58527610e-01 1.12370720e+01], Loss = 0.4056\n",
      "Iteration 4218: Weights = [5.50000000e+01 3.69301490e+00 7.76462295e+00 2.55819181e-02\n",
      " 2.58520189e-01 1.12373075e+01], Loss = 0.4056\n",
      "Iteration 4219: Weights = [5.50000000e+01 3.69290888e+00 7.76440006e+00 2.55811837e-02\n",
      " 2.58512767e-01 1.12375430e+01], Loss = 0.4056\n",
      "Iteration 4220: Weights = [5.50000000e+01 3.69280287e+00 7.76417717e+00 2.55804494e-02\n",
      " 2.58505346e-01 1.12377785e+01], Loss = 0.4056\n",
      "Iteration 4221: Weights = [5.50000000e+01 3.69269687e+00 7.76395429e+00 2.55797151e-02\n",
      " 2.58497926e-01 1.12380140e+01], Loss = 0.4055\n",
      "Iteration 4222: Weights = [5.50000000e+01 3.69259086e+00 7.76373141e+00 2.55789808e-02\n",
      " 2.58490505e-01 1.12382494e+01], Loss = 0.4055\n",
      "Iteration 4223: Weights = [5.50000000e+01 3.69248486e+00 7.76350855e+00 2.55782465e-02\n",
      " 2.58483085e-01 1.12384849e+01], Loss = 0.4055\n",
      "Iteration 4224: Weights = [5.50000000e+01 3.69237887e+00 7.76328568e+00 2.55775122e-02\n",
      " 2.58475665e-01 1.12387203e+01], Loss = 0.4055\n",
      "Iteration 4225: Weights = [5.50000000e+01 3.69227287e+00 7.76306283e+00 2.55767780e-02\n",
      " 2.58468245e-01 1.12389558e+01], Loss = 0.4054\n",
      "Iteration 4226: Weights = [5.50000000e+01 3.69216688e+00 7.76283998e+00 2.55760438e-02\n",
      " 2.58460825e-01 1.12391912e+01], Loss = 0.4054\n",
      "Iteration 4227: Weights = [5.50000000e+01 3.69206089e+00 7.76261714e+00 2.55753096e-02\n",
      " 2.58453406e-01 1.12394266e+01], Loss = 0.4054\n",
      "Iteration 4228: Weights = [5.50000000e+01 3.69195491e+00 7.76239430e+00 2.55745754e-02\n",
      " 2.58445987e-01 1.12396621e+01], Loss = 0.4054\n",
      "Iteration 4229: Weights = [5.50000000e+01 3.69184892e+00 7.76217147e+00 2.55738413e-02\n",
      " 2.58438567e-01 1.12398975e+01], Loss = 0.4054\n",
      "Iteration 4230: Weights = [5.50000000e+01 3.69174294e+00 7.76194865e+00 2.55731071e-02\n",
      " 2.58431149e-01 1.12401329e+01], Loss = 0.4053\n",
      "Iteration 4231: Weights = [5.50000000e+01 3.69163697e+00 7.76172583e+00 2.55723730e-02\n",
      " 2.58423730e-01 1.12403683e+01], Loss = 0.4053\n",
      "Iteration 4232: Weights = [5.50000000e+01 3.69153099e+00 7.76150302e+00 2.55716389e-02\n",
      " 2.58416312e-01 1.12406037e+01], Loss = 0.4053\n",
      "Iteration 4233: Weights = [5.50000000e+01 3.69142502e+00 7.76128022e+00 2.55709049e-02\n",
      " 2.58408894e-01 1.12408391e+01], Loss = 0.4053\n",
      "Iteration 4234: Weights = [5.50000000e+01 3.69131906e+00 7.76105742e+00 2.55701708e-02\n",
      " 2.58401476e-01 1.12410745e+01], Loss = 0.4052\n",
      "Iteration 4235: Weights = [5.50000000e+01 3.69121309e+00 7.76083463e+00 2.55694368e-02\n",
      " 2.58394058e-01 1.12413098e+01], Loss = 0.4052\n",
      "Iteration 4236: Weights = [5.50000000e+01 3.69110713e+00 7.76061184e+00 2.55687028e-02\n",
      " 2.58386640e-01 1.12415452e+01], Loss = 0.4052\n",
      "Iteration 4237: Weights = [5.50000000e+01 3.69100117e+00 7.76038907e+00 2.55679688e-02\n",
      " 2.58379223e-01 1.12417806e+01], Loss = 0.4052\n",
      "Iteration 4238: Weights = [5.50000000e+01 3.69089522e+00 7.76016629e+00 2.55672349e-02\n",
      " 2.58371806e-01 1.12420159e+01], Loss = 0.4051\n",
      "Iteration 4239: Weights = [5.50000000e+01 3.69078927e+00 7.75994353e+00 2.55665009e-02\n",
      " 2.58364389e-01 1.12422513e+01], Loss = 0.4051\n",
      "Iteration 4240: Weights = [5.50000000e+01 3.69068332e+00 7.75972077e+00 2.55657670e-02\n",
      " 2.58356972e-01 1.12424866e+01], Loss = 0.4051\n",
      "Iteration 4241: Weights = [5.50000000e+01 3.69057737e+00 7.75949802e+00 2.55650331e-02\n",
      " 2.58349556e-01 1.12427219e+01], Loss = 0.4051\n",
      "Iteration 4242: Weights = [5.50000000e+01 3.69047143e+00 7.75927527e+00 2.55642992e-02\n",
      " 2.58342139e-01 1.12429573e+01], Loss = 0.4050\n",
      "Iteration 4243: Weights = [5.50000000e+01 3.69036549e+00 7.75905253e+00 2.55635654e-02\n",
      " 2.58334723e-01 1.12431926e+01], Loss = 0.4050\n",
      "Iteration 4244: Weights = [5.50000000e+01 3.69025955e+00 7.75882979e+00 2.55628315e-02\n",
      " 2.58327308e-01 1.12434279e+01], Loss = 0.4050\n",
      "Iteration 4245: Weights = [5.50000000e+01 3.69015362e+00 7.75860707e+00 2.55620977e-02\n",
      " 2.58319892e-01 1.12436632e+01], Loss = 0.4050\n",
      "Iteration 4246: Weights = [5.50000000e+01 3.69004769e+00 7.75838435e+00 2.55613639e-02\n",
      " 2.58312477e-01 1.12438985e+01], Loss = 0.4050\n",
      "Iteration 4247: Weights = [5.50000000e+01 3.68994176e+00 7.75816163e+00 2.55606301e-02\n",
      " 2.58305061e-01 1.12441338e+01], Loss = 0.4049\n",
      "Iteration 4248: Weights = [5.50000000e+01 3.68983584e+00 7.75793892e+00 2.55598964e-02\n",
      " 2.58297646e-01 1.12443691e+01], Loss = 0.4049\n",
      "Iteration 4249: Weights = [5.50000000e+01 3.68972991e+00 7.75771622e+00 2.55591627e-02\n",
      " 2.58290232e-01 1.12446044e+01], Loss = 0.4049\n",
      "Iteration 4250: Weights = [5.50000000e+01 3.68962400e+00 7.75749353e+00 2.55584290e-02\n",
      " 2.58282817e-01 1.12448397e+01], Loss = 0.4049\n",
      "Iteration 4251: Weights = [5.50000000e+01 3.68951808e+00 7.75727084e+00 2.55576953e-02\n",
      " 2.58275403e-01 1.12450749e+01], Loss = 0.4048\n",
      "Iteration 4252: Weights = [5.50000000e+01 3.68941217e+00 7.75704815e+00 2.55569616e-02\n",
      " 2.58267989e-01 1.12453102e+01], Loss = 0.4048\n",
      "Iteration 4253: Weights = [5.50000000e+01 3.68930626e+00 7.75682548e+00 2.55562280e-02\n",
      " 2.58260575e-01 1.12455454e+01], Loss = 0.4048\n",
      "Iteration 4254: Weights = [5.50000000e+01 3.68920035e+00 7.75660281e+00 2.55554943e-02\n",
      " 2.58253161e-01 1.12457807e+01], Loss = 0.4048\n",
      "Iteration 4255: Weights = [5.50000000e+01 3.68909445e+00 7.75638015e+00 2.55547607e-02\n",
      " 2.58245747e-01 1.12460159e+01], Loss = 0.4047\n",
      "Iteration 4256: Weights = [5.50000000e+01 3.68898855e+00 7.75615749e+00 2.55540271e-02\n",
      " 2.58238334e-01 1.12462512e+01], Loss = 0.4047\n",
      "Iteration 4257: Weights = [5.50000000e+01 3.68888265e+00 7.75593484e+00 2.55532936e-02\n",
      " 2.58230921e-01 1.12464864e+01], Loss = 0.4047\n",
      "Iteration 4258: Weights = [5.50000000e+01 3.68877676e+00 7.75571219e+00 2.55525600e-02\n",
      " 2.58223508e-01 1.12467216e+01], Loss = 0.4047\n",
      "Iteration 4259: Weights = [5.50000000e+01 3.68867087e+00 7.75548956e+00 2.55518265e-02\n",
      " 2.58216096e-01 1.12469568e+01], Loss = 0.4047\n",
      "Iteration 4260: Weights = [5.50000000e+01 3.68856498e+00 7.75526692e+00 2.55510930e-02\n",
      " 2.58208683e-01 1.12471920e+01], Loss = 0.4046\n",
      "Iteration 4261: Weights = [5.50000000e+01 3.68845909e+00 7.75504430e+00 2.55503595e-02\n",
      " 2.58201271e-01 1.12474272e+01], Loss = 0.4046\n",
      "Iteration 4262: Weights = [5.50000000e+01 3.68835321e+00 7.75482168e+00 2.55496261e-02\n",
      " 2.58193859e-01 1.12476624e+01], Loss = 0.4046\n",
      "Iteration 4263: Weights = [5.50000000e+01 3.68824733e+00 7.75459907e+00 2.55488927e-02\n",
      " 2.58186447e-01 1.12478976e+01], Loss = 0.4046\n",
      "Iteration 4264: Weights = [5.50000000e+01 3.68814146e+00 7.75437646e+00 2.55481592e-02\n",
      " 2.58179036e-01 1.12481328e+01], Loss = 0.4045\n",
      "Iteration 4265: Weights = [5.50000000e+01 3.68803558e+00 7.75415386e+00 2.55474258e-02\n",
      " 2.58171624e-01 1.12483680e+01], Loss = 0.4045\n",
      "Iteration 4266: Weights = [5.50000000e+01 3.68792971e+00 7.75393127e+00 2.55466925e-02\n",
      " 2.58164213e-01 1.12486031e+01], Loss = 0.4045\n",
      "Iteration 4267: Weights = [5.50000000e+01 3.68782385e+00 7.75370868e+00 2.55459591e-02\n",
      " 2.58156802e-01 1.12488383e+01], Loss = 0.4045\n",
      "Iteration 4268: Weights = [5.50000000e+01 3.68771798e+00 7.75348610e+00 2.55452258e-02\n",
      " 2.58149391e-01 1.12490734e+01], Loss = 0.4044\n",
      "Iteration 4269: Weights = [5.50000000e+01 3.68761212e+00 7.75326353e+00 2.55444925e-02\n",
      " 2.58141981e-01 1.12493086e+01], Loss = 0.4044\n",
      "Iteration 4270: Weights = [5.50000000e+01 3.68750626e+00 7.75304096e+00 2.55437592e-02\n",
      " 2.58134571e-01 1.12495437e+01], Loss = 0.4044\n",
      "Iteration 4271: Weights = [5.50000000e+01 3.68740041e+00 7.75281840e+00 2.55430259e-02\n",
      " 2.58127160e-01 1.12497789e+01], Loss = 0.4044\n",
      "Iteration 4272: Weights = [5.50000000e+01 3.68729456e+00 7.75259584e+00 2.55422927e-02\n",
      " 2.58119751e-01 1.12500140e+01], Loss = 0.4044\n",
      "Iteration 4273: Weights = [5.50000000e+01 3.68718871e+00 7.75237330e+00 2.55415595e-02\n",
      " 2.58112341e-01 1.12502491e+01], Loss = 0.4043\n",
      "Iteration 4274: Weights = [5.50000000e+01 3.68708286e+00 7.75215075e+00 2.55408263e-02\n",
      " 2.58104931e-01 1.12504842e+01], Loss = 0.4043\n",
      "Iteration 4275: Weights = [5.50000000e+01 3.68697702e+00 7.75192822e+00 2.55400931e-02\n",
      " 2.58097522e-01 1.12507193e+01], Loss = 0.4043\n",
      "Iteration 4276: Weights = [5.50000000e+01 3.68687118e+00 7.75170569e+00 2.55393599e-02\n",
      " 2.58090113e-01 1.12509544e+01], Loss = 0.4043\n",
      "Iteration 4277: Weights = [5.50000000e+01 3.68676534e+00 7.75148317e+00 2.55386268e-02\n",
      " 2.58082704e-01 1.12511895e+01], Loss = 0.4042\n",
      "Iteration 4278: Weights = [5.50000000e+01 3.68665951e+00 7.75126065e+00 2.55378936e-02\n",
      " 2.58075296e-01 1.12514246e+01], Loss = 0.4042\n",
      "Iteration 4279: Weights = [5.50000000e+01 3.68655368e+00 7.75103814e+00 2.55371606e-02\n",
      " 2.58067887e-01 1.12516597e+01], Loss = 0.4042\n",
      "Iteration 4280: Weights = [5.50000000e+01 3.68644785e+00 7.75081564e+00 2.55364275e-02\n",
      " 2.58060479e-01 1.12518947e+01], Loss = 0.4042\n",
      "Iteration 4281: Weights = [5.50000000e+01 3.68634203e+00 7.75059314e+00 2.55356944e-02\n",
      " 2.58053071e-01 1.12521298e+01], Loss = 0.4041\n",
      "Iteration 4282: Weights = [5.50000000e+01 3.68623621e+00 7.75037065e+00 2.55349614e-02\n",
      " 2.58045664e-01 1.12523649e+01], Loss = 0.4041\n",
      "Iteration 4283: Weights = [5.50000000e+01 3.68613039e+00 7.75014816e+00 2.55342284e-02\n",
      " 2.58038256e-01 1.12525999e+01], Loss = 0.4041\n",
      "Iteration 4284: Weights = [5.50000000e+01 3.68602457e+00 7.74992569e+00 2.55334954e-02\n",
      " 2.58030849e-01 1.12528350e+01], Loss = 0.4041\n",
      "Iteration 4285: Weights = [5.50000000e+01 3.68591876e+00 7.74970321e+00 2.55327624e-02\n",
      " 2.58023442e-01 1.12530700e+01], Loss = 0.4041\n",
      "Iteration 4286: Weights = [5.50000000e+01 3.68581295e+00 7.74948075e+00 2.55320294e-02\n",
      " 2.58016035e-01 1.12533050e+01], Loss = 0.4040\n",
      "Iteration 4287: Weights = [5.50000000e+01 3.68570715e+00 7.74925829e+00 2.55312965e-02\n",
      " 2.58008628e-01 1.12535401e+01], Loss = 0.4040\n",
      "Iteration 4288: Weights = [5.50000000e+01 3.68560134e+00 7.74903584e+00 2.55305636e-02\n",
      " 2.58001221e-01 1.12537751e+01], Loss = 0.4040\n",
      "Iteration 4289: Weights = [5.50000000e+01 3.68549554e+00 7.74881339e+00 2.55298307e-02\n",
      " 2.57993815e-01 1.12540101e+01], Loss = 0.4040\n",
      "Iteration 4290: Weights = [5.50000000e+01 3.68538975e+00 7.74859095e+00 2.55290979e-02\n",
      " 2.57986409e-01 1.12542451e+01], Loss = 0.4039\n",
      "Iteration 4291: Weights = [5.50000000e+01 3.68528395e+00 7.74836852e+00 2.55283650e-02\n",
      " 2.57979003e-01 1.12544801e+01], Loss = 0.4039\n",
      "Iteration 4292: Weights = [5.50000000e+01 3.68517816e+00 7.74814609e+00 2.55276322e-02\n",
      " 2.57971598e-01 1.12547151e+01], Loss = 0.4039\n",
      "Iteration 4293: Weights = [5.50000000e+01 3.68507237e+00 7.74792367e+00 2.55268994e-02\n",
      " 2.57964192e-01 1.12549501e+01], Loss = 0.4039\n",
      "Iteration 4294: Weights = [5.50000000e+01 3.68496659e+00 7.74770125e+00 2.55261666e-02\n",
      " 2.57956787e-01 1.12551850e+01], Loss = 0.4038\n",
      "Iteration 4295: Weights = [5.50000000e+01 3.68486081e+00 7.74747885e+00 2.55254338e-02\n",
      " 2.57949382e-01 1.12554200e+01], Loss = 0.4038\n",
      "Iteration 4296: Weights = [5.50000000e+01 3.68475503e+00 7.74725645e+00 2.55247011e-02\n",
      " 2.57941977e-01 1.12556550e+01], Loss = 0.4038\n",
      "Iteration 4297: Weights = [5.50000000e+01 3.68464925e+00 7.74703405e+00 2.55239684e-02\n",
      " 2.57934573e-01 1.12558899e+01], Loss = 0.4038\n",
      "Iteration 4298: Weights = [5.50000000e+01 3.68454348e+00 7.74681166e+00 2.55232357e-02\n",
      " 2.57927168e-01 1.12561249e+01], Loss = 0.4037\n",
      "Iteration 4299: Weights = [5.50000000e+01 3.68443771e+00 7.74658928e+00 2.55225030e-02\n",
      " 2.57919764e-01 1.12563598e+01], Loss = 0.4037\n",
      "Iteration 4300: Weights = [5.50000000e+01 3.68433194e+00 7.74636690e+00 2.55217703e-02\n",
      " 2.57912360e-01 1.12565948e+01], Loss = 0.4037\n",
      "Iteration 4301: Weights = [5.50000000e+01 3.68422618e+00 7.74614453e+00 2.55210377e-02\n",
      " 2.57904957e-01 1.12568297e+01], Loss = 0.4037\n",
      "Iteration 4302: Weights = [5.50000000e+01 3.68412042e+00 7.74592217e+00 2.55203051e-02\n",
      " 2.57897553e-01 1.12570646e+01], Loss = 0.4037\n",
      "Iteration 4303: Weights = [5.50000000e+01 3.68401466e+00 7.74569981e+00 2.55195725e-02\n",
      " 2.57890150e-01 1.12572995e+01], Loss = 0.4036\n",
      "Iteration 4304: Weights = [5.50000000e+01 3.68390891e+00 7.74547746e+00 2.55188399e-02\n",
      " 2.57882747e-01 1.12575344e+01], Loss = 0.4036\n",
      "Iteration 4305: Weights = [5.50000000e+01 3.68380316e+00 7.74525512e+00 2.55181074e-02\n",
      " 2.57875344e-01 1.12577693e+01], Loss = 0.4036\n",
      "Iteration 4306: Weights = [5.50000000e+01 3.68369741e+00 7.74503278e+00 2.55173748e-02\n",
      " 2.57867941e-01 1.12580042e+01], Loss = 0.4036\n",
      "Iteration 4307: Weights = [5.50000000e+01 3.68359166e+00 7.74481045e+00 2.55166423e-02\n",
      " 2.57860539e-01 1.12582391e+01], Loss = 0.4035\n",
      "Iteration 4308: Weights = [5.50000000e+01 3.68348592e+00 7.74458813e+00 2.55159098e-02\n",
      " 2.57853137e-01 1.12584740e+01], Loss = 0.4035\n",
      "Iteration 4309: Weights = [5.50000000e+01 3.68338018e+00 7.74436581e+00 2.55151774e-02\n",
      " 2.57845735e-01 1.12587089e+01], Loss = 0.4035\n",
      "Iteration 4310: Weights = [5.50000000e+01 3.68327445e+00 7.74414349e+00 2.55144449e-02\n",
      " 2.57838333e-01 1.12589438e+01], Loss = 0.4035\n",
      "Iteration 4311: Weights = [5.50000000e+01 3.68316871e+00 7.74392119e+00 2.55137125e-02\n",
      " 2.57830931e-01 1.12591786e+01], Loss = 0.4034\n",
      "Iteration 4312: Weights = [5.50000000e+01 3.68306298e+00 7.74369889e+00 2.55129801e-02\n",
      " 2.57823530e-01 1.12594135e+01], Loss = 0.4034\n",
      "Iteration 4313: Weights = [5.50000000e+01 3.68295726e+00 7.74347660e+00 2.55122477e-02\n",
      " 2.57816129e-01 1.12596483e+01], Loss = 0.4034\n",
      "Iteration 4314: Weights = [5.50000000e+01 3.68285153e+00 7.74325431e+00 2.55115154e-02\n",
      " 2.57808728e-01 1.12598832e+01], Loss = 0.4034\n",
      "Iteration 4315: Weights = [5.50000000e+01 3.68274581e+00 7.74303203e+00 2.55107830e-02\n",
      " 2.57801327e-01 1.12601180e+01], Loss = 0.4034\n",
      "Iteration 4316: Weights = [5.50000000e+01 3.68264009e+00 7.74280976e+00 2.55100507e-02\n",
      " 2.57793926e-01 1.12603528e+01], Loss = 0.4033\n",
      "Iteration 4317: Weights = [5.50000000e+01 3.68253438e+00 7.74258749e+00 2.55093184e-02\n",
      " 2.57786526e-01 1.12605876e+01], Loss = 0.4033\n",
      "Iteration 4318: Weights = [5.50000000e+01 3.68242866e+00 7.74236523e+00 2.55085861e-02\n",
      " 2.57779126e-01 1.12608225e+01], Loss = 0.4033\n",
      "Iteration 4319: Weights = [5.50000000e+01 3.68232296e+00 7.74214297e+00 2.55078539e-02\n",
      " 2.57771726e-01 1.12610573e+01], Loss = 0.4033\n",
      "Iteration 4320: Weights = [5.50000000e+01 3.68221725e+00 7.74192072e+00 2.55071216e-02\n",
      " 2.57764326e-01 1.12612921e+01], Loss = 0.4032\n",
      "Iteration 4321: Weights = [5.50000000e+01 3.68211155e+00 7.74169848e+00 2.55063894e-02\n",
      " 2.57756927e-01 1.12615269e+01], Loss = 0.4032\n",
      "Iteration 4322: Weights = [5.50000000e+01 3.68200585e+00 7.74147625e+00 2.55056572e-02\n",
      " 2.57749528e-01 1.12617617e+01], Loss = 0.4032\n",
      "Iteration 4323: Weights = [5.50000000e+01 3.68190015e+00 7.74125402e+00 2.55049250e-02\n",
      " 2.57742129e-01 1.12619964e+01], Loss = 0.4032\n",
      "Iteration 4324: Weights = [5.50000000e+01 3.68179446e+00 7.74103179e+00 2.55041929e-02\n",
      " 2.57734730e-01 1.12622312e+01], Loss = 0.4031\n",
      "Iteration 4325: Weights = [5.50000000e+01 3.68168877e+00 7.74080958e+00 2.55034608e-02\n",
      " 2.57727331e-01 1.12624660e+01], Loss = 0.4031\n",
      "Iteration 4326: Weights = [5.50000000e+01 3.68158308e+00 7.74058737e+00 2.55027286e-02\n",
      " 2.57719933e-01 1.12627007e+01], Loss = 0.4031\n",
      "Iteration 4327: Weights = [5.50000000e+01 3.68147739e+00 7.74036516e+00 2.55019966e-02\n",
      " 2.57712535e-01 1.12629355e+01], Loss = 0.4031\n",
      "Iteration 4328: Weights = [5.50000000e+01 3.68137171e+00 7.74014297e+00 2.55012645e-02\n",
      " 2.57705137e-01 1.12631702e+01], Loss = 0.4031\n",
      "Iteration 4329: Weights = [5.50000000e+01 3.68126603e+00 7.73992078e+00 2.55005324e-02\n",
      " 2.57697739e-01 1.12634050e+01], Loss = 0.4030\n",
      "Iteration 4330: Weights = [5.50000000e+01 3.68116036e+00 7.73969859e+00 2.54998004e-02\n",
      " 2.57690341e-01 1.12636397e+01], Loss = 0.4030\n",
      "Iteration 4331: Weights = [5.50000000e+01 3.68105469e+00 7.73947641e+00 2.54990684e-02\n",
      " 2.57682944e-01 1.12638744e+01], Loss = 0.4030\n",
      "Iteration 4332: Weights = [5.50000000e+01 3.68094902e+00 7.73925424e+00 2.54983364e-02\n",
      " 2.57675547e-01 1.12641092e+01], Loss = 0.4030\n",
      "Iteration 4333: Weights = [5.50000000e+01 3.68084335e+00 7.73903208e+00 2.54976045e-02\n",
      " 2.57668150e-01 1.12643439e+01], Loss = 0.4029\n",
      "Iteration 4334: Weights = [5.50000000e+01 3.68073769e+00 7.73880992e+00 2.54968725e-02\n",
      " 2.57660753e-01 1.12645786e+01], Loss = 0.4029\n",
      "Iteration 4335: Weights = [5.50000000e+01 3.68063203e+00 7.73858776e+00 2.54961406e-02\n",
      " 2.57653357e-01 1.12648133e+01], Loss = 0.4029\n",
      "Iteration 4336: Weights = [5.50000000e+01 3.68052637e+00 7.73836562e+00 2.54954087e-02\n",
      " 2.57645961e-01 1.12650480e+01], Loss = 0.4029\n",
      "Iteration 4337: Weights = [5.50000000e+01 3.68042071e+00 7.73814348e+00 2.54946768e-02\n",
      " 2.57638564e-01 1.12652827e+01], Loss = 0.4028\n",
      "Iteration 4338: Weights = [5.50000000e+01 3.68031506e+00 7.73792134e+00 2.54939450e-02\n",
      " 2.57631169e-01 1.12655174e+01], Loss = 0.4028\n",
      "Iteration 4339: Weights = [5.50000000e+01 3.68020941e+00 7.73769922e+00 2.54932131e-02\n",
      " 2.57623773e-01 1.12657520e+01], Loss = 0.4028\n",
      "Iteration 4340: Weights = [5.50000000e+01 3.68010377e+00 7.73747710e+00 2.54924813e-02\n",
      " 2.57616378e-01 1.12659867e+01], Loss = 0.4028\n",
      "Iteration 4341: Weights = [5.50000000e+01 3.67999813e+00 7.73725498e+00 2.54917495e-02\n",
      " 2.57608982e-01 1.12662214e+01], Loss = 0.4028\n",
      "Iteration 4342: Weights = [5.50000000e+01 3.67989249e+00 7.73703287e+00 2.54910177e-02\n",
      " 2.57601587e-01 1.12664560e+01], Loss = 0.4027\n",
      "Iteration 4343: Weights = [5.50000000e+01 3.67978685e+00 7.73681077e+00 2.54902860e-02\n",
      " 2.57594193e-01 1.12666907e+01], Loss = 0.4027\n",
      "Iteration 4344: Weights = [5.50000000e+01 3.67968122e+00 7.73658868e+00 2.54895542e-02\n",
      " 2.57586798e-01 1.12669253e+01], Loss = 0.4027\n",
      "Iteration 4345: Weights = [5.50000000e+01 3.67957559e+00 7.73636659e+00 2.54888225e-02\n",
      " 2.57579404e-01 1.12671599e+01], Loss = 0.4027\n",
      "Iteration 4346: Weights = [5.50000000e+01 3.67946996e+00 7.73614451e+00 2.54880908e-02\n",
      " 2.57572009e-01 1.12673946e+01], Loss = 0.4026\n",
      "Iteration 4347: Weights = [5.50000000e+01 3.67936434e+00 7.73592243e+00 2.54873592e-02\n",
      " 2.57564616e-01 1.12676292e+01], Loss = 0.4026\n",
      "Iteration 4348: Weights = [5.50000000e+01 3.67925872e+00 7.73570036e+00 2.54866275e-02\n",
      " 2.57557222e-01 1.12678638e+01], Loss = 0.4026\n",
      "Iteration 4349: Weights = [5.50000000e+01 3.67915310e+00 7.73547830e+00 2.54858959e-02\n",
      " 2.57549828e-01 1.12680984e+01], Loss = 0.4026\n",
      "Iteration 4350: Weights = [5.50000000e+01 3.67904748e+00 7.73525624e+00 2.54851643e-02\n",
      " 2.57542435e-01 1.12683330e+01], Loss = 0.4025\n",
      "Iteration 4351: Weights = [5.50000000e+01 3.67894187e+00 7.73503419e+00 2.54844327e-02\n",
      " 2.57535042e-01 1.12685676e+01], Loss = 0.4025\n",
      "Iteration 4352: Weights = [5.50000000e+01 3.67883626e+00 7.73481214e+00 2.54837011e-02\n",
      " 2.57527649e-01 1.12688022e+01], Loss = 0.4025\n",
      "Iteration 4353: Weights = [5.50000000e+01 3.67873066e+00 7.73459011e+00 2.54829696e-02\n",
      " 2.57520256e-01 1.12690368e+01], Loss = 0.4025\n",
      "Iteration 4354: Weights = [5.50000000e+01 3.67862505e+00 7.73436807e+00 2.54822381e-02\n",
      " 2.57512864e-01 1.12692713e+01], Loss = 0.4025\n",
      "Iteration 4355: Weights = [5.50000000e+01 3.67851945e+00 7.73414605e+00 2.54815066e-02\n",
      " 2.57505472e-01 1.12695059e+01], Loss = 0.4024\n",
      "Iteration 4356: Weights = [5.50000000e+01 3.67841386e+00 7.73392403e+00 2.54807751e-02\n",
      " 2.57498080e-01 1.12697405e+01], Loss = 0.4024\n",
      "Iteration 4357: Weights = [5.50000000e+01 3.67830826e+00 7.73370202e+00 2.54800436e-02\n",
      " 2.57490688e-01 1.12699750e+01], Loss = 0.4024\n",
      "Iteration 4358: Weights = [5.50000000e+01 3.67820267e+00 7.73348001e+00 2.54793122e-02\n",
      " 2.57483296e-01 1.12702095e+01], Loss = 0.4024\n",
      "Iteration 4359: Weights = [5.50000000e+01 3.67809709e+00 7.73325801e+00 2.54785808e-02\n",
      " 2.57475905e-01 1.12704441e+01], Loss = 0.4023\n",
      "Iteration 4360: Weights = [5.50000000e+01 3.67799150e+00 7.73303602e+00 2.54778494e-02\n",
      " 2.57468514e-01 1.12706786e+01], Loss = 0.4023\n",
      "Iteration 4361: Weights = [5.50000000e+01 3.67788592e+00 7.73281403e+00 2.54771180e-02\n",
      " 2.57461123e-01 1.12709131e+01], Loss = 0.4023\n",
      "Iteration 4362: Weights = [5.50000000e+01 3.67778034e+00 7.73259205e+00 2.54763867e-02\n",
      " 2.57453732e-01 1.12711477e+01], Loss = 0.4023\n",
      "Iteration 4363: Weights = [5.50000000e+01 3.67767477e+00 7.73237008e+00 2.54756553e-02\n",
      " 2.57446341e-01 1.12713822e+01], Loss = 0.4022\n",
      "Iteration 4364: Weights = [5.50000000e+01 3.67756919e+00 7.73214811e+00 2.54749240e-02\n",
      " 2.57438951e-01 1.12716167e+01], Loss = 0.4022\n",
      "Iteration 4365: Weights = [5.50000000e+01 3.67746362e+00 7.73192615e+00 2.54741927e-02\n",
      " 2.57431561e-01 1.12718512e+01], Loss = 0.4022\n",
      "Iteration 4366: Weights = [5.50000000e+01 3.67735806e+00 7.73170419e+00 2.54734615e-02\n",
      " 2.57424171e-01 1.12720857e+01], Loss = 0.4022\n",
      "Iteration 4367: Weights = [5.50000000e+01 3.67725249e+00 7.73148224e+00 2.54727302e-02\n",
      " 2.57416781e-01 1.12723202e+01], Loss = 0.4022\n",
      "Iteration 4368: Weights = [5.50000000e+01 3.67714693e+00 7.73126030e+00 2.54719990e-02\n",
      " 2.57409392e-01 1.12725546e+01], Loss = 0.4021\n",
      "Iteration 4369: Weights = [5.50000000e+01 3.67704138e+00 7.73103837e+00 2.54712678e-02\n",
      " 2.57402002e-01 1.12727891e+01], Loss = 0.4021\n",
      "Iteration 4370: Weights = [5.50000000e+01 3.67693582e+00 7.73081644e+00 2.54705366e-02\n",
      " 2.57394613e-01 1.12730236e+01], Loss = 0.4021\n",
      "Iteration 4371: Weights = [5.50000000e+01 3.67683027e+00 7.73059451e+00 2.54698054e-02\n",
      " 2.57387225e-01 1.12732580e+01], Loss = 0.4021\n",
      "Iteration 4372: Weights = [5.50000000e+01 3.67672472e+00 7.73037260e+00 2.54690743e-02\n",
      " 2.57379836e-01 1.12734925e+01], Loss = 0.4020\n",
      "Iteration 4373: Weights = [5.50000000e+01 3.67661918e+00 7.73015069e+00 2.54683432e-02\n",
      " 2.57372448e-01 1.12737269e+01], Loss = 0.4020\n",
      "Iteration 4374: Weights = [5.50000000e+01 3.67651364e+00 7.72992878e+00 2.54676121e-02\n",
      " 2.57365059e-01 1.12739614e+01], Loss = 0.4020\n",
      "Iteration 4375: Weights = [5.50000000e+01 3.67640810e+00 7.72970688e+00 2.54668810e-02\n",
      " 2.57357671e-01 1.12741958e+01], Loss = 0.4020\n",
      "Iteration 4376: Weights = [5.50000000e+01 3.67630256e+00 7.72948499e+00 2.54661499e-02\n",
      " 2.57350284e-01 1.12744302e+01], Loss = 0.4019\n",
      "Iteration 4377: Weights = [5.50000000e+01 3.67619703e+00 7.72926311e+00 2.54654189e-02\n",
      " 2.57342896e-01 1.12746646e+01], Loss = 0.4019\n",
      "Iteration 4378: Weights = [5.50000000e+01 3.67609150e+00 7.72904123e+00 2.54646879e-02\n",
      " 2.57335509e-01 1.12748991e+01], Loss = 0.4019\n",
      "Iteration 4379: Weights = [5.50000000e+01 3.67598597e+00 7.72881936e+00 2.54639569e-02\n",
      " 2.57328121e-01 1.12751335e+01], Loss = 0.4019\n",
      "Iteration 4380: Weights = [5.50000000e+01 3.67588045e+00 7.72859749e+00 2.54632259e-02\n",
      " 2.57320734e-01 1.12753679e+01], Loss = 0.4019\n",
      "Iteration 4381: Weights = [5.50000000e+01 3.67577492e+00 7.72837563e+00 2.54624949e-02\n",
      " 2.57313348e-01 1.12756022e+01], Loss = 0.4018\n",
      "Iteration 4382: Weights = [5.50000000e+01 3.67566941e+00 7.72815378e+00 2.54617640e-02\n",
      " 2.57305961e-01 1.12758366e+01], Loss = 0.4018\n",
      "Iteration 4383: Weights = [5.50000000e+01 3.67556389e+00 7.72793193e+00 2.54610331e-02\n",
      " 2.57298575e-01 1.12760710e+01], Loss = 0.4018\n",
      "Iteration 4384: Weights = [5.50000000e+01 3.67545838e+00 7.72771009e+00 2.54603022e-02\n",
      " 2.57291189e-01 1.12763054e+01], Loss = 0.4018\n",
      "Iteration 4385: Weights = [5.50000000e+01 3.67535287e+00 7.72748826e+00 2.54595713e-02\n",
      " 2.57283803e-01 1.12765397e+01], Loss = 0.4017\n",
      "Iteration 4386: Weights = [5.50000000e+01 3.67524737e+00 7.72726643e+00 2.54588405e-02\n",
      " 2.57276417e-01 1.12767741e+01], Loss = 0.4017\n",
      "Iteration 4387: Weights = [5.50000000e+01 3.67514186e+00 7.72704461e+00 2.54581096e-02\n",
      " 2.57269032e-01 1.12770085e+01], Loss = 0.4017\n",
      "Iteration 4388: Weights = [5.50000000e+01 3.67503636e+00 7.72682279e+00 2.54573788e-02\n",
      " 2.57261647e-01 1.12772428e+01], Loss = 0.4017\n",
      "Iteration 4389: Weights = [5.50000000e+01 3.67493087e+00 7.72660099e+00 2.54566480e-02\n",
      " 2.57254262e-01 1.12774771e+01], Loss = 0.4016\n",
      "Iteration 4390: Weights = [5.50000000e+01 3.67482537e+00 7.72637918e+00 2.54559173e-02\n",
      " 2.57246877e-01 1.12777115e+01], Loss = 0.4016\n",
      "Iteration 4391: Weights = [5.50000000e+01 3.67471988e+00 7.72615739e+00 2.54551865e-02\n",
      " 2.57239492e-01 1.12779458e+01], Loss = 0.4016\n",
      "Iteration 4392: Weights = [5.50000000e+01 3.67461439e+00 7.72593560e+00 2.54544558e-02\n",
      " 2.57232108e-01 1.12781801e+01], Loss = 0.4016\n",
      "Iteration 4393: Weights = [5.50000000e+01 3.67450891e+00 7.72571381e+00 2.54537251e-02\n",
      " 2.57224724e-01 1.12784144e+01], Loss = 0.4016\n",
      "Iteration 4394: Weights = [5.50000000e+01 3.67440343e+00 7.72549204e+00 2.54529944e-02\n",
      " 2.57217340e-01 1.12786487e+01], Loss = 0.4015\n",
      "Iteration 4395: Weights = [5.50000000e+01 3.67429795e+00 7.72527027e+00 2.54522638e-02\n",
      " 2.57209956e-01 1.12788830e+01], Loss = 0.4015\n",
      "Iteration 4396: Weights = [5.50000000e+01 3.67419247e+00 7.72504850e+00 2.54515331e-02\n",
      " 2.57202572e-01 1.12791173e+01], Loss = 0.4015\n",
      "Iteration 4397: Weights = [5.50000000e+01 3.67408700e+00 7.72482675e+00 2.54508025e-02\n",
      " 2.57195189e-01 1.12793516e+01], Loss = 0.4015\n",
      "Iteration 4398: Weights = [5.50000000e+01 3.67398153e+00 7.72460499e+00 2.54500719e-02\n",
      " 2.57187806e-01 1.12795859e+01], Loss = 0.4014\n",
      "Iteration 4399: Weights = [5.50000000e+01 3.67387607e+00 7.72438325e+00 2.54493413e-02\n",
      " 2.57180423e-01 1.12798201e+01], Loss = 0.4014\n",
      "Iteration 4400: Weights = [5.50000000e+01 3.67377060e+00 7.72416151e+00 2.54486108e-02\n",
      " 2.57173040e-01 1.12800544e+01], Loss = 0.4014\n",
      "Iteration 4401: Weights = [5.50000000e+01 3.67366514e+00 7.72393978e+00 2.54478802e-02\n",
      " 2.57165658e-01 1.12802887e+01], Loss = 0.4014\n",
      "Iteration 4402: Weights = [5.50000000e+01 3.67355968e+00 7.72371805e+00 2.54471497e-02\n",
      " 2.57158275e-01 1.12805229e+01], Loss = 0.4013\n",
      "Iteration 4403: Weights = [5.50000000e+01 3.67345423e+00 7.72349633e+00 2.54464192e-02\n",
      " 2.57150893e-01 1.12807571e+01], Loss = 0.4013\n",
      "Iteration 4404: Weights = [5.50000000e+01 3.67334878e+00 7.72327462e+00 2.54456887e-02\n",
      " 2.57143512e-01 1.12809914e+01], Loss = 0.4013\n",
      "Iteration 4405: Weights = [5.50000000e+01 3.67324333e+00 7.72305291e+00 2.54449583e-02\n",
      " 2.57136130e-01 1.12812256e+01], Loss = 0.4013\n",
      "Iteration 4406: Weights = [5.50000000e+01 3.67313789e+00 7.72283121e+00 2.54442279e-02\n",
      " 2.57128748e-01 1.12814598e+01], Loss = 0.4013\n",
      "Iteration 4407: Weights = [5.50000000e+01 3.67303244e+00 7.72260952e+00 2.54434975e-02\n",
      " 2.57121367e-01 1.12816941e+01], Loss = 0.4012\n",
      "Iteration 4408: Weights = [5.50000000e+01 3.67292700e+00 7.72238783e+00 2.54427671e-02\n",
      " 2.57113986e-01 1.12819283e+01], Loss = 0.4012\n",
      "Iteration 4409: Weights = [5.50000000e+01 3.67282157e+00 7.72216615e+00 2.54420367e-02\n",
      " 2.57106605e-01 1.12821625e+01], Loss = 0.4012\n",
      "Iteration 4410: Weights = [5.50000000e+01 3.67271613e+00 7.72194448e+00 2.54413064e-02\n",
      " 2.57099225e-01 1.12823967e+01], Loss = 0.4012\n",
      "Iteration 4411: Weights = [5.50000000e+01 3.67261070e+00 7.72172281e+00 2.54405760e-02\n",
      " 2.57091844e-01 1.12826308e+01], Loss = 0.4011\n",
      "Iteration 4412: Weights = [5.50000000e+01 3.67250528e+00 7.72150115e+00 2.54398457e-02\n",
      " 2.57084464e-01 1.12828650e+01], Loss = 0.4011\n",
      "Iteration 4413: Weights = [5.50000000e+01 3.67239985e+00 7.72127949e+00 2.54391154e-02\n",
      " 2.57077084e-01 1.12830992e+01], Loss = 0.4011\n",
      "Iteration 4414: Weights = [5.50000000e+01 3.67229443e+00 7.72105784e+00 2.54383852e-02\n",
      " 2.57069705e-01 1.12833334e+01], Loss = 0.4011\n",
      "Iteration 4415: Weights = [5.50000000e+01 3.67218901e+00 7.72083620e+00 2.54376549e-02\n",
      " 2.57062325e-01 1.12835675e+01], Loss = 0.4010\n",
      "Iteration 4416: Weights = [5.50000000e+01 3.67208360e+00 7.72061456e+00 2.54369247e-02\n",
      " 2.57054946e-01 1.12838017e+01], Loss = 0.4010\n",
      "Iteration 4417: Weights = [5.50000000e+01 3.67197819e+00 7.72039293e+00 2.54361945e-02\n",
      " 2.57047567e-01 1.12840358e+01], Loss = 0.4010\n",
      "Iteration 4418: Weights = [5.50000000e+01 3.67187278e+00 7.72017131e+00 2.54354643e-02\n",
      " 2.57040188e-01 1.12842700e+01], Loss = 0.4010\n",
      "Iteration 4419: Weights = [5.50000000e+01 3.67176737e+00 7.71994969e+00 2.54347342e-02\n",
      " 2.57032809e-01 1.12845041e+01], Loss = 0.4010\n",
      "Iteration 4420: Weights = [5.50000000e+01 3.67166197e+00 7.71972808e+00 2.54340040e-02\n",
      " 2.57025431e-01 1.12847382e+01], Loss = 0.4009\n",
      "Iteration 4421: Weights = [5.50000000e+01 3.67155657e+00 7.71950647e+00 2.54332739e-02\n",
      " 2.57018052e-01 1.12849724e+01], Loss = 0.4009\n",
      "Iteration 4422: Weights = [5.50000000e+01 3.67145117e+00 7.71928487e+00 2.54325438e-02\n",
      " 2.57010674e-01 1.12852065e+01], Loss = 0.4009\n",
      "Iteration 4423: Weights = [5.50000000e+01 3.67134578e+00 7.71906328e+00 2.54318137e-02\n",
      " 2.57003297e-01 1.12854406e+01], Loss = 0.4009\n",
      "Iteration 4424: Weights = [5.50000000e+01 3.67124039e+00 7.71884170e+00 2.54310837e-02\n",
      " 2.56995919e-01 1.12856747e+01], Loss = 0.4008\n",
      "Iteration 4425: Weights = [5.50000000e+01 3.67113500e+00 7.71862012e+00 2.54303537e-02\n",
      " 2.56988542e-01 1.12859088e+01], Loss = 0.4008\n",
      "Iteration 4426: Weights = [5.50000000e+01 3.67102962e+00 7.71839854e+00 2.54296236e-02\n",
      " 2.56981164e-01 1.12861429e+01], Loss = 0.4008\n",
      "Iteration 4427: Weights = [5.50000000e+01 3.67092423e+00 7.71817698e+00 2.54288937e-02\n",
      " 2.56973787e-01 1.12863770e+01], Loss = 0.4008\n",
      "Iteration 4428: Weights = [5.50000000e+01 3.67081886e+00 7.71795542e+00 2.54281637e-02\n",
      " 2.56966411e-01 1.12866110e+01], Loss = 0.4007\n",
      "Iteration 4429: Weights = [5.50000000e+01 3.67071348e+00 7.71773386e+00 2.54274337e-02\n",
      " 2.56959034e-01 1.12868451e+01], Loss = 0.4007\n",
      "Iteration 4430: Weights = [5.50000000e+01 3.67060811e+00 7.71751231e+00 2.54267038e-02\n",
      " 2.56951658e-01 1.12870792e+01], Loss = 0.4007\n",
      "Iteration 4431: Weights = [5.50000000e+01 3.67050274e+00 7.71729077e+00 2.54259739e-02\n",
      " 2.56944282e-01 1.12873132e+01], Loss = 0.4007\n",
      "Iteration 4432: Weights = [5.50000000e+01 3.67039737e+00 7.71706924e+00 2.54252440e-02\n",
      " 2.56936906e-01 1.12875473e+01], Loss = 0.4007\n",
      "Iteration 4433: Weights = [5.50000000e+01 3.67029201e+00 7.71684771e+00 2.54245142e-02\n",
      " 2.56929530e-01 1.12877813e+01], Loss = 0.4006\n",
      "Iteration 4434: Weights = [5.50000000e+01 3.67018665e+00 7.71662619e+00 2.54237843e-02\n",
      " 2.56922154e-01 1.12880153e+01], Loss = 0.4006\n",
      "Iteration 4435: Weights = [5.50000000e+01 3.67008129e+00 7.71640467e+00 2.54230545e-02\n",
      " 2.56914779e-01 1.12882494e+01], Loss = 0.4006\n",
      "Iteration 4436: Weights = [5.50000000e+01 3.66997593e+00 7.71618316e+00 2.54223247e-02\n",
      " 2.56907404e-01 1.12884834e+01], Loss = 0.4006\n",
      "Iteration 4437: Weights = [5.50000000e+01 3.66987058e+00 7.71596166e+00 2.54215949e-02\n",
      " 2.56900029e-01 1.12887174e+01], Loss = 0.4005\n",
      "Iteration 4438: Weights = [5.50000000e+01 3.66976523e+00 7.71574016e+00 2.54208651e-02\n",
      " 2.56892655e-01 1.12889514e+01], Loss = 0.4005\n",
      "Iteration 4439: Weights = [5.50000000e+01 3.66965989e+00 7.71551867e+00 2.54201354e-02\n",
      " 2.56885280e-01 1.12891854e+01], Loss = 0.4005\n",
      "Iteration 4440: Weights = [5.50000000e+01 3.66955455e+00 7.71529719e+00 2.54194057e-02\n",
      " 2.56877906e-01 1.12894194e+01], Loss = 0.4005\n",
      "Iteration 4441: Weights = [5.50000000e+01 3.66944921e+00 7.71507571e+00 2.54186760e-02\n",
      " 2.56870532e-01 1.12896534e+01], Loss = 0.4004\n",
      "Iteration 4442: Weights = [5.50000000e+01 3.66934387e+00 7.71485424e+00 2.54179463e-02\n",
      " 2.56863158e-01 1.12898874e+01], Loss = 0.4004\n",
      "Iteration 4443: Weights = [5.50000000e+01 3.66923854e+00 7.71463277e+00 2.54172167e-02\n",
      " 2.56855784e-01 1.12901214e+01], Loss = 0.4004\n",
      "Iteration 4444: Weights = [5.50000000e+01 3.66913321e+00 7.71441131e+00 2.54164870e-02\n",
      " 2.56848411e-01 1.12903553e+01], Loss = 0.4004\n",
      "Iteration 4445: Weights = [5.50000000e+01 3.66902788e+00 7.71418986e+00 2.54157574e-02\n",
      " 2.56841038e-01 1.12905893e+01], Loss = 0.4004\n",
      "Iteration 4446: Weights = [5.50000000e+01 3.66892256e+00 7.71396842e+00 2.54150278e-02\n",
      " 2.56833665e-01 1.12908232e+01], Loss = 0.4003\n",
      "Iteration 4447: Weights = [5.50000000e+01 3.66881723e+00 7.71374698e+00 2.54142982e-02\n",
      " 2.56826292e-01 1.12910572e+01], Loss = 0.4003\n",
      "Iteration 4448: Weights = [5.50000000e+01 3.66871192e+00 7.71352554e+00 2.54135687e-02\n",
      " 2.56818920e-01 1.12912911e+01], Loss = 0.4003\n",
      "Iteration 4449: Weights = [5.50000000e+01 3.66860660e+00 7.71330412e+00 2.54128392e-02\n",
      " 2.56811547e-01 1.12915251e+01], Loss = 0.4003\n",
      "Iteration 4450: Weights = [5.50000000e+01 3.66850129e+00 7.71308270e+00 2.54121097e-02\n",
      " 2.56804175e-01 1.12917590e+01], Loss = 0.4002\n",
      "Iteration 4451: Weights = [5.50000000e+01 3.66839598e+00 7.71286128e+00 2.54113802e-02\n",
      " 2.56796803e-01 1.12919929e+01], Loss = 0.4002\n",
      "Iteration 4452: Weights = [5.50000000e+01 3.66829067e+00 7.71263987e+00 2.54106507e-02\n",
      " 2.56789432e-01 1.12922268e+01], Loss = 0.4002\n",
      "Iteration 4453: Weights = [5.50000000e+01 3.66818537e+00 7.71241847e+00 2.54099213e-02\n",
      " 2.56782060e-01 1.12924607e+01], Loss = 0.4002\n",
      "Iteration 4454: Weights = [5.50000000e+01 3.66808007e+00 7.71219708e+00 2.54091918e-02\n",
      " 2.56774689e-01 1.12926946e+01], Loss = 0.4001\n",
      "Iteration 4455: Weights = [5.50000000e+01 3.66797477e+00 7.71197569e+00 2.54084624e-02\n",
      " 2.56767318e-01 1.12929285e+01], Loss = 0.4001\n",
      "Iteration 4456: Weights = [5.50000000e+01 3.66786948e+00 7.71175431e+00 2.54077330e-02\n",
      " 2.56759947e-01 1.12931624e+01], Loss = 0.4001\n",
      "Iteration 4457: Weights = [5.50000000e+01 3.66776419e+00 7.71153293e+00 2.54070037e-02\n",
      " 2.56752576e-01 1.12933963e+01], Loss = 0.4001\n",
      "Iteration 4458: Weights = [5.50000000e+01 3.66765890e+00 7.71131156e+00 2.54062743e-02\n",
      " 2.56745206e-01 1.12936302e+01], Loss = 0.4001\n",
      "Iteration 4459: Weights = [5.50000000e+01 3.66755362e+00 7.71109020e+00 2.54055450e-02\n",
      " 2.56737836e-01 1.12938640e+01], Loss = 0.4000\n",
      "Iteration 4460: Weights = [5.50000000e+01 3.66744833e+00 7.71086884e+00 2.54048157e-02\n",
      " 2.56730466e-01 1.12940979e+01], Loss = 0.4000\n",
      "Iteration 4461: Weights = [5.50000000e+01 3.66734305e+00 7.71064749e+00 2.54040864e-02\n",
      " 2.56723096e-01 1.12943317e+01], Loss = 0.4000\n",
      "Iteration 4462: Weights = [5.50000000e+01 3.66723778e+00 7.71042615e+00 2.54033572e-02\n",
      " 2.56715726e-01 1.12945656e+01], Loss = 0.4000\n",
      "Iteration 4463: Weights = [5.50000000e+01 3.66713251e+00 7.71020481e+00 2.54026279e-02\n",
      " 2.56708357e-01 1.12947994e+01], Loss = 0.3999\n",
      "Iteration 4464: Weights = [5.50000000e+01 3.66702724e+00 7.70998348e+00 2.54018987e-02\n",
      " 2.56700988e-01 1.12950333e+01], Loss = 0.3999\n",
      "Iteration 4465: Weights = [5.50000000e+01 3.66692197e+00 7.70976215e+00 2.54011695e-02\n",
      " 2.56693619e-01 1.12952671e+01], Loss = 0.3999\n",
      "Iteration 4466: Weights = [5.50000000e+01 3.66681671e+00 7.70954083e+00 2.54004404e-02\n",
      " 2.56686250e-01 1.12955009e+01], Loss = 0.3999\n",
      "Iteration 4467: Weights = [5.50000000e+01 3.66671145e+00 7.70931952e+00 2.53997112e-02\n",
      " 2.56678882e-01 1.12957347e+01], Loss = 0.3999\n",
      "Iteration 4468: Weights = [5.50000000e+01 3.66660619e+00 7.70909821e+00 2.53989821e-02\n",
      " 2.56671513e-01 1.12959685e+01], Loss = 0.3998\n",
      "Iteration 4469: Weights = [5.50000000e+01 3.66650093e+00 7.70887691e+00 2.53982530e-02\n",
      " 2.56664145e-01 1.12962023e+01], Loss = 0.3998\n",
      "Iteration 4470: Weights = [5.50000000e+01 3.66639568e+00 7.70865562e+00 2.53975239e-02\n",
      " 2.56656777e-01 1.12964361e+01], Loss = 0.3998\n",
      "Iteration 4471: Weights = [5.50000000e+01 3.66629043e+00 7.70843433e+00 2.53967948e-02\n",
      " 2.56649410e-01 1.12966699e+01], Loss = 0.3998\n",
      "Iteration 4472: Weights = [5.50000000e+01 3.66618519e+00 7.70821305e+00 2.53960658e-02\n",
      " 2.56642042e-01 1.12969037e+01], Loss = 0.3997\n",
      "Iteration 4473: Weights = [5.50000000e+01 3.66607994e+00 7.70799178e+00 2.53953367e-02\n",
      " 2.56634675e-01 1.12971375e+01], Loss = 0.3997\n",
      "Iteration 4474: Weights = [5.50000000e+01 3.66597470e+00 7.70777051e+00 2.53946077e-02\n",
      " 2.56627308e-01 1.12973712e+01], Loss = 0.3997\n",
      "Iteration 4475: Weights = [5.50000000e+01 3.66586947e+00 7.70754925e+00 2.53938787e-02\n",
      " 2.56619941e-01 1.12976050e+01], Loss = 0.3997\n",
      "Iteration 4476: Weights = [5.50000000e+01 3.66576423e+00 7.70732799e+00 2.53931498e-02\n",
      " 2.56612575e-01 1.12978387e+01], Loss = 0.3996\n",
      "Iteration 4477: Weights = [5.50000000e+01 3.66565900e+00 7.70710675e+00 2.53924208e-02\n",
      " 2.56605208e-01 1.12980725e+01], Loss = 0.3996\n",
      "Iteration 4478: Weights = [5.50000000e+01 3.66555378e+00 7.70688550e+00 2.53916919e-02\n",
      " 2.56597842e-01 1.12983062e+01], Loss = 0.3996\n",
      "Iteration 4479: Weights = [5.50000000e+01 3.66544855e+00 7.70666427e+00 2.53909630e-02\n",
      " 2.56590476e-01 1.12985400e+01], Loss = 0.3996\n",
      "Iteration 4480: Weights = [5.50000000e+01 3.66534333e+00 7.70644304e+00 2.53902341e-02\n",
      " 2.56583110e-01 1.12987737e+01], Loss = 0.3996\n",
      "Iteration 4481: Weights = [5.50000000e+01 3.66523811e+00 7.70622181e+00 2.53895053e-02\n",
      " 2.56575745e-01 1.12990074e+01], Loss = 0.3995\n",
      "Iteration 4482: Weights = [5.50000000e+01 3.66513290e+00 7.70600060e+00 2.53887764e-02\n",
      " 2.56568379e-01 1.12992411e+01], Loss = 0.3995\n",
      "Iteration 4483: Weights = [5.50000000e+01 3.66502768e+00 7.70577939e+00 2.53880476e-02\n",
      " 2.56561014e-01 1.12994748e+01], Loss = 0.3995\n",
      "Iteration 4484: Weights = [5.50000000e+01 3.66492247e+00 7.70555818e+00 2.53873188e-02\n",
      " 2.56553649e-01 1.12997085e+01], Loss = 0.3995\n",
      "Iteration 4485: Weights = [5.50000000e+01 3.66481727e+00 7.70533698e+00 2.53865900e-02\n",
      " 2.56546285e-01 1.12999422e+01], Loss = 0.3994\n",
      "Iteration 4486: Weights = [5.50000000e+01 3.66471206e+00 7.70511579e+00 2.53858613e-02\n",
      " 2.56538920e-01 1.13001759e+01], Loss = 0.3994\n",
      "Iteration 4487: Weights = [5.50000000e+01 3.66460686e+00 7.70489461e+00 2.53851325e-02\n",
      " 2.56531556e-01 1.13004096e+01], Loss = 0.3994\n",
      "Iteration 4488: Weights = [5.50000000e+01 3.66450167e+00 7.70467343e+00 2.53844038e-02\n",
      " 2.56524192e-01 1.13006432e+01], Loss = 0.3994\n",
      "Iteration 4489: Weights = [5.50000000e+01 3.66439647e+00 7.70445225e+00 2.53836751e-02\n",
      " 2.56516828e-01 1.13008769e+01], Loss = 0.3993\n",
      "Iteration 4490: Weights = [5.50000000e+01 3.66429128e+00 7.70423109e+00 2.53829465e-02\n",
      " 2.56509464e-01 1.13011106e+01], Loss = 0.3993\n",
      "Iteration 4491: Weights = [5.50000000e+01 3.66418609e+00 7.70400993e+00 2.53822178e-02\n",
      " 2.56502101e-01 1.13013442e+01], Loss = 0.3993\n",
      "Iteration 4492: Weights = [5.50000000e+01 3.66408091e+00 7.70378877e+00 2.53814892e-02\n",
      " 2.56494738e-01 1.13015779e+01], Loss = 0.3993\n",
      "Iteration 4493: Weights = [5.50000000e+01 3.66397573e+00 7.70356763e+00 2.53807606e-02\n",
      " 2.56487375e-01 1.13018115e+01], Loss = 0.3993\n",
      "Iteration 4494: Weights = [5.50000000e+01 3.66387055e+00 7.70334649e+00 2.53800320e-02\n",
      " 2.56480012e-01 1.13020451e+01], Loss = 0.3992\n",
      "Iteration 4495: Weights = [5.50000000e+01 3.66376537e+00 7.70312535e+00 2.53793034e-02\n",
      " 2.56472649e-01 1.13022788e+01], Loss = 0.3992\n",
      "Iteration 4496: Weights = [5.50000000e+01 3.66366020e+00 7.70290422e+00 2.53785749e-02\n",
      " 2.56465287e-01 1.13025124e+01], Loss = 0.3992\n",
      "Iteration 4497: Weights = [5.50000000e+01 3.66355503e+00 7.70268310e+00 2.53778464e-02\n",
      " 2.56457925e-01 1.13027460e+01], Loss = 0.3992\n",
      "Iteration 4498: Weights = [5.50000000e+01 3.66344986e+00 7.70246198e+00 2.53771178e-02\n",
      " 2.56450563e-01 1.13029796e+01], Loss = 0.3991\n",
      "Iteration 4499: Weights = [5.50000000e+01 3.66334470e+00 7.70224088e+00 2.53763894e-02\n",
      " 2.56443201e-01 1.13032132e+01], Loss = 0.3991\n",
      "Iteration 4500: Weights = [5.50000000e+01 3.66323953e+00 7.70201977e+00 2.53756609e-02\n",
      " 2.56435839e-01 1.13034468e+01], Loss = 0.3991\n",
      "Iteration 4501: Weights = [5.50000000e+01 3.66313438e+00 7.70179868e+00 2.53749325e-02\n",
      " 2.56428478e-01 1.13036804e+01], Loss = 0.3991\n",
      "Iteration 4502: Weights = [5.50000000e+01 3.66302922e+00 7.70157759e+00 2.53742040e-02\n",
      " 2.56421117e-01 1.13039140e+01], Loss = 0.3990\n",
      "Iteration 4503: Weights = [5.50000000e+01 3.66292407e+00 7.70135650e+00 2.53734756e-02\n",
      " 2.56413756e-01 1.13041475e+01], Loss = 0.3990\n",
      "Iteration 4504: Weights = [5.50000000e+01 3.66281892e+00 7.70113542e+00 2.53727473e-02\n",
      " 2.56406395e-01 1.13043811e+01], Loss = 0.3990\n",
      "Iteration 4505: Weights = [5.50000000e+01 3.66271377e+00 7.70091435e+00 2.53720189e-02\n",
      " 2.56399035e-01 1.13046146e+01], Loss = 0.3990\n",
      "Iteration 4506: Weights = [5.50000000e+01 3.66260863e+00 7.70069329e+00 2.53712906e-02\n",
      " 2.56391675e-01 1.13048482e+01], Loss = 0.3990\n",
      "Iteration 4507: Weights = [5.50000000e+01 3.66250349e+00 7.70047223e+00 2.53705623e-02\n",
      " 2.56384315e-01 1.13050817e+01], Loss = 0.3989\n",
      "Iteration 4508: Weights = [5.50000000e+01 3.66239835e+00 7.70025118e+00 2.53698340e-02\n",
      " 2.56376955e-01 1.13053153e+01], Loss = 0.3989\n",
      "Iteration 4509: Weights = [5.50000000e+01 3.66229322e+00 7.70003013e+00 2.53691057e-02\n",
      " 2.56369595e-01 1.13055488e+01], Loss = 0.3989\n",
      "Iteration 4510: Weights = [5.50000000e+01 3.66218809e+00 7.69980909e+00 2.53683774e-02\n",
      " 2.56362236e-01 1.13057823e+01], Loss = 0.3989\n",
      "Iteration 4511: Weights = [5.50000000e+01 3.66208296e+00 7.69958806e+00 2.53676492e-02\n",
      " 2.56354876e-01 1.13060159e+01], Loss = 0.3988\n",
      "Iteration 4512: Weights = [5.50000000e+01 3.66197784e+00 7.69936703e+00 2.53669210e-02\n",
      " 2.56347517e-01 1.13062494e+01], Loss = 0.3988\n",
      "Iteration 4513: Weights = [5.50000000e+01 3.66187271e+00 7.69914601e+00 2.53661928e-02\n",
      " 2.56340159e-01 1.13064829e+01], Loss = 0.3988\n",
      "Iteration 4514: Weights = [5.50000000e+01 3.66176760e+00 7.69892500e+00 2.53654646e-02\n",
      " 2.56332800e-01 1.13067164e+01], Loss = 0.3988\n",
      "Iteration 4515: Weights = [5.50000000e+01 3.66166248e+00 7.69870399e+00 2.53647365e-02\n",
      " 2.56325442e-01 1.13069499e+01], Loss = 0.3988\n",
      "Iteration 4516: Weights = [5.50000000e+01 3.66155737e+00 7.69848299e+00 2.53640083e-02\n",
      " 2.56318083e-01 1.13071833e+01], Loss = 0.3987\n",
      "Iteration 4517: Weights = [5.50000000e+01 3.66145226e+00 7.69826199e+00 2.53632802e-02\n",
      " 2.56310726e-01 1.13074168e+01], Loss = 0.3987\n",
      "Iteration 4518: Weights = [5.50000000e+01 3.66134715e+00 7.69804101e+00 2.53625522e-02\n",
      " 2.56303368e-01 1.13076503e+01], Loss = 0.3987\n",
      "Iteration 4519: Weights = [5.50000000e+01 3.66124205e+00 7.69782002e+00 2.53618241e-02\n",
      " 2.56296010e-01 1.13078838e+01], Loss = 0.3987\n",
      "Iteration 4520: Weights = [5.50000000e+01 3.66113695e+00 7.69759905e+00 2.53610960e-02\n",
      " 2.56288653e-01 1.13081172e+01], Loss = 0.3986\n",
      "Iteration 4521: Weights = [5.50000000e+01 3.66103185e+00 7.69737808e+00 2.53603680e-02\n",
      " 2.56281296e-01 1.13083507e+01], Loss = 0.3986\n",
      "Iteration 4522: Weights = [5.50000000e+01 3.66092675e+00 7.69715711e+00 2.53596400e-02\n",
      " 2.56273939e-01 1.13085841e+01], Loss = 0.3986\n",
      "Iteration 4523: Weights = [5.50000000e+01 3.66082166e+00 7.69693616e+00 2.53589120e-02\n",
      " 2.56266582e-01 1.13088175e+01], Loss = 0.3986\n",
      "Iteration 4524: Weights = [5.50000000e+01 3.66071657e+00 7.69671521e+00 2.53581841e-02\n",
      " 2.56259226e-01 1.13090510e+01], Loss = 0.3985\n",
      "Iteration 4525: Weights = [5.50000000e+01 3.66061149e+00 7.69649426e+00 2.53574561e-02\n",
      " 2.56251870e-01 1.13092844e+01], Loss = 0.3985\n",
      "Iteration 4526: Weights = [5.50000000e+01 3.66050640e+00 7.69627332e+00 2.53567282e-02\n",
      " 2.56244514e-01 1.13095178e+01], Loss = 0.3985\n",
      "Iteration 4527: Weights = [5.50000000e+01 3.66040133e+00 7.69605239e+00 2.53560003e-02\n",
      " 2.56237158e-01 1.13097512e+01], Loss = 0.3985\n",
      "Iteration 4528: Weights = [5.50000000e+01 3.66029625e+00 7.69583147e+00 2.53552724e-02\n",
      " 2.56229802e-01 1.13099846e+01], Loss = 0.3985\n",
      "Iteration 4529: Weights = [5.50000000e+01 3.66019117e+00 7.69561055e+00 2.53545446e-02\n",
      " 2.56222447e-01 1.13102180e+01], Loss = 0.3984\n",
      "Iteration 4530: Weights = [5.50000000e+01 3.66008610e+00 7.69538964e+00 2.53538168e-02\n",
      " 2.56215091e-01 1.13104514e+01], Loss = 0.3984\n",
      "Iteration 4531: Weights = [5.50000000e+01 3.65998104e+00 7.69516873e+00 2.53530889e-02\n",
      " 2.56207736e-01 1.13106848e+01], Loss = 0.3984\n",
      "Iteration 4532: Weights = [5.50000000e+01 3.65987597e+00 7.69494783e+00 2.53523611e-02\n",
      " 2.56200382e-01 1.13109182e+01], Loss = 0.3984\n",
      "Iteration 4533: Weights = [5.50000000e+01 3.65977091e+00 7.69472694e+00 2.53516334e-02\n",
      " 2.56193027e-01 1.13111516e+01], Loss = 0.3983\n",
      "Iteration 4534: Weights = [5.50000000e+01 3.65966585e+00 7.69450605e+00 2.53509056e-02\n",
      " 2.56185673e-01 1.13113849e+01], Loss = 0.3983\n",
      "Iteration 4535: Weights = [5.50000000e+01 3.65956080e+00 7.69428517e+00 2.53501779e-02\n",
      " 2.56178319e-01 1.13116183e+01], Loss = 0.3983\n",
      "Iteration 4536: Weights = [5.50000000e+01 3.65945574e+00 7.69406429e+00 2.53494502e-02\n",
      " 2.56170965e-01 1.13118516e+01], Loss = 0.3983\n",
      "Iteration 4537: Weights = [5.50000000e+01 3.65935069e+00 7.69384343e+00 2.53487225e-02\n",
      " 2.56163611e-01 1.13120850e+01], Loss = 0.3982\n",
      "Iteration 4538: Weights = [5.50000000e+01 3.65924565e+00 7.69362256e+00 2.53479948e-02\n",
      " 2.56156257e-01 1.13123183e+01], Loss = 0.3982\n",
      "Iteration 4539: Weights = [5.50000000e+01 3.65914060e+00 7.69340171e+00 2.53472672e-02\n",
      " 2.56148904e-01 1.13125516e+01], Loss = 0.3982\n",
      "Iteration 4540: Weights = [5.50000000e+01 3.65903556e+00 7.69318086e+00 2.53465395e-02\n",
      " 2.56141551e-01 1.13127850e+01], Loss = 0.3982\n",
      "Iteration 4541: Weights = [5.50000000e+01 3.65893053e+00 7.69296002e+00 2.53458119e-02\n",
      " 2.56134198e-01 1.13130183e+01], Loss = 0.3982\n",
      "Iteration 4542: Weights = [5.50000000e+01 3.65882549e+00 7.69273918e+00 2.53450844e-02\n",
      " 2.56126846e-01 1.13132516e+01], Loss = 0.3981\n",
      "Iteration 4543: Weights = [5.50000000e+01 3.65872046e+00 7.69251835e+00 2.53443568e-02\n",
      " 2.56119493e-01 1.13134849e+01], Loss = 0.3981\n",
      "Iteration 4544: Weights = [5.50000000e+01 3.65861543e+00 7.69229753e+00 2.53436292e-02\n",
      " 2.56112141e-01 1.13137182e+01], Loss = 0.3981\n",
      "Iteration 4545: Weights = [5.50000000e+01 3.65851041e+00 7.69207671e+00 2.53429017e-02\n",
      " 2.56104789e-01 1.13139515e+01], Loss = 0.3981\n",
      "Iteration 4546: Weights = [5.50000000e+01 3.65840539e+00 7.69185590e+00 2.53421742e-02\n",
      " 2.56097437e-01 1.13141848e+01], Loss = 0.3980\n",
      "Iteration 4547: Weights = [5.50000000e+01 3.65830037e+00 7.69163509e+00 2.53414467e-02\n",
      " 2.56090085e-01 1.13144180e+01], Loss = 0.3980\n",
      "Iteration 4548: Weights = [5.50000000e+01 3.65819535e+00 7.69141429e+00 2.53407193e-02\n",
      " 2.56082734e-01 1.13146513e+01], Loss = 0.3980\n",
      "Iteration 4549: Weights = [5.50000000e+01 3.65809034e+00 7.69119350e+00 2.53399918e-02\n",
      " 2.56075383e-01 1.13148846e+01], Loss = 0.3980\n",
      "Iteration 4550: Weights = [5.50000000e+01 3.65798533e+00 7.69097272e+00 2.53392644e-02\n",
      " 2.56068032e-01 1.13151178e+01], Loss = 0.3979\n",
      "Iteration 4551: Weights = [5.50000000e+01 3.65788032e+00 7.69075194e+00 2.53385370e-02\n",
      " 2.56060681e-01 1.13153511e+01], Loss = 0.3979\n",
      "Iteration 4552: Weights = [5.50000000e+01 3.65777531e+00 7.69053116e+00 2.53378097e-02\n",
      " 2.56053330e-01 1.13155843e+01], Loss = 0.3979\n",
      "Iteration 4553: Weights = [5.50000000e+01 3.65767031e+00 7.69031040e+00 2.53370823e-02\n",
      " 2.56045980e-01 1.13158176e+01], Loss = 0.3979\n",
      "Iteration 4554: Weights = [5.50000000e+01 3.65756532e+00 7.69008964e+00 2.53363550e-02\n",
      " 2.56038630e-01 1.13160508e+01], Loss = 0.3979\n",
      "Iteration 4555: Weights = [5.50000000e+01 3.65746032e+00 7.68986888e+00 2.53356277e-02\n",
      " 2.56031280e-01 1.13162840e+01], Loss = 0.3978\n",
      "Iteration 4556: Weights = [5.50000000e+01 3.65735533e+00 7.68964813e+00 2.53349004e-02\n",
      " 2.56023930e-01 1.13165172e+01], Loss = 0.3978\n",
      "Iteration 4557: Weights = [5.50000000e+01 3.65725034e+00 7.68942739e+00 2.53341731e-02\n",
      " 2.56016581e-01 1.13167504e+01], Loss = 0.3978\n",
      "Iteration 4558: Weights = [5.50000000e+01 3.65714535e+00 7.68920666e+00 2.53334458e-02\n",
      " 2.56009232e-01 1.13169836e+01], Loss = 0.3978\n",
      "Iteration 4559: Weights = [5.50000000e+01 3.65704037e+00 7.68898593e+00 2.53327186e-02\n",
      " 2.56001882e-01 1.13172168e+01], Loss = 0.3977\n",
      "Iteration 4560: Weights = [5.50000000e+01 3.65693539e+00 7.68876521e+00 2.53319914e-02\n",
      " 2.55994534e-01 1.13174500e+01], Loss = 0.3977\n",
      "Iteration 4561: Weights = [5.50000000e+01 3.65683041e+00 7.68854449e+00 2.53312642e-02\n",
      " 2.55987185e-01 1.13176832e+01], Loss = 0.3977\n",
      "Iteration 4562: Weights = [5.50000000e+01 3.65672544e+00 7.68832378e+00 2.53305370e-02\n",
      " 2.55979836e-01 1.13179164e+01], Loss = 0.3977\n",
      "Iteration 4563: Weights = [5.50000000e+01 3.65662047e+00 7.68810308e+00 2.53298099e-02\n",
      " 2.55972488e-01 1.13181496e+01], Loss = 0.3977\n",
      "Iteration 4564: Weights = [5.50000000e+01 3.65651550e+00 7.68788238e+00 2.53290828e-02\n",
      " 2.55965140e-01 1.13183827e+01], Loss = 0.3976\n",
      "Iteration 4565: Weights = [5.50000000e+01 3.65641053e+00 7.68766169e+00 2.53283557e-02\n",
      " 2.55957792e-01 1.13186159e+01], Loss = 0.3976\n",
      "Iteration 4566: Weights = [5.50000000e+01 3.65630557e+00 7.68744101e+00 2.53276286e-02\n",
      " 2.55950445e-01 1.13188490e+01], Loss = 0.3976\n",
      "Iteration 4567: Weights = [5.50000000e+01 3.65620061e+00 7.68722033e+00 2.53269015e-02\n",
      " 2.55943097e-01 1.13190822e+01], Loss = 0.3976\n",
      "Iteration 4568: Weights = [5.50000000e+01 3.65609566e+00 7.68699966e+00 2.53261745e-02\n",
      " 2.55935750e-01 1.13193153e+01], Loss = 0.3975\n",
      "Iteration 4569: Weights = [5.50000000e+01 3.65599070e+00 7.68677899e+00 2.53254475e-02\n",
      " 2.55928403e-01 1.13195484e+01], Loss = 0.3975\n",
      "Iteration 4570: Weights = [5.50000000e+01 3.65588575e+00 7.68655833e+00 2.53247205e-02\n",
      " 2.55921057e-01 1.13197816e+01], Loss = 0.3975\n",
      "Iteration 4571: Weights = [5.50000000e+01 3.65578081e+00 7.68633768e+00 2.53239935e-02\n",
      " 2.55913710e-01 1.13200147e+01], Loss = 0.3975\n",
      "Iteration 4572: Weights = [5.50000000e+01 3.65567586e+00 7.68611703e+00 2.53232665e-02\n",
      " 2.55906364e-01 1.13202478e+01], Loss = 0.3974\n",
      "Iteration 4573: Weights = [5.50000000e+01 3.65557092e+00 7.68589639e+00 2.53225396e-02\n",
      " 2.55899017e-01 1.13204809e+01], Loss = 0.3974\n",
      "Iteration 4574: Weights = [5.50000000e+01 3.65546598e+00 7.68567576e+00 2.53218127e-02\n",
      " 2.55891672e-01 1.13207140e+01], Loss = 0.3974\n",
      "Iteration 4575: Weights = [5.50000000e+01 3.65536105e+00 7.68545513e+00 2.53210858e-02\n",
      " 2.55884326e-01 1.13209471e+01], Loss = 0.3974\n",
      "Iteration 4576: Weights = [5.50000000e+01 3.65525612e+00 7.68523451e+00 2.53203589e-02\n",
      " 2.55876980e-01 1.13211802e+01], Loss = 0.3974\n",
      "Iteration 4577: Weights = [5.50000000e+01 3.65515119e+00 7.68501389e+00 2.53196320e-02\n",
      " 2.55869635e-01 1.13214132e+01], Loss = 0.3973\n",
      "Iteration 4578: Weights = [5.50000000e+01 3.65504626e+00 7.68479329e+00 2.53189052e-02\n",
      " 2.55862290e-01 1.13216463e+01], Loss = 0.3973\n",
      "Iteration 4579: Weights = [5.50000000e+01 3.65494134e+00 7.68457268e+00 2.53181784e-02\n",
      " 2.55854945e-01 1.13218794e+01], Loss = 0.3973\n",
      "Iteration 4580: Weights = [5.50000000e+01 3.65483642e+00 7.68435209e+00 2.53174516e-02\n",
      " 2.55847601e-01 1.13221124e+01], Loss = 0.3973\n",
      "Iteration 4581: Weights = [5.50000000e+01 3.65473150e+00 7.68413150e+00 2.53167248e-02\n",
      " 2.55840256e-01 1.13223455e+01], Loss = 0.3972\n",
      "Iteration 4582: Weights = [5.50000000e+01 3.65462659e+00 7.68391092e+00 2.53159981e-02\n",
      " 2.55832912e-01 1.13225785e+01], Loss = 0.3972\n",
      "Iteration 4583: Weights = [5.50000000e+01 3.65452168e+00 7.68369034e+00 2.53152714e-02\n",
      " 2.55825568e-01 1.13228115e+01], Loss = 0.3972\n",
      "Iteration 4584: Weights = [5.50000000e+01 3.65441677e+00 7.68346977e+00 2.53145447e-02\n",
      " 2.55818224e-01 1.13230446e+01], Loss = 0.3972\n",
      "Iteration 4585: Weights = [5.50000000e+01 3.65431187e+00 7.68324921e+00 2.53138180e-02\n",
      " 2.55810880e-01 1.13232776e+01], Loss = 0.3972\n",
      "Iteration 4586: Weights = [5.50000000e+01 3.65420696e+00 7.68302865e+00 2.53130913e-02\n",
      " 2.55803537e-01 1.13235106e+01], Loss = 0.3971\n",
      "Iteration 4587: Weights = [5.50000000e+01 3.65410206e+00 7.68280810e+00 2.53123647e-02\n",
      " 2.55796194e-01 1.13237436e+01], Loss = 0.3971\n",
      "Iteration 4588: Weights = [5.50000000e+01 3.65399717e+00 7.68258755e+00 2.53116380e-02\n",
      " 2.55788851e-01 1.13239766e+01], Loss = 0.3971\n",
      "Iteration 4589: Weights = [5.50000000e+01 3.65389228e+00 7.68236701e+00 2.53109114e-02\n",
      " 2.55781508e-01 1.13242096e+01], Loss = 0.3971\n",
      "Iteration 4590: Weights = [5.50000000e+01 3.65378739e+00 7.68214648e+00 2.53101848e-02\n",
      " 2.55774166e-01 1.13244426e+01], Loss = 0.3970\n",
      "Iteration 4591: Weights = [5.50000000e+01 3.65368250e+00 7.68192595e+00 2.53094583e-02\n",
      " 2.55766823e-01 1.13246756e+01], Loss = 0.3970\n",
      "Iteration 4592: Weights = [5.50000000e+01 3.65357762e+00 7.68170543e+00 2.53087317e-02\n",
      " 2.55759481e-01 1.13249086e+01], Loss = 0.3970\n",
      "Iteration 4593: Weights = [5.50000000e+01 3.65347273e+00 7.68148492e+00 2.53080052e-02\n",
      " 2.55752139e-01 1.13251415e+01], Loss = 0.3970\n",
      "Iteration 4594: Weights = [5.50000000e+01 3.65336786e+00 7.68126441e+00 2.53072787e-02\n",
      " 2.55744798e-01 1.13253745e+01], Loss = 0.3969\n",
      "Iteration 4595: Weights = [5.50000000e+01 3.65326298e+00 7.68104391e+00 2.53065522e-02\n",
      " 2.55737456e-01 1.13256074e+01], Loss = 0.3969\n",
      "Iteration 4596: Weights = [5.50000000e+01 3.65315811e+00 7.68082342e+00 2.53058258e-02\n",
      " 2.55730115e-01 1.13258404e+01], Loss = 0.3969\n",
      "Iteration 4597: Weights = [5.50000000e+01 3.65305324e+00 7.68060293e+00 2.53050993e-02\n",
      " 2.55722774e-01 1.13260733e+01], Loss = 0.3969\n",
      "Iteration 4598: Weights = [5.50000000e+01 3.65294838e+00 7.68038245e+00 2.53043729e-02\n",
      " 2.55715433e-01 1.13263063e+01], Loss = 0.3969\n",
      "Iteration 4599: Weights = [5.50000000e+01 3.65284351e+00 7.68016197e+00 2.53036465e-02\n",
      " 2.55708092e-01 1.13265392e+01], Loss = 0.3968\n",
      "Iteration 4600: Weights = [5.50000000e+01 3.65273865e+00 7.67994150e+00 2.53029202e-02\n",
      " 2.55700752e-01 1.13267721e+01], Loss = 0.3968\n",
      "Iteration 4601: Weights = [5.50000000e+01 3.65263380e+00 7.67972104e+00 2.53021938e-02\n",
      " 2.55693412e-01 1.13270050e+01], Loss = 0.3968\n",
      "Iteration 4602: Weights = [5.50000000e+01 3.65252894e+00 7.67950058e+00 2.53014675e-02\n",
      " 2.55686072e-01 1.13272380e+01], Loss = 0.3968\n",
      "Iteration 4603: Weights = [5.50000000e+01 3.65242409e+00 7.67928013e+00 2.53007412e-02\n",
      " 2.55678732e-01 1.13274709e+01], Loss = 0.3967\n",
      "Iteration 4604: Weights = [5.50000000e+01 3.65231925e+00 7.67905969e+00 2.53000149e-02\n",
      " 2.55671392e-01 1.13277037e+01], Loss = 0.3967\n",
      "Iteration 4605: Weights = [5.50000000e+01 3.65221440e+00 7.67883925e+00 2.52992886e-02\n",
      " 2.55664053e-01 1.13279366e+01], Loss = 0.3967\n",
      "Iteration 4606: Weights = [5.50000000e+01 3.65210956e+00 7.67861882e+00 2.52985624e-02\n",
      " 2.55656714e-01 1.13281695e+01], Loss = 0.3967\n",
      "Iteration 4607: Weights = [5.50000000e+01 3.65200472e+00 7.67839840e+00 2.52978361e-02\n",
      " 2.55649375e-01 1.13284024e+01], Loss = 0.3966\n",
      "Iteration 4608: Weights = [5.50000000e+01 3.65189989e+00 7.67817798e+00 2.52971099e-02\n",
      " 2.55642036e-01 1.13286353e+01], Loss = 0.3966\n",
      "Iteration 4609: Weights = [5.50000000e+01 3.65179505e+00 7.67795757e+00 2.52963837e-02\n",
      " 2.55634697e-01 1.13288681e+01], Loss = 0.3966\n",
      "Iteration 4610: Weights = [5.50000000e+01 3.65169022e+00 7.67773716e+00 2.52956576e-02\n",
      " 2.55627359e-01 1.13291010e+01], Loss = 0.3966\n",
      "Iteration 4611: Weights = [5.50000000e+01 3.65158540e+00 7.67751676e+00 2.52949314e-02\n",
      " 2.55620021e-01 1.13293338e+01], Loss = 0.3966\n",
      "Iteration 4612: Weights = [5.50000000e+01 3.65148057e+00 7.67729637e+00 2.52942053e-02\n",
      " 2.55612683e-01 1.13295667e+01], Loss = 0.3965\n",
      "Iteration 4613: Weights = [5.50000000e+01 3.65137575e+00 7.67707598e+00 2.52934792e-02\n",
      " 2.55605345e-01 1.13297995e+01], Loss = 0.3965\n",
      "Iteration 4614: Weights = [5.50000000e+01 3.65127093e+00 7.67685560e+00 2.52927531e-02\n",
      " 2.55598008e-01 1.13300323e+01], Loss = 0.3965\n",
      "Iteration 4615: Weights = [5.50000000e+01 3.65116612e+00 7.67663523e+00 2.52920270e-02\n",
      " 2.55590671e-01 1.13302652e+01], Loss = 0.3965\n",
      "Iteration 4616: Weights = [5.50000000e+01 3.65106131e+00 7.67641486e+00 2.52913010e-02\n",
      " 2.55583333e-01 1.13304980e+01], Loss = 0.3964\n",
      "Iteration 4617: Weights = [5.50000000e+01 3.65095650e+00 7.67619450e+00 2.52905750e-02\n",
      " 2.55575997e-01 1.13307308e+01], Loss = 0.3964\n",
      "Iteration 4618: Weights = [5.50000000e+01 3.65085169e+00 7.67597414e+00 2.52898490e-02\n",
      " 2.55568660e-01 1.13309636e+01], Loss = 0.3964\n",
      "Iteration 4619: Weights = [5.50000000e+01 3.65074689e+00 7.67575379e+00 2.52891230e-02\n",
      " 2.55561324e-01 1.13311964e+01], Loss = 0.3964\n",
      "Iteration 4620: Weights = [5.50000000e+01 3.65064209e+00 7.67553345e+00 2.52883971e-02\n",
      " 2.55553987e-01 1.13314292e+01], Loss = 0.3964\n",
      "Iteration 4621: Weights = [5.50000000e+01 3.65053730e+00 7.67531311e+00 2.52876711e-02\n",
      " 2.55546651e-01 1.13316619e+01], Loss = 0.3963\n",
      "Iteration 4622: Weights = [5.50000000e+01 3.65043250e+00 7.67509278e+00 2.52869452e-02\n",
      " 2.55539315e-01 1.13318947e+01], Loss = 0.3963\n",
      "Iteration 4623: Weights = [5.50000000e+01 3.65032771e+00 7.67487246e+00 2.52862193e-02\n",
      " 2.55531980e-01 1.13321275e+01], Loss = 0.3963\n",
      "Iteration 4624: Weights = [5.50000000e+01 3.65022293e+00 7.67465214e+00 2.52854934e-02\n",
      " 2.55524645e-01 1.13323603e+01], Loss = 0.3963\n",
      "Iteration 4625: Weights = [5.50000000e+01 3.65011814e+00 7.67443183e+00 2.52847676e-02\n",
      " 2.55517309e-01 1.13325930e+01], Loss = 0.3962\n",
      "Iteration 4626: Weights = [5.50000000e+01 3.65001336e+00 7.67421153e+00 2.52840417e-02\n",
      " 2.55509974e-01 1.13328258e+01], Loss = 0.3962\n",
      "Iteration 4627: Weights = [5.50000000e+01 3.64990858e+00 7.67399123e+00 2.52833159e-02\n",
      " 2.55502640e-01 1.13330585e+01], Loss = 0.3962\n",
      "Iteration 4628: Weights = [5.50000000e+01 3.64980381e+00 7.67377094e+00 2.52825901e-02\n",
      " 2.55495305e-01 1.13332912e+01], Loss = 0.3962\n",
      "Iteration 4629: Weights = [5.50000000e+01 3.64969903e+00 7.67355065e+00 2.52818644e-02\n",
      " 2.55487971e-01 1.13335240e+01], Loss = 0.3961\n",
      "Iteration 4630: Weights = [5.50000000e+01 3.64959426e+00 7.67333037e+00 2.52811386e-02\n",
      " 2.55480637e-01 1.13337567e+01], Loss = 0.3961\n",
      "Iteration 4631: Weights = [5.50000000e+01 3.64948950e+00 7.67311010e+00 2.52804129e-02\n",
      " 2.55473303e-01 1.13339894e+01], Loss = 0.3961\n",
      "Iteration 4632: Weights = [5.50000000e+01 3.64938473e+00 7.67288983e+00 2.52796872e-02\n",
      " 2.55465969e-01 1.13342221e+01], Loss = 0.3961\n",
      "Iteration 4633: Weights = [5.50000000e+01 3.64927997e+00 7.67266957e+00 2.52789615e-02\n",
      " 2.55458636e-01 1.13344548e+01], Loss = 0.3961\n",
      "Iteration 4634: Weights = [5.50000000e+01 3.64917522e+00 7.67244932e+00 2.52782358e-02\n",
      " 2.55451302e-01 1.13346875e+01], Loss = 0.3960\n",
      "Iteration 4635: Weights = [5.50000000e+01 3.64907046e+00 7.67222907e+00 2.52775102e-02\n",
      " 2.55443969e-01 1.13349202e+01], Loss = 0.3960\n",
      "Iteration 4636: Weights = [5.50000000e+01 3.64896571e+00 7.67200883e+00 2.52767846e-02\n",
      " 2.55436636e-01 1.13351529e+01], Loss = 0.3960\n",
      "Iteration 4637: Weights = [5.50000000e+01 3.64886096e+00 7.67178859e+00 2.52760590e-02\n",
      " 2.55429304e-01 1.13353855e+01], Loss = 0.3960\n",
      "Iteration 4638: Weights = [5.50000000e+01 3.64875622e+00 7.67156837e+00 2.52753334e-02\n",
      " 2.55421971e-01 1.13356182e+01], Loss = 0.3959\n",
      "Iteration 4639: Weights = [5.50000000e+01 3.64865147e+00 7.67134814e+00 2.52746078e-02\n",
      " 2.55414639e-01 1.13358509e+01], Loss = 0.3959\n",
      "Iteration 4640: Weights = [5.50000000e+01 3.64854674e+00 7.67112793e+00 2.52738823e-02\n",
      " 2.55407307e-01 1.13360835e+01], Loss = 0.3959\n",
      "Iteration 4641: Weights = [5.50000000e+01 3.64844200e+00 7.67090772e+00 2.52731568e-02\n",
      " 2.55399975e-01 1.13363162e+01], Loss = 0.3959\n",
      "Iteration 4642: Weights = [5.50000000e+01 3.64833727e+00 7.67068751e+00 2.52724313e-02\n",
      " 2.55392644e-01 1.13365488e+01], Loss = 0.3959\n",
      "Iteration 4643: Weights = [5.50000000e+01 3.64823254e+00 7.67046732e+00 2.52717058e-02\n",
      " 2.55385312e-01 1.13367815e+01], Loss = 0.3958\n",
      "Iteration 4644: Weights = [5.50000000e+01 3.64812781e+00 7.67024713e+00 2.52709803e-02\n",
      " 2.55377981e-01 1.13370141e+01], Loss = 0.3958\n",
      "Iteration 4645: Weights = [5.50000000e+01 3.64802308e+00 7.67002694e+00 2.52702549e-02\n",
      " 2.55370650e-01 1.13372467e+01], Loss = 0.3958\n",
      "Iteration 4646: Weights = [5.50000000e+01 3.64791836e+00 7.66980676e+00 2.52695295e-02\n",
      " 2.55363319e-01 1.13374793e+01], Loss = 0.3958\n",
      "Iteration 4647: Weights = [5.50000000e+01 3.64781364e+00 7.66958659e+00 2.52688041e-02\n",
      " 2.55355989e-01 1.13377119e+01], Loss = 0.3957\n",
      "Iteration 4648: Weights = [5.50000000e+01 3.64770893e+00 7.66936643e+00 2.52680787e-02\n",
      " 2.55348659e-01 1.13379445e+01], Loss = 0.3957\n",
      "Iteration 4649: Weights = [5.50000000e+01 3.64760422e+00 7.66914627e+00 2.52673534e-02\n",
      " 2.55341328e-01 1.13381771e+01], Loss = 0.3957\n",
      "Iteration 4650: Weights = [5.50000000e+01 3.64749951e+00 7.66892611e+00 2.52666280e-02\n",
      " 2.55333999e-01 1.13384097e+01], Loss = 0.3957\n",
      "Iteration 4651: Weights = [5.50000000e+01 3.64739480e+00 7.66870597e+00 2.52659027e-02\n",
      " 2.55326669e-01 1.13386423e+01], Loss = 0.3956\n",
      "Iteration 4652: Weights = [5.50000000e+01 3.64729010e+00 7.66848583e+00 2.52651774e-02\n",
      " 2.55319339e-01 1.13388749e+01], Loss = 0.3956\n",
      "Iteration 4653: Weights = [5.50000000e+01 3.64718540e+00 7.66826569e+00 2.52644521e-02\n",
      " 2.55312010e-01 1.13391074e+01], Loss = 0.3956\n",
      "Iteration 4654: Weights = [5.50000000e+01 3.64708070e+00 7.66804557e+00 2.52637269e-02\n",
      " 2.55304681e-01 1.13393400e+01], Loss = 0.3956\n",
      "Iteration 4655: Weights = [5.50000000e+01 3.64697601e+00 7.66782544e+00 2.52630017e-02\n",
      " 2.55297352e-01 1.13395726e+01], Loss = 0.3956\n",
      "Iteration 4656: Weights = [5.50000000e+01 3.64687132e+00 7.66760533e+00 2.52622765e-02\n",
      " 2.55290023e-01 1.13398051e+01], Loss = 0.3955\n",
      "Iteration 4657: Weights = [5.50000000e+01 3.64676663e+00 7.66738522e+00 2.52615513e-02\n",
      " 2.55282695e-01 1.13400376e+01], Loss = 0.3955\n",
      "Iteration 4658: Weights = [5.50000000e+01 3.64666194e+00 7.66716512e+00 2.52608261e-02\n",
      " 2.55275367e-01 1.13402702e+01], Loss = 0.3955\n",
      "Iteration 4659: Weights = [5.50000000e+01 3.64655726e+00 7.66694502e+00 2.52601010e-02\n",
      " 2.55268039e-01 1.13405027e+01], Loss = 0.3955\n",
      "Iteration 4660: Weights = [5.50000000e+01 3.64645258e+00 7.66672493e+00 2.52593758e-02\n",
      " 2.55260711e-01 1.13407352e+01], Loss = 0.3954\n",
      "Iteration 4661: Weights = [5.50000000e+01 3.64634790e+00 7.66650485e+00 2.52586507e-02\n",
      " 2.55253383e-01 1.13409677e+01], Loss = 0.3954\n",
      "Iteration 4662: Weights = [5.50000000e+01 3.64624323e+00 7.66628477e+00 2.52579257e-02\n",
      " 2.55246056e-01 1.13412002e+01], Loss = 0.3954\n",
      "Iteration 4663: Weights = [5.50000000e+01 3.64613856e+00 7.66606470e+00 2.52572006e-02\n",
      " 2.55238729e-01 1.13414327e+01], Loss = 0.3954\n",
      "Iteration 4664: Weights = [5.50000000e+01 3.64603389e+00 7.66584464e+00 2.52564755e-02\n",
      " 2.55231402e-01 1.13416652e+01], Loss = 0.3954\n",
      "Iteration 4665: Weights = [5.50000000e+01 3.64592923e+00 7.66562458e+00 2.52557505e-02\n",
      " 2.55224075e-01 1.13418977e+01], Loss = 0.3953\n",
      "Iteration 4666: Weights = [5.50000000e+01 3.64582457e+00 7.66540453e+00 2.52550255e-02\n",
      " 2.55216749e-01 1.13421302e+01], Loss = 0.3953\n",
      "Iteration 4667: Weights = [5.50000000e+01 3.64571991e+00 7.66518448e+00 2.52543006e-02\n",
      " 2.55209422e-01 1.13423627e+01], Loss = 0.3953\n",
      "Iteration 4668: Weights = [5.50000000e+01 3.64561525e+00 7.66496444e+00 2.52535756e-02\n",
      " 2.55202096e-01 1.13425952e+01], Loss = 0.3953\n",
      "Iteration 4669: Weights = [5.50000000e+01 3.64551060e+00 7.66474441e+00 2.52528507e-02\n",
      " 2.55194770e-01 1.13428276e+01], Loss = 0.3952\n",
      "Iteration 4670: Weights = [5.50000000e+01 3.64540595e+00 7.66452438e+00 2.52521257e-02\n",
      " 2.55187445e-01 1.13430601e+01], Loss = 0.3952\n",
      "Iteration 4671: Weights = [5.50000000e+01 3.64530131e+00 7.66430436e+00 2.52514008e-02\n",
      " 2.55180119e-01 1.13432925e+01], Loss = 0.3952\n",
      "Iteration 4672: Weights = [5.50000000e+01 3.64519666e+00 7.66408435e+00 2.52506760e-02\n",
      " 2.55172794e-01 1.13435250e+01], Loss = 0.3952\n",
      "Iteration 4673: Weights = [5.50000000e+01 3.64509202e+00 7.66386434e+00 2.52499511e-02\n",
      " 2.55165469e-01 1.13437574e+01], Loss = 0.3951\n",
      "Iteration 4674: Weights = [5.50000000e+01 3.64498739e+00 7.66364434e+00 2.52492263e-02\n",
      " 2.55158144e-01 1.13439898e+01], Loss = 0.3951\n",
      "Iteration 4675: Weights = [5.50000000e+01 3.64488275e+00 7.66342435e+00 2.52485015e-02\n",
      " 2.55150819e-01 1.13442222e+01], Loss = 0.3951\n",
      "Iteration 4676: Weights = [5.50000000e+01 3.64477812e+00 7.66320436e+00 2.52477767e-02\n",
      " 2.55143495e-01 1.13444547e+01], Loss = 0.3951\n",
      "Iteration 4677: Weights = [5.50000000e+01 3.64467349e+00 7.66298437e+00 2.52470519e-02\n",
      " 2.55136171e-01 1.13446871e+01], Loss = 0.3951\n",
      "Iteration 4678: Weights = [5.50000000e+01 3.64456887e+00 7.66276440e+00 2.52463272e-02\n",
      " 2.55128847e-01 1.13449195e+01], Loss = 0.3950\n",
      "Iteration 4679: Weights = [5.50000000e+01 3.64446425e+00 7.66254443e+00 2.52456024e-02\n",
      " 2.55121523e-01 1.13451519e+01], Loss = 0.3950\n",
      "Iteration 4680: Weights = [5.50000000e+01 3.64435963e+00 7.66232447e+00 2.52448777e-02\n",
      " 2.55114199e-01 1.13453842e+01], Loss = 0.3950\n",
      "Iteration 4681: Weights = [5.50000000e+01 3.64425501e+00 7.66210451e+00 2.52441530e-02\n",
      " 2.55106876e-01 1.13456166e+01], Loss = 0.3950\n",
      "Iteration 4682: Weights = [5.50000000e+01 3.64415040e+00 7.66188456e+00 2.52434284e-02\n",
      " 2.55099553e-01 1.13458490e+01], Loss = 0.3949\n",
      "Iteration 4683: Weights = [5.50000000e+01 3.64404579e+00 7.66166461e+00 2.52427037e-02\n",
      " 2.55092230e-01 1.13460814e+01], Loss = 0.3949\n",
      "Iteration 4684: Weights = [5.50000000e+01 3.64394118e+00 7.66144468e+00 2.52419791e-02\n",
      " 2.55084907e-01 1.13463137e+01], Loss = 0.3949\n",
      "Iteration 4685: Weights = [5.50000000e+01 3.64383658e+00 7.66122474e+00 2.52412545e-02\n",
      " 2.55077584e-01 1.13465461e+01], Loss = 0.3949\n",
      "Iteration 4686: Weights = [5.50000000e+01 3.64373198e+00 7.66100482e+00 2.52405299e-02\n",
      " 2.55070262e-01 1.13467784e+01], Loss = 0.3949\n",
      "Iteration 4687: Weights = [5.50000000e+01 3.64362738e+00 7.66078490e+00 2.52398053e-02\n",
      " 2.55062940e-01 1.13470108e+01], Loss = 0.3948\n",
      "Iteration 4688: Weights = [5.50000000e+01 3.64352278e+00 7.66056499e+00 2.52390808e-02\n",
      " 2.55055618e-01 1.13472431e+01], Loss = 0.3948\n",
      "Iteration 4689: Weights = [5.50000000e+01 3.64341819e+00 7.66034508e+00 2.52383563e-02\n",
      " 2.55048296e-01 1.13474754e+01], Loss = 0.3948\n",
      "Iteration 4690: Weights = [5.50000000e+01 3.64331360e+00 7.66012518e+00 2.52376318e-02\n",
      " 2.55040975e-01 1.13477078e+01], Loss = 0.3948\n",
      "Iteration 4691: Weights = [5.50000000e+01 3.64320902e+00 7.65990529e+00 2.52369073e-02\n",
      " 2.55033653e-01 1.13479401e+01], Loss = 0.3947\n",
      "Iteration 4692: Weights = [5.50000000e+01 3.64310443e+00 7.65968540e+00 2.52361828e-02\n",
      " 2.55026332e-01 1.13481724e+01], Loss = 0.3947\n",
      "Iteration 4693: Weights = [5.50000000e+01 3.64299985e+00 7.65946552e+00 2.52354584e-02\n",
      " 2.55019011e-01 1.13484047e+01], Loss = 0.3947\n",
      "Iteration 4694: Weights = [5.50000000e+01 3.64289527e+00 7.65924564e+00 2.52347340e-02\n",
      " 2.55011691e-01 1.13486370e+01], Loss = 0.3947\n",
      "Iteration 4695: Weights = [5.50000000e+01 3.64279070e+00 7.65902577e+00 2.52340096e-02\n",
      " 2.55004370e-01 1.13488693e+01], Loss = 0.3947\n",
      "Iteration 4696: Weights = [5.50000000e+01 3.64268613e+00 7.65880591e+00 2.52332852e-02\n",
      " 2.54997050e-01 1.13491015e+01], Loss = 0.3946\n",
      "Iteration 4697: Weights = [5.50000000e+01 3.64258156e+00 7.65858605e+00 2.52325609e-02\n",
      " 2.54989730e-01 1.13493338e+01], Loss = 0.3946\n",
      "Iteration 4698: Weights = [5.50000000e+01 3.64247700e+00 7.65836620e+00 2.52318365e-02\n",
      " 2.54982410e-01 1.13495661e+01], Loss = 0.3946\n",
      "Iteration 4699: Weights = [5.50000000e+01 3.64237243e+00 7.65814636e+00 2.52311122e-02\n",
      " 2.54975091e-01 1.13497983e+01], Loss = 0.3946\n",
      "Iteration 4700: Weights = [5.50000000e+01 3.64226788e+00 7.65792652e+00 2.52303879e-02\n",
      " 2.54967771e-01 1.13500306e+01], Loss = 0.3945\n",
      "Iteration 4701: Weights = [5.50000000e+01 3.64216332e+00 7.65770669e+00 2.52296637e-02\n",
      " 2.54960452e-01 1.13502628e+01], Loss = 0.3945\n",
      "Iteration 4702: Weights = [5.50000000e+01 3.64205877e+00 7.65748687e+00 2.52289394e-02\n",
      " 2.54953133e-01 1.13504951e+01], Loss = 0.3945\n",
      "Iteration 4703: Weights = [5.50000000e+01 3.64195422e+00 7.65726705e+00 2.52282152e-02\n",
      " 2.54945814e-01 1.13507273e+01], Loss = 0.3945\n",
      "Iteration 4704: Weights = [5.50000000e+01 3.64184967e+00 7.65704724e+00 2.52274910e-02\n",
      " 2.54938496e-01 1.13509596e+01], Loss = 0.3944\n",
      "Iteration 4705: Weights = [5.50000000e+01 3.64174513e+00 7.65682743e+00 2.52267668e-02\n",
      " 2.54931177e-01 1.13511918e+01], Loss = 0.3944\n",
      "Iteration 4706: Weights = [5.50000000e+01 3.64164058e+00 7.65660763e+00 2.52260426e-02\n",
      " 2.54923859e-01 1.13514240e+01], Loss = 0.3944\n",
      "Iteration 4707: Weights = [5.50000000e+01 3.64153605e+00 7.65638784e+00 2.52253185e-02\n",
      " 2.54916541e-01 1.13516562e+01], Loss = 0.3944\n",
      "Iteration 4708: Weights = [5.50000000e+01 3.64143151e+00 7.65616805e+00 2.52245943e-02\n",
      " 2.54909224e-01 1.13518884e+01], Loss = 0.3944\n",
      "Iteration 4709: Weights = [5.50000000e+01 3.64132698e+00 7.65594827e+00 2.52238702e-02\n",
      " 2.54901906e-01 1.13521206e+01], Loss = 0.3943\n",
      "Iteration 4710: Weights = [5.50000000e+01 3.64122245e+00 7.65572850e+00 2.52231462e-02\n",
      " 2.54894589e-01 1.13523528e+01], Loss = 0.3943\n",
      "Iteration 4711: Weights = [5.50000000e+01 3.64111792e+00 7.65550873e+00 2.52224221e-02\n",
      " 2.54887272e-01 1.13525850e+01], Loss = 0.3943\n",
      "Iteration 4712: Weights = [5.50000000e+01 3.64101340e+00 7.65528897e+00 2.52216980e-02\n",
      " 2.54879955e-01 1.13528171e+01], Loss = 0.3943\n",
      "Iteration 4713: Weights = [5.50000000e+01 3.64090888e+00 7.65506922e+00 2.52209740e-02\n",
      " 2.54872638e-01 1.13530493e+01], Loss = 0.3942\n",
      "Iteration 4714: Weights = [5.50000000e+01 3.64080436e+00 7.65484947e+00 2.52202500e-02\n",
      " 2.54865322e-01 1.13532815e+01], Loss = 0.3942\n",
      "Iteration 4715: Weights = [5.50000000e+01 3.64069985e+00 7.65462972e+00 2.52195260e-02\n",
      " 2.54858006e-01 1.13535136e+01], Loss = 0.3942\n",
      "Iteration 4716: Weights = [5.50000000e+01 3.64059534e+00 7.65440999e+00 2.52188021e-02\n",
      " 2.54850690e-01 1.13537458e+01], Loss = 0.3942\n",
      "Iteration 4717: Weights = [5.50000000e+01 3.64049083e+00 7.65419026e+00 2.52180781e-02\n",
      " 2.54843374e-01 1.13539779e+01], Loss = 0.3942\n",
      "Iteration 4718: Weights = [5.50000000e+01 3.64038633e+00 7.65397054e+00 2.52173542e-02\n",
      " 2.54836058e-01 1.13542100e+01], Loss = 0.3941\n",
      "Iteration 4719: Weights = [5.50000000e+01 3.64028182e+00 7.65375082e+00 2.52166303e-02\n",
      " 2.54828743e-01 1.13544422e+01], Loss = 0.3941\n",
      "Iteration 4720: Weights = [5.50000000e+01 3.64017732e+00 7.65353111e+00 2.52159065e-02\n",
      " 2.54821428e-01 1.13546743e+01], Loss = 0.3941\n",
      "Iteration 4721: Weights = [5.50000000e+01 3.64007283e+00 7.65331140e+00 2.52151826e-02\n",
      " 2.54814113e-01 1.13549064e+01], Loss = 0.3941\n",
      "Iteration 4722: Weights = [5.50000000e+01 3.63996834e+00 7.65309170e+00 2.52144588e-02\n",
      " 2.54806798e-01 1.13551385e+01], Loss = 0.3940\n",
      "Iteration 4723: Weights = [5.50000000e+01 3.63986385e+00 7.65287201e+00 2.52137349e-02\n",
      " 2.54799483e-01 1.13553706e+01], Loss = 0.3940\n",
      "Iteration 4724: Weights = [5.50000000e+01 3.63975936e+00 7.65265233e+00 2.52130112e-02\n",
      " 2.54792169e-01 1.13556027e+01], Loss = 0.3940\n",
      "Iteration 4725: Weights = [5.50000000e+01 3.63965487e+00 7.65243265e+00 2.52122874e-02\n",
      " 2.54784855e-01 1.13558348e+01], Loss = 0.3940\n",
      "Iteration 4726: Weights = [5.50000000e+01 3.63955039e+00 7.65221297e+00 2.52115636e-02\n",
      " 2.54777541e-01 1.13560669e+01], Loss = 0.3939\n",
      "Iteration 4727: Weights = [5.50000000e+01 3.63944591e+00 7.65199331e+00 2.52108399e-02\n",
      " 2.54770227e-01 1.13562990e+01], Loss = 0.3939\n",
      "Iteration 4728: Weights = [5.50000000e+01 3.63934144e+00 7.65177365e+00 2.52101162e-02\n",
      " 2.54762914e-01 1.13565310e+01], Loss = 0.3939\n",
      "Iteration 4729: Weights = [5.50000000e+01 3.63923697e+00 7.65155399e+00 2.52093925e-02\n",
      " 2.54755600e-01 1.13567631e+01], Loss = 0.3939\n",
      "Iteration 4730: Weights = [5.50000000e+01 3.63913250e+00 7.65133434e+00 2.52086688e-02\n",
      " 2.54748287e-01 1.13569951e+01], Loss = 0.3939\n",
      "Iteration 4731: Weights = [5.50000000e+01 3.63902803e+00 7.65111470e+00 2.52079452e-02\n",
      " 2.54740974e-01 1.13572272e+01], Loss = 0.3938\n",
      "Iteration 4732: Weights = [5.50000000e+01 3.63892357e+00 7.65089507e+00 2.52072216e-02\n",
      " 2.54733662e-01 1.13574592e+01], Loss = 0.3938\n",
      "Iteration 4733: Weights = [5.50000000e+01 3.63881911e+00 7.65067544e+00 2.52064980e-02\n",
      " 2.54726349e-01 1.13576913e+01], Loss = 0.3938\n",
      "Iteration 4734: Weights = [5.50000000e+01 3.63871465e+00 7.65045582e+00 2.52057744e-02\n",
      " 2.54719037e-01 1.13579233e+01], Loss = 0.3938\n",
      "Iteration 4735: Weights = [5.50000000e+01 3.63861020e+00 7.65023620e+00 2.52050508e-02\n",
      " 2.54711725e-01 1.13581553e+01], Loss = 0.3937\n",
      "Iteration 4736: Weights = [5.50000000e+01 3.63850575e+00 7.65001659e+00 2.52043273e-02\n",
      " 2.54704413e-01 1.13583873e+01], Loss = 0.3937\n",
      "Iteration 4737: Weights = [5.50000000e+01 3.63840130e+00 7.64979699e+00 2.52036037e-02\n",
      " 2.54697101e-01 1.13586193e+01], Loss = 0.3937\n",
      "Iteration 4738: Weights = [5.50000000e+01 3.63829685e+00 7.64957739e+00 2.52028802e-02\n",
      " 2.54689790e-01 1.13588513e+01], Loss = 0.3937\n",
      "Iteration 4739: Weights = [5.50000000e+01 3.63819241e+00 7.64935780e+00 2.52021567e-02\n",
      " 2.54682479e-01 1.13590833e+01], Loss = 0.3937\n",
      "Iteration 4740: Weights = [5.50000000e+01 3.63808797e+00 7.64913821e+00 2.52014333e-02\n",
      " 2.54675168e-01 1.13593153e+01], Loss = 0.3936\n",
      "Iteration 4741: Weights = [5.50000000e+01 3.63798354e+00 7.64891863e+00 2.52007098e-02\n",
      " 2.54667857e-01 1.13595473e+01], Loss = 0.3936\n",
      "Iteration 4742: Weights = [5.50000000e+01 3.63787910e+00 7.64869906e+00 2.51999864e-02\n",
      " 2.54660546e-01 1.13597793e+01], Loss = 0.3936\n",
      "Iteration 4743: Weights = [5.50000000e+01 3.63777467e+00 7.64847950e+00 2.51992630e-02\n",
      " 2.54653236e-01 1.13600112e+01], Loss = 0.3936\n",
      "Iteration 4744: Weights = [5.50000000e+01 3.63767025e+00 7.64825994e+00 2.51985397e-02\n",
      " 2.54645926e-01 1.13602432e+01], Loss = 0.3935\n",
      "Iteration 4745: Weights = [5.50000000e+01 3.63756582e+00 7.64804038e+00 2.51978163e-02\n",
      " 2.54638616e-01 1.13604752e+01], Loss = 0.3935\n",
      "Iteration 4746: Weights = [5.50000000e+01 3.63746140e+00 7.64782084e+00 2.51970930e-02\n",
      " 2.54631306e-01 1.13607071e+01], Loss = 0.3935\n",
      "Iteration 4747: Weights = [5.50000000e+01 3.63735698e+00 7.64760130e+00 2.51963696e-02\n",
      " 2.54623997e-01 1.13609390e+01], Loss = 0.3935\n",
      "Iteration 4748: Weights = [5.50000000e+01 3.63725257e+00 7.64738176e+00 2.51956463e-02\n",
      " 2.54616687e-01 1.13611710e+01], Loss = 0.3935\n",
      "Iteration 4749: Weights = [5.50000000e+01 3.63714816e+00 7.64716223e+00 2.51949231e-02\n",
      " 2.54609378e-01 1.13614029e+01], Loss = 0.3934\n",
      "Iteration 4750: Weights = [5.50000000e+01 3.63704375e+00 7.64694271e+00 2.51941998e-02\n",
      " 2.54602069e-01 1.13616348e+01], Loss = 0.3934\n",
      "Iteration 4751: Weights = [5.50000000e+01 3.63693934e+00 7.64672320e+00 2.51934766e-02\n",
      " 2.54594761e-01 1.13618667e+01], Loss = 0.3934\n",
      "Iteration 4752: Weights = [5.50000000e+01 3.63683494e+00 7.64650369e+00 2.51927534e-02\n",
      " 2.54587452e-01 1.13620986e+01], Loss = 0.3934\n",
      "Iteration 4753: Weights = [5.50000000e+01 3.63673054e+00 7.64628418e+00 2.51920302e-02\n",
      " 2.54580144e-01 1.13623305e+01], Loss = 0.3933\n",
      "Iteration 4754: Weights = [5.50000000e+01 3.63662614e+00 7.64606469e+00 2.51913070e-02\n",
      " 2.54572836e-01 1.13625624e+01], Loss = 0.3933\n",
      "Iteration 4755: Weights = [5.50000000e+01 3.63652175e+00 7.64584520e+00 2.51905839e-02\n",
      " 2.54565528e-01 1.13627943e+01], Loss = 0.3933\n",
      "Iteration 4756: Weights = [5.50000000e+01 3.63641736e+00 7.64562571e+00 2.51898607e-02\n",
      " 2.54558220e-01 1.13630262e+01], Loss = 0.3933\n",
      "Iteration 4757: Weights = [5.50000000e+01 3.63631297e+00 7.64540623e+00 2.51891376e-02\n",
      " 2.54550913e-01 1.13632581e+01], Loss = 0.3932\n",
      "Iteration 4758: Weights = [5.50000000e+01 3.63620858e+00 7.64518676e+00 2.51884145e-02\n",
      " 2.54543606e-01 1.13634900e+01], Loss = 0.3932\n",
      "Iteration 4759: Weights = [5.50000000e+01 3.63610420e+00 7.64496730e+00 2.51876915e-02\n",
      " 2.54536299e-01 1.13637218e+01], Loss = 0.3932\n",
      "Iteration 4760: Weights = [5.50000000e+01 3.63599982e+00 7.64474784e+00 2.51869684e-02\n",
      " 2.54528992e-01 1.13639537e+01], Loss = 0.3932\n",
      "Iteration 4761: Weights = [5.50000000e+01 3.63589544e+00 7.64452839e+00 2.51862454e-02\n",
      " 2.54521685e-01 1.13641855e+01], Loss = 0.3932\n",
      "Iteration 4762: Weights = [5.50000000e+01 3.63579107e+00 7.64430894e+00 2.51855224e-02\n",
      " 2.54514379e-01 1.13644174e+01], Loss = 0.3931\n",
      "Iteration 4763: Weights = [5.50000000e+01 3.63568670e+00 7.64408950e+00 2.51847994e-02\n",
      " 2.54507073e-01 1.13646492e+01], Loss = 0.3931\n",
      "Iteration 4764: Weights = [5.50000000e+01 3.63558233e+00 7.64387007e+00 2.51840765e-02\n",
      " 2.54499767e-01 1.13648810e+01], Loss = 0.3931\n",
      "Iteration 4765: Weights = [5.50000000e+01 3.63547797e+00 7.64365064e+00 2.51833535e-02\n",
      " 2.54492461e-01 1.13651128e+01], Loss = 0.3931\n",
      "Iteration 4766: Weights = [5.50000000e+01 3.63537361e+00 7.64343122e+00 2.51826306e-02\n",
      " 2.54485156e-01 1.13653447e+01], Loss = 0.3930\n",
      "Iteration 4767: Weights = [5.50000000e+01 3.63526925e+00 7.64321180e+00 2.51819077e-02\n",
      " 2.54477850e-01 1.13655765e+01], Loss = 0.3930\n",
      "Iteration 4768: Weights = [5.50000000e+01 3.63516490e+00 7.64299240e+00 2.51811848e-02\n",
      " 2.54470545e-01 1.13658083e+01], Loss = 0.3930\n",
      "Iteration 4769: Weights = [5.50000000e+01 3.63506054e+00 7.64277299e+00 2.51804620e-02\n",
      " 2.54463240e-01 1.13660401e+01], Loss = 0.3930\n",
      "Iteration 4770: Weights = [5.50000000e+01 3.63495619e+00 7.64255360e+00 2.51797391e-02\n",
      " 2.54455936e-01 1.13662719e+01], Loss = 0.3930\n",
      "Iteration 4771: Weights = [5.50000000e+01 3.63485185e+00 7.64233421e+00 2.51790163e-02\n",
      " 2.54448631e-01 1.13665036e+01], Loss = 0.3929\n",
      "Iteration 4772: Weights = [5.50000000e+01 3.63474751e+00 7.64211483e+00 2.51782935e-02\n",
      " 2.54441327e-01 1.13667354e+01], Loss = 0.3929\n",
      "Iteration 4773: Weights = [5.50000000e+01 3.63464316e+00 7.64189545e+00 2.51775707e-02\n",
      " 2.54434023e-01 1.13669672e+01], Loss = 0.3929\n",
      "Iteration 4774: Weights = [5.50000000e+01 3.63453883e+00 7.64167608e+00 2.51768480e-02\n",
      " 2.54426719e-01 1.13671989e+01], Loss = 0.3929\n",
      "Iteration 4775: Weights = [5.50000000e+01 3.63443449e+00 7.64145671e+00 2.51761252e-02\n",
      " 2.54419415e-01 1.13674307e+01], Loss = 0.3928\n",
      "Iteration 4776: Weights = [5.50000000e+01 3.63433016e+00 7.64123736e+00 2.51754025e-02\n",
      " 2.54412112e-01 1.13676624e+01], Loss = 0.3928\n",
      "Iteration 4777: Weights = [5.50000000e+01 3.63422583e+00 7.64101800e+00 2.51746798e-02\n",
      " 2.54404809e-01 1.13678942e+01], Loss = 0.3928\n",
      "Iteration 4778: Weights = [5.50000000e+01 3.63412151e+00 7.64079866e+00 2.51739572e-02\n",
      " 2.54397505e-01 1.13681259e+01], Loss = 0.3928\n",
      "Iteration 4779: Weights = [5.50000000e+01 3.63401719e+00 7.64057932e+00 2.51732345e-02\n",
      " 2.54390203e-01 1.13683576e+01], Loss = 0.3928\n",
      "Iteration 4780: Weights = [5.50000000e+01 3.63391287e+00 7.64035999e+00 2.51725119e-02\n",
      " 2.54382900e-01 1.13685894e+01], Loss = 0.3927\n",
      "Iteration 4781: Weights = [5.50000000e+01 3.63380855e+00 7.64014066e+00 2.51717893e-02\n",
      " 2.54375598e-01 1.13688211e+01], Loss = 0.3927\n",
      "Iteration 4782: Weights = [5.50000000e+01 3.63370424e+00 7.63992134e+00 2.51710667e-02\n",
      " 2.54368295e-01 1.13690528e+01], Loss = 0.3927\n",
      "Iteration 4783: Weights = [5.50000000e+01 3.63359993e+00 7.63970203e+00 2.51703441e-02\n",
      " 2.54360994e-01 1.13692845e+01], Loss = 0.3927\n",
      "Iteration 4784: Weights = [5.50000000e+01 3.63349562e+00 7.63948272e+00 2.51696216e-02\n",
      " 2.54353692e-01 1.13695162e+01], Loss = 0.3926\n",
      "Iteration 4785: Weights = [5.50000000e+01 3.63339132e+00 7.63926342e+00 2.51688990e-02\n",
      " 2.54346390e-01 1.13697479e+01], Loss = 0.3926\n",
      "Iteration 4786: Weights = [5.50000000e+01 3.63328701e+00 7.63904412e+00 2.51681765e-02\n",
      " 2.54339089e-01 1.13699796e+01], Loss = 0.3926\n",
      "Iteration 4787: Weights = [5.50000000e+01 3.63318272e+00 7.63882483e+00 2.51674540e-02\n",
      " 2.54331788e-01 1.13702112e+01], Loss = 0.3926\n",
      "Iteration 4788: Weights = [5.50000000e+01 3.63307842e+00 7.63860555e+00 2.51667316e-02\n",
      " 2.54324487e-01 1.13704429e+01], Loss = 0.3925\n",
      "Iteration 4789: Weights = [5.50000000e+01 3.63297413e+00 7.63838627e+00 2.51660091e-02\n",
      " 2.54317186e-01 1.13706746e+01], Loss = 0.3925\n",
      "Iteration 4790: Weights = [5.50000000e+01 3.63286984e+00 7.63816700e+00 2.51652867e-02\n",
      " 2.54309886e-01 1.13709062e+01], Loss = 0.3925\n",
      "Iteration 4791: Weights = [5.50000000e+01 3.63276555e+00 7.63794774e+00 2.51645643e-02\n",
      " 2.54302585e-01 1.13711379e+01], Loss = 0.3925\n",
      "Iteration 4792: Weights = [5.50000000e+01 3.63266127e+00 7.63772848e+00 2.51638419e-02\n",
      " 2.54295285e-01 1.13713695e+01], Loss = 0.3925\n",
      "Iteration 4793: Weights = [5.50000000e+01 3.63255699e+00 7.63750923e+00 2.51631196e-02\n",
      " 2.54287985e-01 1.13716011e+01], Loss = 0.3924\n",
      "Iteration 4794: Weights = [5.50000000e+01 3.63245271e+00 7.63728999e+00 2.51623972e-02\n",
      " 2.54280686e-01 1.13718328e+01], Loss = 0.3924\n",
      "Iteration 4795: Weights = [5.50000000e+01 3.63234844e+00 7.63707075e+00 2.51616749e-02\n",
      " 2.54273386e-01 1.13720644e+01], Loss = 0.3924\n",
      "Iteration 4796: Weights = [5.50000000e+01 3.63224417e+00 7.63685152e+00 2.51609526e-02\n",
      " 2.54266087e-01 1.13722960e+01], Loss = 0.3924\n",
      "Iteration 4797: Weights = [5.50000000e+01 3.63213990e+00 7.63663229e+00 2.51602303e-02\n",
      " 2.54258788e-01 1.13725276e+01], Loss = 0.3923\n",
      "Iteration 4798: Weights = [5.50000000e+01 3.63203563e+00 7.63641307e+00 2.51595081e-02\n",
      " 2.54251489e-01 1.13727592e+01], Loss = 0.3923\n",
      "Iteration 4799: Weights = [5.50000000e+01 3.63193137e+00 7.63619386e+00 2.51587858e-02\n",
      " 2.54244190e-01 1.13729908e+01], Loss = 0.3923\n",
      "Iteration 4800: Weights = [5.50000000e+01 3.63182711e+00 7.63597465e+00 2.51580636e-02\n",
      " 2.54236892e-01 1.13732224e+01], Loss = 0.3923\n",
      "Iteration 4801: Weights = [5.50000000e+01 3.63172286e+00 7.63575545e+00 2.51573414e-02\n",
      " 2.54229594e-01 1.13734540e+01], Loss = 0.3923\n",
      "Iteration 4802: Weights = [5.50000000e+01 3.63161860e+00 7.63553626e+00 2.51566192e-02\n",
      " 2.54222296e-01 1.13736856e+01], Loss = 0.3922\n",
      "Iteration 4803: Weights = [5.50000000e+01 3.63151435e+00 7.63531707e+00 2.51558971e-02\n",
      " 2.54214998e-01 1.13739171e+01], Loss = 0.3922\n",
      "Iteration 4804: Weights = [5.50000000e+01 3.63141010e+00 7.63509789e+00 2.51551750e-02\n",
      " 2.54207700e-01 1.13741487e+01], Loss = 0.3922\n",
      "Iteration 4805: Weights = [5.50000000e+01 3.63130586e+00 7.63487871e+00 2.51544529e-02\n",
      " 2.54200403e-01 1.13743802e+01], Loss = 0.3922\n",
      "Iteration 4806: Weights = [5.50000000e+01 3.63120162e+00 7.63465954e+00 2.51537308e-02\n",
      " 2.54193106e-01 1.13746118e+01], Loss = 0.3921\n",
      "Iteration 4807: Weights = [5.50000000e+01 3.63109738e+00 7.63444038e+00 2.51530087e-02\n",
      " 2.54185809e-01 1.13748433e+01], Loss = 0.3921\n",
      "Iteration 4808: Weights = [5.50000000e+01 3.63099314e+00 7.63422122e+00 2.51522866e-02\n",
      " 2.54178512e-01 1.13750749e+01], Loss = 0.3921\n",
      "Iteration 4809: Weights = [5.50000000e+01 3.63088891e+00 7.63400207e+00 2.51515646e-02\n",
      " 2.54171216e-01 1.13753064e+01], Loss = 0.3921\n",
      "Iteration 4810: Weights = [5.50000000e+01 3.63078468e+00 7.63378293e+00 2.51508426e-02\n",
      " 2.54163919e-01 1.13755379e+01], Loss = 0.3921\n",
      "Iteration 4811: Weights = [5.50000000e+01 3.63068046e+00 7.63356379e+00 2.51501206e-02\n",
      " 2.54156623e-01 1.13757694e+01], Loss = 0.3920\n",
      "Iteration 4812: Weights = [5.50000000e+01 3.63057623e+00 7.63334466e+00 2.51493986e-02\n",
      " 2.54149327e-01 1.13760009e+01], Loss = 0.3920\n",
      "Iteration 4813: Weights = [5.50000000e+01 3.63047201e+00 7.63312553e+00 2.51486767e-02\n",
      " 2.54142032e-01 1.13762325e+01], Loss = 0.3920\n",
      "Iteration 4814: Weights = [5.50000000e+01 3.63036780e+00 7.63290641e+00 2.51479548e-02\n",
      " 2.54134736e-01 1.13764639e+01], Loss = 0.3920\n",
      "Iteration 4815: Weights = [5.50000000e+01 3.63026358e+00 7.63268730e+00 2.51472329e-02\n",
      " 2.54127441e-01 1.13766954e+01], Loss = 0.3919\n",
      "Iteration 4816: Weights = [5.50000000e+01 3.63015937e+00 7.63246820e+00 2.51465110e-02\n",
      " 2.54120146e-01 1.13769269e+01], Loss = 0.3919\n",
      "Iteration 4817: Weights = [5.50000000e+01 3.63005516e+00 7.63224910e+00 2.51457891e-02\n",
      " 2.54112851e-01 1.13771584e+01], Loss = 0.3919\n",
      "Iteration 4818: Weights = [5.50000000e+01 3.62995096e+00 7.63203000e+00 2.51450673e-02\n",
      " 2.54105556e-01 1.13773899e+01], Loss = 0.3919\n",
      "Iteration 4819: Weights = [5.50000000e+01 3.62984675e+00 7.63181092e+00 2.51443455e-02\n",
      " 2.54098262e-01 1.13776213e+01], Loss = 0.3919\n",
      "Iteration 4820: Weights = [5.50000000e+01 3.62974255e+00 7.63159183e+00 2.51436237e-02\n",
      " 2.54090968e-01 1.13778528e+01], Loss = 0.3918\n",
      "Iteration 4821: Weights = [5.50000000e+01 3.62963836e+00 7.63137276e+00 2.51429019e-02\n",
      " 2.54083674e-01 1.13780842e+01], Loss = 0.3918\n",
      "Iteration 4822: Weights = [5.50000000e+01 3.62953416e+00 7.63115369e+00 2.51421801e-02\n",
      " 2.54076380e-01 1.13783157e+01], Loss = 0.3918\n",
      "Iteration 4823: Weights = [5.50000000e+01 3.62942997e+00 7.63093463e+00 2.51414584e-02\n",
      " 2.54069086e-01 1.13785471e+01], Loss = 0.3918\n",
      "Iteration 4824: Weights = [5.50000000e+01 3.62932579e+00 7.63071557e+00 2.51407367e-02\n",
      " 2.54061793e-01 1.13787785e+01], Loss = 0.3917\n",
      "Iteration 4825: Weights = [5.50000000e+01 3.62922160e+00 7.63049652e+00 2.51400150e-02\n",
      " 2.54054500e-01 1.13790100e+01], Loss = 0.3917\n",
      "Iteration 4826: Weights = [5.50000000e+01 3.62911742e+00 7.63027748e+00 2.51392933e-02\n",
      " 2.54047207e-01 1.13792414e+01], Loss = 0.3917\n",
      "Iteration 4827: Weights = [5.50000000e+01 3.62901324e+00 7.63005844e+00 2.51385716e-02\n",
      " 2.54039914e-01 1.13794728e+01], Loss = 0.3917\n",
      "Iteration 4828: Weights = [5.50000000e+01 3.62890906e+00 7.62983941e+00 2.51378500e-02\n",
      " 2.54032622e-01 1.13797042e+01], Loss = 0.3916\n",
      "Iteration 4829: Weights = [5.50000000e+01 3.62880489e+00 7.62962039e+00 2.51371284e-02\n",
      " 2.54025329e-01 1.13799356e+01], Loss = 0.3916\n",
      "Iteration 4830: Weights = [5.50000000e+01 3.62870072e+00 7.62940137e+00 2.51364068e-02\n",
      " 2.54018037e-01 1.13801670e+01], Loss = 0.3916\n",
      "Iteration 4831: Weights = [5.50000000e+01 3.62859656e+00 7.62918236e+00 2.51356852e-02\n",
      " 2.54010745e-01 1.13803984e+01], Loss = 0.3916\n",
      "Iteration 4832: Weights = [5.50000000e+01 3.62849239e+00 7.62896335e+00 2.51349637e-02\n",
      " 2.54003453e-01 1.13806297e+01], Loss = 0.3916\n",
      "Iteration 4833: Weights = [5.50000000e+01 3.62838823e+00 7.62874435e+00 2.51342421e-02\n",
      " 2.53996162e-01 1.13808611e+01], Loss = 0.3915\n",
      "Iteration 4834: Weights = [5.50000000e+01 3.62828407e+00 7.62852536e+00 2.51335206e-02\n",
      " 2.53988871e-01 1.13810925e+01], Loss = 0.3915\n",
      "Iteration 4835: Weights = [5.50000000e+01 3.62817992e+00 7.62830637e+00 2.51327991e-02\n",
      " 2.53981580e-01 1.13813238e+01], Loss = 0.3915\n",
      "Iteration 4836: Weights = [5.50000000e+01 3.62807577e+00 7.62808739e+00 2.51320776e-02\n",
      " 2.53974289e-01 1.13815552e+01], Loss = 0.3915\n",
      "Iteration 4837: Weights = [5.50000000e+01 3.62797162e+00 7.62786842e+00 2.51313562e-02\n",
      " 2.53966998e-01 1.13817865e+01], Loss = 0.3914\n",
      "Iteration 4838: Weights = [5.50000000e+01 3.62786747e+00 7.62764945e+00 2.51306348e-02\n",
      " 2.53959708e-01 1.13820178e+01], Loss = 0.3914\n",
      "Iteration 4839: Weights = [5.50000000e+01 3.62776333e+00 7.62743049e+00 2.51299134e-02\n",
      " 2.53952417e-01 1.13822492e+01], Loss = 0.3914\n",
      "Iteration 4840: Weights = [5.50000000e+01 3.62765919e+00 7.62721153e+00 2.51291920e-02\n",
      " 2.53945127e-01 1.13824805e+01], Loss = 0.3914\n",
      "Iteration 4841: Weights = [5.50000000e+01 3.62755505e+00 7.62699258e+00 2.51284706e-02\n",
      " 2.53937837e-01 1.13827118e+01], Loss = 0.3914\n",
      "Iteration 4842: Weights = [5.50000000e+01 3.62745092e+00 7.62677364e+00 2.51277493e-02\n",
      " 2.53930548e-01 1.13829431e+01], Loss = 0.3913\n",
      "Iteration 4843: Weights = [5.50000000e+01 3.62734679e+00 7.62655470e+00 2.51270279e-02\n",
      " 2.53923258e-01 1.13831744e+01], Loss = 0.3913\n",
      "Iteration 4844: Weights = [5.50000000e+01 3.62724266e+00 7.62633577e+00 2.51263066e-02\n",
      " 2.53915969e-01 1.13834057e+01], Loss = 0.3913\n",
      "Iteration 4845: Weights = [5.50000000e+01 3.62713854e+00 7.62611685e+00 2.51255854e-02\n",
      " 2.53908680e-01 1.13836370e+01], Loss = 0.3913\n",
      "Iteration 4846: Weights = [5.50000000e+01 3.62703442e+00 7.62589793e+00 2.51248641e-02\n",
      " 2.53901391e-01 1.13838683e+01], Loss = 0.3912\n",
      "Iteration 4847: Weights = [5.50000000e+01 3.62693030e+00 7.62567902e+00 2.51241428e-02\n",
      " 2.53894103e-01 1.13840996e+01], Loss = 0.3912\n",
      "Iteration 4848: Weights = [5.50000000e+01 3.62682618e+00 7.62546012e+00 2.51234216e-02\n",
      " 2.53886814e-01 1.13843308e+01], Loss = 0.3912\n",
      "Iteration 4849: Weights = [5.50000000e+01 3.62672207e+00 7.62524122e+00 2.51227004e-02\n",
      " 2.53879526e-01 1.13845621e+01], Loss = 0.3912\n",
      "Iteration 4850: Weights = [5.50000000e+01 3.62661796e+00 7.62502232e+00 2.51219792e-02\n",
      " 2.53872238e-01 1.13847934e+01], Loss = 0.3912\n",
      "Iteration 4851: Weights = [5.50000000e+01 3.62651385e+00 7.62480344e+00 2.51212581e-02\n",
      " 2.53864951e-01 1.13850246e+01], Loss = 0.3911\n",
      "Iteration 4852: Weights = [5.50000000e+01 3.62640975e+00 7.62458456e+00 2.51205369e-02\n",
      " 2.53857663e-01 1.13852559e+01], Loss = 0.3911\n",
      "Iteration 4853: Weights = [5.50000000e+01 3.62630565e+00 7.62436568e+00 2.51198158e-02\n",
      " 2.53850376e-01 1.13854871e+01], Loss = 0.3911\n",
      "Iteration 4854: Weights = [5.50000000e+01 3.62620155e+00 7.62414682e+00 2.51190947e-02\n",
      " 2.53843089e-01 1.13857183e+01], Loss = 0.3911\n",
      "Iteration 4855: Weights = [5.50000000e+01 3.62609745e+00 7.62392796e+00 2.51183737e-02\n",
      " 2.53835802e-01 1.13859495e+01], Loss = 0.3910\n",
      "Iteration 4856: Weights = [5.50000000e+01 3.62599336e+00 7.62370910e+00 2.51176526e-02\n",
      " 2.53828515e-01 1.13861808e+01], Loss = 0.3910\n",
      "Iteration 4857: Weights = [5.50000000e+01 3.62588927e+00 7.62349025e+00 2.51169316e-02\n",
      " 2.53821229e-01 1.13864120e+01], Loss = 0.3910\n",
      "Iteration 4858: Weights = [5.50000000e+01 3.62578519e+00 7.62327141e+00 2.51162106e-02\n",
      " 2.53813942e-01 1.13866432e+01], Loss = 0.3910\n",
      "Iteration 4859: Weights = [5.50000000e+01 3.62568110e+00 7.62305257e+00 2.51154896e-02\n",
      " 2.53806656e-01 1.13868744e+01], Loss = 0.3910\n",
      "Iteration 4860: Weights = [5.50000000e+01 3.62557703e+00 7.62283374e+00 2.51147686e-02\n",
      " 2.53799370e-01 1.13871056e+01], Loss = 0.3909\n",
      "Iteration 4861: Weights = [5.50000000e+01 3.62547295e+00 7.62261492e+00 2.51140476e-02\n",
      " 2.53792085e-01 1.13873367e+01], Loss = 0.3909\n",
      "Iteration 4862: Weights = [5.50000000e+01 3.62536887e+00 7.62239610e+00 2.51133267e-02\n",
      " 2.53784799e-01 1.13875679e+01], Loss = 0.3909\n",
      "Iteration 4863: Weights = [5.50000000e+01 3.62526480e+00 7.62217729e+00 2.51126058e-02\n",
      " 2.53777514e-01 1.13877991e+01], Loss = 0.3909\n",
      "Iteration 4864: Weights = [5.50000000e+01 3.62516074e+00 7.62195849e+00 2.51118849e-02\n",
      " 2.53770229e-01 1.13880303e+01], Loss = 0.3908\n",
      "Iteration 4865: Weights = [5.50000000e+01 3.62505667e+00 7.62173969e+00 2.51111640e-02\n",
      " 2.53762944e-01 1.13882614e+01], Loss = 0.3908\n",
      "Iteration 4866: Weights = [5.50000000e+01 3.62495261e+00 7.62152090e+00 2.51104432e-02\n",
      " 2.53755660e-01 1.13884926e+01], Loss = 0.3908\n",
      "Iteration 4867: Weights = [5.50000000e+01 3.62484855e+00 7.62130211e+00 2.51097224e-02\n",
      " 2.53748375e-01 1.13887237e+01], Loss = 0.3908\n",
      "Iteration 4868: Weights = [5.50000000e+01 3.62474449e+00 7.62108333e+00 2.51090015e-02\n",
      " 2.53741091e-01 1.13889548e+01], Loss = 0.3908\n",
      "Iteration 4869: Weights = [5.50000000e+01 3.62464044e+00 7.62086456e+00 2.51082808e-02\n",
      " 2.53733807e-01 1.13891860e+01], Loss = 0.3907\n",
      "Iteration 4870: Weights = [5.50000000e+01 3.62453639e+00 7.62064579e+00 2.51075600e-02\n",
      " 2.53726523e-01 1.13894171e+01], Loss = 0.3907\n",
      "Iteration 4871: Weights = [5.50000000e+01 3.62443234e+00 7.62042703e+00 2.51068392e-02\n",
      " 2.53719240e-01 1.13896482e+01], Loss = 0.3907\n",
      "Iteration 4872: Weights = [5.50000000e+01 3.62432830e+00 7.62020828e+00 2.51061185e-02\n",
      " 2.53711957e-01 1.13898793e+01], Loss = 0.3907\n",
      "Iteration 4873: Weights = [5.50000000e+01 3.62422426e+00 7.61998953e+00 2.51053978e-02\n",
      " 2.53704673e-01 1.13901104e+01], Loss = 0.3906\n",
      "Iteration 4874: Weights = [5.50000000e+01 3.62412022e+00 7.61977079e+00 2.51046771e-02\n",
      " 2.53697390e-01 1.13903415e+01], Loss = 0.3906\n",
      "Iteration 4875: Weights = [5.50000000e+01 3.62401618e+00 7.61955205e+00 2.51039565e-02\n",
      " 2.53690108e-01 1.13905726e+01], Loss = 0.3906\n",
      "Iteration 4876: Weights = [5.50000000e+01 3.62391215e+00 7.61933332e+00 2.51032358e-02\n",
      " 2.53682825e-01 1.13908037e+01], Loss = 0.3906\n",
      "Iteration 4877: Weights = [5.50000000e+01 3.62380812e+00 7.61911460e+00 2.51025152e-02\n",
      " 2.53675543e-01 1.13910348e+01], Loss = 0.3905\n",
      "Iteration 4878: Weights = [5.50000000e+01 3.62370410e+00 7.61889588e+00 2.51017946e-02\n",
      " 2.53668261e-01 1.13912658e+01], Loss = 0.3905\n",
      "Iteration 4879: Weights = [5.50000000e+01 3.62360007e+00 7.61867717e+00 2.51010740e-02\n",
      " 2.53660979e-01 1.13914969e+01], Loss = 0.3905\n",
      "Iteration 4880: Weights = [5.50000000e+01 3.62349605e+00 7.61845847e+00 2.51003535e-02\n",
      " 2.53653697e-01 1.13917280e+01], Loss = 0.3905\n",
      "Iteration 4881: Weights = [5.50000000e+01 3.62339204e+00 7.61823977e+00 2.50996329e-02\n",
      " 2.53646416e-01 1.13919590e+01], Loss = 0.3905\n",
      "Iteration 4882: Weights = [5.50000000e+01 3.62328802e+00 7.61802108e+00 2.50989124e-02\n",
      " 2.53639135e-01 1.13921901e+01], Loss = 0.3904\n",
      "Iteration 4883: Weights = [5.50000000e+01 3.62318401e+00 7.61780239e+00 2.50981919e-02\n",
      " 2.53631854e-01 1.13924211e+01], Loss = 0.3904\n",
      "Iteration 4884: Weights = [5.50000000e+01 3.62308000e+00 7.61758372e+00 2.50974714e-02\n",
      " 2.53624573e-01 1.13926521e+01], Loss = 0.3904\n",
      "Iteration 4885: Weights = [5.50000000e+01 3.62297600e+00 7.61736504e+00 2.50967510e-02\n",
      " 2.53617292e-01 1.13928832e+01], Loss = 0.3904\n",
      "Iteration 4886: Weights = [5.50000000e+01 3.62287200e+00 7.61714638e+00 2.50960305e-02\n",
      " 2.53610012e-01 1.13931142e+01], Loss = 0.3903\n",
      "Iteration 4887: Weights = [5.50000000e+01 3.62276800e+00 7.61692772e+00 2.50953101e-02\n",
      " 2.53602731e-01 1.13933452e+01], Loss = 0.3903\n",
      "Iteration 4888: Weights = [5.50000000e+01 3.62266400e+00 7.61670906e+00 2.50945897e-02\n",
      " 2.53595451e-01 1.13935762e+01], Loss = 0.3903\n",
      "Iteration 4889: Weights = [5.50000000e+01 3.62256001e+00 7.61649041e+00 2.50938694e-02\n",
      " 2.53588172e-01 1.13938072e+01], Loss = 0.3903\n",
      "Iteration 4890: Weights = [5.50000000e+01 3.62245602e+00 7.61627177e+00 2.50931490e-02\n",
      " 2.53580892e-01 1.13940382e+01], Loss = 0.3903\n",
      "Iteration 4891: Weights = [5.50000000e+01 3.62235203e+00 7.61605314e+00 2.50924287e-02\n",
      " 2.53573613e-01 1.13942692e+01], Loss = 0.3902\n",
      "Iteration 4892: Weights = [5.50000000e+01 3.62224804e+00 7.61583451e+00 2.50917084e-02\n",
      " 2.53566334e-01 1.13945001e+01], Loss = 0.3902\n",
      "Iteration 4893: Weights = [5.50000000e+01 3.62214406e+00 7.61561589e+00 2.50909881e-02\n",
      " 2.53559055e-01 1.13947311e+01], Loss = 0.3902\n",
      "Iteration 4894: Weights = [5.50000000e+01 3.62204008e+00 7.61539727e+00 2.50902678e-02\n",
      " 2.53551776e-01 1.13949621e+01], Loss = 0.3902\n",
      "Iteration 4895: Weights = [5.50000000e+01 3.62193611e+00 7.61517866e+00 2.50895476e-02\n",
      " 2.53544497e-01 1.13951930e+01], Loss = 0.3901\n",
      "Iteration 4896: Weights = [5.50000000e+01 3.62183214e+00 7.61496006e+00 2.50888273e-02\n",
      " 2.53537219e-01 1.13954240e+01], Loss = 0.3901\n",
      "Iteration 4897: Weights = [5.50000000e+01 3.62172817e+00 7.61474146e+00 2.50881071e-02\n",
      " 2.53529941e-01 1.13956549e+01], Loss = 0.3901\n",
      "Iteration 4898: Weights = [5.50000000e+01 3.62162420e+00 7.61452287e+00 2.50873869e-02\n",
      " 2.53522663e-01 1.13958859e+01], Loss = 0.3901\n",
      "Iteration 4899: Weights = [5.50000000e+01 3.62152024e+00 7.61430428e+00 2.50866668e-02\n",
      " 2.53515385e-01 1.13961168e+01], Loss = 0.3901\n",
      "Iteration 4900: Weights = [5.50000000e+01 3.62141628e+00 7.61408571e+00 2.50859466e-02\n",
      " 2.53508108e-01 1.13963477e+01], Loss = 0.3900\n",
      "Iteration 4901: Weights = [5.50000000e+01 3.62131232e+00 7.61386713e+00 2.50852265e-02\n",
      " 2.53500831e-01 1.13965786e+01], Loss = 0.3900\n",
      "Iteration 4902: Weights = [5.50000000e+01 3.62120837e+00 7.61364857e+00 2.50845064e-02\n",
      " 2.53493553e-01 1.13968096e+01], Loss = 0.3900\n",
      "Iteration 4903: Weights = [5.50000000e+01 3.62110441e+00 7.61343001e+00 2.50837863e-02\n",
      " 2.53486277e-01 1.13970405e+01], Loss = 0.3900\n",
      "Iteration 4904: Weights = [5.50000000e+01 3.62100047e+00 7.61321145e+00 2.50830663e-02\n",
      " 2.53479000e-01 1.13972714e+01], Loss = 0.3899\n",
      "Iteration 4905: Weights = [5.50000000e+01 3.62089652e+00 7.61299291e+00 2.50823462e-02\n",
      " 2.53471723e-01 1.13975023e+01], Loss = 0.3899\n",
      "Iteration 4906: Weights = [5.50000000e+01 3.62079258e+00 7.61277437e+00 2.50816262e-02\n",
      " 2.53464447e-01 1.13977331e+01], Loss = 0.3899\n",
      "Iteration 4907: Weights = [5.50000000e+01 3.62068864e+00 7.61255583e+00 2.50809062e-02\n",
      " 2.53457171e-01 1.13979640e+01], Loss = 0.3899\n",
      "Iteration 4908: Weights = [5.50000000e+01 3.62058470e+00 7.61233730e+00 2.50801862e-02\n",
      " 2.53449895e-01 1.13981949e+01], Loss = 0.3899\n",
      "Iteration 4909: Weights = [5.50000000e+01 3.62048077e+00 7.61211878e+00 2.50794662e-02\n",
      " 2.53442620e-01 1.13984258e+01], Loss = 0.3898\n",
      "Iteration 4910: Weights = [5.50000000e+01 3.62037684e+00 7.61190026e+00 2.50787463e-02\n",
      " 2.53435344e-01 1.13986566e+01], Loss = 0.3898\n",
      "Iteration 4911: Weights = [5.50000000e+01 3.62027291e+00 7.61168175e+00 2.50780264e-02\n",
      " 2.53428069e-01 1.13988875e+01], Loss = 0.3898\n",
      "Iteration 4912: Weights = [5.50000000e+01 3.62016898e+00 7.61146325e+00 2.50773065e-02\n",
      " 2.53420794e-01 1.13991183e+01], Loss = 0.3898\n",
      "Iteration 4913: Weights = [5.50000000e+01 3.62006506e+00 7.61124475e+00 2.50765866e-02\n",
      " 2.53413519e-01 1.13993491e+01], Loss = 0.3897\n",
      "Iteration 4914: Weights = [5.50000000e+01 3.61996114e+00 7.61102626e+00 2.50758668e-02\n",
      " 2.53406245e-01 1.13995800e+01], Loss = 0.3897\n",
      "Iteration 4915: Weights = [5.50000000e+01 3.61985723e+00 7.61080778e+00 2.50751469e-02\n",
      " 2.53398971e-01 1.13998108e+01], Loss = 0.3897\n",
      "Iteration 4916: Weights = [5.50000000e+01 3.61975332e+00 7.61058930e+00 2.50744271e-02\n",
      " 2.53391696e-01 1.14000416e+01], Loss = 0.3897\n",
      "Iteration 4917: Weights = [5.50000000e+01 3.61964941e+00 7.61037083e+00 2.50737073e-02\n",
      " 2.53384422e-01 1.14002724e+01], Loss = 0.3897\n",
      "Iteration 4918: Weights = [5.50000000e+01 3.61954550e+00 7.61015236e+00 2.50729875e-02\n",
      " 2.53377149e-01 1.14005032e+01], Loss = 0.3896\n",
      "Iteration 4919: Weights = [5.50000000e+01 3.61944160e+00 7.60993390e+00 2.50722678e-02\n",
      " 2.53369875e-01 1.14007340e+01], Loss = 0.3896\n",
      "Iteration 4920: Weights = [5.50000000e+01 3.61933769e+00 7.60971545e+00 2.50715481e-02\n",
      " 2.53362602e-01 1.14009648e+01], Loss = 0.3896\n",
      "Iteration 4921: Weights = [5.50000000e+01 3.61923380e+00 7.60949700e+00 2.50708283e-02\n",
      " 2.53355329e-01 1.14011956e+01], Loss = 0.3896\n",
      "Iteration 4922: Weights = [5.50000000e+01 3.61912990e+00 7.60927856e+00 2.50701087e-02\n",
      " 2.53348056e-01 1.14014264e+01], Loss = 0.3895\n",
      "Iteration 4923: Weights = [5.50000000e+01 3.61902601e+00 7.60906013e+00 2.50693890e-02\n",
      " 2.53340783e-01 1.14016572e+01], Loss = 0.3895\n",
      "Iteration 4924: Weights = [5.50000000e+01 3.61892212e+00 7.60884170e+00 2.50686693e-02\n",
      " 2.53333511e-01 1.14018879e+01], Loss = 0.3895\n",
      "Iteration 4925: Weights = [5.50000000e+01 3.61881823e+00 7.60862328e+00 2.50679497e-02\n",
      " 2.53326238e-01 1.14021187e+01], Loss = 0.3895\n",
      "Iteration 4926: Weights = [5.50000000e+01 3.61871435e+00 7.60840486e+00 2.50672301e-02\n",
      " 2.53318966e-01 1.14023494e+01], Loss = 0.3895\n",
      "Iteration 4927: Weights = [5.50000000e+01 3.61861047e+00 7.60818645e+00 2.50665105e-02\n",
      " 2.53311694e-01 1.14025802e+01], Loss = 0.3894\n",
      "Iteration 4928: Weights = [5.50000000e+01 3.61850660e+00 7.60796805e+00 2.50657909e-02\n",
      " 2.53304423e-01 1.14028109e+01], Loss = 0.3894\n",
      "Iteration 4929: Weights = [5.50000000e+01 3.61840272e+00 7.60774966e+00 2.50650714e-02\n",
      " 2.53297151e-01 1.14030417e+01], Loss = 0.3894\n",
      "Iteration 4930: Weights = [5.50000000e+01 3.61829885e+00 7.60753126e+00 2.50643519e-02\n",
      " 2.53289880e-01 1.14032724e+01], Loss = 0.3894\n",
      "Iteration 4931: Weights = [5.50000000e+01 3.61819498e+00 7.60731288e+00 2.50636324e-02\n",
      " 2.53282609e-01 1.14035031e+01], Loss = 0.3893\n",
      "Iteration 4932: Weights = [5.50000000e+01 3.61809112e+00 7.60709450e+00 2.50629129e-02\n",
      " 2.53275338e-01 1.14037338e+01], Loss = 0.3893\n",
      "Iteration 4933: Weights = [5.50000000e+01 3.61798726e+00 7.60687613e+00 2.50621934e-02\n",
      " 2.53268068e-01 1.14039645e+01], Loss = 0.3893\n",
      "Iteration 4934: Weights = [5.50000000e+01 3.61788340e+00 7.60665777e+00 2.50614740e-02\n",
      " 2.53260797e-01 1.14041952e+01], Loss = 0.3893\n",
      "Iteration 4935: Weights = [5.50000000e+01 3.61777954e+00 7.60643941e+00 2.50607546e-02\n",
      " 2.53253527e-01 1.14044259e+01], Loss = 0.3893\n",
      "Iteration 4936: Weights = [5.50000000e+01 3.61767569e+00 7.60622105e+00 2.50600352e-02\n",
      " 2.53246257e-01 1.14046566e+01], Loss = 0.3892\n",
      "Iteration 4937: Weights = [5.50000000e+01 3.61757184e+00 7.60600271e+00 2.50593158e-02\n",
      " 2.53238987e-01 1.14048873e+01], Loss = 0.3892\n",
      "Iteration 4938: Weights = [5.50000000e+01 3.61746799e+00 7.60578437e+00 2.50585964e-02\n",
      " 2.53231718e-01 1.14051180e+01], Loss = 0.3892\n",
      "Iteration 4939: Weights = [5.50000000e+01 3.61736415e+00 7.60556603e+00 2.50578771e-02\n",
      " 2.53224449e-01 1.14053486e+01], Loss = 0.3892\n",
      "Iteration 4940: Weights = [5.50000000e+01 3.61726030e+00 7.60534771e+00 2.50571577e-02\n",
      " 2.53217179e-01 1.14055793e+01], Loss = 0.3891\n",
      "Iteration 4941: Weights = [5.50000000e+01 3.61715647e+00 7.60512938e+00 2.50564385e-02\n",
      " 2.53209910e-01 1.14058099e+01], Loss = 0.3891\n",
      "Iteration 4942: Weights = [5.50000000e+01 3.61705263e+00 7.60491107e+00 2.50557192e-02\n",
      " 2.53202642e-01 1.14060406e+01], Loss = 0.3891\n",
      "Iteration 4943: Weights = [5.50000000e+01 3.61694880e+00 7.60469276e+00 2.50549999e-02\n",
      " 2.53195373e-01 1.14062712e+01], Loss = 0.3891\n",
      "Iteration 4944: Weights = [5.50000000e+01 3.61684497e+00 7.60447446e+00 2.50542807e-02\n",
      " 2.53188105e-01 1.14065019e+01], Loss = 0.3890\n",
      "Iteration 4945: Weights = [5.50000000e+01 3.61674114e+00 7.60425616e+00 2.50535615e-02\n",
      " 2.53180837e-01 1.14067325e+01], Loss = 0.3890\n",
      "Iteration 4946: Weights = [5.50000000e+01 3.61663732e+00 7.60403787e+00 2.50528423e-02\n",
      " 2.53173569e-01 1.14069631e+01], Loss = 0.3890\n",
      "Iteration 4947: Weights = [5.50000000e+01 3.61653350e+00 7.60381959e+00 2.50521231e-02\n",
      " 2.53166301e-01 1.14071937e+01], Loss = 0.3890\n",
      "Iteration 4948: Weights = [5.50000000e+01 3.61642968e+00 7.60360131e+00 2.50514039e-02\n",
      " 2.53159034e-01 1.14074243e+01], Loss = 0.3890\n",
      "Iteration 4949: Weights = [5.50000000e+01 3.61632587e+00 7.60338304e+00 2.50506848e-02\n",
      " 2.53151767e-01 1.14076549e+01], Loss = 0.3889\n",
      "Iteration 4950: Weights = [5.50000000e+01 3.61622206e+00 7.60316477e+00 2.50499657e-02\n",
      " 2.53144499e-01 1.14078855e+01], Loss = 0.3889\n",
      "Iteration 4951: Weights = [5.50000000e+01 3.61611825e+00 7.60294651e+00 2.50492466e-02\n",
      " 2.53137233e-01 1.14081161e+01], Loss = 0.3889\n",
      "Iteration 4952: Weights = [5.50000000e+01 3.61601444e+00 7.60272826e+00 2.50485275e-02\n",
      " 2.53129966e-01 1.14083467e+01], Loss = 0.3889\n",
      "Iteration 4953: Weights = [5.50000000e+01 3.61591064e+00 7.60251002e+00 2.50478085e-02\n",
      " 2.53122700e-01 1.14085773e+01], Loss = 0.3888\n",
      "Iteration 4954: Weights = [5.50000000e+01 3.61580684e+00 7.60229178e+00 2.50470894e-02\n",
      " 2.53115433e-01 1.14088078e+01], Loss = 0.3888\n",
      "Iteration 4955: Weights = [5.50000000e+01 3.61570304e+00 7.60207354e+00 2.50463704e-02\n",
      " 2.53108167e-01 1.14090384e+01], Loss = 0.3888\n",
      "Iteration 4956: Weights = [5.50000000e+01 3.61559925e+00 7.60185531e+00 2.50456515e-02\n",
      " 2.53100902e-01 1.14092689e+01], Loss = 0.3888\n",
      "Iteration 4957: Weights = [5.50000000e+01 3.61549546e+00 7.60163709e+00 2.50449325e-02\n",
      " 2.53093636e-01 1.14094995e+01], Loss = 0.3888\n",
      "Iteration 4958: Weights = [5.50000000e+01 3.61539167e+00 7.60141888e+00 2.50442135e-02\n",
      " 2.53086371e-01 1.14097300e+01], Loss = 0.3887\n",
      "Iteration 4959: Weights = [5.50000000e+01 3.61528789e+00 7.60120067e+00 2.50434946e-02\n",
      " 2.53079105e-01 1.14099606e+01], Loss = 0.3887\n",
      "Iteration 4960: Weights = [5.50000000e+01 3.61518411e+00 7.60098247e+00 2.50427757e-02\n",
      " 2.53071840e-01 1.14101911e+01], Loss = 0.3887\n",
      "Iteration 4961: Weights = [5.50000000e+01 3.61508033e+00 7.60076427e+00 2.50420568e-02\n",
      " 2.53064576e-01 1.14104216e+01], Loss = 0.3887\n",
      "Iteration 4962: Weights = [5.50000000e+01 3.61497655e+00 7.60054608e+00 2.50413380e-02\n",
      " 2.53057311e-01 1.14106521e+01], Loss = 0.3886\n",
      "Iteration 4963: Weights = [5.50000000e+01 3.61487278e+00 7.60032790e+00 2.50406191e-02\n",
      " 2.53050047e-01 1.14108826e+01], Loss = 0.3886\n",
      "Iteration 4964: Weights = [5.50000000e+01 3.61476901e+00 7.60010972e+00 2.50399003e-02\n",
      " 2.53042783e-01 1.14111131e+01], Loss = 0.3886\n",
      "Iteration 4965: Weights = [5.50000000e+01 3.61466524e+00 7.59989155e+00 2.50391815e-02\n",
      " 2.53035519e-01 1.14113436e+01], Loss = 0.3886\n",
      "Iteration 4966: Weights = [5.50000000e+01 3.61456148e+00 7.59967338e+00 2.50384627e-02\n",
      " 2.53028255e-01 1.14115741e+01], Loss = 0.3886\n",
      "Iteration 4967: Weights = [5.50000000e+01 3.61445772e+00 7.59945523e+00 2.50377439e-02\n",
      " 2.53020992e-01 1.14118046e+01], Loss = 0.3885\n",
      "Iteration 4968: Weights = [5.50000000e+01 3.61435396e+00 7.59923707e+00 2.50370252e-02\n",
      " 2.53013728e-01 1.14120351e+01], Loss = 0.3885\n",
      "Iteration 4969: Weights = [5.50000000e+01 3.61425021e+00 7.59901893e+00 2.50363065e-02\n",
      " 2.53006465e-01 1.14122655e+01], Loss = 0.3885\n",
      "Iteration 4970: Weights = [5.50000000e+01 3.61414645e+00 7.59880079e+00 2.50355878e-02\n",
      " 2.52999202e-01 1.14124960e+01], Loss = 0.3885\n",
      "Iteration 4971: Weights = [5.50000000e+01 3.61404271e+00 7.59858265e+00 2.50348691e-02\n",
      " 2.52991940e-01 1.14127265e+01], Loss = 0.3884\n",
      "Iteration 4972: Weights = [5.50000000e+01 3.61393896e+00 7.59836453e+00 2.50341504e-02\n",
      " 2.52984677e-01 1.14129569e+01], Loss = 0.3884\n",
      "Iteration 4973: Weights = [5.50000000e+01 3.61383522e+00 7.59814641e+00 2.50334318e-02\n",
      " 2.52977415e-01 1.14131873e+01], Loss = 0.3884\n",
      "Iteration 4974: Weights = [5.50000000e+01 3.61373148e+00 7.59792829e+00 2.50327132e-02\n",
      " 2.52970153e-01 1.14134178e+01], Loss = 0.3884\n",
      "Iteration 4975: Weights = [5.50000000e+01 3.61362774e+00 7.59771018e+00 2.50319946e-02\n",
      " 2.52962891e-01 1.14136482e+01], Loss = 0.3884\n",
      "Iteration 4976: Weights = [5.50000000e+01 3.61352401e+00 7.59749208e+00 2.50312760e-02\n",
      " 2.52955629e-01 1.14138786e+01], Loss = 0.3883\n",
      "Iteration 4977: Weights = [5.50000000e+01 3.61342028e+00 7.59727398e+00 2.50305575e-02\n",
      " 2.52948368e-01 1.14141090e+01], Loss = 0.3883\n",
      "Iteration 4978: Weights = [5.50000000e+01 3.61331655e+00 7.59705589e+00 2.50298389e-02\n",
      " 2.52941107e-01 1.14143394e+01], Loss = 0.3883\n",
      "Iteration 4979: Weights = [5.50000000e+01 3.61321282e+00 7.59683781e+00 2.50291204e-02\n",
      " 2.52933846e-01 1.14145699e+01], Loss = 0.3883\n",
      "Iteration 4980: Weights = [5.50000000e+01 3.61310910e+00 7.59661973e+00 2.50284019e-02\n",
      " 2.52926585e-01 1.14148002e+01], Loss = 0.3882\n",
      "Iteration 4981: Weights = [5.50000000e+01 3.61300538e+00 7.59640166e+00 2.50276834e-02\n",
      " 2.52919324e-01 1.14150306e+01], Loss = 0.3882\n",
      "Iteration 4982: Weights = [5.50000000e+01 3.61290167e+00 7.59618360e+00 2.50269650e-02\n",
      " 2.52912064e-01 1.14152610e+01], Loss = 0.3882\n",
      "Iteration 4983: Weights = [5.50000000e+01 3.61279795e+00 7.59596554e+00 2.50262466e-02\n",
      " 2.52904804e-01 1.14154914e+01], Loss = 0.3882\n",
      "Iteration 4984: Weights = [5.50000000e+01 3.61269424e+00 7.59574749e+00 2.50255281e-02\n",
      " 2.52897544e-01 1.14157218e+01], Loss = 0.3882\n",
      "Iteration 4985: Weights = [5.50000000e+01 3.61259054e+00 7.59552944e+00 2.50248098e-02\n",
      " 2.52890284e-01 1.14159521e+01], Loss = 0.3881\n",
      "Iteration 4986: Weights = [5.50000000e+01 3.61248683e+00 7.59531140e+00 2.50240914e-02\n",
      " 2.52883024e-01 1.14161825e+01], Loss = 0.3881\n",
      "Iteration 4987: Weights = [5.50000000e+01 3.61238313e+00 7.59509337e+00 2.50233730e-02\n",
      " 2.52875765e-01 1.14164128e+01], Loss = 0.3881\n",
      "Iteration 4988: Weights = [5.50000000e+01 3.61227943e+00 7.59487534e+00 2.50226547e-02\n",
      " 2.52868506e-01 1.14166432e+01], Loss = 0.3881\n",
      "Iteration 4989: Weights = [5.50000000e+01 3.61217574e+00 7.59465732e+00 2.50219364e-02\n",
      " 2.52861247e-01 1.14168735e+01], Loss = 0.3880\n",
      "Iteration 4990: Weights = [5.50000000e+01 3.61207204e+00 7.59443931e+00 2.50212181e-02\n",
      " 2.52853988e-01 1.14171038e+01], Loss = 0.3880\n",
      "Iteration 4991: Weights = [5.50000000e+01 3.61196836e+00 7.59422130e+00 2.50204998e-02\n",
      " 2.52846730e-01 1.14173342e+01], Loss = 0.3880\n",
      "Iteration 4992: Weights = [5.50000000e+01 3.61186467e+00 7.59400330e+00 2.50197816e-02\n",
      " 2.52839472e-01 1.14175645e+01], Loss = 0.3880\n",
      "Iteration 4993: Weights = [5.50000000e+01 3.61176099e+00 7.59378530e+00 2.50190634e-02\n",
      " 2.52832213e-01 1.14177948e+01], Loss = 0.3880\n",
      "Iteration 4994: Weights = [5.50000000e+01 3.61165731e+00 7.59356731e+00 2.50183452e-02\n",
      " 2.52824956e-01 1.14180251e+01], Loss = 0.3879\n",
      "Iteration 4995: Weights = [5.50000000e+01 3.61155363e+00 7.59334933e+00 2.50176270e-02\n",
      " 2.52817698e-01 1.14182554e+01], Loss = 0.3879\n",
      "Iteration 4996: Weights = [5.50000000e+01 3.61144995e+00 7.59313135e+00 2.50169088e-02\n",
      " 2.52810440e-01 1.14184857e+01], Loss = 0.3879\n",
      "Iteration 4997: Weights = [5.50000000e+01 3.61134628e+00 7.59291338e+00 2.50161907e-02\n",
      " 2.52803183e-01 1.14187159e+01], Loss = 0.3879\n",
      "Iteration 4998: Weights = [5.50000000e+01 3.61124261e+00 7.59269541e+00 2.50154725e-02\n",
      " 2.52795926e-01 1.14189462e+01], Loss = 0.3878\n",
      "Iteration 4999: Weights = [5.50000000e+01 3.61113895e+00 7.59247746e+00 2.50147544e-02\n",
      " 2.52788669e-01 1.14191765e+01], Loss = 0.3878\n",
      "Iteration 5000: Weights = [5.50000000e+01 3.61103529e+00 7.59225950e+00 2.50140364e-02\n",
      " 2.52781413e-01 1.14194068e+01], Loss = 0.3878\n",
      "Iteration 5001: Weights = [5.50000000e+01 3.61093163e+00 7.59204156e+00 2.50133183e-02\n",
      " 2.52774156e-01 1.14196370e+01], Loss = 0.3878\n",
      "Iteration 5002: Weights = [5.50000000e+01 3.61082797e+00 7.59182362e+00 2.50126003e-02\n",
      " 2.52766900e-01 1.14198673e+01], Loss = 0.3878\n",
      "Iteration 5003: Weights = [5.50000000e+01 3.61072432e+00 7.59160569e+00 2.50118822e-02\n",
      " 2.52759644e-01 1.14200975e+01], Loss = 0.3877\n",
      "Iteration 5004: Weights = [5.50000000e+01 3.61062067e+00 7.59138776e+00 2.50111642e-02\n",
      " 2.52752388e-01 1.14203277e+01], Loss = 0.3877\n",
      "Iteration 5005: Weights = [5.50000000e+01 3.61051702e+00 7.59116984e+00 2.50104463e-02\n",
      " 2.52745133e-01 1.14205580e+01], Loss = 0.3877\n",
      "Iteration 5006: Weights = [5.50000000e+01 3.61041337e+00 7.59095192e+00 2.50097283e-02\n",
      " 2.52737877e-01 1.14207882e+01], Loss = 0.3877\n",
      "Iteration 5007: Weights = [5.50000000e+01 3.61030973e+00 7.59073402e+00 2.50090104e-02\n",
      " 2.52730622e-01 1.14210184e+01], Loss = 0.3876\n",
      "Iteration 5008: Weights = [5.50000000e+01 3.61020609e+00 7.59051611e+00 2.50082925e-02\n",
      " 2.52723367e-01 1.14212486e+01], Loss = 0.3876\n",
      "Iteration 5009: Weights = [5.50000000e+01 3.61010246e+00 7.59029822e+00 2.50075746e-02\n",
      " 2.52716112e-01 1.14214788e+01], Loss = 0.3876\n",
      "Iteration 5010: Weights = [5.50000000e+01 3.60999882e+00 7.59008033e+00 2.50068567e-02\n",
      " 2.52708858e-01 1.14217090e+01], Loss = 0.3876\n",
      "Iteration 5011: Weights = [5.50000000e+01 3.60989520e+00 7.58986245e+00 2.50061388e-02\n",
      " 2.52701604e-01 1.14219392e+01], Loss = 0.3876\n",
      "Iteration 5012: Weights = [5.50000000e+01 3.60979157e+00 7.58964457e+00 2.50054210e-02\n",
      " 2.52694349e-01 1.14221694e+01], Loss = 0.3875\n",
      "Iteration 5013: Weights = [5.50000000e+01 3.60968794e+00 7.58942670e+00 2.50047032e-02\n",
      " 2.52687095e-01 1.14223996e+01], Loss = 0.3875\n",
      "Iteration 5014: Weights = [5.50000000e+01 3.60958432e+00 7.58920883e+00 2.50039854e-02\n",
      " 2.52679842e-01 1.14226297e+01], Loss = 0.3875\n",
      "Iteration 5015: Weights = [5.50000000e+01 3.60948071e+00 7.58899098e+00 2.50032676e-02\n",
      " 2.52672588e-01 1.14228599e+01], Loss = 0.3875\n",
      "Iteration 5016: Weights = [5.50000000e+01 3.60937709e+00 7.58877312e+00 2.50025499e-02\n",
      " 2.52665335e-01 1.14230901e+01], Loss = 0.3874\n",
      "Iteration 5017: Weights = [5.50000000e+01 3.60927348e+00 7.58855528e+00 2.50018321e-02\n",
      " 2.52658082e-01 1.14233202e+01], Loss = 0.3874\n",
      "Iteration 5018: Weights = [5.50000000e+01 3.60916987e+00 7.58833744e+00 2.50011144e-02\n",
      " 2.52650829e-01 1.14235504e+01], Loss = 0.3874\n",
      "Iteration 5019: Weights = [5.50000000e+01 3.60906626e+00 7.58811961e+00 2.50003967e-02\n",
      " 2.52643576e-01 1.14237805e+01], Loss = 0.3874\n",
      "Iteration 5020: Weights = [5.50000000e+01 3.60896266e+00 7.58790178e+00 2.49996791e-02\n",
      " 2.52636324e-01 1.14240106e+01], Loss = 0.3874\n",
      "Iteration 5021: Weights = [5.50000000e+01 3.60885906e+00 7.58768396e+00 2.49989614e-02\n",
      " 2.52629072e-01 1.14242408e+01], Loss = 0.3873\n",
      "Iteration 5022: Weights = [5.50000000e+01 3.60875546e+00 7.58746614e+00 2.49982438e-02\n",
      " 2.52621820e-01 1.14244709e+01], Loss = 0.3873\n",
      "Iteration 5023: Weights = [5.50000000e+01 3.60865187e+00 7.58724833e+00 2.49975262e-02\n",
      " 2.52614568e-01 1.14247010e+01], Loss = 0.3873\n",
      "Iteration 5024: Weights = [5.50000000e+01 3.60854828e+00 7.58703053e+00 2.49968086e-02\n",
      " 2.52607316e-01 1.14249311e+01], Loss = 0.3873\n",
      "Iteration 5025: Weights = [5.50000000e+01 3.60844469e+00 7.58681274e+00 2.49960910e-02\n",
      " 2.52600065e-01 1.14251612e+01], Loss = 0.3872\n",
      "Iteration 5026: Weights = [5.50000000e+01 3.60834111e+00 7.58659495e+00 2.49953735e-02\n",
      " 2.52592813e-01 1.14253913e+01], Loss = 0.3872\n",
      "Iteration 5027: Weights = [5.50000000e+01 3.60823752e+00 7.58637716e+00 2.49946560e-02\n",
      " 2.52585562e-01 1.14256214e+01], Loss = 0.3872\n",
      "Iteration 5028: Weights = [5.50000000e+01 3.60813394e+00 7.58615939e+00 2.49939385e-02\n",
      " 2.52578312e-01 1.14258514e+01], Loss = 0.3872\n",
      "Iteration 5029: Weights = [5.50000000e+01 3.60803037e+00 7.58594162e+00 2.49932210e-02\n",
      " 2.52571061e-01 1.14260815e+01], Loss = 0.3872\n",
      "Iteration 5030: Weights = [5.50000000e+01 3.60792680e+00 7.58572385e+00 2.49925035e-02\n",
      " 2.52563811e-01 1.14263116e+01], Loss = 0.3871\n",
      "Iteration 5031: Weights = [5.50000000e+01 3.60782322e+00 7.58550609e+00 2.49917861e-02\n",
      " 2.52556560e-01 1.14265416e+01], Loss = 0.3871\n",
      "Iteration 5032: Weights = [5.50000000e+01 3.60771966e+00 7.58528834e+00 2.49910686e-02\n",
      " 2.52549311e-01 1.14267717e+01], Loss = 0.3871\n",
      "Iteration 5033: Weights = [5.50000000e+01 3.60761609e+00 7.58507060e+00 2.49903512e-02\n",
      " 2.52542061e-01 1.14270017e+01], Loss = 0.3871\n",
      "Iteration 5034: Weights = [5.50000000e+01 3.60751253e+00 7.58485286e+00 2.49896339e-02\n",
      " 2.52534811e-01 1.14272318e+01], Loss = 0.3870\n",
      "Iteration 5035: Weights = [5.50000000e+01 3.60740897e+00 7.58463512e+00 2.49889165e-02\n",
      " 2.52527562e-01 1.14274618e+01], Loss = 0.3870\n",
      "Iteration 5036: Weights = [5.50000000e+01 3.60730542e+00 7.58441740e+00 2.49881992e-02\n",
      " 2.52520313e-01 1.14276918e+01], Loss = 0.3870\n",
      "Iteration 5037: Weights = [5.50000000e+01 3.60720187e+00 7.58419968e+00 2.49874818e-02\n",
      " 2.52513064e-01 1.14279218e+01], Loss = 0.3870\n",
      "Iteration 5038: Weights = [5.50000000e+01 3.60709832e+00 7.58398196e+00 2.49867645e-02\n",
      " 2.52505815e-01 1.14281518e+01], Loss = 0.3870\n",
      "Iteration 5039: Weights = [5.50000000e+01 3.60699477e+00 7.58376425e+00 2.49860473e-02\n",
      " 2.52498567e-01 1.14283819e+01], Loss = 0.3869\n",
      "Iteration 5040: Weights = [5.50000000e+01 3.60689123e+00 7.58354655e+00 2.49853300e-02\n",
      " 2.52491318e-01 1.14286119e+01], Loss = 0.3869\n",
      "Iteration 5041: Weights = [5.50000000e+01 3.60678769e+00 7.58332886e+00 2.49846128e-02\n",
      " 2.52484070e-01 1.14288418e+01], Loss = 0.3869\n",
      "Iteration 5042: Weights = [5.50000000e+01 3.60668415e+00 7.58311117e+00 2.49838956e-02\n",
      " 2.52476822e-01 1.14290718e+01], Loss = 0.3869\n",
      "Iteration 5043: Weights = [5.50000000e+01 3.60658061e+00 7.58289348e+00 2.49831784e-02\n",
      " 2.52469575e-01 1.14293018e+01], Loss = 0.3868\n",
      "Iteration 5044: Weights = [5.50000000e+01 3.60647708e+00 7.58267581e+00 2.49824612e-02\n",
      " 2.52462327e-01 1.14295318e+01], Loss = 0.3868\n",
      "Iteration 5045: Weights = [5.50000000e+01 3.60637355e+00 7.58245814e+00 2.49817440e-02\n",
      " 2.52455080e-01 1.14297617e+01], Loss = 0.3868\n",
      "Iteration 5046: Weights = [5.50000000e+01 3.60627003e+00 7.58224047e+00 2.49810269e-02\n",
      " 2.52447833e-01 1.14299917e+01], Loss = 0.3868\n",
      "Iteration 5047: Weights = [5.50000000e+01 3.60616650e+00 7.58202281e+00 2.49803098e-02\n",
      " 2.52440586e-01 1.14302217e+01], Loss = 0.3868\n",
      "Iteration 5048: Weights = [5.50000000e+01 3.60606299e+00 7.58180516e+00 2.49795927e-02\n",
      " 2.52433339e-01 1.14304516e+01], Loss = 0.3867\n",
      "Iteration 5049: Weights = [5.50000000e+01 3.60595947e+00 7.58158752e+00 2.49788756e-02\n",
      " 2.52426093e-01 1.14306815e+01], Loss = 0.3867\n",
      "Iteration 5050: Weights = [5.50000000e+01 3.60585595e+00 7.58136988e+00 2.49781586e-02\n",
      " 2.52418847e-01 1.14309115e+01], Loss = 0.3867\n",
      "Iteration 5051: Weights = [5.50000000e+01 3.60575244e+00 7.58115224e+00 2.49774415e-02\n",
      " 2.52411601e-01 1.14311414e+01], Loss = 0.3867\n",
      "Iteration 5052: Weights = [5.50000000e+01 3.60564894e+00 7.58093462e+00 2.49767245e-02\n",
      " 2.52404355e-01 1.14313713e+01], Loss = 0.3866\n",
      "Iteration 5053: Weights = [5.50000000e+01 3.60554543e+00 7.58071700e+00 2.49760075e-02\n",
      " 2.52397109e-01 1.14316012e+01], Loss = 0.3866\n",
      "Iteration 5054: Weights = [5.50000000e+01 3.60544193e+00 7.58049938e+00 2.49752906e-02\n",
      " 2.52389864e-01 1.14318311e+01], Loss = 0.3866\n",
      "Iteration 5055: Weights = [5.50000000e+01 3.60533843e+00 7.58028177e+00 2.49745736e-02\n",
      " 2.52382619e-01 1.14320610e+01], Loss = 0.3866\n",
      "Iteration 5056: Weights = [5.50000000e+01 3.60523493e+00 7.58006417e+00 2.49738567e-02\n",
      " 2.52375374e-01 1.14322909e+01], Loss = 0.3866\n",
      "Iteration 5057: Weights = [5.50000000e+01 3.60513144e+00 7.57984658e+00 2.49731398e-02\n",
      " 2.52368129e-01 1.14325208e+01], Loss = 0.3865\n",
      "Iteration 5058: Weights = [5.50000000e+01 3.60502795e+00 7.57962899e+00 2.49724229e-02\n",
      " 2.52360884e-01 1.14327507e+01], Loss = 0.3865\n",
      "Iteration 5059: Weights = [5.50000000e+01 3.60492446e+00 7.57941140e+00 2.49717060e-02\n",
      " 2.52353640e-01 1.14329806e+01], Loss = 0.3865\n",
      "Iteration 5060: Weights = [5.50000000e+01 3.60482098e+00 7.57919383e+00 2.49709892e-02\n",
      " 2.52346396e-01 1.14332104e+01], Loss = 0.3865\n",
      "Iteration 5061: Weights = [5.50000000e+01 3.60471750e+00 7.57897626e+00 2.49702724e-02\n",
      " 2.52339152e-01 1.14334403e+01], Loss = 0.3864\n",
      "Iteration 5062: Weights = [5.50000000e+01 3.60461402e+00 7.57875869e+00 2.49695556e-02\n",
      " 2.52331908e-01 1.14336701e+01], Loss = 0.3864\n",
      "Iteration 5063: Weights = [5.50000000e+01 3.60451055e+00 7.57854113e+00 2.49688388e-02\n",
      " 2.52324665e-01 1.14339000e+01], Loss = 0.3864\n",
      "Iteration 5064: Weights = [5.50000000e+01 3.60440707e+00 7.57832358e+00 2.49681220e-02\n",
      " 2.52317421e-01 1.14341298e+01], Loss = 0.3864\n",
      "Iteration 5065: Weights = [5.50000000e+01 3.60430360e+00 7.57810604e+00 2.49674053e-02\n",
      " 2.52310178e-01 1.14343597e+01], Loss = 0.3864\n",
      "Iteration 5066: Weights = [5.50000000e+01 3.60420014e+00 7.57788850e+00 2.49666886e-02\n",
      " 2.52302935e-01 1.14345895e+01], Loss = 0.3863\n",
      "Iteration 5067: Weights = [5.50000000e+01 3.60409667e+00 7.57767096e+00 2.49659718e-02\n",
      " 2.52295693e-01 1.14348193e+01], Loss = 0.3863\n",
      "Iteration 5068: Weights = [5.50000000e+01 3.60399321e+00 7.57745344e+00 2.49652552e-02\n",
      " 2.52288450e-01 1.14350491e+01], Loss = 0.3863\n",
      "Iteration 5069: Weights = [5.50000000e+01 3.60388976e+00 7.57723592e+00 2.49645385e-02\n",
      " 2.52281208e-01 1.14352789e+01], Loss = 0.3863\n",
      "Iteration 5070: Weights = [5.50000000e+01 3.60378630e+00 7.57701840e+00 2.49638219e-02\n",
      " 2.52273966e-01 1.14355087e+01], Loss = 0.3862\n",
      "Iteration 5071: Weights = [5.50000000e+01 3.60368285e+00 7.57680089e+00 2.49631052e-02\n",
      " 2.52266724e-01 1.14357385e+01], Loss = 0.3862\n",
      "Iteration 5072: Weights = [5.50000000e+01 3.60357940e+00 7.57658339e+00 2.49623887e-02\n",
      " 2.52259482e-01 1.14359683e+01], Loss = 0.3862\n",
      "Iteration 5073: Weights = [5.50000000e+01 3.60347596e+00 7.57636590e+00 2.49616721e-02\n",
      " 2.52252241e-01 1.14361981e+01], Loss = 0.3862\n",
      "Iteration 5074: Weights = [5.50000000e+01 3.60337252e+00 7.57614841e+00 2.49609555e-02\n",
      " 2.52245000e-01 1.14364279e+01], Loss = 0.3862\n",
      "Iteration 5075: Weights = [5.50000000e+01 3.60326908e+00 7.57593092e+00 2.49602390e-02\n",
      " 2.52237759e-01 1.14366576e+01], Loss = 0.3861\n",
      "Iteration 5076: Weights = [5.50000000e+01 3.60316564e+00 7.57571345e+00 2.49595225e-02\n",
      " 2.52230518e-01 1.14368874e+01], Loss = 0.3861\n",
      "Iteration 5077: Weights = [5.50000000e+01 3.60306221e+00 7.57549598e+00 2.49588060e-02\n",
      " 2.52223277e-01 1.14371172e+01], Loss = 0.3861\n",
      "Iteration 5078: Weights = [5.50000000e+01 3.60295877e+00 7.57527851e+00 2.49580895e-02\n",
      " 2.52216037e-01 1.14373469e+01], Loss = 0.3861\n",
      "Iteration 5079: Weights = [5.50000000e+01 3.60285535e+00 7.57506105e+00 2.49573730e-02\n",
      " 2.52208797e-01 1.14375766e+01], Loss = 0.3860\n",
      "Iteration 5080: Weights = [5.50000000e+01 3.60275192e+00 7.57484360e+00 2.49566566e-02\n",
      " 2.52201557e-01 1.14378064e+01], Loss = 0.3860\n",
      "Iteration 5081: Weights = [5.50000000e+01 3.60264850e+00 7.57462615e+00 2.49559402e-02\n",
      " 2.52194317e-01 1.14380361e+01], Loss = 0.3860\n",
      "Iteration 5082: Weights = [5.50000000e+01 3.60254508e+00 7.57440871e+00 2.49552238e-02\n",
      " 2.52187077e-01 1.14382658e+01], Loss = 0.3860\n",
      "Iteration 5083: Weights = [5.50000000e+01 3.60244167e+00 7.57419128e+00 2.49545074e-02\n",
      " 2.52179838e-01 1.14384955e+01], Loss = 0.3860\n",
      "Iteration 5084: Weights = [5.50000000e+01 3.60233825e+00 7.57397385e+00 2.49537911e-02\n",
      " 2.52172599e-01 1.14387253e+01], Loss = 0.3859\n",
      "Iteration 5085: Weights = [5.50000000e+01 3.60223484e+00 7.57375643e+00 2.49530747e-02\n",
      " 2.52165360e-01 1.14389550e+01], Loss = 0.3859\n",
      "Iteration 5086: Weights = [5.50000000e+01 3.60213144e+00 7.57353902e+00 2.49523584e-02\n",
      " 2.52158121e-01 1.14391847e+01], Loss = 0.3859\n",
      "Iteration 5087: Weights = [5.50000000e+01 3.60202803e+00 7.57332161e+00 2.49516421e-02\n",
      " 2.52150883e-01 1.14394143e+01], Loss = 0.3859\n",
      "Iteration 5088: Weights = [5.50000000e+01 3.60192463e+00 7.57310421e+00 2.49509259e-02\n",
      " 2.52143644e-01 1.14396440e+01], Loss = 0.3858\n",
      "Iteration 5089: Weights = [5.50000000e+01 3.60182123e+00 7.57288681e+00 2.49502096e-02\n",
      " 2.52136406e-01 1.14398737e+01], Loss = 0.3858\n",
      "Iteration 5090: Weights = [5.50000000e+01 3.60171784e+00 7.57266942e+00 2.49494934e-02\n",
      " 2.52129168e-01 1.14401034e+01], Loss = 0.3858\n",
      "Iteration 5091: Weights = [5.50000000e+01 3.60161445e+00 7.57245204e+00 2.49487772e-02\n",
      " 2.52121931e-01 1.14403330e+01], Loss = 0.3858\n",
      "Iteration 5092: Weights = [5.50000000e+01 3.60151106e+00 7.57223466e+00 2.49480610e-02\n",
      " 2.52114693e-01 1.14405627e+01], Loss = 0.3858\n",
      "Iteration 5093: Weights = [5.50000000e+01 3.60140767e+00 7.57201729e+00 2.49473448e-02\n",
      " 2.52107456e-01 1.14407923e+01], Loss = 0.3857\n",
      "Iteration 5094: Weights = [5.50000000e+01 3.60130429e+00 7.57179993e+00 2.49466287e-02\n",
      " 2.52100219e-01 1.14410220e+01], Loss = 0.3857\n",
      "Iteration 5095: Weights = [5.50000000e+01 3.60120091e+00 7.57158257e+00 2.49459126e-02\n",
      " 2.52092982e-01 1.14412516e+01], Loss = 0.3857\n",
      "Iteration 5096: Weights = [5.50000000e+01 3.60109753e+00 7.57136522e+00 2.49451965e-02\n",
      " 2.52085745e-01 1.14414812e+01], Loss = 0.3857\n",
      "Iteration 5097: Weights = [5.50000000e+01 3.60099416e+00 7.57114787e+00 2.49444804e-02\n",
      " 2.52078509e-01 1.14417109e+01], Loss = 0.3856\n",
      "Iteration 5098: Weights = [5.50000000e+01 3.60089079e+00 7.57093053e+00 2.49437643e-02\n",
      " 2.52071273e-01 1.14419405e+01], Loss = 0.3856\n",
      "Iteration 5099: Weights = [5.50000000e+01 3.60078742e+00 7.57071320e+00 2.49430483e-02\n",
      " 2.52064037e-01 1.14421701e+01], Loss = 0.3856\n",
      "Iteration 5100: Weights = [5.50000000e+01 3.60068405e+00 7.57049587e+00 2.49423322e-02\n",
      " 2.52056801e-01 1.14423997e+01], Loss = 0.3856\n",
      "Iteration 5101: Weights = [5.50000000e+01 3.60058069e+00 7.57027855e+00 2.49416162e-02\n",
      " 2.52049565e-01 1.14426293e+01], Loss = 0.3856\n",
      "Iteration 5102: Weights = [5.50000000e+01 3.60047733e+00 7.57006123e+00 2.49409003e-02\n",
      " 2.52042330e-01 1.14428589e+01], Loss = 0.3855\n",
      "Iteration 5103: Weights = [5.50000000e+01 3.60037397e+00 7.56984393e+00 2.49401843e-02\n",
      " 2.52035094e-01 1.14430885e+01], Loss = 0.3855\n",
      "Iteration 5104: Weights = [5.50000000e+01 3.60027062e+00 7.56962662e+00 2.49394684e-02\n",
      " 2.52027859e-01 1.14433180e+01], Loss = 0.3855\n",
      "Iteration 5105: Weights = [5.50000000e+01 3.60016727e+00 7.56940933e+00 2.49387524e-02\n",
      " 2.52020625e-01 1.14435476e+01], Loss = 0.3855\n",
      "Iteration 5106: Weights = [5.50000000e+01 3.60006392e+00 7.56919204e+00 2.49380365e-02\n",
      " 2.52013390e-01 1.14437772e+01], Loss = 0.3854\n",
      "Iteration 5107: Weights = [5.50000000e+01 3.59996058e+00 7.56897475e+00 2.49373207e-02\n",
      " 2.52006156e-01 1.14440067e+01], Loss = 0.3854\n",
      "Iteration 5108: Weights = [5.50000000e+01 3.59985724e+00 7.56875748e+00 2.49366048e-02\n",
      " 2.51998922e-01 1.14442363e+01], Loss = 0.3854\n",
      "Iteration 5109: Weights = [5.50000000e+01 3.59975390e+00 7.56854021e+00 2.49358890e-02\n",
      " 2.51991688e-01 1.14444658e+01], Loss = 0.3854\n",
      "Iteration 5110: Weights = [5.50000000e+01 3.59965056e+00 7.56832294e+00 2.49351731e-02\n",
      " 2.51984454e-01 1.14446954e+01], Loss = 0.3854\n",
      "Iteration 5111: Weights = [5.50000000e+01 3.59954723e+00 7.56810568e+00 2.49344573e-02\n",
      " 2.51977220e-01 1.14449249e+01], Loss = 0.3853\n",
      "Iteration 5112: Weights = [5.50000000e+01 3.59944390e+00 7.56788843e+00 2.49337416e-02\n",
      " 2.51969987e-01 1.14451544e+01], Loss = 0.3853\n",
      "Iteration 5113: Weights = [5.50000000e+01 3.59934057e+00 7.56767118e+00 2.49330258e-02\n",
      " 2.51962754e-01 1.14453839e+01], Loss = 0.3853\n",
      "Iteration 5114: Weights = [5.50000000e+01 3.59923725e+00 7.56745394e+00 2.49323101e-02\n",
      " 2.51955521e-01 1.14456134e+01], Loss = 0.3853\n",
      "Iteration 5115: Weights = [5.50000000e+01 3.59913393e+00 7.56723671e+00 2.49315944e-02\n",
      " 2.51948288e-01 1.14458429e+01], Loss = 0.3852\n",
      "Iteration 5116: Weights = [5.50000000e+01 3.59903061e+00 7.56701948e+00 2.49308787e-02\n",
      " 2.51941056e-01 1.14460724e+01], Loss = 0.3852\n",
      "Iteration 5117: Weights = [5.50000000e+01 3.59892730e+00 7.56680226e+00 2.49301630e-02\n",
      " 2.51933823e-01 1.14463019e+01], Loss = 0.3852\n",
      "Iteration 5118: Weights = [5.50000000e+01 3.59882398e+00 7.56658505e+00 2.49294473e-02\n",
      " 2.51926591e-01 1.14465314e+01], Loss = 0.3852\n",
      "Iteration 5119: Weights = [5.50000000e+01 3.59872067e+00 7.56636784e+00 2.49287317e-02\n",
      " 2.51919359e-01 1.14467609e+01], Loss = 0.3852\n",
      "Iteration 5120: Weights = [5.50000000e+01 3.59861737e+00 7.56615064e+00 2.49280161e-02\n",
      " 2.51912128e-01 1.14469904e+01], Loss = 0.3851\n",
      "Iteration 5121: Weights = [5.50000000e+01 3.59851407e+00 7.56593344e+00 2.49273005e-02\n",
      " 2.51904896e-01 1.14472198e+01], Loss = 0.3851\n",
      "Iteration 5122: Weights = [5.50000000e+01 3.59841077e+00 7.56571625e+00 2.49265849e-02\n",
      " 2.51897665e-01 1.14474493e+01], Loss = 0.3851\n",
      "Iteration 5123: Weights = [5.50000000e+01 3.59830747e+00 7.56549907e+00 2.49258694e-02\n",
      " 2.51890434e-01 1.14476787e+01], Loss = 0.3851\n",
      "Iteration 5124: Weights = [5.50000000e+01 3.59820417e+00 7.56528189e+00 2.49251539e-02\n",
      " 2.51883203e-01 1.14479082e+01], Loss = 0.3850\n",
      "Iteration 5125: Weights = [5.50000000e+01 3.59810088e+00 7.56506472e+00 2.49244383e-02\n",
      " 2.51875972e-01 1.14481376e+01], Loss = 0.3850\n",
      "Iteration 5126: Weights = [5.50000000e+01 3.59799760e+00 7.56484755e+00 2.49237229e-02\n",
      " 2.51868742e-01 1.14483670e+01], Loss = 0.3850\n",
      "Iteration 5127: Weights = [5.50000000e+01 3.59789431e+00 7.56463039e+00 2.49230074e-02\n",
      " 2.51861512e-01 1.14485965e+01], Loss = 0.3850\n",
      "Iteration 5128: Weights = [5.50000000e+01 3.59779103e+00 7.56441324e+00 2.49222919e-02\n",
      " 2.51854282e-01 1.14488259e+01], Loss = 0.3850\n",
      "Iteration 5129: Weights = [5.50000000e+01 3.59768775e+00 7.56419609e+00 2.49215765e-02\n",
      " 2.51847052e-01 1.14490553e+01], Loss = 0.3849\n",
      "Iteration 5130: Weights = [5.50000000e+01 3.59758447e+00 7.56397895e+00 2.49208611e-02\n",
      " 2.51839822e-01 1.14492847e+01], Loss = 0.3849\n",
      "Iteration 5131: Weights = [5.50000000e+01 3.59748120e+00 7.56376182e+00 2.49201457e-02\n",
      " 2.51832593e-01 1.14495141e+01], Loss = 0.3849\n",
      "Iteration 5132: Weights = [5.50000000e+01 3.59737793e+00 7.56354469e+00 2.49194304e-02\n",
      " 2.51825364e-01 1.14497435e+01], Loss = 0.3849\n",
      "Iteration 5133: Weights = [5.50000000e+01 3.59727466e+00 7.56332757e+00 2.49187150e-02\n",
      " 2.51818135e-01 1.14499729e+01], Loss = 0.3849\n",
      "Iteration 5134: Weights = [5.50000000e+01 3.59717140e+00 7.56311045e+00 2.49179997e-02\n",
      " 2.51810906e-01 1.14502023e+01], Loss = 0.3848\n",
      "Iteration 5135: Weights = [5.50000000e+01 3.59706813e+00 7.56289335e+00 2.49172844e-02\n",
      " 2.51803678e-01 1.14504316e+01], Loss = 0.3848\n",
      "Iteration 5136: Weights = [5.50000000e+01 3.59696488e+00 7.56267624e+00 2.49165691e-02\n",
      " 2.51796449e-01 1.14506610e+01], Loss = 0.3848\n",
      "Iteration 5137: Weights = [5.50000000e+01 3.59686162e+00 7.56245915e+00 2.49158538e-02\n",
      " 2.51789221e-01 1.14508904e+01], Loss = 0.3848\n",
      "Iteration 5138: Weights = [5.50000000e+01 3.59675837e+00 7.56224206e+00 2.49151386e-02\n",
      " 2.51781993e-01 1.14511197e+01], Loss = 0.3847\n",
      "Iteration 5139: Weights = [5.50000000e+01 3.59665512e+00 7.56202497e+00 2.49144234e-02\n",
      " 2.51774765e-01 1.14513491e+01], Loss = 0.3847\n",
      "Iteration 5140: Weights = [5.50000000e+01 3.59655187e+00 7.56180789e+00 2.49137082e-02\n",
      " 2.51767538e-01 1.14515784e+01], Loss = 0.3847\n",
      "Iteration 5141: Weights = [5.50000000e+01 3.59644863e+00 7.56159082e+00 2.49129930e-02\n",
      " 2.51760311e-01 1.14518077e+01], Loss = 0.3847\n",
      "Iteration 5142: Weights = [5.50000000e+01 3.59634539e+00 7.56137376e+00 2.49122778e-02\n",
      " 2.51753083e-01 1.14520371e+01], Loss = 0.3847\n",
      "Iteration 5143: Weights = [5.50000000e+01 3.59624215e+00 7.56115670e+00 2.49115627e-02\n",
      " 2.51745857e-01 1.14522664e+01], Loss = 0.3846\n",
      "Iteration 5144: Weights = [5.50000000e+01 3.59613891e+00 7.56093965e+00 2.49108476e-02\n",
      " 2.51738630e-01 1.14524957e+01], Loss = 0.3846\n",
      "Iteration 5145: Weights = [5.50000000e+01 3.59603568e+00 7.56072260e+00 2.49101325e-02\n",
      " 2.51731403e-01 1.14527250e+01], Loss = 0.3846\n",
      "Iteration 5146: Weights = [5.50000000e+01 3.59593245e+00 7.56050556e+00 2.49094174e-02\n",
      " 2.51724177e-01 1.14529543e+01], Loss = 0.3846\n",
      "Iteration 5147: Weights = [5.50000000e+01 3.59582923e+00 7.56028852e+00 2.49087023e-02\n",
      " 2.51716951e-01 1.14531836e+01], Loss = 0.3845\n",
      "Iteration 5148: Weights = [5.50000000e+01 3.59572600e+00 7.56007150e+00 2.49079873e-02\n",
      " 2.51709725e-01 1.14534129e+01], Loss = 0.3845\n",
      "Iteration 5149: Weights = [5.50000000e+01 3.59562278e+00 7.55985447e+00 2.49072723e-02\n",
      " 2.51702499e-01 1.14536422e+01], Loss = 0.3845\n",
      "Iteration 5150: Weights = [5.50000000e+01 3.59551957e+00 7.55963746e+00 2.49065573e-02\n",
      " 2.51695274e-01 1.14538714e+01], Loss = 0.3845\n",
      "Iteration 5151: Weights = [5.50000000e+01 3.59541635e+00 7.55942045e+00 2.49058423e-02\n",
      " 2.51688049e-01 1.14541007e+01], Loss = 0.3845\n",
      "Iteration 5152: Weights = [5.50000000e+01 3.59531314e+00 7.55920345e+00 2.49051274e-02\n",
      " 2.51680824e-01 1.14543300e+01], Loss = 0.3844\n",
      "Iteration 5153: Weights = [5.50000000e+01 3.59520993e+00 7.55898645e+00 2.49044124e-02\n",
      " 2.51673599e-01 1.14545592e+01], Loss = 0.3844\n",
      "Iteration 5154: Weights = [5.50000000e+01 3.59510673e+00 7.55876946e+00 2.49036975e-02\n",
      " 2.51666374e-01 1.14547885e+01], Loss = 0.3844\n",
      "Iteration 5155: Weights = [5.50000000e+01 3.59500353e+00 7.55855247e+00 2.49029826e-02\n",
      " 2.51659150e-01 1.14550177e+01], Loss = 0.3844\n",
      "Iteration 5156: Weights = [5.50000000e+01 3.59490033e+00 7.55833550e+00 2.49022677e-02\n",
      " 2.51651926e-01 1.14552469e+01], Loss = 0.3843\n",
      "Iteration 5157: Weights = [5.50000000e+01 3.59479713e+00 7.55811852e+00 2.49015529e-02\n",
      " 2.51644702e-01 1.14554762e+01], Loss = 0.3843\n",
      "Iteration 5158: Weights = [5.50000000e+01 3.59469394e+00 7.55790156e+00 2.49008381e-02\n",
      " 2.51637478e-01 1.14557054e+01], Loss = 0.3843\n",
      "Iteration 5159: Weights = [5.50000000e+01 3.59459075e+00 7.55768460e+00 2.49001233e-02\n",
      " 2.51630254e-01 1.14559346e+01], Loss = 0.3843\n",
      "Iteration 5160: Weights = [5.50000000e+01 3.59448756e+00 7.55746765e+00 2.48994085e-02\n",
      " 2.51623031e-01 1.14561638e+01], Loss = 0.3843\n",
      "Iteration 5161: Weights = [5.50000000e+01 3.59438438e+00 7.55725070e+00 2.48986937e-02\n",
      " 2.51615808e-01 1.14563930e+01], Loss = 0.3842\n",
      "Iteration 5162: Weights = [5.50000000e+01 3.59428119e+00 7.55703376e+00 2.48979789e-02\n",
      " 2.51608585e-01 1.14566222e+01], Loss = 0.3842\n",
      "Iteration 5163: Weights = [5.50000000e+01 3.59417802e+00 7.55681682e+00 2.48972642e-02\n",
      " 2.51601362e-01 1.14568514e+01], Loss = 0.3842\n",
      "Iteration 5164: Weights = [5.50000000e+01 3.59407484e+00 7.55659990e+00 2.48965495e-02\n",
      " 2.51594139e-01 1.14570806e+01], Loss = 0.3842\n",
      "Iteration 5165: Weights = [5.50000000e+01 3.59397167e+00 7.55638297e+00 2.48958348e-02\n",
      " 2.51586917e-01 1.14573097e+01], Loss = 0.3841\n",
      "Iteration 5166: Weights = [5.50000000e+01 3.59386850e+00 7.55616606e+00 2.48951201e-02\n",
      " 2.51579695e-01 1.14575389e+01], Loss = 0.3841\n",
      "Iteration 5167: Weights = [5.50000000e+01 3.59376533e+00 7.55594915e+00 2.48944055e-02\n",
      " 2.51572473e-01 1.14577681e+01], Loss = 0.3841\n",
      "Iteration 5168: Weights = [5.50000000e+01 3.59366217e+00 7.55573224e+00 2.48936909e-02\n",
      " 2.51565251e-01 1.14579972e+01], Loss = 0.3841\n",
      "Iteration 5169: Weights = [5.50000000e+01 3.59355901e+00 7.55551535e+00 2.48929763e-02\n",
      " 2.51558030e-01 1.14582264e+01], Loss = 0.3841\n",
      "Iteration 5170: Weights = [5.50000000e+01 3.59345585e+00 7.55529846e+00 2.48922617e-02\n",
      " 2.51550809e-01 1.14584555e+01], Loss = 0.3840\n",
      "Iteration 5171: Weights = [5.50000000e+01 3.59335269e+00 7.55508157e+00 2.48915471e-02\n",
      " 2.51543587e-01 1.14586846e+01], Loss = 0.3840\n",
      "Iteration 5172: Weights = [5.50000000e+01 3.59324954e+00 7.55486469e+00 2.48908326e-02\n",
      " 2.51536367e-01 1.14589138e+01], Loss = 0.3840\n",
      "Iteration 5173: Weights = [5.50000000e+01 3.59314639e+00 7.55464782e+00 2.48901180e-02\n",
      " 2.51529146e-01 1.14591429e+01], Loss = 0.3840\n",
      "Iteration 5174: Weights = [5.50000000e+01 3.59304325e+00 7.55443096e+00 2.48894035e-02\n",
      " 2.51521925e-01 1.14593720e+01], Loss = 0.3839\n",
      "Iteration 5175: Weights = [5.50000000e+01 3.59294010e+00 7.55421410e+00 2.48886891e-02\n",
      " 2.51514705e-01 1.14596011e+01], Loss = 0.3839\n",
      "Iteration 5176: Weights = [5.50000000e+01 3.59283696e+00 7.55399724e+00 2.48879746e-02\n",
      " 2.51507485e-01 1.14598302e+01], Loss = 0.3839\n",
      "Iteration 5177: Weights = [5.50000000e+01 3.59273383e+00 7.55378039e+00 2.48872602e-02\n",
      " 2.51500265e-01 1.14600593e+01], Loss = 0.3839\n",
      "Iteration 5178: Weights = [5.50000000e+01 3.59263069e+00 7.55356355e+00 2.48865457e-02\n",
      " 2.51493046e-01 1.14602884e+01], Loss = 0.3839\n",
      "Iteration 5179: Weights = [5.50000000e+01 3.59252756e+00 7.55334672e+00 2.48858313e-02\n",
      " 2.51485826e-01 1.14605175e+01], Loss = 0.3838\n",
      "Iteration 5180: Weights = [5.50000000e+01 3.59242443e+00 7.55312989e+00 2.48851170e-02\n",
      " 2.51478607e-01 1.14607466e+01], Loss = 0.3838\n",
      "Iteration 5181: Weights = [5.50000000e+01 3.59232131e+00 7.55291307e+00 2.48844026e-02\n",
      " 2.51471388e-01 1.14609756e+01], Loss = 0.3838\n",
      "Iteration 5182: Weights = [5.50000000e+01 3.59221819e+00 7.55269625e+00 2.48836883e-02\n",
      " 2.51464169e-01 1.14612047e+01], Loss = 0.3838\n",
      "Iteration 5183: Weights = [5.50000000e+01 3.59211507e+00 7.55247944e+00 2.48829739e-02\n",
      " 2.51456950e-01 1.14614338e+01], Loss = 0.3837\n",
      "Iteration 5184: Weights = [5.50000000e+01 3.59201195e+00 7.55226264e+00 2.48822596e-02\n",
      " 2.51449732e-01 1.14616628e+01], Loss = 0.3837\n",
      "Iteration 5185: Weights = [5.50000000e+01 3.59190884e+00 7.55204584e+00 2.48815454e-02\n",
      " 2.51442514e-01 1.14618919e+01], Loss = 0.3837\n",
      "Iteration 5186: Weights = [5.50000000e+01 3.59180573e+00 7.55182905e+00 2.48808311e-02\n",
      " 2.51435296e-01 1.14621209e+01], Loss = 0.3837\n",
      "Iteration 5187: Weights = [5.50000000e+01 3.59170262e+00 7.55161226e+00 2.48801169e-02\n",
      " 2.51428078e-01 1.14623499e+01], Loss = 0.3837\n",
      "Iteration 5188: Weights = [5.50000000e+01 3.59159951e+00 7.55139548e+00 2.48794027e-02\n",
      " 2.51420861e-01 1.14625789e+01], Loss = 0.3836\n",
      "Iteration 5189: Weights = [5.50000000e+01 3.59149641e+00 7.55117871e+00 2.48786885e-02\n",
      " 2.51413643e-01 1.14628080e+01], Loss = 0.3836\n",
      "Iteration 5190: Weights = [5.50000000e+01 3.59139331e+00 7.55096194e+00 2.48779743e-02\n",
      " 2.51406426e-01 1.14630370e+01], Loss = 0.3836\n",
      "Iteration 5191: Weights = [5.50000000e+01 3.59129022e+00 7.55074518e+00 2.48772601e-02\n",
      " 2.51399209e-01 1.14632660e+01], Loss = 0.3836\n",
      "Iteration 5192: Weights = [5.50000000e+01 3.59118713e+00 7.55052843e+00 2.48765460e-02\n",
      " 2.51391992e-01 1.14634950e+01], Loss = 0.3835\n",
      "Iteration 5193: Weights = [5.50000000e+01 3.59108404e+00 7.55031168e+00 2.48758319e-02\n",
      " 2.51384776e-01 1.14637240e+01], Loss = 0.3835\n",
      "Iteration 5194: Weights = [5.50000000e+01 3.59098095e+00 7.55009494e+00 2.48751178e-02\n",
      " 2.51377559e-01 1.14639529e+01], Loss = 0.3835\n",
      "Iteration 5195: Weights = [5.50000000e+01 3.59087787e+00 7.54987821e+00 2.48744037e-02\n",
      " 2.51370343e-01 1.14641819e+01], Loss = 0.3835\n",
      "Iteration 5196: Weights = [5.50000000e+01 3.59077478e+00 7.54966148e+00 2.48736897e-02\n",
      " 2.51363127e-01 1.14644109e+01], Loss = 0.3835\n",
      "Iteration 5197: Weights = [5.50000000e+01 3.59067171e+00 7.54944475e+00 2.48729756e-02\n",
      " 2.51355912e-01 1.14646399e+01], Loss = 0.3834\n",
      "Iteration 5198: Weights = [5.50000000e+01 3.59056863e+00 7.54922804e+00 2.48722616e-02\n",
      " 2.51348696e-01 1.14648688e+01], Loss = 0.3834\n",
      "Iteration 5199: Weights = [5.50000000e+01 3.59046556e+00 7.54901133e+00 2.48715476e-02\n",
      " 2.51341481e-01 1.14650978e+01], Loss = 0.3834\n",
      "Iteration 5200: Weights = [5.50000000e+01 3.59036249e+00 7.54879462e+00 2.48708337e-02\n",
      " 2.51334266e-01 1.14653267e+01], Loss = 0.3834\n",
      "Iteration 5201: Weights = [5.50000000e+01 3.59025942e+00 7.54857792e+00 2.48701197e-02\n",
      " 2.51327051e-01 1.14655556e+01], Loss = 0.3834\n",
      "Iteration 5202: Weights = [5.50000000e+01 3.59015636e+00 7.54836123e+00 2.48694058e-02\n",
      " 2.51319836e-01 1.14657846e+01], Loss = 0.3833\n",
      "Iteration 5203: Weights = [5.50000000e+01 3.59005330e+00 7.54814455e+00 2.48686919e-02\n",
      " 2.51312622e-01 1.14660135e+01], Loss = 0.3833\n",
      "Iteration 5204: Weights = [5.50000000e+01 3.58995024e+00 7.54792787e+00 2.48679780e-02\n",
      " 2.51305408e-01 1.14662424e+01], Loss = 0.3833\n",
      "Iteration 5205: Weights = [5.50000000e+01 3.58984719e+00 7.54771119e+00 2.48672641e-02\n",
      " 2.51298194e-01 1.14664713e+01], Loss = 0.3833\n",
      "Iteration 5206: Weights = [5.50000000e+01 3.58974414e+00 7.54749453e+00 2.48665503e-02\n",
      " 2.51290980e-01 1.14667002e+01], Loss = 0.3832\n",
      "Iteration 5207: Weights = [5.50000000e+01 3.58964109e+00 7.54727787e+00 2.48658364e-02\n",
      " 2.51283766e-01 1.14669291e+01], Loss = 0.3832\n",
      "Iteration 5208: Weights = [5.50000000e+01 3.58953805e+00 7.54706121e+00 2.48651226e-02\n",
      " 2.51276553e-01 1.14671580e+01], Loss = 0.3832\n",
      "Iteration 5209: Weights = [5.50000000e+01 3.58943500e+00 7.54684456e+00 2.48644088e-02\n",
      " 2.51269339e-01 1.14673869e+01], Loss = 0.3832\n",
      "Iteration 5210: Weights = [5.50000000e+01 3.58933196e+00 7.54662792e+00 2.48636951e-02\n",
      " 2.51262126e-01 1.14676158e+01], Loss = 0.3832\n",
      "Iteration 5211: Weights = [5.50000000e+01 3.58922893e+00 7.54641129e+00 2.48629813e-02\n",
      " 2.51254914e-01 1.14678447e+01], Loss = 0.3831\n",
      "Iteration 5212: Weights = [5.50000000e+01 3.58912589e+00 7.54619466e+00 2.48622676e-02\n",
      " 2.51247701e-01 1.14680735e+01], Loss = 0.3831\n",
      "Iteration 5213: Weights = [5.50000000e+01 3.58902286e+00 7.54597803e+00 2.48615539e-02\n",
      " 2.51240489e-01 1.14683024e+01], Loss = 0.3831\n",
      "Iteration 5214: Weights = [5.50000000e+01 3.58891984e+00 7.54576142e+00 2.48608402e-02\n",
      " 2.51233276e-01 1.14685312e+01], Loss = 0.3831\n",
      "Iteration 5215: Weights = [5.50000000e+01 3.58881681e+00 7.54554480e+00 2.48601266e-02\n",
      " 2.51226064e-01 1.14687601e+01], Loss = 0.3830\n",
      "Iteration 5216: Weights = [5.50000000e+01 3.58871379e+00 7.54532820e+00 2.48594129e-02\n",
      " 2.51218853e-01 1.14689889e+01], Loss = 0.3830\n",
      "Iteration 5217: Weights = [5.50000000e+01 3.58861077e+00 7.54511160e+00 2.48586993e-02\n",
      " 2.51211641e-01 1.14692178e+01], Loss = 0.3830\n",
      "Iteration 5218: Weights = [5.50000000e+01 3.58850775e+00 7.54489501e+00 2.48579857e-02\n",
      " 2.51204430e-01 1.14694466e+01], Loss = 0.3830\n",
      "Iteration 5219: Weights = [5.50000000e+01 3.58840474e+00 7.54467842e+00 2.48572721e-02\n",
      " 2.51197219e-01 1.14696754e+01], Loss = 0.3830\n",
      "Iteration 5220: Weights = [5.50000000e+01 3.58830173e+00 7.54446184e+00 2.48565586e-02\n",
      " 2.51190008e-01 1.14699042e+01], Loss = 0.3829\n",
      "Iteration 5221: Weights = [5.50000000e+01 3.58819872e+00 7.54424527e+00 2.48558450e-02\n",
      " 2.51182797e-01 1.14701330e+01], Loss = 0.3829\n",
      "Iteration 5222: Weights = [5.50000000e+01 3.58809572e+00 7.54402870e+00 2.48551315e-02\n",
      " 2.51175586e-01 1.14703618e+01], Loss = 0.3829\n",
      "Iteration 5223: Weights = [5.50000000e+01 3.58799272e+00 7.54381214e+00 2.48544180e-02\n",
      " 2.51168376e-01 1.14705906e+01], Loss = 0.3829\n",
      "Iteration 5224: Weights = [5.50000000e+01 3.58788972e+00 7.54359559e+00 2.48537045e-02\n",
      " 2.51161166e-01 1.14708194e+01], Loss = 0.3828\n",
      "Iteration 5225: Weights = [5.50000000e+01 3.58778673e+00 7.54337904e+00 2.48529911e-02\n",
      " 2.51153956e-01 1.14710482e+01], Loss = 0.3828\n",
      "Iteration 5226: Weights = [5.50000000e+01 3.58768373e+00 7.54316249e+00 2.48522776e-02\n",
      " 2.51146746e-01 1.14712770e+01], Loss = 0.3828\n",
      "Iteration 5227: Weights = [5.50000000e+01 3.58758075e+00 7.54294596e+00 2.48515642e-02\n",
      " 2.51139537e-01 1.14715057e+01], Loss = 0.3828\n",
      "Iteration 5228: Weights = [5.50000000e+01 3.58747776e+00 7.54272943e+00 2.48508508e-02\n",
      " 2.51132328e-01 1.14717345e+01], Loss = 0.3828\n",
      "Iteration 5229: Weights = [5.50000000e+01 3.58737478e+00 7.54251290e+00 2.48501374e-02\n",
      " 2.51125118e-01 1.14719632e+01], Loss = 0.3827\n",
      "Iteration 5230: Weights = [5.50000000e+01 3.58727180e+00 7.54229639e+00 2.48494241e-02\n",
      " 2.51117910e-01 1.14721920e+01], Loss = 0.3827\n",
      "Iteration 5231: Weights = [5.50000000e+01 3.58716882e+00 7.54207988e+00 2.48487107e-02\n",
      " 2.51110701e-01 1.14724207e+01], Loss = 0.3827\n",
      "Iteration 5232: Weights = [5.50000000e+01 3.58706584e+00 7.54186337e+00 2.48479974e-02\n",
      " 2.51103492e-01 1.14726495e+01], Loss = 0.3827\n",
      "Iteration 5233: Weights = [5.50000000e+01 3.58696287e+00 7.54164687e+00 2.48472841e-02\n",
      " 2.51096284e-01 1.14728782e+01], Loss = 0.3826\n",
      "Iteration 5234: Weights = [5.50000000e+01 3.58685990e+00 7.54143038e+00 2.48465709e-02\n",
      " 2.51089076e-01 1.14731069e+01], Loss = 0.3826\n",
      "Iteration 5235: Weights = [5.50000000e+01 3.58675694e+00 7.54121389e+00 2.48458576e-02\n",
      " 2.51081868e-01 1.14733356e+01], Loss = 0.3826\n",
      "Iteration 5236: Weights = [5.50000000e+01 3.58665398e+00 7.54099741e+00 2.48451444e-02\n",
      " 2.51074661e-01 1.14735643e+01], Loss = 0.3826\n",
      "Iteration 5237: Weights = [5.50000000e+01 3.58655102e+00 7.54078094e+00 2.48444312e-02\n",
      " 2.51067453e-01 1.14737930e+01], Loss = 0.3826\n",
      "Iteration 5238: Weights = [5.50000000e+01 3.58644806e+00 7.54056447e+00 2.48437180e-02\n",
      " 2.51060246e-01 1.14740217e+01], Loss = 0.3825\n",
      "Iteration 5239: Weights = [5.50000000e+01 3.58634511e+00 7.54034801e+00 2.48430048e-02\n",
      " 2.51053039e-01 1.14742504e+01], Loss = 0.3825\n",
      "Iteration 5240: Weights = [5.50000000e+01 3.58624216e+00 7.54013155e+00 2.48422916e-02\n",
      " 2.51045832e-01 1.14744791e+01], Loss = 0.3825\n",
      "Iteration 5241: Weights = [5.50000000e+01 3.58613921e+00 7.53991510e+00 2.48415785e-02\n",
      " 2.51038626e-01 1.14747078e+01], Loss = 0.3825\n",
      "Iteration 5242: Weights = [5.50000000e+01 3.58603626e+00 7.53969866e+00 2.48408654e-02\n",
      " 2.51031419e-01 1.14749365e+01], Loss = 0.3824\n",
      "Iteration 5243: Weights = [5.50000000e+01 3.58593332e+00 7.53948222e+00 2.48401523e-02\n",
      " 2.51024213e-01 1.14751651e+01], Loss = 0.3824\n",
      "Iteration 5244: Weights = [5.50000000e+01 3.58583038e+00 7.53926579e+00 2.48394392e-02\n",
      " 2.51017007e-01 1.14753938e+01], Loss = 0.3824\n",
      "Iteration 5245: Weights = [5.50000000e+01 3.58572745e+00 7.53904937e+00 2.48387262e-02\n",
      " 2.51009801e-01 1.14756224e+01], Loss = 0.3824\n",
      "Iteration 5246: Weights = [5.50000000e+01 3.58562451e+00 7.53883295e+00 2.48380132e-02\n",
      " 2.51002596e-01 1.14758511e+01], Loss = 0.3824\n",
      "Iteration 5247: Weights = [5.50000000e+01 3.58552158e+00 7.53861654e+00 2.48373002e-02\n",
      " 2.50995390e-01 1.14760797e+01], Loss = 0.3823\n",
      "Iteration 5248: Weights = [5.50000000e+01 3.58541866e+00 7.53840013e+00 2.48365872e-02\n",
      " 2.50988185e-01 1.14763083e+01], Loss = 0.3823\n",
      "Iteration 5249: Weights = [5.50000000e+01 3.58531573e+00 7.53818373e+00 2.48358742e-02\n",
      " 2.50980980e-01 1.14765369e+01], Loss = 0.3823\n",
      "Iteration 5250: Weights = [5.50000000e+01 3.58521281e+00 7.53796734e+00 2.48351613e-02\n",
      " 2.50973776e-01 1.14767656e+01], Loss = 0.3823\n",
      "Iteration 5251: Weights = [5.50000000e+01 3.58510989e+00 7.53775095e+00 2.48344483e-02\n",
      " 2.50966571e-01 1.14769942e+01], Loss = 0.3823\n",
      "Iteration 5252: Weights = [5.50000000e+01 3.58500698e+00 7.53753457e+00 2.48337354e-02\n",
      " 2.50959367e-01 1.14772228e+01], Loss = 0.3822\n",
      "Iteration 5253: Weights = [5.50000000e+01 3.58490407e+00 7.53731819e+00 2.48330225e-02\n",
      " 2.50952163e-01 1.14774514e+01], Loss = 0.3822\n",
      "Iteration 5254: Weights = [5.50000000e+01 3.58480116e+00 7.53710183e+00 2.48323097e-02\n",
      " 2.50944959e-01 1.14776800e+01], Loss = 0.3822\n",
      "Iteration 5255: Weights = [5.50000000e+01 3.58469825e+00 7.53688546e+00 2.48315968e-02\n",
      " 2.50937755e-01 1.14779085e+01], Loss = 0.3822\n",
      "Iteration 5256: Weights = [5.50000000e+01 3.58459535e+00 7.53666911e+00 2.48308840e-02\n",
      " 2.50930551e-01 1.14781371e+01], Loss = 0.3821\n",
      "Iteration 5257: Weights = [5.50000000e+01 3.58449245e+00 7.53645276e+00 2.48301712e-02\n",
      " 2.50923348e-01 1.14783657e+01], Loss = 0.3821\n",
      "Iteration 5258: Weights = [5.50000000e+01 3.58438955e+00 7.53623641e+00 2.48294584e-02\n",
      " 2.50916145e-01 1.14785943e+01], Loss = 0.3821\n",
      "Iteration 5259: Weights = [5.50000000e+01 3.58428665e+00 7.53602008e+00 2.48287457e-02\n",
      " 2.50908942e-01 1.14788228e+01], Loss = 0.3821\n",
      "Iteration 5260: Weights = [5.50000000e+01 3.58418376e+00 7.53580374e+00 2.48280329e-02\n",
      " 2.50901739e-01 1.14790514e+01], Loss = 0.3821\n",
      "Iteration 5261: Weights = [5.50000000e+01 3.58408087e+00 7.53558742e+00 2.48273202e-02\n",
      " 2.50894537e-01 1.14792799e+01], Loss = 0.3820\n",
      "Iteration 5262: Weights = [5.50000000e+01 3.58397799e+00 7.53537110e+00 2.48266075e-02\n",
      " 2.50887335e-01 1.14795084e+01], Loss = 0.3820\n",
      "Iteration 5263: Weights = [5.50000000e+01 3.58387510e+00 7.53515479e+00 2.48258948e-02\n",
      " 2.50880133e-01 1.14797370e+01], Loss = 0.3820\n",
      "Iteration 5264: Weights = [5.50000000e+01 3.58377222e+00 7.53493848e+00 2.48251822e-02\n",
      " 2.50872931e-01 1.14799655e+01], Loss = 0.3820\n",
      "Iteration 5265: Weights = [5.50000000e+01 3.58366935e+00 7.53472218e+00 2.48244695e-02\n",
      " 2.50865729e-01 1.14801940e+01], Loss = 0.3819\n",
      "Iteration 5266: Weights = [5.50000000e+01 3.58356647e+00 7.53450589e+00 2.48237569e-02\n",
      " 2.50858528e-01 1.14804225e+01], Loss = 0.3819\n",
      "Iteration 5267: Weights = [5.50000000e+01 3.58346360e+00 7.53428960e+00 2.48230443e-02\n",
      " 2.50851327e-01 1.14806510e+01], Loss = 0.3819\n",
      "Iteration 5268: Weights = [5.50000000e+01 3.58336073e+00 7.53407332e+00 2.48223317e-02\n",
      " 2.50844126e-01 1.14808795e+01], Loss = 0.3819\n",
      "Iteration 5269: Weights = [5.50000000e+01 3.58325787e+00 7.53385704e+00 2.48216192e-02\n",
      " 2.50836925e-01 1.14811080e+01], Loss = 0.3819\n",
      "Iteration 5270: Weights = [5.50000000e+01 3.58315501e+00 7.53364077e+00 2.48209066e-02\n",
      " 2.50829724e-01 1.14813365e+01], Loss = 0.3818\n",
      "Iteration 5271: Weights = [5.50000000e+01 3.58305215e+00 7.53342451e+00 2.48201941e-02\n",
      " 2.50822524e-01 1.14815650e+01], Loss = 0.3818\n",
      "Iteration 5272: Weights = [5.50000000e+01 3.58294929e+00 7.53320825e+00 2.48194816e-02\n",
      " 2.50815324e-01 1.14817935e+01], Loss = 0.3818\n",
      "Iteration 5273: Weights = [5.50000000e+01 3.58284644e+00 7.53299200e+00 2.48187691e-02\n",
      " 2.50808124e-01 1.14820219e+01], Loss = 0.3818\n",
      "Iteration 5274: Weights = [5.50000000e+01 3.58274359e+00 7.53277576e+00 2.48180567e-02\n",
      " 2.50800924e-01 1.14822504e+01], Loss = 0.3817\n",
      "Iteration 5275: Weights = [5.50000000e+01 3.58264074e+00 7.53255952e+00 2.48173443e-02\n",
      " 2.50793724e-01 1.14824788e+01], Loss = 0.3817\n",
      "Iteration 5276: Weights = [5.50000000e+01 3.58253790e+00 7.53234329e+00 2.48166318e-02\n",
      " 2.50786525e-01 1.14827073e+01], Loss = 0.3817\n",
      "Iteration 5277: Weights = [5.50000000e+01 3.58243506e+00 7.53212706e+00 2.48159194e-02\n",
      " 2.50779326e-01 1.14829357e+01], Loss = 0.3817\n",
      "Iteration 5278: Weights = [5.50000000e+01 3.58233222e+00 7.53191084e+00 2.48152071e-02\n",
      " 2.50772127e-01 1.14831642e+01], Loss = 0.3817\n",
      "Iteration 5279: Weights = [5.50000000e+01 3.58222938e+00 7.53169463e+00 2.48144947e-02\n",
      " 2.50764928e-01 1.14833926e+01], Loss = 0.3816\n",
      "Iteration 5280: Weights = [5.50000000e+01 3.58212655e+00 7.53147842e+00 2.48137824e-02\n",
      " 2.50757730e-01 1.14836210e+01], Loss = 0.3816\n",
      "Iteration 5281: Weights = [5.50000000e+01 3.58202372e+00 7.53126222e+00 2.48130701e-02\n",
      " 2.50750531e-01 1.14838494e+01], Loss = 0.3816\n",
      "Iteration 5282: Weights = [5.50000000e+01 3.58192089e+00 7.53104603e+00 2.48123578e-02\n",
      " 2.50743333e-01 1.14840778e+01], Loss = 0.3816\n",
      "Iteration 5283: Weights = [5.50000000e+01 3.58181807e+00 7.53082984e+00 2.48116455e-02\n",
      " 2.50736135e-01 1.14843062e+01], Loss = 0.3816\n",
      "Iteration 5284: Weights = [5.50000000e+01 3.58171525e+00 7.53061366e+00 2.48109333e-02\n",
      " 2.50728937e-01 1.14845346e+01], Loss = 0.3815\n",
      "Iteration 5285: Weights = [5.50000000e+01 3.58161243e+00 7.53039748e+00 2.48102210e-02\n",
      " 2.50721740e-01 1.14847630e+01], Loss = 0.3815\n",
      "Iteration 5286: Weights = [5.50000000e+01 3.58150962e+00 7.53018131e+00 2.48095088e-02\n",
      " 2.50714543e-01 1.14849914e+01], Loss = 0.3815\n",
      "Iteration 5287: Weights = [5.50000000e+01 3.58140680e+00 7.52996515e+00 2.48087966e-02\n",
      " 2.50707346e-01 1.14852198e+01], Loss = 0.3815\n",
      "Iteration 5288: Weights = [5.50000000e+01 3.58130399e+00 7.52974899e+00 2.48080845e-02\n",
      " 2.50700149e-01 1.14854481e+01], Loss = 0.3814\n",
      "Iteration 5289: Weights = [5.50000000e+01 3.58120119e+00 7.52953284e+00 2.48073723e-02\n",
      " 2.50692952e-01 1.14856765e+01], Loss = 0.3814\n",
      "Iteration 5290: Weights = [5.50000000e+01 3.58109839e+00 7.52931669e+00 2.48066602e-02\n",
      " 2.50685756e-01 1.14859048e+01], Loss = 0.3814\n",
      "Iteration 5291: Weights = [5.50000000e+01 3.58099559e+00 7.52910055e+00 2.48059481e-02\n",
      " 2.50678559e-01 1.14861332e+01], Loss = 0.3814\n",
      "Iteration 5292: Weights = [5.50000000e+01 3.58089279e+00 7.52888442e+00 2.48052360e-02\n",
      " 2.50671363e-01 1.14863615e+01], Loss = 0.3814\n",
      "Iteration 5293: Weights = [5.50000000e+01 3.58078999e+00 7.52866829e+00 2.48045239e-02\n",
      " 2.50664167e-01 1.14865899e+01], Loss = 0.3813\n",
      "Iteration 5294: Weights = [5.50000000e+01 3.58068720e+00 7.52845217e+00 2.48038119e-02\n",
      " 2.50656972e-01 1.14868182e+01], Loss = 0.3813\n",
      "Iteration 5295: Weights = [5.50000000e+01 3.58058441e+00 7.52823606e+00 2.48030998e-02\n",
      " 2.50649776e-01 1.14870465e+01], Loss = 0.3813\n",
      "Iteration 5296: Weights = [5.50000000e+01 3.58048163e+00 7.52801995e+00 2.48023878e-02\n",
      " 2.50642581e-01 1.14872748e+01], Loss = 0.3813\n",
      "Iteration 5297: Weights = [5.50000000e+01 3.58037885e+00 7.52780385e+00 2.48016759e-02\n",
      " 2.50635386e-01 1.14875031e+01], Loss = 0.3812\n",
      "Iteration 5298: Weights = [5.50000000e+01 3.58027607e+00 7.52758775e+00 2.48009639e-02\n",
      " 2.50628191e-01 1.14877314e+01], Loss = 0.3812\n",
      "Iteration 5299: Weights = [5.50000000e+01 3.58017329e+00 7.52737167e+00 2.48002519e-02\n",
      " 2.50620997e-01 1.14879597e+01], Loss = 0.3812\n",
      "Iteration 5300: Weights = [5.50000000e+01 3.58007052e+00 7.52715558e+00 2.47995400e-02\n",
      " 2.50613802e-01 1.14881880e+01], Loss = 0.3812\n",
      "Iteration 5301: Weights = [5.50000000e+01 3.57996775e+00 7.52693951e+00 2.47988281e-02\n",
      " 2.50606608e-01 1.14884163e+01], Loss = 0.3812\n",
      "Iteration 5302: Weights = [5.50000000e+01 3.57986498e+00 7.52672343e+00 2.47981162e-02\n",
      " 2.50599414e-01 1.14886446e+01], Loss = 0.3811\n",
      "Iteration 5303: Weights = [5.50000000e+01 3.57976221e+00 7.52650737e+00 2.47974044e-02\n",
      " 2.50592220e-01 1.14888728e+01], Loss = 0.3811\n",
      "Iteration 5304: Weights = [5.50000000e+01 3.57965945e+00 7.52629131e+00 2.47966925e-02\n",
      " 2.50585027e-01 1.14891011e+01], Loss = 0.3811\n",
      "Iteration 5305: Weights = [5.50000000e+01 3.57955669e+00 7.52607526e+00 2.47959807e-02\n",
      " 2.50577833e-01 1.14893294e+01], Loss = 0.3811\n",
      "Iteration 5306: Weights = [5.50000000e+01 3.57945394e+00 7.52585921e+00 2.47952689e-02\n",
      " 2.50570640e-01 1.14895576e+01], Loss = 0.3810\n",
      "Iteration 5307: Weights = [5.50000000e+01 3.57935118e+00 7.52564317e+00 2.47945571e-02\n",
      " 2.50563447e-01 1.14897858e+01], Loss = 0.3810\n",
      "Iteration 5308: Weights = [5.50000000e+01 3.57924843e+00 7.52542714e+00 2.47938454e-02\n",
      " 2.50556254e-01 1.14900141e+01], Loss = 0.3810\n",
      "Iteration 5309: Weights = [5.50000000e+01 3.57914569e+00 7.52521111e+00 2.47931336e-02\n",
      " 2.50549062e-01 1.14902423e+01], Loss = 0.3810\n",
      "Iteration 5310: Weights = [5.50000000e+01 3.57904294e+00 7.52499509e+00 2.47924219e-02\n",
      " 2.50541870e-01 1.14904705e+01], Loss = 0.3810\n",
      "Iteration 5311: Weights = [5.50000000e+01 3.57894020e+00 7.52477908e+00 2.47917102e-02\n",
      " 2.50534677e-01 1.14906987e+01], Loss = 0.3809\n",
      "Iteration 5312: Weights = [5.50000000e+01 3.57883746e+00 7.52456307e+00 2.47909985e-02\n",
      " 2.50527485e-01 1.14909270e+01], Loss = 0.3809\n",
      "Iteration 5313: Weights = [5.50000000e+01 3.57873473e+00 7.52434707e+00 2.47902869e-02\n",
      " 2.50520294e-01 1.14911552e+01], Loss = 0.3809\n",
      "Iteration 5314: Weights = [5.50000000e+01 3.57863200e+00 7.52413107e+00 2.47895752e-02\n",
      " 2.50513102e-01 1.14913834e+01], Loss = 0.3809\n",
      "Iteration 5315: Weights = [5.50000000e+01 3.57852927e+00 7.52391508e+00 2.47888636e-02\n",
      " 2.50505911e-01 1.14916115e+01], Loss = 0.3808\n",
      "Iteration 5316: Weights = [5.50000000e+01 3.57842654e+00 7.52369910e+00 2.47881520e-02\n",
      " 2.50498720e-01 1.14918397e+01], Loss = 0.3808\n",
      "Iteration 5317: Weights = [5.50000000e+01 3.57832382e+00 7.52348312e+00 2.47874404e-02\n",
      " 2.50491529e-01 1.14920679e+01], Loss = 0.3808\n",
      "Iteration 5318: Weights = [5.50000000e+01 3.57822110e+00 7.52326715e+00 2.47867289e-02\n",
      " 2.50484338e-01 1.14922961e+01], Loss = 0.3808\n",
      "Iteration 5319: Weights = [5.50000000e+01 3.57811838e+00 7.52305118e+00 2.47860174e-02\n",
      " 2.50477148e-01 1.14925242e+01], Loss = 0.3808\n",
      "Iteration 5320: Weights = [5.50000000e+01 3.57801567e+00 7.52283522e+00 2.47853058e-02\n",
      " 2.50469957e-01 1.14927524e+01], Loss = 0.3807\n",
      "Iteration 5321: Weights = [5.50000000e+01 3.57791295e+00 7.52261927e+00 2.47845943e-02\n",
      " 2.50462767e-01 1.14929806e+01], Loss = 0.3807\n",
      "Iteration 5322: Weights = [5.50000000e+01 3.57781024e+00 7.52240332e+00 2.47838829e-02\n",
      " 2.50455578e-01 1.14932087e+01], Loss = 0.3807\n",
      "Iteration 5323: Weights = [5.50000000e+01 3.57770754e+00 7.52218738e+00 2.47831714e-02\n",
      " 2.50448388e-01 1.14934368e+01], Loss = 0.3807\n",
      "Iteration 5324: Weights = [5.50000000e+01 3.57760484e+00 7.52197145e+00 2.47824600e-02\n",
      " 2.50441198e-01 1.14936650e+01], Loss = 0.3807\n",
      "Iteration 5325: Weights = [5.50000000e+01 3.57750214e+00 7.52175552e+00 2.47817486e-02\n",
      " 2.50434009e-01 1.14938931e+01], Loss = 0.3806\n",
      "Iteration 5326: Weights = [5.50000000e+01 3.57739944e+00 7.52153960e+00 2.47810372e-02\n",
      " 2.50426820e-01 1.14941212e+01], Loss = 0.3806\n",
      "Iteration 5327: Weights = [5.50000000e+01 3.57729675e+00 7.52132368e+00 2.47803258e-02\n",
      " 2.50419631e-01 1.14943493e+01], Loss = 0.3806\n",
      "Iteration 5328: Weights = [5.50000000e+01 3.57719405e+00 7.52110777e+00 2.47796145e-02\n",
      " 2.50412443e-01 1.14945774e+01], Loss = 0.3806\n",
      "Iteration 5329: Weights = [5.50000000e+01 3.57709137e+00 7.52089187e+00 2.47789031e-02\n",
      " 2.50405254e-01 1.14948055e+01], Loss = 0.3805\n",
      "Iteration 5330: Weights = [5.50000000e+01 3.57698868e+00 7.52067597e+00 2.47781918e-02\n",
      " 2.50398066e-01 1.14950336e+01], Loss = 0.3805\n",
      "Iteration 5331: Weights = [5.50000000e+01 3.57688600e+00 7.52046008e+00 2.47774805e-02\n",
      " 2.50390878e-01 1.14952617e+01], Loss = 0.3805\n",
      "Iteration 5332: Weights = [5.50000000e+01 3.57678332e+00 7.52024420e+00 2.47767693e-02\n",
      " 2.50383690e-01 1.14954898e+01], Loss = 0.3805\n",
      "Iteration 5333: Weights = [5.50000000e+01 3.57668064e+00 7.52002832e+00 2.47760580e-02\n",
      " 2.50376503e-01 1.14957178e+01], Loss = 0.3805\n",
      "Iteration 5334: Weights = [5.50000000e+01 3.57657797e+00 7.51981245e+00 2.47753468e-02\n",
      " 2.50369315e-01 1.14959459e+01], Loss = 0.3804\n",
      "Iteration 5335: Weights = [5.50000000e+01 3.57647530e+00 7.51959658e+00 2.47746356e-02\n",
      " 2.50362128e-01 1.14961740e+01], Loss = 0.3804\n",
      "Iteration 5336: Weights = [5.50000000e+01 3.57637263e+00 7.51938072e+00 2.47739244e-02\n",
      " 2.50354941e-01 1.14964020e+01], Loss = 0.3804\n",
      "Iteration 5337: Weights = [5.50000000e+01 3.57626997e+00 7.51916487e+00 2.47732132e-02\n",
      " 2.50347754e-01 1.14966301e+01], Loss = 0.3804\n",
      "Iteration 5338: Weights = [5.50000000e+01 3.57616731e+00 7.51894902e+00 2.47725021e-02\n",
      " 2.50340568e-01 1.14968581e+01], Loss = 0.3803\n",
      "Iteration 5339: Weights = [5.50000000e+01 3.57606465e+00 7.51873318e+00 2.47717909e-02\n",
      " 2.50333381e-01 1.14970861e+01], Loss = 0.3803\n",
      "Iteration 5340: Weights = [5.50000000e+01 3.57596199e+00 7.51851734e+00 2.47710798e-02\n",
      " 2.50326195e-01 1.14973142e+01], Loss = 0.3803\n",
      "Iteration 5341: Weights = [5.50000000e+01 3.57585934e+00 7.51830152e+00 2.47703687e-02\n",
      " 2.50319009e-01 1.14975422e+01], Loss = 0.3803\n",
      "Iteration 5342: Weights = [5.50000000e+01 3.57575669e+00 7.51808569e+00 2.47696577e-02\n",
      " 2.50311824e-01 1.14977702e+01], Loss = 0.3803\n",
      "Iteration 5343: Weights = [5.50000000e+01 3.57565404e+00 7.51786988e+00 2.47689466e-02\n",
      " 2.50304638e-01 1.14979982e+01], Loss = 0.3802\n",
      "Iteration 5344: Weights = [5.50000000e+01 3.57555140e+00 7.51765407e+00 2.47682356e-02\n",
      " 2.50297453e-01 1.14982262e+01], Loss = 0.3802\n",
      "Iteration 5345: Weights = [5.50000000e+01 3.57544876e+00 7.51743826e+00 2.47675246e-02\n",
      " 2.50290268e-01 1.14984542e+01], Loss = 0.3802\n",
      "Iteration 5346: Weights = [5.50000000e+01 3.57534612e+00 7.51722246e+00 2.47668136e-02\n",
      " 2.50283083e-01 1.14986822e+01], Loss = 0.3802\n",
      "Iteration 5347: Weights = [5.50000000e+01 3.57524349e+00 7.51700667e+00 2.47661027e-02\n",
      " 2.50275898e-01 1.14989102e+01], Loss = 0.3802\n",
      "Iteration 5348: Weights = [5.50000000e+01 3.57514085e+00 7.51679089e+00 2.47653917e-02\n",
      " 2.50268714e-01 1.14991381e+01], Loss = 0.3801\n",
      "Iteration 5349: Weights = [5.50000000e+01 3.57503822e+00 7.51657511e+00 2.47646808e-02\n",
      " 2.50261529e-01 1.14993661e+01], Loss = 0.3801\n",
      "Iteration 5350: Weights = [5.50000000e+01 3.57493560e+00 7.51635933e+00 2.47639699e-02\n",
      " 2.50254345e-01 1.14995941e+01], Loss = 0.3801\n",
      "Iteration 5351: Weights = [5.50000000e+01 3.57483298e+00 7.51614357e+00 2.47632590e-02\n",
      " 2.50247161e-01 1.14998220e+01], Loss = 0.3801\n",
      "Iteration 5352: Weights = [5.50000000e+01 3.57473036e+00 7.51592781e+00 2.47625481e-02\n",
      " 2.50239978e-01 1.15000500e+01], Loss = 0.3800\n",
      "Iteration 5353: Weights = [5.50000000e+01 3.57462774e+00 7.51571205e+00 2.47618373e-02\n",
      " 2.50232794e-01 1.15002779e+01], Loss = 0.3800\n",
      "Iteration 5354: Weights = [5.50000000e+01 3.57452512e+00 7.51549630e+00 2.47611265e-02\n",
      " 2.50225611e-01 1.15005059e+01], Loss = 0.3800\n",
      "Iteration 5355: Weights = [5.50000000e+01 3.57442251e+00 7.51528056e+00 2.47604157e-02\n",
      " 2.50218428e-01 1.15007338e+01], Loss = 0.3800\n",
      "Iteration 5356: Weights = [5.50000000e+01 3.57431990e+00 7.51506483e+00 2.47597049e-02\n",
      " 2.50211245e-01 1.15009617e+01], Loss = 0.3800\n",
      "Iteration 5357: Weights = [5.50000000e+01 3.57421730e+00 7.51484910e+00 2.47589941e-02\n",
      " 2.50204062e-01 1.15011896e+01], Loss = 0.3799\n",
      "Iteration 5358: Weights = [5.50000000e+01 3.57411470e+00 7.51463337e+00 2.47582834e-02\n",
      " 2.50196880e-01 1.15014175e+01], Loss = 0.3799\n",
      "Iteration 5359: Weights = [5.50000000e+01 3.57401210e+00 7.51441766e+00 2.47575727e-02\n",
      " 2.50189698e-01 1.15016454e+01], Loss = 0.3799\n",
      "Iteration 5360: Weights = [5.50000000e+01 3.57390950e+00 7.51420194e+00 2.47568620e-02\n",
      " 2.50182516e-01 1.15018733e+01], Loss = 0.3799\n",
      "Iteration 5361: Weights = [5.50000000e+01 3.57380691e+00 7.51398624e+00 2.47561513e-02\n",
      " 2.50175334e-01 1.15021012e+01], Loss = 0.3798\n",
      "Iteration 5362: Weights = [5.50000000e+01 3.57370431e+00 7.51377054e+00 2.47554406e-02\n",
      " 2.50168152e-01 1.15023291e+01], Loss = 0.3798\n",
      "Iteration 5363: Weights = [5.50000000e+01 3.57360173e+00 7.51355485e+00 2.47547300e-02\n",
      " 2.50160971e-01 1.15025570e+01], Loss = 0.3798\n",
      "Iteration 5364: Weights = [5.50000000e+01 3.57349914e+00 7.51333916e+00 2.47540194e-02\n",
      " 2.50153790e-01 1.15027848e+01], Loss = 0.3798\n",
      "Iteration 5365: Weights = [5.50000000e+01 3.57339656e+00 7.51312348e+00 2.47533088e-02\n",
      " 2.50146609e-01 1.15030127e+01], Loss = 0.3798\n",
      "Iteration 5366: Weights = [5.50000000e+01 3.57329398e+00 7.51290781e+00 2.47525982e-02\n",
      " 2.50139428e-01 1.15032406e+01], Loss = 0.3797\n",
      "Iteration 5367: Weights = [5.50000000e+01 3.57319140e+00 7.51269214e+00 2.47518877e-02\n",
      " 2.50132247e-01 1.15034684e+01], Loss = 0.3797\n",
      "Iteration 5368: Weights = [5.50000000e+01 3.57308883e+00 7.51247648e+00 2.47511771e-02\n",
      " 2.50125067e-01 1.15036963e+01], Loss = 0.3797\n",
      "Iteration 5369: Weights = [5.50000000e+01 3.57298626e+00 7.51226082e+00 2.47504666e-02\n",
      " 2.50117887e-01 1.15039241e+01], Loss = 0.3797\n",
      "Iteration 5370: Weights = [5.50000000e+01 3.57288369e+00 7.51204517e+00 2.47497561e-02\n",
      " 2.50110707e-01 1.15041519e+01], Loss = 0.3796\n",
      "Iteration 5371: Weights = [5.50000000e+01 3.57278113e+00 7.51182953e+00 2.47490456e-02\n",
      " 2.50103527e-01 1.15043797e+01], Loss = 0.3796\n",
      "Iteration 5372: Weights = [5.50000000e+01 3.57267857e+00 7.51161389e+00 2.47483352e-02\n",
      " 2.50096348e-01 1.15046076e+01], Loss = 0.3796\n",
      "Iteration 5373: Weights = [5.50000000e+01 3.57257601e+00 7.51139826e+00 2.47476248e-02\n",
      " 2.50089168e-01 1.15048354e+01], Loss = 0.3796\n",
      "Iteration 5374: Weights = [5.50000000e+01 3.57247345e+00 7.51118264e+00 2.47469143e-02\n",
      " 2.50081989e-01 1.15050632e+01], Loss = 0.3796\n",
      "Iteration 5375: Weights = [5.50000000e+01 3.57237090e+00 7.51096702e+00 2.47462040e-02\n",
      " 2.50074810e-01 1.15052910e+01], Loss = 0.3795\n",
      "Iteration 5376: Weights = [5.50000000e+01 3.57226835e+00 7.51075141e+00 2.47454936e-02\n",
      " 2.50067631e-01 1.15055188e+01], Loss = 0.3795\n",
      "Iteration 5377: Weights = [5.50000000e+01 3.57216581e+00 7.51053580e+00 2.47447832e-02\n",
      " 2.50060453e-01 1.15057465e+01], Loss = 0.3795\n",
      "Iteration 5378: Weights = [5.50000000e+01 3.57206326e+00 7.51032020e+00 2.47440729e-02\n",
      " 2.50053275e-01 1.15059743e+01], Loss = 0.3795\n",
      "Iteration 5379: Weights = [5.50000000e+01 3.57196072e+00 7.51010461e+00 2.47433626e-02\n",
      " 2.50046096e-01 1.15062021e+01], Loss = 0.3795\n",
      "Iteration 5380: Weights = [5.50000000e+01 3.57185818e+00 7.50988902e+00 2.47426523e-02\n",
      " 2.50038919e-01 1.15064299e+01], Loss = 0.3794\n",
      "Iteration 5381: Weights = [5.50000000e+01 3.57175565e+00 7.50967344e+00 2.47419420e-02\n",
      " 2.50031741e-01 1.15066576e+01], Loss = 0.3794\n",
      "Iteration 5382: Weights = [5.50000000e+01 3.57165312e+00 7.50945786e+00 2.47412318e-02\n",
      " 2.50024563e-01 1.15068854e+01], Loss = 0.3794\n",
      "Iteration 5383: Weights = [5.50000000e+01 3.57155059e+00 7.50924230e+00 2.47405215e-02\n",
      " 2.50017386e-01 1.15071131e+01], Loss = 0.3794\n",
      "Iteration 5384: Weights = [5.50000000e+01 3.57144806e+00 7.50902673e+00 2.47398113e-02\n",
      " 2.50010209e-01 1.15073409e+01], Loss = 0.3793\n",
      "Iteration 5385: Weights = [5.50000000e+01 3.57134554e+00 7.50881118e+00 2.47391011e-02\n",
      " 2.50003032e-01 1.15075686e+01], Loss = 0.3793\n",
      "Iteration 5386: Weights = [5.50000000e+01 3.57124302e+00 7.50859563e+00 2.47383910e-02\n",
      " 2.49995855e-01 1.15077963e+01], Loss = 0.3793\n",
      "Iteration 5387: Weights = [5.50000000e+01 3.57114050e+00 7.50838008e+00 2.47376808e-02\n",
      " 2.49988679e-01 1.15080240e+01], Loss = 0.3793\n",
      "Iteration 5388: Weights = [5.50000000e+01 3.57103799e+00 7.50816454e+00 2.47369707e-02\n",
      " 2.49981503e-01 1.15082517e+01], Loss = 0.3793\n",
      "Iteration 5389: Weights = [5.50000000e+01 3.57093548e+00 7.50794901e+00 2.47362606e-02\n",
      " 2.49974327e-01 1.15084794e+01], Loss = 0.3792\n",
      "Iteration 5390: Weights = [5.50000000e+01 3.57083297e+00 7.50773349e+00 2.47355505e-02\n",
      " 2.49967151e-01 1.15087071e+01], Loss = 0.3792\n",
      "Iteration 5391: Weights = [5.50000000e+01 3.57073046e+00 7.50751797e+00 2.47348404e-02\n",
      " 2.49959975e-01 1.15089348e+01], Loss = 0.3792\n",
      "Iteration 5392: Weights = [5.50000000e+01 3.57062796e+00 7.50730245e+00 2.47341304e-02\n",
      " 2.49952800e-01 1.15091625e+01], Loss = 0.3792\n",
      "Iteration 5393: Weights = [5.50000000e+01 3.57052546e+00 7.50708695e+00 2.47334204e-02\n",
      " 2.49945625e-01 1.15093902e+01], Loss = 0.3791\n",
      "Iteration 5394: Weights = [5.50000000e+01 3.57042296e+00 7.50687145e+00 2.47327104e-02\n",
      " 2.49938450e-01 1.15096179e+01], Loss = 0.3791\n",
      "Iteration 5395: Weights = [5.50000000e+01 3.57032047e+00 7.50665595e+00 2.47320004e-02\n",
      " 2.49931275e-01 1.15098455e+01], Loss = 0.3791\n",
      "Iteration 5396: Weights = [5.50000000e+01 3.57021798e+00 7.50644046e+00 2.47312904e-02\n",
      " 2.49924100e-01 1.15100732e+01], Loss = 0.3791\n",
      "Iteration 5397: Weights = [5.50000000e+01 3.57011549e+00 7.50622498e+00 2.47305805e-02\n",
      " 2.49916926e-01 1.15103009e+01], Loss = 0.3791\n",
      "Iteration 5398: Weights = [5.50000000e+01 3.57001301e+00 7.50600951e+00 2.47298706e-02\n",
      " 2.49909752e-01 1.15105285e+01], Loss = 0.3790\n",
      "Iteration 5399: Weights = [5.50000000e+01 3.56991052e+00 7.50579404e+00 2.47291606e-02\n",
      " 2.49902578e-01 1.15107561e+01], Loss = 0.3790\n",
      "Iteration 5400: Weights = [5.50000000e+01 3.56980805e+00 7.50557857e+00 2.47284508e-02\n",
      " 2.49895404e-01 1.15109838e+01], Loss = 0.3790\n",
      "Iteration 5401: Weights = [5.50000000e+01 3.56970557e+00 7.50536311e+00 2.47277409e-02\n",
      " 2.49888230e-01 1.15112114e+01], Loss = 0.3790\n",
      "Iteration 5402: Weights = [5.50000000e+01 3.56960310e+00 7.50514766e+00 2.47270311e-02\n",
      " 2.49881057e-01 1.15114390e+01], Loss = 0.3790\n",
      "Iteration 5403: Weights = [5.50000000e+01 3.56950063e+00 7.50493222e+00 2.47263212e-02\n",
      " 2.49873884e-01 1.15116666e+01], Loss = 0.3789\n",
      "Iteration 5404: Weights = [5.50000000e+01 3.56939816e+00 7.50471678e+00 2.47256114e-02\n",
      " 2.49866711e-01 1.15118942e+01], Loss = 0.3789\n",
      "Iteration 5405: Weights = [5.50000000e+01 3.56929569e+00 7.50450135e+00 2.47249017e-02\n",
      " 2.49859538e-01 1.15121218e+01], Loss = 0.3789\n",
      "Iteration 5406: Weights = [5.50000000e+01 3.56919323e+00 7.50428592e+00 2.47241919e-02\n",
      " 2.49852365e-01 1.15123494e+01], Loss = 0.3789\n",
      "Iteration 5407: Weights = [5.50000000e+01 3.56909078e+00 7.50407050e+00 2.47234822e-02\n",
      " 2.49845193e-01 1.15125770e+01], Loss = 0.3788\n",
      "Iteration 5408: Weights = [5.50000000e+01 3.56898832e+00 7.50385509e+00 2.47227724e-02\n",
      " 2.49838021e-01 1.15128046e+01], Loss = 0.3788\n",
      "Iteration 5409: Weights = [5.50000000e+01 3.56888587e+00 7.50363968e+00 2.47220627e-02\n",
      " 2.49830849e-01 1.15130322e+01], Loss = 0.3788\n",
      "Iteration 5410: Weights = [5.50000000e+01 3.56878342e+00 7.50342428e+00 2.47213531e-02\n",
      " 2.49823677e-01 1.15132598e+01], Loss = 0.3788\n",
      "Iteration 5411: Weights = [5.50000000e+01 3.56868097e+00 7.50320888e+00 2.47206434e-02\n",
      " 2.49816506e-01 1.15134873e+01], Loss = 0.3788\n",
      "Iteration 5412: Weights = [5.50000000e+01 3.56857853e+00 7.50299349e+00 2.47199338e-02\n",
      " 2.49809334e-01 1.15137149e+01], Loss = 0.3787\n",
      "Iteration 5413: Weights = [5.50000000e+01 3.56847609e+00 7.50277811e+00 2.47192241e-02\n",
      " 2.49802163e-01 1.15139424e+01], Loss = 0.3787\n",
      "Iteration 5414: Weights = [5.50000000e+01 3.56837365e+00 7.50256273e+00 2.47185145e-02\n",
      " 2.49794992e-01 1.15141700e+01], Loss = 0.3787\n",
      "Iteration 5415: Weights = [5.50000000e+01 3.56827121e+00 7.50234736e+00 2.47178050e-02\n",
      " 2.49787822e-01 1.15143975e+01], Loss = 0.3787\n",
      "Iteration 5416: Weights = [5.50000000e+01 3.56816878e+00 7.50213199e+00 2.47170954e-02\n",
      " 2.49780651e-01 1.15146250e+01], Loss = 0.3786\n",
      "Iteration 5417: Weights = [5.50000000e+01 3.56806635e+00 7.50191664e+00 2.47163859e-02\n",
      " 2.49773481e-01 1.15148526e+01], Loss = 0.3786\n",
      "Iteration 5418: Weights = [5.50000000e+01 3.56796393e+00 7.50170128e+00 2.47156764e-02\n",
      " 2.49766311e-01 1.15150801e+01], Loss = 0.3786\n",
      "Iteration 5419: Weights = [5.50000000e+01 3.56786150e+00 7.50148594e+00 2.47149669e-02\n",
      " 2.49759141e-01 1.15153076e+01], Loss = 0.3786\n",
      "Iteration 5420: Weights = [5.50000000e+01 3.56775908e+00 7.50127060e+00 2.47142574e-02\n",
      " 2.49751971e-01 1.15155351e+01], Loss = 0.3786\n",
      "Iteration 5421: Weights = [5.50000000e+01 3.56765667e+00 7.50105526e+00 2.47135479e-02\n",
      " 2.49744802e-01 1.15157626e+01], Loss = 0.3785\n",
      "Iteration 5422: Weights = [5.50000000e+01 3.56755425e+00 7.50083994e+00 2.47128385e-02\n",
      " 2.49737633e-01 1.15159901e+01], Loss = 0.3785\n",
      "Iteration 5423: Weights = [5.50000000e+01 3.56745184e+00 7.50062461e+00 2.47121291e-02\n",
      " 2.49730464e-01 1.15162176e+01], Loss = 0.3785\n",
      "Iteration 5424: Weights = [5.50000000e+01 3.56734943e+00 7.50040930e+00 2.47114197e-02\n",
      " 2.49723295e-01 1.15164450e+01], Loss = 0.3785\n",
      "Iteration 5425: Weights = [5.50000000e+01 3.56724703e+00 7.50019399e+00 2.47107103e-02\n",
      " 2.49716126e-01 1.15166725e+01], Loss = 0.3785\n",
      "Iteration 5426: Weights = [5.50000000e+01 3.56714463e+00 7.49997869e+00 2.47100010e-02\n",
      " 2.49708958e-01 1.15169000e+01], Loss = 0.3784\n",
      "Iteration 5427: Weights = [5.50000000e+01 3.56704223e+00 7.49976339e+00 2.47092916e-02\n",
      " 2.49701790e-01 1.15171274e+01], Loss = 0.3784\n",
      "Iteration 5428: Weights = [5.50000000e+01 3.56693983e+00 7.49954810e+00 2.47085823e-02\n",
      " 2.49694622e-01 1.15173549e+01], Loss = 0.3784\n",
      "Iteration 5429: Weights = [5.50000000e+01 3.56683744e+00 7.49933282e+00 2.47078730e-02\n",
      " 2.49687454e-01 1.15175823e+01], Loss = 0.3784\n",
      "Iteration 5430: Weights = [5.50000000e+01 3.56673504e+00 7.49911754e+00 2.47071637e-02\n",
      " 2.49680286e-01 1.15178098e+01], Loss = 0.3783\n",
      "Iteration 5431: Weights = [5.50000000e+01 3.56663266e+00 7.49890227e+00 2.47064545e-02\n",
      " 2.49673119e-01 1.15180372e+01], Loss = 0.3783\n",
      "Iteration 5432: Weights = [5.50000000e+01 3.56653027e+00 7.49868700e+00 2.47057453e-02\n",
      " 2.49665952e-01 1.15182646e+01], Loss = 0.3783\n",
      "Iteration 5433: Weights = [5.50000000e+01 3.56642789e+00 7.49847174e+00 2.47050361e-02\n",
      " 2.49658785e-01 1.15184920e+01], Loss = 0.3783\n",
      "Iteration 5434: Weights = [5.50000000e+01 3.56632551e+00 7.49825649e+00 2.47043269e-02\n",
      " 2.49651618e-01 1.15187194e+01], Loss = 0.3783\n",
      "Iteration 5435: Weights = [5.50000000e+01 3.56622313e+00 7.49804124e+00 2.47036177e-02\n",
      " 2.49644451e-01 1.15189468e+01], Loss = 0.3782\n",
      "Iteration 5436: Weights = [5.50000000e+01 3.56612076e+00 7.49782600e+00 2.47029085e-02\n",
      " 2.49637285e-01 1.15191742e+01], Loss = 0.3782\n",
      "Iteration 5437: Weights = [5.50000000e+01 3.56601839e+00 7.49761076e+00 2.47021994e-02\n",
      " 2.49630119e-01 1.15194016e+01], Loss = 0.3782\n",
      "Iteration 5438: Weights = [5.50000000e+01 3.56591602e+00 7.49739553e+00 2.47014903e-02\n",
      " 2.49622953e-01 1.15196290e+01], Loss = 0.3782\n",
      "Iteration 5439: Weights = [5.50000000e+01 3.56581366e+00 7.49718031e+00 2.47007812e-02\n",
      " 2.49615787e-01 1.15198564e+01], Loss = 0.3781\n",
      "Iteration 5440: Weights = [5.50000000e+01 3.56571130e+00 7.49696510e+00 2.47000722e-02\n",
      " 2.49608621e-01 1.15200838e+01], Loss = 0.3781\n",
      "Iteration 5441: Weights = [5.50000000e+01 3.56560894e+00 7.49674989e+00 2.46993631e-02\n",
      " 2.49601456e-01 1.15203111e+01], Loss = 0.3781\n",
      "Iteration 5442: Weights = [5.50000000e+01 3.56550658e+00 7.49653468e+00 2.46986541e-02\n",
      " 2.49594291e-01 1.15205385e+01], Loss = 0.3781\n",
      "Iteration 5443: Weights = [5.50000000e+01 3.56540423e+00 7.49631948e+00 2.46979451e-02\n",
      " 2.49587126e-01 1.15207659e+01], Loss = 0.3781\n",
      "Iteration 5444: Weights = [5.50000000e+01 3.56530188e+00 7.49610429e+00 2.46972361e-02\n",
      " 2.49579961e-01 1.15209932e+01], Loss = 0.3780\n",
      "Iteration 5445: Weights = [5.50000000e+01 3.56519954e+00 7.49588911e+00 2.46965271e-02\n",
      " 2.49572797e-01 1.15212205e+01], Loss = 0.3780\n",
      "Iteration 5446: Weights = [5.50000000e+01 3.56509719e+00 7.49567393e+00 2.46958182e-02\n",
      " 2.49565632e-01 1.15214479e+01], Loss = 0.3780\n",
      "Iteration 5447: Weights = [5.50000000e+01 3.56499485e+00 7.49545875e+00 2.46951092e-02\n",
      " 2.49558468e-01 1.15216752e+01], Loss = 0.3780\n",
      "Iteration 5448: Weights = [5.50000000e+01 3.56489251e+00 7.49524359e+00 2.46944003e-02\n",
      " 2.49551304e-01 1.15219025e+01], Loss = 0.3780\n",
      "Iteration 5449: Weights = [5.50000000e+01 3.56479018e+00 7.49502843e+00 2.46936915e-02\n",
      " 2.49544141e-01 1.15221298e+01], Loss = 0.3779\n",
      "Iteration 5450: Weights = [5.50000000e+01 3.56468785e+00 7.49481327e+00 2.46929826e-02\n",
      " 2.49536977e-01 1.15223571e+01], Loss = 0.3779\n",
      "Iteration 5451: Weights = [5.50000000e+01 3.56458552e+00 7.49459812e+00 2.46922737e-02\n",
      " 2.49529814e-01 1.15225844e+01], Loss = 0.3779\n",
      "Iteration 5452: Weights = [5.50000000e+01 3.56448319e+00 7.49438298e+00 2.46915649e-02\n",
      " 2.49522651e-01 1.15228117e+01], Loss = 0.3779\n",
      "Iteration 5453: Weights = [5.50000000e+01 3.56438087e+00 7.49416785e+00 2.46908561e-02\n",
      " 2.49515488e-01 1.15230390e+01], Loss = 0.3778\n",
      "Iteration 5454: Weights = [5.50000000e+01 3.56427855e+00 7.49395272e+00 2.46901473e-02\n",
      " 2.49508325e-01 1.15232663e+01], Loss = 0.3778\n",
      "Iteration 5455: Weights = [5.50000000e+01 3.56417623e+00 7.49373759e+00 2.46894386e-02\n",
      " 2.49501163e-01 1.15234936e+01], Loss = 0.3778\n",
      "Iteration 5456: Weights = [5.50000000e+01 3.56407392e+00 7.49352247e+00 2.46887298e-02\n",
      " 2.49494001e-01 1.15237209e+01], Loss = 0.3778\n",
      "Iteration 5457: Weights = [5.50000000e+01 3.56397161e+00 7.49330736e+00 2.46880211e-02\n",
      " 2.49486839e-01 1.15239481e+01], Loss = 0.3778\n",
      "Iteration 5458: Weights = [5.50000000e+01 3.56386930e+00 7.49309226e+00 2.46873124e-02\n",
      " 2.49479677e-01 1.15241754e+01], Loss = 0.3777\n",
      "Iteration 5459: Weights = [5.50000000e+01 3.56376699e+00 7.49287716e+00 2.46866037e-02\n",
      " 2.49472515e-01 1.15244026e+01], Loss = 0.3777\n",
      "Iteration 5460: Weights = [5.50000000e+01 3.56366469e+00 7.49266207e+00 2.46858951e-02\n",
      " 2.49465354e-01 1.15246299e+01], Loss = 0.3777\n",
      "Iteration 5461: Weights = [5.50000000e+01 3.56356239e+00 7.49244698e+00 2.46851864e-02\n",
      " 2.49458192e-01 1.15248571e+01], Loss = 0.3777\n",
      "Iteration 5462: Weights = [5.50000000e+01 3.56346009e+00 7.49223190e+00 2.46844778e-02\n",
      " 2.49451031e-01 1.15250843e+01], Loss = 0.3776\n",
      "Iteration 5463: Weights = [5.50000000e+01 3.56335780e+00 7.49201682e+00 2.46837692e-02\n",
      " 2.49443871e-01 1.15253115e+01], Loss = 0.3776\n",
      "Iteration 5464: Weights = [5.50000000e+01 3.56325551e+00 7.49180176e+00 2.46830606e-02\n",
      " 2.49436710e-01 1.15255388e+01], Loss = 0.3776\n",
      "Iteration 5465: Weights = [5.50000000e+01 3.56315322e+00 7.49158669e+00 2.46823521e-02\n",
      " 2.49429549e-01 1.15257660e+01], Loss = 0.3776\n",
      "Iteration 5466: Weights = [5.50000000e+01 3.56305093e+00 7.49137164e+00 2.46816435e-02\n",
      " 2.49422389e-01 1.15259932e+01], Loss = 0.3776\n",
      "Iteration 5467: Weights = [5.50000000e+01 3.56294865e+00 7.49115659e+00 2.46809350e-02\n",
      " 2.49415229e-01 1.15262204e+01], Loss = 0.3775\n",
      "Iteration 5468: Weights = [5.50000000e+01 3.56284637e+00 7.49094155e+00 2.46802265e-02\n",
      " 2.49408070e-01 1.15264476e+01], Loss = 0.3775\n",
      "Iteration 5469: Weights = [5.50000000e+01 3.56274410e+00 7.49072651e+00 2.46795180e-02\n",
      " 2.49400910e-01 1.15266747e+01], Loss = 0.3775\n",
      "Iteration 5470: Weights = [5.50000000e+01 3.56264182e+00 7.49051148e+00 2.46788096e-02\n",
      " 2.49393751e-01 1.15269019e+01], Loss = 0.3775\n",
      "Iteration 5471: Weights = [5.50000000e+01 3.56253955e+00 7.49029645e+00 2.46781011e-02\n",
      " 2.49386591e-01 1.15271291e+01], Loss = 0.3775\n",
      "Iteration 5472: Weights = [5.50000000e+01 3.56243729e+00 7.49008143e+00 2.46773927e-02\n",
      " 2.49379432e-01 1.15273563e+01], Loss = 0.3774\n",
      "Iteration 5473: Weights = [5.50000000e+01 3.56233502e+00 7.48986642e+00 2.46766843e-02\n",
      " 2.49372274e-01 1.15275834e+01], Loss = 0.3774\n",
      "Iteration 5474: Weights = [5.50000000e+01 3.56223276e+00 7.48965141e+00 2.46759759e-02\n",
      " 2.49365115e-01 1.15278106e+01], Loss = 0.3774\n",
      "Iteration 5475: Weights = [5.50000000e+01 3.56213050e+00 7.48943641e+00 2.46752676e-02\n",
      " 2.49357957e-01 1.15280377e+01], Loss = 0.3774\n",
      "Iteration 5476: Weights = [5.50000000e+01 3.56202825e+00 7.48922142e+00 2.46745592e-02\n",
      " 2.49350799e-01 1.15282648e+01], Loss = 0.3773\n",
      "Iteration 5477: Weights = [5.50000000e+01 3.56192599e+00 7.48900643e+00 2.46738509e-02\n",
      " 2.49343641e-01 1.15284920e+01], Loss = 0.3773\n",
      "Iteration 5478: Weights = [5.50000000e+01 3.56182374e+00 7.48879145e+00 2.46731426e-02\n",
      " 2.49336483e-01 1.15287191e+01], Loss = 0.3773\n",
      "Iteration 5479: Weights = [5.50000000e+01 3.56172150e+00 7.48857647e+00 2.46724344e-02\n",
      " 2.49329325e-01 1.15289462e+01], Loss = 0.3773\n",
      "Iteration 5480: Weights = [5.50000000e+01 3.56161925e+00 7.48836151e+00 2.46717261e-02\n",
      " 2.49322168e-01 1.15291733e+01], Loss = 0.3773\n",
      "Iteration 5481: Weights = [5.50000000e+01 3.56151701e+00 7.48814654e+00 2.46710179e-02\n",
      " 2.49315011e-01 1.15294004e+01], Loss = 0.3772\n",
      "Iteration 5482: Weights = [5.50000000e+01 3.56141477e+00 7.48793158e+00 2.46703097e-02\n",
      " 2.49307854e-01 1.15296275e+01], Loss = 0.3772\n",
      "Iteration 5483: Weights = [5.50000000e+01 3.56131254e+00 7.48771663e+00 2.46696015e-02\n",
      " 2.49300697e-01 1.15298546e+01], Loss = 0.3772\n",
      "Iteration 5484: Weights = [5.50000000e+01 3.56121031e+00 7.48750169e+00 2.46688933e-02\n",
      " 2.49293541e-01 1.15300817e+01], Loss = 0.3772\n",
      "Iteration 5485: Weights = [5.50000000e+01 3.56110808e+00 7.48728675e+00 2.46681851e-02\n",
      " 2.49286385e-01 1.15303088e+01], Loss = 0.3772\n",
      "Iteration 5486: Weights = [5.50000000e+01 3.56100585e+00 7.48707182e+00 2.46674770e-02\n",
      " 2.49279228e-01 1.15305359e+01], Loss = 0.3771\n",
      "Iteration 5487: Weights = [5.50000000e+01 3.56090363e+00 7.48685689e+00 2.46667689e-02\n",
      " 2.49272073e-01 1.15307629e+01], Loss = 0.3771\n",
      "Iteration 5488: Weights = [5.50000000e+01 3.56080141e+00 7.48664197e+00 2.46660608e-02\n",
      " 2.49264917e-01 1.15309900e+01], Loss = 0.3771\n",
      "Iteration 5489: Weights = [5.50000000e+01 3.56069919e+00 7.48642706e+00 2.46653527e-02\n",
      " 2.49257761e-01 1.15312170e+01], Loss = 0.3771\n",
      "Iteration 5490: Weights = [5.50000000e+01 3.56059698e+00 7.48621215e+00 2.46646447e-02\n",
      " 2.49250606e-01 1.15314441e+01], Loss = 0.3770\n",
      "Iteration 5491: Weights = [5.50000000e+01 3.56049476e+00 7.48599725e+00 2.46639366e-02\n",
      " 2.49243451e-01 1.15316711e+01], Loss = 0.3770\n",
      "Iteration 5492: Weights = [5.50000000e+01 3.56039256e+00 7.48578235e+00 2.46632286e-02\n",
      " 2.49236296e-01 1.15318982e+01], Loss = 0.3770\n",
      "Iteration 5493: Weights = [5.50000000e+01 3.56029035e+00 7.48556746e+00 2.46625206e-02\n",
      " 2.49229142e-01 1.15321252e+01], Loss = 0.3770\n",
      "Iteration 5494: Weights = [5.50000000e+01 3.56018815e+00 7.48535258e+00 2.46618127e-02\n",
      " 2.49221987e-01 1.15323522e+01], Loss = 0.3770\n",
      "Iteration 5495: Weights = [5.50000000e+01 3.56008595e+00 7.48513770e+00 2.46611047e-02\n",
      " 2.49214833e-01 1.15325792e+01], Loss = 0.3769\n",
      "Iteration 5496: Weights = [5.50000000e+01 3.55998375e+00 7.48492283e+00 2.46603968e-02\n",
      " 2.49207679e-01 1.15328062e+01], Loss = 0.3769\n",
      "Iteration 5497: Weights = [5.50000000e+01 3.55988156e+00 7.48470797e+00 2.46596889e-02\n",
      " 2.49200525e-01 1.15330332e+01], Loss = 0.3769\n",
      "Iteration 5498: Weights = [5.50000000e+01 3.55977937e+00 7.48449311e+00 2.46589810e-02\n",
      " 2.49193371e-01 1.15332602e+01], Loss = 0.3769\n",
      "Iteration 5499: Weights = [5.50000000e+01 3.55967718e+00 7.48427826e+00 2.46582731e-02\n",
      " 2.49186218e-01 1.15334872e+01], Loss = 0.3768\n",
      "Iteration 5500: Weights = [5.50000000e+01 3.55957499e+00 7.48406341e+00 2.46575653e-02\n",
      " 2.49179065e-01 1.15337142e+01], Loss = 0.3768\n",
      "Iteration 5501: Weights = [5.50000000e+01 3.55947281e+00 7.48384857e+00 2.46568575e-02\n",
      " 2.49171912e-01 1.15339412e+01], Loss = 0.3768\n",
      "Iteration 5502: Weights = [5.50000000e+01 3.55937063e+00 7.48363374e+00 2.46561496e-02\n",
      " 2.49164759e-01 1.15341681e+01], Loss = 0.3768\n",
      "Iteration 5503: Weights = [5.50000000e+01 3.55926845e+00 7.48341891e+00 2.46554419e-02\n",
      " 2.49157606e-01 1.15343951e+01], Loss = 0.3768\n",
      "Iteration 5504: Weights = [5.50000000e+01 3.55916628e+00 7.48320409e+00 2.46547341e-02\n",
      " 2.49150454e-01 1.15346221e+01], Loss = 0.3767\n",
      "Iteration 5505: Weights = [5.50000000e+01 3.55906411e+00 7.48298928e+00 2.46540263e-02\n",
      " 2.49143302e-01 1.15348490e+01], Loss = 0.3767\n",
      "Iteration 5506: Weights = [5.50000000e+01 3.55896194e+00 7.48277447e+00 2.46533186e-02\n",
      " 2.49136150e-01 1.15350759e+01], Loss = 0.3767\n",
      "Iteration 5507: Weights = [5.50000000e+01 3.55885978e+00 7.48255966e+00 2.46526109e-02\n",
      " 2.49128998e-01 1.15353029e+01], Loss = 0.3767\n",
      "Iteration 5508: Weights = [5.50000000e+01 3.55875762e+00 7.48234487e+00 2.46519032e-02\n",
      " 2.49121846e-01 1.15355298e+01], Loss = 0.3767\n",
      "Iteration 5509: Weights = [5.50000000e+01 3.55865546e+00 7.48213008e+00 2.46511956e-02\n",
      " 2.49114695e-01 1.15357567e+01], Loss = 0.3766\n",
      "Iteration 5510: Weights = [5.50000000e+01 3.55855330e+00 7.48191529e+00 2.46504879e-02\n",
      " 2.49107544e-01 1.15359837e+01], Loss = 0.3766\n",
      "Iteration 5511: Weights = [5.50000000e+01 3.55845115e+00 7.48170051e+00 2.46497803e-02\n",
      " 2.49100393e-01 1.15362106e+01], Loss = 0.3766\n",
      "Iteration 5512: Weights = [5.50000000e+01 3.55834900e+00 7.48148574e+00 2.46490727e-02\n",
      " 2.49093242e-01 1.15364375e+01], Loss = 0.3766\n",
      "Iteration 5513: Weights = [5.50000000e+01 3.55824685e+00 7.48127098e+00 2.46483651e-02\n",
      " 2.49086092e-01 1.15366644e+01], Loss = 0.3765\n",
      "Iteration 5514: Weights = [5.50000000e+01 3.55814471e+00 7.48105622e+00 2.46476575e-02\n",
      " 2.49078941e-01 1.15368913e+01], Loss = 0.3765\n",
      "Iteration 5515: Weights = [5.50000000e+01 3.55804257e+00 7.48084146e+00 2.46469500e-02\n",
      " 2.49071791e-01 1.15371181e+01], Loss = 0.3765\n",
      "Iteration 5516: Weights = [5.50000000e+01 3.55794043e+00 7.48062672e+00 2.46462425e-02\n",
      " 2.49064641e-01 1.15373450e+01], Loss = 0.3765\n",
      "Iteration 5517: Weights = [5.50000000e+01 3.55783829e+00 7.48041197e+00 2.46455350e-02\n",
      " 2.49057491e-01 1.15375719e+01], Loss = 0.3765\n",
      "Iteration 5518: Weights = [5.50000000e+01 3.55773616e+00 7.48019724e+00 2.46448275e-02\n",
      " 2.49050342e-01 1.15377987e+01], Loss = 0.3764\n",
      "Iteration 5519: Weights = [5.50000000e+01 3.55763403e+00 7.47998251e+00 2.46441200e-02\n",
      " 2.49043193e-01 1.15380256e+01], Loss = 0.3764\n",
      "Iteration 5520: Weights = [5.50000000e+01 3.55753190e+00 7.47976779e+00 2.46434126e-02\n",
      " 2.49036043e-01 1.15382525e+01], Loss = 0.3764\n",
      "Iteration 5521: Weights = [5.50000000e+01 3.55742978e+00 7.47955307e+00 2.46427052e-02\n",
      " 2.49028895e-01 1.15384793e+01], Loss = 0.3764\n",
      "Iteration 5522: Weights = [5.50000000e+01 3.55732766e+00 7.47933836e+00 2.46419978e-02\n",
      " 2.49021746e-01 1.15387061e+01], Loss = 0.3764\n",
      "Iteration 5523: Weights = [5.50000000e+01 3.55722554e+00 7.47912366e+00 2.46412904e-02\n",
      " 2.49014597e-01 1.15389330e+01], Loss = 0.3763\n",
      "Iteration 5524: Weights = [5.50000000e+01 3.55712343e+00 7.47890896e+00 2.46405830e-02\n",
      " 2.49007449e-01 1.15391598e+01], Loss = 0.3763\n",
      "Iteration 5525: Weights = [5.50000000e+01 3.55702132e+00 7.47869427e+00 2.46398757e-02\n",
      " 2.49000301e-01 1.15393866e+01], Loss = 0.3763\n",
      "Iteration 5526: Weights = [5.50000000e+01 3.55691921e+00 7.47847958e+00 2.46391684e-02\n",
      " 2.48993153e-01 1.15396134e+01], Loss = 0.3763\n",
      "Iteration 5527: Weights = [5.50000000e+01 3.55681710e+00 7.47826490e+00 2.46384611e-02\n",
      " 2.48986005e-01 1.15398402e+01], Loss = 0.3762\n",
      "Iteration 5528: Weights = [5.50000000e+01 3.55671500e+00 7.47805023e+00 2.46377538e-02\n",
      " 2.48978858e-01 1.15400670e+01], Loss = 0.3762\n",
      "Iteration 5529: Weights = [5.50000000e+01 3.55661290e+00 7.47783556e+00 2.46370465e-02\n",
      " 2.48971711e-01 1.15402938e+01], Loss = 0.3762\n",
      "Iteration 5530: Weights = [5.50000000e+01 3.55651080e+00 7.47762090e+00 2.46363393e-02\n",
      " 2.48964564e-01 1.15405206e+01], Loss = 0.3762\n",
      "Iteration 5531: Weights = [5.50000000e+01 3.55640871e+00 7.47740625e+00 2.46356321e-02\n",
      " 2.48957417e-01 1.15407474e+01], Loss = 0.3762\n",
      "Iteration 5532: Weights = [5.50000000e+01 3.55630661e+00 7.47719160e+00 2.46349249e-02\n",
      " 2.48950270e-01 1.15409742e+01], Loss = 0.3761\n",
      "Iteration 5533: Weights = [5.50000000e+01 3.55620453e+00 7.47697695e+00 2.46342177e-02\n",
      " 2.48943124e-01 1.15412009e+01], Loss = 0.3761\n",
      "Iteration 5534: Weights = [5.50000000e+01 3.55610244e+00 7.47676232e+00 2.46335105e-02\n",
      " 2.48935977e-01 1.15414277e+01], Loss = 0.3761\n",
      "Iteration 5535: Weights = [5.50000000e+01 3.55600036e+00 7.47654769e+00 2.46328034e-02\n",
      " 2.48928831e-01 1.15416544e+01], Loss = 0.3761\n",
      "Iteration 5536: Weights = [5.50000000e+01 3.55589828e+00 7.47633306e+00 2.46320963e-02\n",
      " 2.48921686e-01 1.15418812e+01], Loss = 0.3760\n",
      "Iteration 5537: Weights = [5.50000000e+01 3.55579620e+00 7.47611845e+00 2.46313892e-02\n",
      " 2.48914540e-01 1.15421079e+01], Loss = 0.3760\n",
      "Iteration 5538: Weights = [5.50000000e+01 3.55569413e+00 7.47590383e+00 2.46306821e-02\n",
      " 2.48907395e-01 1.15423347e+01], Loss = 0.3760\n",
      "Iteration 5539: Weights = [5.50000000e+01 3.55559206e+00 7.47568923e+00 2.46299751e-02\n",
      " 2.48900249e-01 1.15425614e+01], Loss = 0.3760\n",
      "Iteration 5540: Weights = [5.50000000e+01 3.55548999e+00 7.47547463e+00 2.46292680e-02\n",
      " 2.48893104e-01 1.15427881e+01], Loss = 0.3760\n",
      "Iteration 5541: Weights = [5.50000000e+01 3.55538792e+00 7.47526003e+00 2.46285610e-02\n",
      " 2.48885960e-01 1.15430148e+01], Loss = 0.3759\n",
      "Iteration 5542: Weights = [5.50000000e+01 3.55528586e+00 7.47504545e+00 2.46278540e-02\n",
      " 2.48878815e-01 1.15432415e+01], Loss = 0.3759\n",
      "Iteration 5543: Weights = [5.50000000e+01 3.55518380e+00 7.47483087e+00 2.46271470e-02\n",
      " 2.48871671e-01 1.15434682e+01], Loss = 0.3759\n",
      "Iteration 5544: Weights = [5.50000000e+01 3.55508175e+00 7.47461629e+00 2.46264401e-02\n",
      " 2.48864526e-01 1.15436949e+01], Loss = 0.3759\n",
      "Iteration 5545: Weights = [5.50000000e+01 3.55497969e+00 7.47440172e+00 2.46257331e-02\n",
      " 2.48857382e-01 1.15439216e+01], Loss = 0.3759\n",
      "Iteration 5546: Weights = [5.50000000e+01 3.55487764e+00 7.47418716e+00 2.46250262e-02\n",
      " 2.48850239e-01 1.15441483e+01], Loss = 0.3758\n",
      "Iteration 5547: Weights = [5.50000000e+01 3.55477560e+00 7.47397260e+00 2.46243193e-02\n",
      " 2.48843095e-01 1.15443750e+01], Loss = 0.3758\n",
      "Iteration 5548: Weights = [5.50000000e+01 3.55467355e+00 7.47375805e+00 2.46236125e-02\n",
      " 2.48835952e-01 1.15446016e+01], Loss = 0.3758\n",
      "Iteration 5549: Weights = [5.50000000e+01 3.55457151e+00 7.47354351e+00 2.46229056e-02\n",
      " 2.48828809e-01 1.15448283e+01], Loss = 0.3758\n",
      "Iteration 5550: Weights = [5.50000000e+01 3.55446947e+00 7.47332897e+00 2.46221988e-02\n",
      " 2.48821666e-01 1.15450550e+01], Loss = 0.3757\n",
      "Iteration 5551: Weights = [5.50000000e+01 3.55436743e+00 7.47311444e+00 2.46214920e-02\n",
      " 2.48814523e-01 1.15452816e+01], Loss = 0.3757\n",
      "Iteration 5552: Weights = [5.50000000e+01 3.55426540e+00 7.47289992e+00 2.46207852e-02\n",
      " 2.48807380e-01 1.15455083e+01], Loss = 0.3757\n",
      "Iteration 5553: Weights = [5.50000000e+01 3.55416337e+00 7.47268540e+00 2.46200784e-02\n",
      " 2.48800238e-01 1.15457349e+01], Loss = 0.3757\n",
      "Iteration 5554: Weights = [5.50000000e+01 3.55406135e+00 7.47247088e+00 2.46193717e-02\n",
      " 2.48793096e-01 1.15459615e+01], Loss = 0.3757\n",
      "Iteration 5555: Weights = [5.50000000e+01 3.55395932e+00 7.47225638e+00 2.46186649e-02\n",
      " 2.48785954e-01 1.15461881e+01], Loss = 0.3756\n",
      "Iteration 5556: Weights = [5.50000000e+01 3.55385730e+00 7.47204187e+00 2.46179582e-02\n",
      " 2.48778812e-01 1.15464148e+01], Loss = 0.3756\n",
      "Iteration 5557: Weights = [5.50000000e+01 3.55375528e+00 7.47182738e+00 2.46172515e-02\n",
      " 2.48771671e-01 1.15466414e+01], Loss = 0.3756\n",
      "Iteration 5558: Weights = [5.50000000e+01 3.55365327e+00 7.47161289e+00 2.46165448e-02\n",
      " 2.48764529e-01 1.15468680e+01], Loss = 0.3756\n",
      "Iteration 5559: Weights = [5.50000000e+01 3.55355125e+00 7.47139841e+00 2.46158382e-02\n",
      " 2.48757388e-01 1.15470946e+01], Loss = 0.3756\n",
      "Iteration 5560: Weights = [5.50000000e+01 3.55344925e+00 7.47118393e+00 2.46151316e-02\n",
      " 2.48750247e-01 1.15473212e+01], Loss = 0.3755\n",
      "Iteration 5561: Weights = [5.50000000e+01 3.55334724e+00 7.47096946e+00 2.46144250e-02\n",
      " 2.48743107e-01 1.15475477e+01], Loss = 0.3755\n",
      "Iteration 5562: Weights = [5.50000000e+01 3.55324524e+00 7.47075500e+00 2.46137184e-02\n",
      " 2.48735966e-01 1.15477743e+01], Loss = 0.3755\n",
      "Iteration 5563: Weights = [5.50000000e+01 3.55314324e+00 7.47054054e+00 2.46130118e-02\n",
      " 2.48728826e-01 1.15480009e+01], Loss = 0.3755\n",
      "Iteration 5564: Weights = [5.50000000e+01 3.55304124e+00 7.47032609e+00 2.46123053e-02\n",
      " 2.48721686e-01 1.15482275e+01], Loss = 0.3754\n",
      "Iteration 5565: Weights = [5.50000000e+01 3.55293924e+00 7.47011164e+00 2.46115987e-02\n",
      " 2.48714546e-01 1.15484540e+01], Loss = 0.3754\n",
      "Iteration 5566: Weights = [5.50000000e+01 3.55283725e+00 7.46989720e+00 2.46108922e-02\n",
      " 2.48707406e-01 1.15486806e+01], Loss = 0.3754\n",
      "Iteration 5567: Weights = [5.50000000e+01 3.55273526e+00 7.46968277e+00 2.46101857e-02\n",
      " 2.48700267e-01 1.15489071e+01], Loss = 0.3754\n",
      "Iteration 5568: Weights = [5.50000000e+01 3.55263328e+00 7.46946834e+00 2.46094793e-02\n",
      " 2.48693127e-01 1.15491337e+01], Loss = 0.3754\n",
      "Iteration 5569: Weights = [5.50000000e+01 3.55253129e+00 7.46925392e+00 2.46087728e-02\n",
      " 2.48685988e-01 1.15493602e+01], Loss = 0.3753\n",
      "Iteration 5570: Weights = [5.50000000e+01 3.55242931e+00 7.46903951e+00 2.46080664e-02\n",
      " 2.48678849e-01 1.15495867e+01], Loss = 0.3753\n",
      "Iteration 5571: Weights = [5.50000000e+01 3.55232734e+00 7.46882510e+00 2.46073600e-02\n",
      " 2.48671711e-01 1.15498132e+01], Loss = 0.3753\n",
      "Iteration 5572: Weights = [5.50000000e+01 3.55222536e+00 7.46861070e+00 2.46066536e-02\n",
      " 2.48664572e-01 1.15500397e+01], Loss = 0.3753\n",
      "Iteration 5573: Weights = [5.50000000e+01 3.55212339e+00 7.46839630e+00 2.46059472e-02\n",
      " 2.48657434e-01 1.15502663e+01], Loss = 0.3752\n",
      "Iteration 5574: Weights = [5.50000000e+01 3.55202142e+00 7.46818191e+00 2.46052409e-02\n",
      " 2.48650296e-01 1.15504928e+01], Loss = 0.3752\n",
      "Iteration 5575: Weights = [5.50000000e+01 3.55191946e+00 7.46796753e+00 2.46045346e-02\n",
      " 2.48643158e-01 1.15507192e+01], Loss = 0.3752\n",
      "Iteration 5576: Weights = [5.50000000e+01 3.55181749e+00 7.46775315e+00 2.46038282e-02\n",
      " 2.48636021e-01 1.15509457e+01], Loss = 0.3752\n",
      "Iteration 5577: Weights = [5.50000000e+01 3.55171553e+00 7.46753878e+00 2.46031220e-02\n",
      " 2.48628883e-01 1.15511722e+01], Loss = 0.3752\n",
      "Iteration 5578: Weights = [5.50000000e+01 3.55161358e+00 7.46732441e+00 2.46024157e-02\n",
      " 2.48621746e-01 1.15513987e+01], Loss = 0.3751\n",
      "Iteration 5579: Weights = [5.50000000e+01 3.55151162e+00 7.46711005e+00 2.46017095e-02\n",
      " 2.48614609e-01 1.15516252e+01], Loss = 0.3751\n",
      "Iteration 5580: Weights = [5.50000000e+01 3.55140967e+00 7.46689570e+00 2.46010032e-02\n",
      " 2.48607472e-01 1.15518516e+01], Loss = 0.3751\n",
      "Iteration 5581: Weights = [5.50000000e+01 3.55130773e+00 7.46668135e+00 2.46002970e-02\n",
      " 2.48600336e-01 1.15520781e+01], Loss = 0.3751\n",
      "Iteration 5582: Weights = [5.50000000e+01 3.55120578e+00 7.46646701e+00 2.45995908e-02\n",
      " 2.48593199e-01 1.15523045e+01], Loss = 0.3751\n",
      "Iteration 5583: Weights = [5.50000000e+01 3.55110384e+00 7.46625268e+00 2.45988847e-02\n",
      " 2.48586063e-01 1.15525310e+01], Loss = 0.3750\n",
      "Iteration 5584: Weights = [5.50000000e+01 3.55100190e+00 7.46603835e+00 2.45981785e-02\n",
      " 2.48578927e-01 1.15527574e+01], Loss = 0.3750\n",
      "Iteration 5585: Weights = [5.50000000e+01 3.55089996e+00 7.46582403e+00 2.45974724e-02\n",
      " 2.48571791e-01 1.15529838e+01], Loss = 0.3750\n",
      "Iteration 5586: Weights = [5.50000000e+01 3.55079803e+00 7.46560971e+00 2.45967663e-02\n",
      " 2.48564656e-01 1.15532102e+01], Loss = 0.3750\n",
      "Iteration 5587: Weights = [5.50000000e+01 3.55069610e+00 7.46539540e+00 2.45960602e-02\n",
      " 2.48557520e-01 1.15534367e+01], Loss = 0.3749\n",
      "Iteration 5588: Weights = [5.50000000e+01 3.55059417e+00 7.46518110e+00 2.45953542e-02\n",
      " 2.48550385e-01 1.15536631e+01], Loss = 0.3749\n",
      "Iteration 5589: Weights = [5.50000000e+01 3.55049225e+00 7.46496680e+00 2.45946481e-02\n",
      " 2.48543250e-01 1.15538895e+01], Loss = 0.3749\n",
      "Iteration 5590: Weights = [5.50000000e+01 3.55039033e+00 7.46475251e+00 2.45939421e-02\n",
      " 2.48536115e-01 1.15541159e+01], Loss = 0.3749\n",
      "Iteration 5591: Weights = [5.50000000e+01 3.55028841e+00 7.46453822e+00 2.45932361e-02\n",
      " 2.48528981e-01 1.15543423e+01], Loss = 0.3749\n",
      "Iteration 5592: Weights = [5.50000000e+01 3.55018649e+00 7.46432394e+00 2.45925301e-02\n",
      " 2.48521846e-01 1.15545686e+01], Loss = 0.3748\n",
      "Iteration 5593: Weights = [5.50000000e+01 3.55008458e+00 7.46410967e+00 2.45918242e-02\n",
      " 2.48514712e-01 1.15547950e+01], Loss = 0.3748\n",
      "Iteration 5594: Weights = [5.50000000e+01 3.54998267e+00 7.46389540e+00 2.45911182e-02\n",
      " 2.48507578e-01 1.15550214e+01], Loss = 0.3748\n",
      "Iteration 5595: Weights = [5.50000000e+01 3.54988076e+00 7.46368114e+00 2.45904123e-02\n",
      " 2.48500445e-01 1.15552477e+01], Loss = 0.3748\n",
      "Iteration 5596: Weights = [5.50000000e+01 3.54977886e+00 7.46346689e+00 2.45897064e-02\n",
      " 2.48493311e-01 1.15554741e+01], Loss = 0.3748\n",
      "Iteration 5597: Weights = [5.50000000e+01 3.54967696e+00 7.46325264e+00 2.45890005e-02\n",
      " 2.48486178e-01 1.15557005e+01], Loss = 0.3747\n",
      "Iteration 5598: Weights = [5.50000000e+01 3.54957506e+00 7.46303840e+00 2.45882947e-02\n",
      " 2.48479045e-01 1.15559268e+01], Loss = 0.3747\n",
      "Iteration 5599: Weights = [5.50000000e+01 3.54947316e+00 7.46282416e+00 2.45875888e-02\n",
      " 2.48471912e-01 1.15561531e+01], Loss = 0.3747\n",
      "Iteration 5600: Weights = [5.50000000e+01 3.54937127e+00 7.46260993e+00 2.45868830e-02\n",
      " 2.48464779e-01 1.15563795e+01], Loss = 0.3747\n",
      "Iteration 5601: Weights = [5.50000000e+01 3.54926938e+00 7.46239570e+00 2.45861772e-02\n",
      " 2.48457647e-01 1.15566058e+01], Loss = 0.3746\n",
      "Iteration 5602: Weights = [5.50000000e+01 3.54916750e+00 7.46218149e+00 2.45854714e-02\n",
      " 2.48450514e-01 1.15568321e+01], Loss = 0.3746\n",
      "Iteration 5603: Weights = [5.50000000e+01 3.54906561e+00 7.46196728e+00 2.45847657e-02\n",
      " 2.48443382e-01 1.15570584e+01], Loss = 0.3746\n",
      "Iteration 5604: Weights = [5.50000000e+01 3.54896373e+00 7.46175307e+00 2.45840599e-02\n",
      " 2.48436250e-01 1.15572847e+01], Loss = 0.3746\n",
      "Iteration 5605: Weights = [5.50000000e+01 3.54886185e+00 7.46153887e+00 2.45833542e-02\n",
      " 2.48429119e-01 1.15575110e+01], Loss = 0.3746\n",
      "Iteration 5606: Weights = [5.50000000e+01 3.54875998e+00 7.46132468e+00 2.45826485e-02\n",
      " 2.48421987e-01 1.15577373e+01], Loss = 0.3745\n",
      "Iteration 5607: Weights = [5.50000000e+01 3.54865811e+00 7.46111049e+00 2.45819428e-02\n",
      " 2.48414856e-01 1.15579636e+01], Loss = 0.3745\n",
      "Iteration 5608: Weights = [5.50000000e+01 3.54855624e+00 7.46089631e+00 2.45812372e-02\n",
      " 2.48407725e-01 1.15581899e+01], Loss = 0.3745\n",
      "Iteration 5609: Weights = [5.50000000e+01 3.54845437e+00 7.46068213e+00 2.45805315e-02\n",
      " 2.48400594e-01 1.15584161e+01], Loss = 0.3745\n",
      "Iteration 5610: Weights = [5.50000000e+01 3.54835251e+00 7.46046797e+00 2.45798259e-02\n",
      " 2.48393463e-01 1.15586424e+01], Loss = 0.3745\n",
      "Iteration 5611: Weights = [5.50000000e+01 3.54825065e+00 7.46025380e+00 2.45791203e-02\n",
      " 2.48386333e-01 1.15588687e+01], Loss = 0.3744\n",
      "Iteration 5612: Weights = [5.50000000e+01 3.54814879e+00 7.46003965e+00 2.45784148e-02\n",
      " 2.48379202e-01 1.15590949e+01], Loss = 0.3744\n",
      "Iteration 5613: Weights = [5.50000000e+01 3.54804694e+00 7.45982550e+00 2.45777092e-02\n",
      " 2.48372072e-01 1.15593212e+01], Loss = 0.3744\n",
      "Iteration 5614: Weights = [5.50000000e+01 3.54794509e+00 7.45961135e+00 2.45770037e-02\n",
      " 2.48364943e-01 1.15595474e+01], Loss = 0.3744\n",
      "Iteration 5615: Weights = [5.50000000e+01 3.54784324e+00 7.45939721e+00 2.45762981e-02\n",
      " 2.48357813e-01 1.15597736e+01], Loss = 0.3743\n",
      "Iteration 5616: Weights = [5.50000000e+01 3.54774139e+00 7.45918308e+00 2.45755927e-02\n",
      " 2.48350683e-01 1.15599999e+01], Loss = 0.3743\n",
      "Iteration 5617: Weights = [5.50000000e+01 3.54763955e+00 7.45896896e+00 2.45748872e-02\n",
      " 2.48343554e-01 1.15602261e+01], Loss = 0.3743\n",
      "Iteration 5618: Weights = [5.50000000e+01 3.54753771e+00 7.45875484e+00 2.45741817e-02\n",
      " 2.48336425e-01 1.15604523e+01], Loss = 0.3743\n",
      "Iteration 5619: Weights = [5.50000000e+01 3.54743587e+00 7.45854072e+00 2.45734763e-02\n",
      " 2.48329296e-01 1.15606785e+01], Loss = 0.3743\n",
      "Iteration 5620: Weights = [5.50000000e+01 3.54733404e+00 7.45832662e+00 2.45727709e-02\n",
      " 2.48322168e-01 1.15609047e+01], Loss = 0.3742\n",
      "Iteration 5621: Weights = [5.50000000e+01 3.54723221e+00 7.45811252e+00 2.45720655e-02\n",
      " 2.48315039e-01 1.15611309e+01], Loss = 0.3742\n",
      "Iteration 5622: Weights = [5.50000000e+01 3.54713038e+00 7.45789842e+00 2.45713601e-02\n",
      " 2.48307911e-01 1.15613571e+01], Loss = 0.3742\n",
      "Iteration 5623: Weights = [5.50000000e+01 3.54702856e+00 7.45768433e+00 2.45706548e-02\n",
      " 2.48300783e-01 1.15615833e+01], Loss = 0.3742\n",
      "Iteration 5624: Weights = [5.50000000e+01 3.54692673e+00 7.45747025e+00 2.45699494e-02\n",
      " 2.48293655e-01 1.15618095e+01], Loss = 0.3742\n",
      "Iteration 5625: Weights = [5.50000000e+01 3.54682492e+00 7.45725617e+00 2.45692441e-02\n",
      " 2.48286528e-01 1.15620356e+01], Loss = 0.3741\n",
      "Iteration 5626: Weights = [5.50000000e+01 3.54672310e+00 7.45704210e+00 2.45685388e-02\n",
      " 2.48279400e-01 1.15622618e+01], Loss = 0.3741\n",
      "Iteration 5627: Weights = [5.50000000e+01 3.54662129e+00 7.45682804e+00 2.45678335e-02\n",
      " 2.48272273e-01 1.15624879e+01], Loss = 0.3741\n",
      "Iteration 5628: Weights = [5.50000000e+01 3.54651948e+00 7.45661398e+00 2.45671283e-02\n",
      " 2.48265146e-01 1.15627141e+01], Loss = 0.3741\n",
      "Iteration 5629: Weights = [5.50000000e+01 3.54641767e+00 7.45639993e+00 2.45664231e-02\n",
      " 2.48258019e-01 1.15629402e+01], Loss = 0.3740\n",
      "Iteration 5630: Weights = [5.50000000e+01 3.54631586e+00 7.45618588e+00 2.45657179e-02\n",
      " 2.48250893e-01 1.15631664e+01], Loss = 0.3740\n",
      "Iteration 5631: Weights = [5.50000000e+01 3.54621406e+00 7.45597184e+00 2.45650127e-02\n",
      " 2.48243767e-01 1.15633925e+01], Loss = 0.3740\n",
      "Iteration 5632: Weights = [5.50000000e+01 3.54611226e+00 7.45575781e+00 2.45643075e-02\n",
      " 2.48236640e-01 1.15636186e+01], Loss = 0.3740\n",
      "Iteration 5633: Weights = [5.50000000e+01 3.54601047e+00 7.45554378e+00 2.45636023e-02\n",
      " 2.48229514e-01 1.15638447e+01], Loss = 0.3740\n",
      "Iteration 5634: Weights = [5.50000000e+01 3.54590867e+00 7.45532976e+00 2.45628972e-02\n",
      " 2.48222389e-01 1.15640708e+01], Loss = 0.3739\n",
      "Iteration 5635: Weights = [5.50000000e+01 3.54580688e+00 7.45511575e+00 2.45621921e-02\n",
      " 2.48215263e-01 1.15642969e+01], Loss = 0.3739\n",
      "Iteration 5636: Weights = [5.50000000e+01 3.54570510e+00 7.45490174e+00 2.45614870e-02\n",
      " 2.48208138e-01 1.15645230e+01], Loss = 0.3739\n",
      "Iteration 5637: Weights = [5.50000000e+01 3.54560331e+00 7.45468774e+00 2.45607819e-02\n",
      " 2.48201013e-01 1.15647491e+01], Loss = 0.3739\n",
      "Iteration 5638: Weights = [5.50000000e+01 3.54550153e+00 7.45447374e+00 2.45600769e-02\n",
      " 2.48193888e-01 1.15649752e+01], Loss = 0.3739\n",
      "Iteration 5639: Weights = [5.50000000e+01 3.54539975e+00 7.45425975e+00 2.45593719e-02\n",
      " 2.48186763e-01 1.15652013e+01], Loss = 0.3738\n",
      "Iteration 5640: Weights = [5.50000000e+01 3.54529798e+00 7.45404576e+00 2.45586669e-02\n",
      " 2.48179638e-01 1.15654274e+01], Loss = 0.3738\n",
      "Iteration 5641: Weights = [5.50000000e+01 3.54519621e+00 7.45383179e+00 2.45579619e-02\n",
      " 2.48172514e-01 1.15656534e+01], Loss = 0.3738\n",
      "Iteration 5642: Weights = [5.50000000e+01 3.54509444e+00 7.45361781e+00 2.45572569e-02\n",
      " 2.48165390e-01 1.15658795e+01], Loss = 0.3738\n",
      "Iteration 5643: Weights = [5.50000000e+01 3.54499267e+00 7.45340385e+00 2.45565519e-02\n",
      " 2.48158266e-01 1.15661055e+01], Loss = 0.3737\n",
      "Iteration 5644: Weights = [5.50000000e+01 3.54489091e+00 7.45318989e+00 2.45558470e-02\n",
      " 2.48151142e-01 1.15663316e+01], Loss = 0.3737\n",
      "Iteration 5645: Weights = [5.50000000e+01 3.54478915e+00 7.45297593e+00 2.45551421e-02\n",
      " 2.48144019e-01 1.15665576e+01], Loss = 0.3737\n",
      "Iteration 5646: Weights = [5.50000000e+01 3.54468739e+00 7.45276199e+00 2.45544372e-02\n",
      " 2.48136896e-01 1.15667837e+01], Loss = 0.3737\n",
      "Iteration 5647: Weights = [5.50000000e+01 3.54458563e+00 7.45254805e+00 2.45537324e-02\n",
      " 2.48129772e-01 1.15670097e+01], Loss = 0.3737\n",
      "Iteration 5648: Weights = [5.50000000e+01 3.54448388e+00 7.45233411e+00 2.45530275e-02\n",
      " 2.48122650e-01 1.15672357e+01], Loss = 0.3736\n",
      "Iteration 5649: Weights = [5.50000000e+01 3.54438213e+00 7.45212018e+00 2.45523227e-02\n",
      " 2.48115527e-01 1.15674617e+01], Loss = 0.3736\n",
      "Iteration 5650: Weights = [5.50000000e+01 3.54428039e+00 7.45190626e+00 2.45516179e-02\n",
      " 2.48108404e-01 1.15676877e+01], Loss = 0.3736\n",
      "Iteration 5651: Weights = [5.50000000e+01 3.54417864e+00 7.45169234e+00 2.45509131e-02\n",
      " 2.48101282e-01 1.15679137e+01], Loss = 0.3736\n",
      "Iteration 5652: Weights = [5.50000000e+01 3.54407690e+00 7.45147843e+00 2.45502083e-02\n",
      " 2.48094160e-01 1.15681397e+01], Loss = 0.3736\n",
      "Iteration 5653: Weights = [5.50000000e+01 3.54397517e+00 7.45126453e+00 2.45495036e-02\n",
      " 2.48087038e-01 1.15683657e+01], Loss = 0.3735\n",
      "Iteration 5654: Weights = [5.50000000e+01 3.54387343e+00 7.45105063e+00 2.45487989e-02\n",
      " 2.48079917e-01 1.15685917e+01], Loss = 0.3735\n",
      "Iteration 5655: Weights = [5.50000000e+01 3.54377170e+00 7.45083674e+00 2.45480941e-02\n",
      " 2.48072795e-01 1.15688177e+01], Loss = 0.3735\n",
      "Iteration 5656: Weights = [5.50000000e+01 3.54366997e+00 7.45062285e+00 2.45473895e-02\n",
      " 2.48065674e-01 1.15690436e+01], Loss = 0.3735\n",
      "Iteration 5657: Weights = [5.50000000e+01 3.54356824e+00 7.45040897e+00 2.45466848e-02\n",
      " 2.48058553e-01 1.15692696e+01], Loss = 0.3734\n",
      "Iteration 5658: Weights = [5.50000000e+01 3.54346652e+00 7.45019510e+00 2.45459802e-02\n",
      " 2.48051432e-01 1.15694955e+01], Loss = 0.3734\n",
      "Iteration 5659: Weights = [5.50000000e+01 3.54336480e+00 7.44998123e+00 2.45452755e-02\n",
      " 2.48044311e-01 1.15697215e+01], Loss = 0.3734\n",
      "Iteration 5660: Weights = [5.50000000e+01 3.54326309e+00 7.44976737e+00 2.45445709e-02\n",
      " 2.48037191e-01 1.15699474e+01], Loss = 0.3734\n",
      "Iteration 5661: Weights = [5.50000000e+01 3.54316137e+00 7.44955351e+00 2.45438663e-02\n",
      " 2.48030071e-01 1.15701734e+01], Loss = 0.3734\n",
      "Iteration 5662: Weights = [5.50000000e+01 3.54305966e+00 7.44933966e+00 2.45431618e-02\n",
      " 2.48022951e-01 1.15703993e+01], Loss = 0.3733\n",
      "Iteration 5663: Weights = [5.50000000e+01 3.54295795e+00 7.44912582e+00 2.45424572e-02\n",
      " 2.48015831e-01 1.15706252e+01], Loss = 0.3733\n",
      "Iteration 5664: Weights = [5.50000000e+01 3.54285625e+00 7.44891198e+00 2.45417527e-02\n",
      " 2.48008711e-01 1.15708511e+01], Loss = 0.3733\n",
      "Iteration 5665: Weights = [5.50000000e+01 3.54275454e+00 7.44869815e+00 2.45410482e-02\n",
      " 2.48001592e-01 1.15710770e+01], Loss = 0.3733\n",
      "Iteration 5666: Weights = [5.50000000e+01 3.54265285e+00 7.44848433e+00 2.45403437e-02\n",
      " 2.47994473e-01 1.15713029e+01], Loss = 0.3733\n",
      "Iteration 5667: Weights = [5.50000000e+01 3.54255115e+00 7.44827051e+00 2.45396393e-02\n",
      " 2.47987354e-01 1.15715288e+01], Loss = 0.3732\n",
      "Iteration 5668: Weights = [5.50000000e+01 3.54244946e+00 7.44805670e+00 2.45389348e-02\n",
      " 2.47980235e-01 1.15717547e+01], Loss = 0.3732\n",
      "Iteration 5669: Weights = [5.50000000e+01 3.54234776e+00 7.44784289e+00 2.45382304e-02\n",
      " 2.47973116e-01 1.15719806e+01], Loss = 0.3732\n",
      "Iteration 5670: Weights = [5.50000000e+01 3.54224608e+00 7.44762909e+00 2.45375260e-02\n",
      " 2.47965998e-01 1.15722065e+01], Loss = 0.3732\n",
      "Iteration 5671: Weights = [5.50000000e+01 3.54214439e+00 7.44741530e+00 2.45368216e-02\n",
      " 2.47958880e-01 1.15724323e+01], Loss = 0.3731\n",
      "Iteration 5672: Weights = [5.50000000e+01 3.54204271e+00 7.44720151e+00 2.45361172e-02\n",
      " 2.47951762e-01 1.15726582e+01], Loss = 0.3731\n",
      "Iteration 5673: Weights = [5.50000000e+01 3.54194103e+00 7.44698773e+00 2.45354129e-02\n",
      " 2.47944644e-01 1.15728841e+01], Loss = 0.3731\n",
      "Iteration 5674: Weights = [5.50000000e+01 3.54183936e+00 7.44677395e+00 2.45347086e-02\n",
      " 2.47937526e-01 1.15731099e+01], Loss = 0.3731\n",
      "Iteration 5675: Weights = [5.50000000e+01 3.54173768e+00 7.44656018e+00 2.45340043e-02\n",
      " 2.47930409e-01 1.15733358e+01], Loss = 0.3731\n",
      "Iteration 5676: Weights = [5.50000000e+01 3.54163601e+00 7.44634642e+00 2.45333000e-02\n",
      " 2.47923292e-01 1.15735616e+01], Loss = 0.3730\n",
      "Iteration 5677: Weights = [5.50000000e+01 3.54153434e+00 7.44613266e+00 2.45325957e-02\n",
      " 2.47916175e-01 1.15737874e+01], Loss = 0.3730\n",
      "Iteration 5678: Weights = [5.50000000e+01 3.54143268e+00 7.44591891e+00 2.45318915e-02\n",
      " 2.47909058e-01 1.15740133e+01], Loss = 0.3730\n",
      "Iteration 5679: Weights = [5.50000000e+01 3.54133102e+00 7.44570517e+00 2.45311873e-02\n",
      " 2.47901941e-01 1.15742391e+01], Loss = 0.3730\n",
      "Iteration 5680: Weights = [5.50000000e+01 3.54122936e+00 7.44549143e+00 2.45304831e-02\n",
      " 2.47894825e-01 1.15744649e+01], Loss = 0.3730\n",
      "Iteration 5681: Weights = [5.50000000e+01 3.54112770e+00 7.44527770e+00 2.45297789e-02\n",
      " 2.47887709e-01 1.15746907e+01], Loss = 0.3729\n",
      "Iteration 5682: Weights = [5.50000000e+01 3.54102605e+00 7.44506397e+00 2.45290747e-02\n",
      " 2.47880593e-01 1.15749165e+01], Loss = 0.3729\n",
      "Iteration 5683: Weights = [5.50000000e+01 3.54092440e+00 7.44485025e+00 2.45283706e-02\n",
      " 2.47873477e-01 1.15751423e+01], Loss = 0.3729\n",
      "Iteration 5684: Weights = [5.50000000e+01 3.54082276e+00 7.44463653e+00 2.45276665e-02\n",
      " 2.47866362e-01 1.15753681e+01], Loss = 0.3729\n",
      "Iteration 5685: Weights = [5.50000000e+01 3.54072111e+00 7.44442283e+00 2.45269624e-02\n",
      " 2.47859246e-01 1.15755938e+01], Loss = 0.3728\n",
      "Iteration 5686: Weights = [5.50000000e+01 3.54061947e+00 7.44420912e+00 2.45262583e-02\n",
      " 2.47852131e-01 1.15758196e+01], Loss = 0.3728\n",
      "Iteration 5687: Weights = [5.50000000e+01 3.54051783e+00 7.44399543e+00 2.45255543e-02\n",
      " 2.47845016e-01 1.15760454e+01], Loss = 0.3728\n",
      "Iteration 5688: Weights = [5.50000000e+01 3.54041620e+00 7.44378174e+00 2.45248502e-02\n",
      " 2.47837902e-01 1.15762711e+01], Loss = 0.3728\n",
      "Iteration 5689: Weights = [5.50000000e+01 3.54031456e+00 7.44356806e+00 2.45241462e-02\n",
      " 2.47830787e-01 1.15764969e+01], Loss = 0.3728\n",
      "Iteration 5690: Weights = [5.50000000e+01 3.54021294e+00 7.44335438e+00 2.45234422e-02\n",
      " 2.47823673e-01 1.15767226e+01], Loss = 0.3727\n",
      "Iteration 5691: Weights = [5.50000000e+01 3.54011131e+00 7.44314071e+00 2.45227382e-02\n",
      " 2.47816559e-01 1.15769484e+01], Loss = 0.3727\n",
      "Iteration 5692: Weights = [5.50000000e+01 3.54000969e+00 7.44292704e+00 2.45220343e-02\n",
      " 2.47809445e-01 1.15771741e+01], Loss = 0.3727\n",
      "Iteration 5693: Weights = [5.50000000e+01 3.53990806e+00 7.44271338e+00 2.45213303e-02\n",
      " 2.47802331e-01 1.15773998e+01], Loss = 0.3727\n",
      "Iteration 5694: Weights = [5.50000000e+01 3.53980645e+00 7.44249973e+00 2.45206264e-02\n",
      " 2.47795218e-01 1.15776256e+01], Loss = 0.3727\n",
      "Iteration 5695: Weights = [5.50000000e+01 3.53970483e+00 7.44228608e+00 2.45199225e-02\n",
      " 2.47788104e-01 1.15778513e+01], Loss = 0.3726\n",
      "Iteration 5696: Weights = [5.50000000e+01 3.53960322e+00 7.44207244e+00 2.45192186e-02\n",
      " 2.47780991e-01 1.15780770e+01], Loss = 0.3726\n",
      "Iteration 5697: Weights = [5.50000000e+01 3.53950161e+00 7.44185881e+00 2.45185148e-02\n",
      " 2.47773878e-01 1.15783027e+01], Loss = 0.3726\n",
      "Iteration 5698: Weights = [5.50000000e+01 3.53940001e+00 7.44164518e+00 2.45178109e-02\n",
      " 2.47766766e-01 1.15785284e+01], Loss = 0.3726\n",
      "Iteration 5699: Weights = [5.50000000e+01 3.53929840e+00 7.44143156e+00 2.45171071e-02\n",
      " 2.47759653e-01 1.15787541e+01], Loss = 0.3725\n",
      "Iteration 5700: Weights = [5.50000000e+01 3.53919680e+00 7.44121794e+00 2.45164033e-02\n",
      " 2.47752541e-01 1.15789798e+01], Loss = 0.3725\n",
      "Iteration 5701: Weights = [5.50000000e+01 3.53909520e+00 7.44100433e+00 2.45156996e-02\n",
      " 2.47745429e-01 1.15792054e+01], Loss = 0.3725\n",
      "Iteration 5702: Weights = [5.50000000e+01 3.53899361e+00 7.44079073e+00 2.45149958e-02\n",
      " 2.47738317e-01 1.15794311e+01], Loss = 0.3725\n",
      "Iteration 5703: Weights = [5.50000000e+01 3.53889202e+00 7.44057713e+00 2.45142921e-02\n",
      " 2.47731205e-01 1.15796568e+01], Loss = 0.3725\n",
      "Iteration 5704: Weights = [5.50000000e+01 3.53879043e+00 7.44036354e+00 2.45135884e-02\n",
      " 2.47724094e-01 1.15798824e+01], Loss = 0.3724\n",
      "Iteration 5705: Weights = [5.50000000e+01 3.53868884e+00 7.44014995e+00 2.45128847e-02\n",
      " 2.47716983e-01 1.15801081e+01], Loss = 0.3724\n",
      "Iteration 5706: Weights = [5.50000000e+01 3.53858726e+00 7.43993637e+00 2.45121810e-02\n",
      " 2.47709872e-01 1.15803337e+01], Loss = 0.3724\n",
      "Iteration 5707: Weights = [5.50000000e+01 3.53848568e+00 7.43972280e+00 2.45114773e-02\n",
      " 2.47702761e-01 1.15805593e+01], Loss = 0.3724\n",
      "Iteration 5708: Weights = [5.50000000e+01 3.53838411e+00 7.43950923e+00 2.45107737e-02\n",
      " 2.47695650e-01 1.15807850e+01], Loss = 0.3724\n",
      "Iteration 5709: Weights = [5.50000000e+01 3.53828253e+00 7.43929567e+00 2.45100701e-02\n",
      " 2.47688540e-01 1.15810106e+01], Loss = 0.3723\n",
      "Iteration 5710: Weights = [5.50000000e+01 3.53818096e+00 7.43908212e+00 2.45093665e-02\n",
      " 2.47681429e-01 1.15812362e+01], Loss = 0.3723\n",
      "Iteration 5711: Weights = [5.50000000e+01 3.53807939e+00 7.43886857e+00 2.45086629e-02\n",
      " 2.47674319e-01 1.15814618e+01], Loss = 0.3723\n",
      "Iteration 5712: Weights = [5.50000000e+01 3.53797783e+00 7.43865503e+00 2.45079594e-02\n",
      " 2.47667210e-01 1.15816874e+01], Loss = 0.3723\n",
      "Iteration 5713: Weights = [5.50000000e+01 3.53787626e+00 7.43844149e+00 2.45072558e-02\n",
      " 2.47660100e-01 1.15819130e+01], Loss = 0.3722\n",
      "Iteration 5714: Weights = [5.50000000e+01 3.53777471e+00 7.43822796e+00 2.45065523e-02\n",
      " 2.47652991e-01 1.15821386e+01], Loss = 0.3722\n",
      "Iteration 5715: Weights = [5.50000000e+01 3.53767315e+00 7.43801444e+00 2.45058488e-02\n",
      " 2.47645881e-01 1.15823642e+01], Loss = 0.3722\n",
      "Iteration 5716: Weights = [5.50000000e+01 3.53757160e+00 7.43780092e+00 2.45051453e-02\n",
      " 2.47638772e-01 1.15825898e+01], Loss = 0.3722\n",
      "Iteration 5717: Weights = [5.50000000e+01 3.53747004e+00 7.43758741e+00 2.45044419e-02\n",
      " 2.47631664e-01 1.15828154e+01], Loss = 0.3722\n",
      "Iteration 5718: Weights = [5.50000000e+01 3.53736850e+00 7.43737390e+00 2.45037385e-02\n",
      " 2.47624555e-01 1.15830409e+01], Loss = 0.3721\n",
      "Iteration 5719: Weights = [5.50000000e+01 3.53726695e+00 7.43716040e+00 2.45030351e-02\n",
      " 2.47617447e-01 1.15832665e+01], Loss = 0.3721\n",
      "Iteration 5720: Weights = [5.50000000e+01 3.53716541e+00 7.43694691e+00 2.45023317e-02\n",
      " 2.47610338e-01 1.15834920e+01], Loss = 0.3721\n",
      "Iteration 5721: Weights = [5.50000000e+01 3.53706387e+00 7.43673342e+00 2.45016283e-02\n",
      " 2.47603231e-01 1.15837176e+01], Loss = 0.3721\n",
      "Iteration 5722: Weights = [5.50000000e+01 3.53696234e+00 7.43651994e+00 2.45009249e-02\n",
      " 2.47596123e-01 1.15839431e+01], Loss = 0.3721\n",
      "Iteration 5723: Weights = [5.50000000e+01 3.53686080e+00 7.43630647e+00 2.45002216e-02\n",
      " 2.47589015e-01 1.15841687e+01], Loss = 0.3720\n",
      "Iteration 5724: Weights = [5.50000000e+01 3.53675927e+00 7.43609300e+00 2.44995183e-02\n",
      " 2.47581908e-01 1.15843942e+01], Loss = 0.3720\n",
      "Iteration 5725: Weights = [5.50000000e+01 3.53665774e+00 7.43587953e+00 2.44988150e-02\n",
      " 2.47574801e-01 1.15846197e+01], Loss = 0.3720\n",
      "Iteration 5726: Weights = [5.50000000e+01 3.53655622e+00 7.43566608e+00 2.44981117e-02\n",
      " 2.47567694e-01 1.15848452e+01], Loss = 0.3720\n",
      "Iteration 5727: Weights = [5.50000000e+01 3.53645470e+00 7.43545263e+00 2.44974085e-02\n",
      " 2.47560587e-01 1.15850707e+01], Loss = 0.3719\n",
      "Iteration 5728: Weights = [5.50000000e+01 3.53635318e+00 7.43523918e+00 2.44967053e-02\n",
      " 2.47553480e-01 1.15852962e+01], Loss = 0.3719\n",
      "Iteration 5729: Weights = [5.50000000e+01 3.53625166e+00 7.43502574e+00 2.44960020e-02\n",
      " 2.47546374e-01 1.15855217e+01], Loss = 0.3719\n",
      "Iteration 5730: Weights = [5.50000000e+01 3.53615015e+00 7.43481231e+00 2.44952989e-02\n",
      " 2.47539268e-01 1.15857472e+01], Loss = 0.3719\n",
      "Iteration 5731: Weights = [5.50000000e+01 3.53604864e+00 7.43459889e+00 2.44945957e-02\n",
      " 2.47532162e-01 1.15859727e+01], Loss = 0.3719\n",
      "Iteration 5732: Weights = [5.50000000e+01 3.53594714e+00 7.43438547e+00 2.44938925e-02\n",
      " 2.47525056e-01 1.15861982e+01], Loss = 0.3718\n",
      "Iteration 5733: Weights = [5.50000000e+01 3.53584563e+00 7.43417205e+00 2.44931894e-02\n",
      " 2.47517951e-01 1.15864236e+01], Loss = 0.3718\n",
      "Iteration 5734: Weights = [5.50000000e+01 3.53574413e+00 7.43395864e+00 2.44924863e-02\n",
      " 2.47510845e-01 1.15866491e+01], Loss = 0.3718\n",
      "Iteration 5735: Weights = [5.50000000e+01 3.53564263e+00 7.43374524e+00 2.44917832e-02\n",
      " 2.47503740e-01 1.15868745e+01], Loss = 0.3718\n",
      "Iteration 5736: Weights = [5.50000000e+01 3.53554114e+00 7.43353185e+00 2.44910801e-02\n",
      " 2.47496635e-01 1.15871000e+01], Loss = 0.3718\n",
      "Iteration 5737: Weights = [5.50000000e+01 3.53543964e+00 7.43331846e+00 2.44903771e-02\n",
      " 2.47489531e-01 1.15873254e+01], Loss = 0.3717\n",
      "Iteration 5738: Weights = [5.50000000e+01 3.53533815e+00 7.43310507e+00 2.44896741e-02\n",
      " 2.47482426e-01 1.15875509e+01], Loss = 0.3717\n",
      "Iteration 5739: Weights = [5.50000000e+01 3.53523667e+00 7.43289170e+00 2.44889711e-02\n",
      " 2.47475322e-01 1.15877763e+01], Loss = 0.3717\n",
      "Iteration 5740: Weights = [5.50000000e+01 3.53513518e+00 7.43267833e+00 2.44882681e-02\n",
      " 2.47468218e-01 1.15880017e+01], Loss = 0.3717\n",
      "Iteration 5741: Weights = [5.50000000e+01 3.53503370e+00 7.43246496e+00 2.44875651e-02\n",
      " 2.47461114e-01 1.15882271e+01], Loss = 0.3716\n",
      "Iteration 5742: Weights = [5.50000000e+01 3.53493223e+00 7.43225160e+00 2.44868621e-02\n",
      " 2.47454010e-01 1.15884525e+01], Loss = 0.3716\n",
      "Iteration 5743: Weights = [5.50000000e+01 3.53483075e+00 7.43203825e+00 2.44861592e-02\n",
      " 2.47446907e-01 1.15886780e+01], Loss = 0.3716\n",
      "Iteration 5744: Weights = [5.50000000e+01 3.53472928e+00 7.43182490e+00 2.44854563e-02\n",
      " 2.47439803e-01 1.15889033e+01], Loss = 0.3716\n",
      "Iteration 5745: Weights = [5.50000000e+01 3.53462781e+00 7.43161156e+00 2.44847534e-02\n",
      " 2.47432700e-01 1.15891287e+01], Loss = 0.3716\n",
      "Iteration 5746: Weights = [5.50000000e+01 3.53452634e+00 7.43139823e+00 2.44840506e-02\n",
      " 2.47425597e-01 1.15893541e+01], Loss = 0.3715\n",
      "Iteration 5747: Weights = [5.50000000e+01 3.53442488e+00 7.43118490e+00 2.44833477e-02\n",
      " 2.47418495e-01 1.15895795e+01], Loss = 0.3715\n",
      "Iteration 5748: Weights = [5.50000000e+01 3.53432342e+00 7.43097158e+00 2.44826449e-02\n",
      " 2.47411392e-01 1.15898049e+01], Loss = 0.3715\n",
      "Iteration 5749: Weights = [5.50000000e+01 3.53422196e+00 7.43075826e+00 2.44819421e-02\n",
      " 2.47404290e-01 1.15900302e+01], Loss = 0.3715\n",
      "Iteration 5750: Weights = [5.50000000e+01 3.53412051e+00 7.43054495e+00 2.44812393e-02\n",
      " 2.47397188e-01 1.15902556e+01], Loss = 0.3715\n",
      "Iteration 5751: Weights = [5.50000000e+01 3.53401906e+00 7.43033165e+00 2.44805365e-02\n",
      " 2.47390086e-01 1.15904809e+01], Loss = 0.3714\n",
      "Iteration 5752: Weights = [5.50000000e+01 3.53391761e+00 7.43011835e+00 2.44798338e-02\n",
      " 2.47382984e-01 1.15907063e+01], Loss = 0.3714\n",
      "Iteration 5753: Weights = [5.50000000e+01 3.53381616e+00 7.42990506e+00 2.44791311e-02\n",
      " 2.47375883e-01 1.15909316e+01], Loss = 0.3714\n",
      "Iteration 5754: Weights = [5.50000000e+01 3.53371472e+00 7.42969178e+00 2.44784284e-02\n",
      " 2.47368782e-01 1.15911570e+01], Loss = 0.3714\n",
      "Iteration 5755: Weights = [5.50000000e+01 3.53361328e+00 7.42947850e+00 2.44777257e-02\n",
      " 2.47361681e-01 1.15913823e+01], Loss = 0.3713\n",
      "Iteration 5756: Weights = [5.50000000e+01 3.53351184e+00 7.42926523e+00 2.44770230e-02\n",
      " 2.47354580e-01 1.15916076e+01], Loss = 0.3713\n",
      "Iteration 5757: Weights = [5.50000000e+01 3.53341041e+00 7.42905196e+00 2.44763204e-02\n",
      " 2.47347479e-01 1.15918329e+01], Loss = 0.3713\n",
      "Iteration 5758: Weights = [5.50000000e+01 3.53330898e+00 7.42883870e+00 2.44756177e-02\n",
      " 2.47340379e-01 1.15920582e+01], Loss = 0.3713\n",
      "Iteration 5759: Weights = [5.50000000e+01 3.53320755e+00 7.42862544e+00 2.44749151e-02\n",
      " 2.47333278e-01 1.15922835e+01], Loss = 0.3713\n",
      "Iteration 5760: Weights = [5.50000000e+01 3.53310612e+00 7.42841220e+00 2.44742125e-02\n",
      " 2.47326178e-01 1.15925088e+01], Loss = 0.3712\n",
      "Iteration 5761: Weights = [5.50000000e+01 3.53300470e+00 7.42819895e+00 2.44735100e-02\n",
      " 2.47319079e-01 1.15927341e+01], Loss = 0.3712\n",
      "Iteration 5762: Weights = [5.50000000e+01 3.53290328e+00 7.42798572e+00 2.44728074e-02\n",
      " 2.47311979e-01 1.15929594e+01], Loss = 0.3712\n",
      "Iteration 5763: Weights = [5.50000000e+01 3.53280187e+00 7.42777249e+00 2.44721049e-02\n",
      " 2.47304880e-01 1.15931847e+01], Loss = 0.3712\n",
      "Iteration 5764: Weights = [5.50000000e+01 3.53270045e+00 7.42755926e+00 2.44714024e-02\n",
      " 2.47297780e-01 1.15934099e+01], Loss = 0.3712\n",
      "Iteration 5765: Weights = [5.50000000e+01 3.53259904e+00 7.42734604e+00 2.44706999e-02\n",
      " 2.47290681e-01 1.15936352e+01], Loss = 0.3711\n",
      "Iteration 5766: Weights = [5.50000000e+01 3.53249763e+00 7.42713283e+00 2.44699975e-02\n",
      " 2.47283583e-01 1.15938604e+01], Loss = 0.3711\n",
      "Iteration 5767: Weights = [5.50000000e+01 3.53239623e+00 7.42691963e+00 2.44692950e-02\n",
      " 2.47276484e-01 1.15940857e+01], Loss = 0.3711\n",
      "Iteration 5768: Weights = [5.50000000e+01 3.53229483e+00 7.42670643e+00 2.44685926e-02\n",
      " 2.47269386e-01 1.15943109e+01], Loss = 0.3711\n",
      "Iteration 5769: Weights = [5.50000000e+01 3.53219343e+00 7.42649323e+00 2.44678902e-02\n",
      " 2.47262287e-01 1.15945362e+01], Loss = 0.3711\n",
      "Iteration 5770: Weights = [5.50000000e+01 3.53209203e+00 7.42628005e+00 2.44671878e-02\n",
      " 2.47255189e-01 1.15947614e+01], Loss = 0.3710\n",
      "Iteration 5771: Weights = [5.50000000e+01 3.53199064e+00 7.42606687e+00 2.44664854e-02\n",
      " 2.47248092e-01 1.15949866e+01], Loss = 0.3710\n",
      "Iteration 5772: Weights = [5.50000000e+01 3.53188925e+00 7.42585369e+00 2.44657831e-02\n",
      " 2.47240994e-01 1.15952118e+01], Loss = 0.3710\n",
      "Iteration 5773: Weights = [5.50000000e+01 3.53178786e+00 7.42564052e+00 2.44650808e-02\n",
      " 2.47233897e-01 1.15954370e+01], Loss = 0.3710\n",
      "Iteration 5774: Weights = [5.50000000e+01 3.53168648e+00 7.42542736e+00 2.44643785e-02\n",
      " 2.47226799e-01 1.15956623e+01], Loss = 0.3709\n",
      "Iteration 5775: Weights = [5.50000000e+01 3.53158509e+00 7.42521420e+00 2.44636762e-02\n",
      " 2.47219702e-01 1.15958874e+01], Loss = 0.3709\n",
      "Iteration 5776: Weights = [5.50000000e+01 3.53148371e+00 7.42500105e+00 2.44629739e-02\n",
      " 2.47212606e-01 1.15961126e+01], Loss = 0.3709\n",
      "Iteration 5777: Weights = [5.50000000e+01 3.53138234e+00 7.42478791e+00 2.44622717e-02\n",
      " 2.47205509e-01 1.15963378e+01], Loss = 0.3709\n",
      "Iteration 5778: Weights = [5.50000000e+01 3.53128097e+00 7.42457477e+00 2.44615695e-02\n",
      " 2.47198413e-01 1.15965630e+01], Loss = 0.3709\n",
      "Iteration 5779: Weights = [5.50000000e+01 3.53117960e+00 7.42436164e+00 2.44608673e-02\n",
      " 2.47191317e-01 1.15967882e+01], Loss = 0.3708\n",
      "Iteration 5780: Weights = [5.50000000e+01 3.53107823e+00 7.42414851e+00 2.44601651e-02\n",
      " 2.47184221e-01 1.15970133e+01], Loss = 0.3708\n",
      "Iteration 5781: Weights = [5.50000000e+01 3.53097686e+00 7.42393539e+00 2.44594629e-02\n",
      " 2.47177125e-01 1.15972385e+01], Loss = 0.3708\n",
      "Iteration 5782: Weights = [5.50000000e+01 3.53087550e+00 7.42372228e+00 2.44587608e-02\n",
      " 2.47170029e-01 1.15974636e+01], Loss = 0.3708\n",
      "Iteration 5783: Weights = [5.50000000e+01 3.53077414e+00 7.42350917e+00 2.44580587e-02\n",
      " 2.47162934e-01 1.15976888e+01], Loss = 0.3708\n",
      "Iteration 5784: Weights = [5.50000000e+01 3.53067279e+00 7.42329607e+00 2.44573566e-02\n",
      " 2.47155839e-01 1.15979139e+01], Loss = 0.3707\n",
      "Iteration 5785: Weights = [5.50000000e+01 3.53057144e+00 7.42308297e+00 2.44566545e-02\n",
      " 2.47148744e-01 1.15981391e+01], Loss = 0.3707\n",
      "Iteration 5786: Weights = [5.50000000e+01 3.53047009e+00 7.42286988e+00 2.44559524e-02\n",
      " 2.47141649e-01 1.15983642e+01], Loss = 0.3707\n",
      "Iteration 5787: Weights = [5.50000000e+01 3.53036874e+00 7.42265680e+00 2.44552504e-02\n",
      " 2.47134555e-01 1.15985893e+01], Loss = 0.3707\n",
      "Iteration 5788: Weights = [5.50000000e+01 3.53026740e+00 7.42244372e+00 2.44545484e-02\n",
      " 2.47127460e-01 1.15988144e+01], Loss = 0.3706\n",
      "Iteration 5789: Weights = [5.50000000e+01 3.53016606e+00 7.42223065e+00 2.44538464e-02\n",
      " 2.47120366e-01 1.15990395e+01], Loss = 0.3706\n",
      "Iteration 5790: Weights = [5.50000000e+01 3.53006472e+00 7.42201759e+00 2.44531444e-02\n",
      " 2.47113272e-01 1.15992646e+01], Loss = 0.3706\n",
      "Iteration 5791: Weights = [5.50000000e+01 3.52996338e+00 7.42180453e+00 2.44524424e-02\n",
      " 2.47106179e-01 1.15994897e+01], Loss = 0.3706\n",
      "Iteration 5792: Weights = [5.50000000e+01 3.52986205e+00 7.42159148e+00 2.44517405e-02\n",
      " 2.47099085e-01 1.15997148e+01], Loss = 0.3706\n",
      "Iteration 5793: Weights = [5.50000000e+01 3.52976072e+00 7.42137843e+00 2.44510386e-02\n",
      " 2.47091992e-01 1.15999399e+01], Loss = 0.3705\n",
      "Iteration 5794: Weights = [5.50000000e+01 3.52965939e+00 7.42116539e+00 2.44503367e-02\n",
      " 2.47084899e-01 1.16001650e+01], Loss = 0.3705\n",
      "Iteration 5795: Weights = [5.50000000e+01 3.52955807e+00 7.42095236e+00 2.44496348e-02\n",
      " 2.47077806e-01 1.16003900e+01], Loss = 0.3705\n",
      "Iteration 5796: Weights = [5.50000000e+01 3.52945675e+00 7.42073933e+00 2.44489329e-02\n",
      " 2.47070713e-01 1.16006151e+01], Loss = 0.3705\n",
      "Iteration 5797: Weights = [5.50000000e+01 3.52935543e+00 7.42052631e+00 2.44482311e-02\n",
      " 2.47063621e-01 1.16008401e+01], Loss = 0.3705\n",
      "Iteration 5798: Weights = [5.50000000e+01 3.52925412e+00 7.42031329e+00 2.44475293e-02\n",
      " 2.47056528e-01 1.16010652e+01], Loss = 0.3704\n",
      "Iteration 5799: Weights = [5.50000000e+01 3.52915281e+00 7.42010028e+00 2.44468275e-02\n",
      " 2.47049436e-01 1.16012902e+01], Loss = 0.3704\n",
      "Iteration 5800: Weights = [5.50000000e+01 3.52905150e+00 7.41988728e+00 2.44461257e-02\n",
      " 2.47042344e-01 1.16015153e+01], Loss = 0.3704\n",
      "Iteration 5801: Weights = [5.50000000e+01 3.52895019e+00 7.41967428e+00 2.44454239e-02\n",
      " 2.47035253e-01 1.16017403e+01], Loss = 0.3704\n",
      "Iteration 5802: Weights = [5.50000000e+01 3.52884889e+00 7.41946129e+00 2.44447222e-02\n",
      " 2.47028161e-01 1.16019653e+01], Loss = 0.3703\n",
      "Iteration 5803: Weights = [5.50000000e+01 3.52874759e+00 7.41924830e+00 2.44440205e-02\n",
      " 2.47021070e-01 1.16021903e+01], Loss = 0.3703\n",
      "Iteration 5804: Weights = [5.50000000e+01 3.52864629e+00 7.41903532e+00 2.44433188e-02\n",
      " 2.47013979e-01 1.16024153e+01], Loss = 0.3703\n",
      "Iteration 5805: Weights = [5.50000000e+01 3.52854500e+00 7.41882235e+00 2.44426171e-02\n",
      " 2.47006888e-01 1.16026403e+01], Loss = 0.3703\n",
      "Iteration 5806: Weights = [5.50000000e+01 3.52844370e+00 7.41860938e+00 2.44419154e-02\n",
      " 2.46999797e-01 1.16028653e+01], Loss = 0.3703\n",
      "Iteration 5807: Weights = [5.50000000e+01 3.52834242e+00 7.41839642e+00 2.44412138e-02\n",
      " 2.46992707e-01 1.16030903e+01], Loss = 0.3702\n",
      "Iteration 5808: Weights = [5.50000000e+01 3.52824113e+00 7.41818347e+00 2.44405122e-02\n",
      " 2.46985617e-01 1.16033153e+01], Loss = 0.3702\n",
      "Iteration 5809: Weights = [5.50000000e+01 3.52813985e+00 7.41797052e+00 2.44398106e-02\n",
      " 2.46978527e-01 1.16035403e+01], Loss = 0.3702\n",
      "Iteration 5810: Weights = [5.50000000e+01 3.52803857e+00 7.41775758e+00 2.44391090e-02\n",
      " 2.46971437e-01 1.16037653e+01], Loss = 0.3702\n",
      "Iteration 5811: Weights = [5.50000000e+01 3.52793729e+00 7.41754464e+00 2.44384075e-02\n",
      " 2.46964347e-01 1.16039902e+01], Loss = 0.3702\n",
      "Iteration 5812: Weights = [5.50000000e+01 3.52783602e+00 7.41733171e+00 2.44377059e-02\n",
      " 2.46957258e-01 1.16042152e+01], Loss = 0.3701\n",
      "Iteration 5813: Weights = [5.50000000e+01 3.52773475e+00 7.41711878e+00 2.44370044e-02\n",
      " 2.46950169e-01 1.16044401e+01], Loss = 0.3701\n",
      "Iteration 5814: Weights = [5.50000000e+01 3.52763348e+00 7.41690587e+00 2.44363029e-02\n",
      " 2.46943080e-01 1.16046651e+01], Loss = 0.3701\n",
      "Iteration 5815: Weights = [5.50000000e+01 3.52753221e+00 7.41669295e+00 2.44356014e-02\n",
      " 2.46935991e-01 1.16048900e+01], Loss = 0.3701\n",
      "Iteration 5816: Weights = [5.50000000e+01 3.52743095e+00 7.41648005e+00 2.44349000e-02\n",
      " 2.46928902e-01 1.16051149e+01], Loss = 0.3701\n",
      "Iteration 5817: Weights = [5.50000000e+01 3.52732969e+00 7.41626715e+00 2.44341985e-02\n",
      " 2.46921814e-01 1.16053399e+01], Loss = 0.3700\n",
      "Iteration 5818: Weights = [5.50000000e+01 3.52722843e+00 7.41605426e+00 2.44334971e-02\n",
      " 2.46914725e-01 1.16055648e+01], Loss = 0.3700\n",
      "Iteration 5819: Weights = [5.50000000e+01 3.52712718e+00 7.41584137e+00 2.44327957e-02\n",
      " 2.46907637e-01 1.16057897e+01], Loss = 0.3700\n",
      "Iteration 5820: Weights = [5.50000000e+01 3.52702593e+00 7.41562849e+00 2.44320944e-02\n",
      " 2.46900550e-01 1.16060146e+01], Loss = 0.3700\n",
      "Iteration 5821: Weights = [5.50000000e+01 3.52692468e+00 7.41541561e+00 2.44313930e-02\n",
      " 2.46893462e-01 1.16062395e+01], Loss = 0.3699\n",
      "Iteration 5822: Weights = [5.50000000e+01 3.52682344e+00 7.41520274e+00 2.44306917e-02\n",
      " 2.46886375e-01 1.16064644e+01], Loss = 0.3699\n",
      "Iteration 5823: Weights = [5.50000000e+01 3.52672219e+00 7.41498988e+00 2.44299904e-02\n",
      " 2.46879287e-01 1.16066893e+01], Loss = 0.3699\n",
      "Iteration 5824: Weights = [5.50000000e+01 3.52662095e+00 7.41477702e+00 2.44292891e-02\n",
      " 2.46872200e-01 1.16069142e+01], Loss = 0.3699\n",
      "Iteration 5825: Weights = [5.50000000e+01 3.52651972e+00 7.41456417e+00 2.44285878e-02\n",
      " 2.46865114e-01 1.16071390e+01], Loss = 0.3699\n",
      "Iteration 5826: Weights = [5.50000000e+01 3.52641849e+00 7.41435133e+00 2.44278865e-02\n",
      " 2.46858027e-01 1.16073639e+01], Loss = 0.3698\n",
      "Iteration 5827: Weights = [5.50000000e+01 3.52631725e+00 7.41413849e+00 2.44271853e-02\n",
      " 2.46850941e-01 1.16075888e+01], Loss = 0.3698\n",
      "Iteration 5828: Weights = [5.50000000e+01 3.52621603e+00 7.41392565e+00 2.44264841e-02\n",
      " 2.46843855e-01 1.16078136e+01], Loss = 0.3698\n",
      "Iteration 5829: Weights = [5.50000000e+01 3.52611480e+00 7.41371283e+00 2.44257829e-02\n",
      " 2.46836769e-01 1.16080385e+01], Loss = 0.3698\n",
      "Iteration 5830: Weights = [5.50000000e+01 3.52601358e+00 7.41350001e+00 2.44250817e-02\n",
      " 2.46829683e-01 1.16082633e+01], Loss = 0.3698\n",
      "Iteration 5831: Weights = [5.50000000e+01 3.52591236e+00 7.41328719e+00 2.44243806e-02\n",
      " 2.46822597e-01 1.16084881e+01], Loss = 0.3697\n",
      "Iteration 5832: Weights = [5.50000000e+01 3.52581115e+00 7.41307439e+00 2.44236794e-02\n",
      " 2.46815512e-01 1.16087130e+01], Loss = 0.3697\n",
      "Iteration 5833: Weights = [5.50000000e+01 3.52570993e+00 7.41286158e+00 2.44229783e-02\n",
      " 2.46808427e-01 1.16089378e+01], Loss = 0.3697\n",
      "Iteration 5834: Weights = [5.50000000e+01 3.52560872e+00 7.41264879e+00 2.44222772e-02\n",
      " 2.46801342e-01 1.16091626e+01], Loss = 0.3697\n",
      "Iteration 5835: Weights = [5.50000000e+01 3.52550752e+00 7.41243600e+00 2.44215761e-02\n",
      " 2.46794257e-01 1.16093874e+01], Loss = 0.3696\n",
      "Iteration 5836: Weights = [5.50000000e+01 3.52540631e+00 7.41222321e+00 2.44208751e-02\n",
      " 2.46787172e-01 1.16096122e+01], Loss = 0.3696\n",
      "Iteration 5837: Weights = [5.50000000e+01 3.52530511e+00 7.41201044e+00 2.44201741e-02\n",
      " 2.46780088e-01 1.16098370e+01], Loss = 0.3696\n",
      "Iteration 5838: Weights = [5.50000000e+01 3.52520391e+00 7.41179767e+00 2.44194730e-02\n",
      " 2.46773004e-01 1.16100618e+01], Loss = 0.3696\n",
      "Iteration 5839: Weights = [5.50000000e+01 3.52510272e+00 7.41158490e+00 2.44187721e-02\n",
      " 2.46765920e-01 1.16102866e+01], Loss = 0.3696\n",
      "Iteration 5840: Weights = [5.50000000e+01 3.52500152e+00 7.41137214e+00 2.44180711e-02\n",
      " 2.46758836e-01 1.16105114e+01], Loss = 0.3695\n",
      "Iteration 5841: Weights = [5.50000000e+01 3.52490033e+00 7.41115939e+00 2.44173701e-02\n",
      " 2.46751753e-01 1.16107361e+01], Loss = 0.3695\n",
      "Iteration 5842: Weights = [5.50000000e+01 3.52479915e+00 7.41094664e+00 2.44166692e-02\n",
      " 2.46744669e-01 1.16109609e+01], Loss = 0.3695\n",
      "Iteration 5843: Weights = [5.50000000e+01 3.52469796e+00 7.41073390e+00 2.44159683e-02\n",
      " 2.46737586e-01 1.16111857e+01], Loss = 0.3695\n",
      "Iteration 5844: Weights = [5.50000000e+01 3.52459678e+00 7.41052116e+00 2.44152674e-02\n",
      " 2.46730503e-01 1.16114104e+01], Loss = 0.3695\n",
      "Iteration 5845: Weights = [5.50000000e+01 3.52449560e+00 7.41030844e+00 2.44145665e-02\n",
      " 2.46723421e-01 1.16116352e+01], Loss = 0.3694\n",
      "Iteration 5846: Weights = [5.50000000e+01 3.52439443e+00 7.41009571e+00 2.44138657e-02\n",
      " 2.46716338e-01 1.16118599e+01], Loss = 0.3694\n",
      "Iteration 5847: Weights = [5.50000000e+01 3.52429326e+00 7.40988300e+00 2.44131648e-02\n",
      " 2.46709256e-01 1.16120846e+01], Loss = 0.3694\n",
      "Iteration 5848: Weights = [5.50000000e+01 3.52419209e+00 7.40967029e+00 2.44124640e-02\n",
      " 2.46702174e-01 1.16123093e+01], Loss = 0.3694\n",
      "Iteration 5849: Weights = [5.50000000e+01 3.52409092e+00 7.40945758e+00 2.44117632e-02\n",
      " 2.46695092e-01 1.16125341e+01], Loss = 0.3694\n",
      "Iteration 5850: Weights = [5.50000000e+01 3.52398976e+00 7.40924488e+00 2.44110625e-02\n",
      " 2.46688010e-01 1.16127588e+01], Loss = 0.3693\n",
      "Iteration 5851: Weights = [5.50000000e+01 3.52388860e+00 7.40903219e+00 2.44103617e-02\n",
      " 2.46680929e-01 1.16129835e+01], Loss = 0.3693\n",
      "Iteration 5852: Weights = [5.50000000e+01 3.52378744e+00 7.40881951e+00 2.44096610e-02\n",
      " 2.46673847e-01 1.16132082e+01], Loss = 0.3693\n",
      "Iteration 5853: Weights = [5.50000000e+01 3.52368628e+00 7.40860683e+00 2.44089603e-02\n",
      " 2.46666766e-01 1.16134329e+01], Loss = 0.3693\n",
      "Iteration 5854: Weights = [5.50000000e+01 3.52358513e+00 7.40839415e+00 2.44082596e-02\n",
      " 2.46659685e-01 1.16136576e+01], Loss = 0.3692\n",
      "Iteration 5855: Weights = [5.50000000e+01 3.52348398e+00 7.40818148e+00 2.44075589e-02\n",
      " 2.46652605e-01 1.16138822e+01], Loss = 0.3692\n",
      "Iteration 5856: Weights = [5.50000000e+01 3.52338284e+00 7.40796882e+00 2.44068583e-02\n",
      " 2.46645524e-01 1.16141069e+01], Loss = 0.3692\n",
      "Iteration 5857: Weights = [5.50000000e+01 3.52328169e+00 7.40775617e+00 2.44061576e-02\n",
      " 2.46638444e-01 1.16143316e+01], Loss = 0.3692\n",
      "Iteration 5858: Weights = [5.50000000e+01 3.52318055e+00 7.40754352e+00 2.44054570e-02\n",
      " 2.46631364e-01 1.16145562e+01], Loss = 0.3692\n",
      "Iteration 5859: Weights = [5.50000000e+01 3.52307941e+00 7.40733088e+00 2.44047564e-02\n",
      " 2.46624284e-01 1.16147809e+01], Loss = 0.3691\n",
      "Iteration 5860: Weights = [5.50000000e+01 3.52297828e+00 7.40711824e+00 2.44040559e-02\n",
      " 2.46617204e-01 1.16150055e+01], Loss = 0.3691\n",
      "Iteration 5861: Weights = [5.50000000e+01 3.52287715e+00 7.40690561e+00 2.44033553e-02\n",
      " 2.46610125e-01 1.16152302e+01], Loss = 0.3691\n",
      "Iteration 5862: Weights = [5.50000000e+01 3.52277602e+00 7.40669298e+00 2.44026548e-02\n",
      " 2.46603045e-01 1.16154548e+01], Loss = 0.3691\n",
      "Iteration 5863: Weights = [5.50000000e+01 3.52267489e+00 7.40648036e+00 2.44019543e-02\n",
      " 2.46595966e-01 1.16156795e+01], Loss = 0.3691\n",
      "Iteration 5864: Weights = [5.50000000e+01 3.52257377e+00 7.40626775e+00 2.44012538e-02\n",
      " 2.46588888e-01 1.16159041e+01], Loss = 0.3690\n",
      "Iteration 5865: Weights = [5.50000000e+01 3.52247265e+00 7.40605514e+00 2.44005533e-02\n",
      " 2.46581809e-01 1.16161287e+01], Loss = 0.3690\n",
      "Iteration 5866: Weights = [5.50000000e+01 3.52237153e+00 7.40584254e+00 2.43998528e-02\n",
      " 2.46574730e-01 1.16163533e+01], Loss = 0.3690\n",
      "Iteration 5867: Weights = [5.50000000e+01 3.52227042e+00 7.40562995e+00 2.43991524e-02\n",
      " 2.46567652e-01 1.16165779e+01], Loss = 0.3690\n",
      "Iteration 5868: Weights = [5.50000000e+01 3.52216931e+00 7.40541736e+00 2.43984520e-02\n",
      " 2.46560574e-01 1.16168025e+01], Loss = 0.3689\n",
      "Iteration 5869: Weights = [5.50000000e+01 3.52206820e+00 7.40520478e+00 2.43977516e-02\n",
      " 2.46553496e-01 1.16170271e+01], Loss = 0.3689\n",
      "Iteration 5870: Weights = [5.50000000e+01 3.52196709e+00 7.40499220e+00 2.43970513e-02\n",
      " 2.46546419e-01 1.16172517e+01], Loss = 0.3689\n",
      "Iteration 5871: Weights = [5.50000000e+01 3.52186599e+00 7.40477963e+00 2.43963509e-02\n",
      " 2.46539341e-01 1.16174762e+01], Loss = 0.3689\n",
      "Iteration 5872: Weights = [5.50000000e+01 3.52176489e+00 7.40456707e+00 2.43956506e-02\n",
      " 2.46532264e-01 1.16177008e+01], Loss = 0.3689\n",
      "Iteration 5873: Weights = [5.50000000e+01 3.52166379e+00 7.40435451e+00 2.43949503e-02\n",
      " 2.46525187e-01 1.16179254e+01], Loss = 0.3688\n",
      "Iteration 5874: Weights = [5.50000000e+01 3.52156270e+00 7.40414196e+00 2.43942500e-02\n",
      " 2.46518110e-01 1.16181499e+01], Loss = 0.3688\n",
      "Iteration 5875: Weights = [5.50000000e+01 3.52146161e+00 7.40392941e+00 2.43935497e-02\n",
      " 2.46511033e-01 1.16183745e+01], Loss = 0.3688\n",
      "Iteration 5876: Weights = [5.50000000e+01 3.52136052e+00 7.40371687e+00 2.43928495e-02\n",
      " 2.46503957e-01 1.16185990e+01], Loss = 0.3688\n",
      "Iteration 5877: Weights = [5.50000000e+01 3.52125943e+00 7.40350434e+00 2.43921492e-02\n",
      " 2.46496881e-01 1.16188236e+01], Loss = 0.3688\n",
      "Iteration 5878: Weights = [5.50000000e+01 3.52115835e+00 7.40329181e+00 2.43914490e-02\n",
      " 2.46489805e-01 1.16190481e+01], Loss = 0.3687\n",
      "Iteration 5879: Weights = [5.50000000e+01 3.52105727e+00 7.40307929e+00 2.43907488e-02\n",
      " 2.46482729e-01 1.16192726e+01], Loss = 0.3687\n",
      "Iteration 5880: Weights = [5.50000000e+01 3.52095620e+00 7.40286678e+00 2.43900487e-02\n",
      " 2.46475653e-01 1.16194971e+01], Loss = 0.3687\n",
      "Iteration 5881: Weights = [5.50000000e+01 3.52085512e+00 7.40265427e+00 2.43893485e-02\n",
      " 2.46468578e-01 1.16197217e+01], Loss = 0.3687\n",
      "Iteration 5882: Weights = [5.50000000e+01 3.52075405e+00 7.40244177e+00 2.43886484e-02\n",
      " 2.46461503e-01 1.16199462e+01], Loss = 0.3687\n",
      "Iteration 5883: Weights = [5.50000000e+01 3.52065298e+00 7.40222927e+00 2.43879483e-02\n",
      " 2.46454428e-01 1.16201707e+01], Loss = 0.3686\n",
      "Iteration 5884: Weights = [5.50000000e+01 3.52055192e+00 7.40201678e+00 2.43872482e-02\n",
      " 2.46447353e-01 1.16203952e+01], Loss = 0.3686\n",
      "Iteration 5885: Weights = [5.50000000e+01 3.52045086e+00 7.40180429e+00 2.43865481e-02\n",
      " 2.46440278e-01 1.16206196e+01], Loss = 0.3686\n",
      "Iteration 5886: Weights = [5.50000000e+01 3.52034980e+00 7.40159181e+00 2.43858481e-02\n",
      " 2.46433204e-01 1.16208441e+01], Loss = 0.3686\n",
      "Iteration 5887: Weights = [5.50000000e+01 3.52024874e+00 7.40137934e+00 2.43851480e-02\n",
      " 2.46426130e-01 1.16210686e+01], Loss = 0.3685\n",
      "Iteration 5888: Weights = [5.50000000e+01 3.52014769e+00 7.40116688e+00 2.43844480e-02\n",
      " 2.46419056e-01 1.16212931e+01], Loss = 0.3685\n",
      "Iteration 5889: Weights = [5.50000000e+01 3.52004664e+00 7.40095442e+00 2.43837481e-02\n",
      " 2.46411982e-01 1.16215175e+01], Loss = 0.3685\n",
      "Iteration 5890: Weights = [5.50000000e+01 3.51994559e+00 7.40074196e+00 2.43830481e-02\n",
      " 2.46404908e-01 1.16217420e+01], Loss = 0.3685\n",
      "Iteration 5891: Weights = [5.50000000e+01 3.51984455e+00 7.40052951e+00 2.43823481e-02\n",
      " 2.46397835e-01 1.16219664e+01], Loss = 0.3685\n",
      "Iteration 5892: Weights = [5.50000000e+01 3.51974350e+00 7.40031707e+00 2.43816482e-02\n",
      " 2.46390762e-01 1.16221909e+01], Loss = 0.3684\n",
      "Iteration 5893: Weights = [5.50000000e+01 3.51964247e+00 7.40010464e+00 2.43809483e-02\n",
      " 2.46383689e-01 1.16224153e+01], Loss = 0.3684\n",
      "Iteration 5894: Weights = [5.50000000e+01 3.51954143e+00 7.39989221e+00 2.43802484e-02\n",
      " 2.46376616e-01 1.16226397e+01], Loss = 0.3684\n",
      "Iteration 5895: Weights = [5.50000000e+01 3.51944040e+00 7.39967978e+00 2.43795485e-02\n",
      " 2.46369544e-01 1.16228642e+01], Loss = 0.3684\n",
      "Iteration 5896: Weights = [5.50000000e+01 3.51933937e+00 7.39946737e+00 2.43788487e-02\n",
      " 2.46362471e-01 1.16230886e+01], Loss = 0.3684\n",
      "Iteration 5897: Weights = [5.50000000e+01 3.51923834e+00 7.39925495e+00 2.43781489e-02\n",
      " 2.46355399e-01 1.16233130e+01], Loss = 0.3683\n",
      "Iteration 5898: Weights = [5.50000000e+01 3.51913731e+00 7.39904255e+00 2.43774491e-02\n",
      " 2.46348327e-01 1.16235374e+01], Loss = 0.3683\n",
      "Iteration 5899: Weights = [5.50000000e+01 3.51903629e+00 7.39883015e+00 2.43767493e-02\n",
      " 2.46341255e-01 1.16237618e+01], Loss = 0.3683\n",
      "Iteration 5900: Weights = [5.50000000e+01 3.51893527e+00 7.39861776e+00 2.43760495e-02\n",
      " 2.46334184e-01 1.16239862e+01], Loss = 0.3683\n",
      "Iteration 5901: Weights = [5.50000000e+01 3.51883426e+00 7.39840537e+00 2.43753498e-02\n",
      " 2.46327112e-01 1.16242106e+01], Loss = 0.3682\n",
      "Iteration 5902: Weights = [5.50000000e+01 3.51873325e+00 7.39819299e+00 2.43746500e-02\n",
      " 2.46320041e-01 1.16244349e+01], Loss = 0.3682\n",
      "Iteration 5903: Weights = [5.50000000e+01 3.51863224e+00 7.39798061e+00 2.43739503e-02\n",
      " 2.46312970e-01 1.16246593e+01], Loss = 0.3682\n",
      "Iteration 5904: Weights = [5.50000000e+01 3.51853123e+00 7.39776825e+00 2.43732507e-02\n",
      " 2.46305900e-01 1.16248837e+01], Loss = 0.3682\n",
      "Iteration 5905: Weights = [5.50000000e+01 3.51843023e+00 7.39755588e+00 2.43725510e-02\n",
      " 2.46298829e-01 1.16251080e+01], Loss = 0.3682\n",
      "Iteration 5906: Weights = [5.50000000e+01 3.51832922e+00 7.39734353e+00 2.43718513e-02\n",
      " 2.46291759e-01 1.16253324e+01], Loss = 0.3681\n",
      "Iteration 5907: Weights = [5.50000000e+01 3.51822823e+00 7.39713118e+00 2.43711517e-02\n",
      " 2.46284689e-01 1.16255567e+01], Loss = 0.3681\n",
      "Iteration 5908: Weights = [5.50000000e+01 3.51812723e+00 7.39691883e+00 2.43704521e-02\n",
      " 2.46277619e-01 1.16257811e+01], Loss = 0.3681\n",
      "Iteration 5909: Weights = [5.50000000e+01 3.51802624e+00 7.39670649e+00 2.43697525e-02\n",
      " 2.46270549e-01 1.16260054e+01], Loss = 0.3681\n",
      "Iteration 5910: Weights = [5.50000000e+01 3.51792525e+00 7.39649416e+00 2.43690530e-02\n",
      " 2.46263480e-01 1.16262297e+01], Loss = 0.3681\n",
      "Iteration 5911: Weights = [5.50000000e+01 3.51782426e+00 7.39628183e+00 2.43683534e-02\n",
      " 2.46256410e-01 1.16264540e+01], Loss = 0.3680\n",
      "Iteration 5912: Weights = [5.50000000e+01 3.51772328e+00 7.39606951e+00 2.43676539e-02\n",
      " 2.46249341e-01 1.16266783e+01], Loss = 0.3680\n",
      "Iteration 5913: Weights = [5.50000000e+01 3.51762230e+00 7.39585720e+00 2.43669544e-02\n",
      " 2.46242272e-01 1.16269027e+01], Loss = 0.3680\n",
      "Iteration 5914: Weights = [5.50000000e+01 3.51752132e+00 7.39564489e+00 2.43662549e-02\n",
      " 2.46235203e-01 1.16271270e+01], Loss = 0.3680\n",
      "Iteration 5915: Weights = [5.50000000e+01 3.51742034e+00 7.39543259e+00 2.43655554e-02\n",
      " 2.46228135e-01 1.16273512e+01], Loss = 0.3680\n",
      "Iteration 5916: Weights = [5.50000000e+01 3.51731937e+00 7.39522030e+00 2.43648560e-02\n",
      " 2.46221067e-01 1.16275755e+01], Loss = 0.3679\n",
      "Iteration 5917: Weights = [5.50000000e+01 3.51721840e+00 7.39500801e+00 2.43641566e-02\n",
      " 2.46213999e-01 1.16277998e+01], Loss = 0.3679\n",
      "Iteration 5918: Weights = [5.50000000e+01 3.51711744e+00 7.39479572e+00 2.43634572e-02\n",
      " 2.46206931e-01 1.16280241e+01], Loss = 0.3679\n",
      "Iteration 5919: Weights = [5.50000000e+01 3.51701647e+00 7.39458345e+00 2.43627578e-02\n",
      " 2.46199863e-01 1.16282484e+01], Loss = 0.3679\n",
      "Iteration 5920: Weights = [5.50000000e+01 3.51691551e+00 7.39437117e+00 2.43620584e-02\n",
      " 2.46192795e-01 1.16284726e+01], Loss = 0.3678\n",
      "Iteration 5921: Weights = [5.50000000e+01 3.51681455e+00 7.39415891e+00 2.43613591e-02\n",
      " 2.46185728e-01 1.16286969e+01], Loss = 0.3678\n",
      "Iteration 5922: Weights = [5.50000000e+01 3.51671360e+00 7.39394665e+00 2.43606597e-02\n",
      " 2.46178661e-01 1.16289211e+01], Loss = 0.3678\n",
      "Iteration 5923: Weights = [5.50000000e+01 3.51661265e+00 7.39373440e+00 2.43599604e-02\n",
      " 2.46171594e-01 1.16291454e+01], Loss = 0.3678\n",
      "Iteration 5924: Weights = [5.50000000e+01 3.51651170e+00 7.39352215e+00 2.43592611e-02\n",
      " 2.46164528e-01 1.16293696e+01], Loss = 0.3678\n",
      "Iteration 5925: Weights = [5.50000000e+01 3.51641075e+00 7.39330991e+00 2.43585619e-02\n",
      " 2.46157461e-01 1.16295938e+01], Loss = 0.3677\n",
      "Iteration 5926: Weights = [5.50000000e+01 3.51630981e+00 7.39309768e+00 2.43578626e-02\n",
      " 2.46150395e-01 1.16298180e+01], Loss = 0.3677\n",
      "Iteration 5927: Weights = [5.50000000e+01 3.51620887e+00 7.39288545e+00 2.43571634e-02\n",
      " 2.46143329e-01 1.16300423e+01], Loss = 0.3677\n",
      "Iteration 5928: Weights = [5.50000000e+01 3.51610793e+00 7.39267322e+00 2.43564642e-02\n",
      " 2.46136263e-01 1.16302665e+01], Loss = 0.3677\n",
      "Iteration 5929: Weights = [5.50000000e+01 3.51600700e+00 7.39246101e+00 2.43557650e-02\n",
      " 2.46129197e-01 1.16304907e+01], Loss = 0.3677\n",
      "Iteration 5930: Weights = [5.50000000e+01 3.51590607e+00 7.39224880e+00 2.43550659e-02\n",
      " 2.46122132e-01 1.16307149e+01], Loss = 0.3676\n",
      "Iteration 5931: Weights = [5.50000000e+01 3.51580514e+00 7.39203659e+00 2.43543667e-02\n",
      " 2.46115066e-01 1.16309391e+01], Loss = 0.3676\n",
      "Iteration 5932: Weights = [5.50000000e+01 3.51570421e+00 7.39182440e+00 2.43536676e-02\n",
      " 2.46108001e-01 1.16311632e+01], Loss = 0.3676\n",
      "Iteration 5933: Weights = [5.50000000e+01 3.51560329e+00 7.39161220e+00 2.43529685e-02\n",
      " 2.46100937e-01 1.16313874e+01], Loss = 0.3676\n",
      "Iteration 5934: Weights = [5.50000000e+01 3.51550237e+00 7.39140002e+00 2.43522694e-02\n",
      " 2.46093872e-01 1.16316116e+01], Loss = 0.3676\n",
      "Iteration 5935: Weights = [5.50000000e+01 3.51540145e+00 7.39118784e+00 2.43515703e-02\n",
      " 2.46086807e-01 1.16318358e+01], Loss = 0.3675\n",
      "Iteration 5936: Weights = [5.50000000e+01 3.51530054e+00 7.39097566e+00 2.43508713e-02\n",
      " 2.46079743e-01 1.16320599e+01], Loss = 0.3675\n",
      "Iteration 5937: Weights = [5.50000000e+01 3.51519963e+00 7.39076350e+00 2.43501723e-02\n",
      " 2.46072679e-01 1.16322841e+01], Loss = 0.3675\n",
      "Iteration 5938: Weights = [5.50000000e+01 3.51509872e+00 7.39055133e+00 2.43494733e-02\n",
      " 2.46065615e-01 1.16325082e+01], Loss = 0.3675\n",
      "Iteration 5939: Weights = [5.50000000e+01 3.51499781e+00 7.39033918e+00 2.43487743e-02\n",
      " 2.46058552e-01 1.16327324e+01], Loss = 0.3674\n",
      "Iteration 5940: Weights = [5.50000000e+01 3.51489691e+00 7.39012703e+00 2.43480753e-02\n",
      " 2.46051488e-01 1.16329565e+01], Loss = 0.3674\n",
      "Iteration 5941: Weights = [5.50000000e+01 3.51479601e+00 7.38991489e+00 2.43473764e-02\n",
      " 2.46044425e-01 1.16331806e+01], Loss = 0.3674\n",
      "Iteration 5942: Weights = [5.50000000e+01 3.51469511e+00 7.38970275e+00 2.43466775e-02\n",
      " 2.46037362e-01 1.16334047e+01], Loss = 0.3674\n",
      "Iteration 5943: Weights = [5.50000000e+01 3.51459422e+00 7.38949062e+00 2.43459786e-02\n",
      " 2.46030299e-01 1.16336288e+01], Loss = 0.3674\n",
      "Iteration 5944: Weights = [5.50000000e+01 3.51449333e+00 7.38927849e+00 2.43452797e-02\n",
      " 2.46023237e-01 1.16338530e+01], Loss = 0.3673\n",
      "Iteration 5945: Weights = [5.50000000e+01 3.51439244e+00 7.38906637e+00 2.43445808e-02\n",
      " 2.46016174e-01 1.16340771e+01], Loss = 0.3673\n",
      "Iteration 5946: Weights = [5.50000000e+01 3.51429156e+00 7.38885426e+00 2.43438820e-02\n",
      " 2.46009112e-01 1.16343011e+01], Loss = 0.3673\n",
      "Iteration 5947: Weights = [5.50000000e+01 3.51419067e+00 7.38864215e+00 2.43431831e-02\n",
      " 2.46002050e-01 1.16345252e+01], Loss = 0.3673\n",
      "Iteration 5948: Weights = [5.50000000e+01 3.51408979e+00 7.38843005e+00 2.43424843e-02\n",
      " 2.45994988e-01 1.16347493e+01], Loss = 0.3673\n",
      "Iteration 5949: Weights = [5.50000000e+01 3.51398892e+00 7.38821796e+00 2.43417856e-02\n",
      " 2.45987927e-01 1.16349734e+01], Loss = 0.3672\n",
      "Iteration 5950: Weights = [5.50000000e+01 3.51388804e+00 7.38800587e+00 2.43410868e-02\n",
      " 2.45980865e-01 1.16351975e+01], Loss = 0.3672\n",
      "Iteration 5951: Weights = [5.50000000e+01 3.51378717e+00 7.38779379e+00 2.43403880e-02\n",
      " 2.45973804e-01 1.16354215e+01], Loss = 0.3672\n",
      "Iteration 5952: Weights = [5.50000000e+01 3.51368630e+00 7.38758171e+00 2.43396893e-02\n",
      " 2.45966743e-01 1.16356456e+01], Loss = 0.3672\n",
      "Iteration 5953: Weights = [5.50000000e+01 3.51358544e+00 7.38736964e+00 2.43389906e-02\n",
      " 2.45959682e-01 1.16358696e+01], Loss = 0.3672\n",
      "Iteration 5954: Weights = [5.50000000e+01 3.51348458e+00 7.38715758e+00 2.43382919e-02\n",
      " 2.45952622e-01 1.16360937e+01], Loss = 0.3671\n",
      "Iteration 5955: Weights = [5.50000000e+01 3.51338372e+00 7.38694552e+00 2.43375933e-02\n",
      " 2.45945561e-01 1.16363177e+01], Loss = 0.3671\n",
      "Iteration 5956: Weights = [5.50000000e+01 3.51328286e+00 7.38673347e+00 2.43368946e-02\n",
      " 2.45938501e-01 1.16365417e+01], Loss = 0.3671\n",
      "Iteration 5957: Weights = [5.50000000e+01 3.51318201e+00 7.38652142e+00 2.43361960e-02\n",
      " 2.45931441e-01 1.16367658e+01], Loss = 0.3671\n",
      "Iteration 5958: Weights = [5.50000000e+01 3.51308116e+00 7.38630938e+00 2.43354974e-02\n",
      " 2.45924381e-01 1.16369898e+01], Loss = 0.3670\n",
      "Iteration 5959: Weights = [5.50000000e+01 3.51298031e+00 7.38609735e+00 2.43347988e-02\n",
      " 2.45917322e-01 1.16372138e+01], Loss = 0.3670\n",
      "Iteration 5960: Weights = [5.50000000e+01 3.51287947e+00 7.38588532e+00 2.43341003e-02\n",
      " 2.45910262e-01 1.16374378e+01], Loss = 0.3670\n",
      "Iteration 5961: Weights = [5.50000000e+01 3.51277862e+00 7.38567330e+00 2.43334017e-02\n",
      " 2.45903203e-01 1.16376618e+01], Loss = 0.3670\n",
      "Iteration 5962: Weights = [5.50000000e+01 3.51267779e+00 7.38546128e+00 2.43327032e-02\n",
      " 2.45896144e-01 1.16378858e+01], Loss = 0.3670\n",
      "Iteration 5963: Weights = [5.50000000e+01 3.51257695e+00 7.38524928e+00 2.43320047e-02\n",
      " 2.45889085e-01 1.16381098e+01], Loss = 0.3669\n",
      "Iteration 5964: Weights = [5.50000000e+01 3.51247612e+00 7.38503727e+00 2.43313062e-02\n",
      " 2.45882027e-01 1.16383337e+01], Loss = 0.3669\n",
      "Iteration 5965: Weights = [5.50000000e+01 3.51237529e+00 7.38482527e+00 2.43306078e-02\n",
      " 2.45874968e-01 1.16385577e+01], Loss = 0.3669\n",
      "Iteration 5966: Weights = [5.50000000e+01 3.51227446e+00 7.38461328e+00 2.43299093e-02\n",
      " 2.45867910e-01 1.16387817e+01], Loss = 0.3669\n",
      "Iteration 5967: Weights = [5.50000000e+01 3.51217363e+00 7.38440130e+00 2.43292109e-02\n",
      " 2.45860852e-01 1.16390056e+01], Loss = 0.3669\n",
      "Iteration 5968: Weights = [5.50000000e+01 3.51207281e+00 7.38418932e+00 2.43285125e-02\n",
      " 2.45853794e-01 1.16392296e+01], Loss = 0.3668\n",
      "Iteration 5969: Weights = [5.50000000e+01 3.51197199e+00 7.38397735e+00 2.43278141e-02\n",
      " 2.45846737e-01 1.16394535e+01], Loss = 0.3668\n",
      "Iteration 5970: Weights = [5.50000000e+01 3.51187118e+00 7.38376538e+00 2.43271157e-02\n",
      " 2.45839680e-01 1.16396775e+01], Loss = 0.3668\n",
      "Iteration 5971: Weights = [5.50000000e+01 3.51177037e+00 7.38355342e+00 2.43264174e-02\n",
      " 2.45832622e-01 1.16399014e+01], Loss = 0.3668\n",
      "Iteration 5972: Weights = [5.50000000e+01 3.51166956e+00 7.38334147e+00 2.43257191e-02\n",
      " 2.45825565e-01 1.16401253e+01], Loss = 0.3668\n",
      "Iteration 5973: Weights = [5.50000000e+01 3.51156875e+00 7.38312952e+00 2.43250208e-02\n",
      " 2.45818509e-01 1.16403492e+01], Loss = 0.3667\n",
      "Iteration 5974: Weights = [5.50000000e+01 3.51146794e+00 7.38291757e+00 2.43243225e-02\n",
      " 2.45811452e-01 1.16405732e+01], Loss = 0.3667\n",
      "Iteration 5975: Weights = [5.50000000e+01 3.51136714e+00 7.38270564e+00 2.43236242e-02\n",
      " 2.45804396e-01 1.16407971e+01], Loss = 0.3667\n",
      "Iteration 5976: Weights = [5.50000000e+01 3.51126634e+00 7.38249371e+00 2.43229260e-02\n",
      " 2.45797340e-01 1.16410210e+01], Loss = 0.3667\n",
      "Iteration 5977: Weights = [5.50000000e+01 3.51116555e+00 7.38228178e+00 2.43222278e-02\n",
      " 2.45790284e-01 1.16412449e+01], Loss = 0.3666\n",
      "Iteration 5978: Weights = [5.50000000e+01 3.51106476e+00 7.38206987e+00 2.43215296e-02\n",
      " 2.45783228e-01 1.16414688e+01], Loss = 0.3666\n",
      "Iteration 5979: Weights = [5.50000000e+01 3.51096397e+00 7.38185795e+00 2.43208314e-02\n",
      " 2.45776173e-01 1.16416926e+01], Loss = 0.3666\n",
      "Iteration 5980: Weights = [5.50000000e+01 3.51086318e+00 7.38164605e+00 2.43201332e-02\n",
      " 2.45769117e-01 1.16419165e+01], Loss = 0.3666\n",
      "Iteration 5981: Weights = [5.50000000e+01 3.51076240e+00 7.38143415e+00 2.43194351e-02\n",
      " 2.45762062e-01 1.16421404e+01], Loss = 0.3666\n",
      "Iteration 5982: Weights = [5.50000000e+01 3.51066161e+00 7.38122225e+00 2.43187370e-02\n",
      " 2.45755007e-01 1.16423642e+01], Loss = 0.3665\n",
      "Iteration 5983: Weights = [5.50000000e+01 3.51056084e+00 7.38101037e+00 2.43180389e-02\n",
      " 2.45747952e-01 1.16425881e+01], Loss = 0.3665\n",
      "Iteration 5984: Weights = [5.50000000e+01 3.51046006e+00 7.38079848e+00 2.43173408e-02\n",
      " 2.45740898e-01 1.16428119e+01], Loss = 0.3665\n",
      "Iteration 5985: Weights = [5.50000000e+01 3.51035929e+00 7.38058661e+00 2.43166427e-02\n",
      " 2.45733844e-01 1.16430358e+01], Loss = 0.3665\n",
      "Iteration 5986: Weights = [5.50000000e+01 3.51025852e+00 7.38037474e+00 2.43159447e-02\n",
      " 2.45726789e-01 1.16432596e+01], Loss = 0.3665\n",
      "Iteration 5987: Weights = [5.50000000e+01 3.51015775e+00 7.38016288e+00 2.43152467e-02\n",
      " 2.45719736e-01 1.16434835e+01], Loss = 0.3664\n",
      "Iteration 5988: Weights = [5.50000000e+01 3.51005699e+00 7.37995102e+00 2.43145487e-02\n",
      " 2.45712682e-01 1.16437073e+01], Loss = 0.3664\n",
      "Iteration 5989: Weights = [5.50000000e+01 3.50995623e+00 7.37973917e+00 2.43138507e-02\n",
      " 2.45705628e-01 1.16439311e+01], Loss = 0.3664\n",
      "Iteration 5990: Weights = [5.50000000e+01 3.50985547e+00 7.37952732e+00 2.43131527e-02\n",
      " 2.45698575e-01 1.16441549e+01], Loss = 0.3664\n",
      "Iteration 5991: Weights = [5.50000000e+01 3.50975472e+00 7.37931548e+00 2.43124548e-02\n",
      " 2.45691522e-01 1.16443787e+01], Loss = 0.3664\n",
      "Iteration 5992: Weights = [5.50000000e+01 3.50965396e+00 7.37910365e+00 2.43117569e-02\n",
      " 2.45684469e-01 1.16446025e+01], Loss = 0.3663\n",
      "Iteration 5993: Weights = [5.50000000e+01 3.50955321e+00 7.37889182e+00 2.43110590e-02\n",
      " 2.45677416e-01 1.16448263e+01], Loss = 0.3663\n",
      "Iteration 5994: Weights = [5.50000000e+01 3.50945247e+00 7.37868000e+00 2.43103611e-02\n",
      " 2.45670364e-01 1.16450501e+01], Loss = 0.3663\n",
      "Iteration 5995: Weights = [5.50000000e+01 3.50935172e+00 7.37846819e+00 2.43096632e-02\n",
      " 2.45663312e-01 1.16452739e+01], Loss = 0.3663\n",
      "Iteration 5996: Weights = [5.50000000e+01 3.50925098e+00 7.37825638e+00 2.43089654e-02\n",
      " 2.45656260e-01 1.16454976e+01], Loss = 0.3662\n",
      "Iteration 5997: Weights = [5.50000000e+01 3.50915025e+00 7.37804458e+00 2.43082676e-02\n",
      " 2.45649208e-01 1.16457214e+01], Loss = 0.3662\n",
      "Iteration 5998: Weights = [5.50000000e+01 3.50904951e+00 7.37783278e+00 2.43075698e-02\n",
      " 2.45642156e-01 1.16459452e+01], Loss = 0.3662\n",
      "Iteration 5999: Weights = [5.50000000e+01 3.50894878e+00 7.37762099e+00 2.43068720e-02\n",
      " 2.45635104e-01 1.16461689e+01], Loss = 0.3662\n",
      "Iteration 6000: Weights = [5.50000000e+01 3.50884805e+00 7.37740921e+00 2.43061742e-02\n",
      " 2.45628053e-01 1.16463927e+01], Loss = 0.3662\n",
      "Iteration 6001: Weights = [5.50000000e+01 3.50874732e+00 7.37719743e+00 2.43054765e-02\n",
      " 2.45621002e-01 1.16466164e+01], Loss = 0.3661\n",
      "Iteration 6002: Weights = [5.50000000e+01 3.50864660e+00 7.37698566e+00 2.43047788e-02\n",
      " 2.45613951e-01 1.16468401e+01], Loss = 0.3661\n",
      "Iteration 6003: Weights = [5.50000000e+01 3.50854588e+00 7.37677389e+00 2.43040811e-02\n",
      " 2.45606901e-01 1.16470639e+01], Loss = 0.3661\n",
      "Iteration 6004: Weights = [5.50000000e+01 3.50844516e+00 7.37656213e+00 2.43033834e-02\n",
      " 2.45599850e-01 1.16472876e+01], Loss = 0.3661\n",
      "Iteration 6005: Weights = [5.50000000e+01 3.50834445e+00 7.37635038e+00 2.43026857e-02\n",
      " 2.45592800e-01 1.16475113e+01], Loss = 0.3661\n",
      "Iteration 6006: Weights = [5.50000000e+01 3.50824374e+00 7.37613863e+00 2.43019881e-02\n",
      " 2.45585750e-01 1.16477350e+01], Loss = 0.3660\n",
      "Iteration 6007: Weights = [5.50000000e+01 3.50814303e+00 7.37592689e+00 2.43012904e-02\n",
      " 2.45578700e-01 1.16479587e+01], Loss = 0.3660\n",
      "Iteration 6008: Weights = [5.50000000e+01 3.50804232e+00 7.37571515e+00 2.43005928e-02\n",
      " 2.45571650e-01 1.16481824e+01], Loss = 0.3660\n",
      "Iteration 6009: Weights = [5.50000000e+01 3.50794162e+00 7.37550342e+00 2.42998953e-02\n",
      " 2.45564601e-01 1.16484061e+01], Loss = 0.3660\n",
      "Iteration 6010: Weights = [5.50000000e+01 3.50784092e+00 7.37529170e+00 2.42991977e-02\n",
      " 2.45557552e-01 1.16486298e+01], Loss = 0.3660\n",
      "Iteration 6011: Weights = [5.50000000e+01 3.50774022e+00 7.37507998e+00 2.42985002e-02\n",
      " 2.45550502e-01 1.16488535e+01], Loss = 0.3659\n",
      "Iteration 6012: Weights = [5.50000000e+01 3.50763953e+00 7.37486827e+00 2.42978026e-02\n",
      " 2.45543454e-01 1.16490771e+01], Loss = 0.3659\n",
      "Iteration 6013: Weights = [5.50000000e+01 3.50753884e+00 7.37465656e+00 2.42971051e-02\n",
      " 2.45536405e-01 1.16493008e+01], Loss = 0.3659\n",
      "Iteration 6014: Weights = [5.50000000e+01 3.50743815e+00 7.37444487e+00 2.42964077e-02\n",
      " 2.45529357e-01 1.16495244e+01], Loss = 0.3659\n",
      "Iteration 6015: Weights = [5.50000000e+01 3.50733746e+00 7.37423317e+00 2.42957102e-02\n",
      " 2.45522308e-01 1.16497481e+01], Loss = 0.3658\n",
      "Iteration 6016: Weights = [5.50000000e+01 3.50723678e+00 7.37402149e+00 2.42950128e-02\n",
      " 2.45515260e-01 1.16499717e+01], Loss = 0.3658\n",
      "Iteration 6017: Weights = [5.50000000e+01 3.50713610e+00 7.37380980e+00 2.42943153e-02\n",
      " 2.45508212e-01 1.16501954e+01], Loss = 0.3658\n",
      "Iteration 6018: Weights = [5.50000000e+01 3.50703542e+00 7.37359813e+00 2.42936179e-02\n",
      " 2.45501165e-01 1.16504190e+01], Loss = 0.3658\n",
      "Iteration 6019: Weights = [5.50000000e+01 3.50693475e+00 7.37338646e+00 2.42929206e-02\n",
      " 2.45494117e-01 1.16506426e+01], Loss = 0.3658\n",
      "Iteration 6020: Weights = [5.50000000e+01 3.50683408e+00 7.37317480e+00 2.42922232e-02\n",
      " 2.45487070e-01 1.16508662e+01], Loss = 0.3657\n",
      "Iteration 6021: Weights = [5.50000000e+01 3.50673341e+00 7.37296314e+00 2.42915259e-02\n",
      " 2.45480023e-01 1.16510899e+01], Loss = 0.3657\n",
      "Iteration 6022: Weights = [5.50000000e+01 3.50663274e+00 7.37275149e+00 2.42908285e-02\n",
      " 2.45472976e-01 1.16513135e+01], Loss = 0.3657\n",
      "Iteration 6023: Weights = [5.50000000e+01 3.50653208e+00 7.37253985e+00 2.42901312e-02\n",
      " 2.45465930e-01 1.16515371e+01], Loss = 0.3657\n",
      "Iteration 6024: Weights = [5.50000000e+01 3.50643142e+00 7.37232821e+00 2.42894340e-02\n",
      " 2.45458883e-01 1.16517607e+01], Loss = 0.3657\n",
      "Iteration 6025: Weights = [5.50000000e+01 3.50633077e+00 7.37211658e+00 2.42887367e-02\n",
      " 2.45451837e-01 1.16519842e+01], Loss = 0.3656\n",
      "Iteration 6026: Weights = [5.50000000e+01 3.50623011e+00 7.37190495e+00 2.42880395e-02\n",
      " 2.45444791e-01 1.16522078e+01], Loss = 0.3656\n",
      "Iteration 6027: Weights = [5.50000000e+01 3.50612946e+00 7.37169333e+00 2.42873422e-02\n",
      " 2.45437745e-01 1.16524314e+01], Loss = 0.3656\n",
      "Iteration 6028: Weights = [5.50000000e+01 3.50602881e+00 7.37148171e+00 2.42866450e-02\n",
      " 2.45430700e-01 1.16526550e+01], Loss = 0.3656\n",
      "Iteration 6029: Weights = [5.50000000e+01 3.50592817e+00 7.37127011e+00 2.42859479e-02\n",
      " 2.45423654e-01 1.16528785e+01], Loss = 0.3656\n",
      "Iteration 6030: Weights = [5.50000000e+01 3.50582753e+00 7.37105850e+00 2.42852507e-02\n",
      " 2.45416609e-01 1.16531021e+01], Loss = 0.3655\n",
      "Iteration 6031: Weights = [5.50000000e+01 3.50572689e+00 7.37084691e+00 2.42845536e-02\n",
      " 2.45409564e-01 1.16533256e+01], Loss = 0.3655\n",
      "Iteration 6032: Weights = [5.50000000e+01 3.50562625e+00 7.37063532e+00 2.42838564e-02\n",
      " 2.45402519e-01 1.16535492e+01], Loss = 0.3655\n",
      "Iteration 6033: Weights = [5.50000000e+01 3.50552562e+00 7.37042374e+00 2.42831593e-02\n",
      " 2.45395475e-01 1.16537727e+01], Loss = 0.3655\n",
      "Iteration 6034: Weights = [5.50000000e+01 3.50542499e+00 7.37021216e+00 2.42824623e-02\n",
      " 2.45388430e-01 1.16539962e+01], Loss = 0.3654\n",
      "Iteration 6035: Weights = [5.50000000e+01 3.50532436e+00 7.37000059e+00 2.42817652e-02\n",
      " 2.45381386e-01 1.16542198e+01], Loss = 0.3654\n",
      "Iteration 6036: Weights = [5.50000000e+01 3.50522373e+00 7.36978902e+00 2.42810682e-02\n",
      " 2.45374342e-01 1.16544433e+01], Loss = 0.3654\n",
      "Iteration 6037: Weights = [5.50000000e+01 3.50512311e+00 7.36957746e+00 2.42803711e-02\n",
      " 2.45367298e-01 1.16546668e+01], Loss = 0.3654\n",
      "Iteration 6038: Weights = [5.50000000e+01 3.50502249e+00 7.36936591e+00 2.42796741e-02\n",
      " 2.45360255e-01 1.16548903e+01], Loss = 0.3654\n",
      "Iteration 6039: Weights = [5.50000000e+01 3.50492188e+00 7.36915436e+00 2.42789772e-02\n",
      " 2.45353211e-01 1.16551138e+01], Loss = 0.3653\n",
      "Iteration 6040: Weights = [5.50000000e+01 3.50482126e+00 7.36894282e+00 2.42782802e-02\n",
      " 2.45346168e-01 1.16553373e+01], Loss = 0.3653\n",
      "Iteration 6041: Weights = [5.50000000e+01 3.50472065e+00 7.36873128e+00 2.42775833e-02\n",
      " 2.45339125e-01 1.16555607e+01], Loss = 0.3653\n",
      "Iteration 6042: Weights = [5.50000000e+01 3.50462004e+00 7.36851976e+00 2.42768863e-02\n",
      " 2.45332082e-01 1.16557842e+01], Loss = 0.3653\n",
      "Iteration 6043: Weights = [5.50000000e+01 3.50451944e+00 7.36830823e+00 2.42761894e-02\n",
      " 2.45325040e-01 1.16560077e+01], Loss = 0.3653\n",
      "Iteration 6044: Weights = [5.50000000e+01 3.50441884e+00 7.36809672e+00 2.42754926e-02\n",
      " 2.45317997e-01 1.16562312e+01], Loss = 0.3652\n",
      "Iteration 6045: Weights = [5.50000000e+01 3.50431824e+00 7.36788520e+00 2.42747957e-02\n",
      " 2.45310955e-01 1.16564546e+01], Loss = 0.3652\n",
      "Iteration 6046: Weights = [5.50000000e+01 3.50421764e+00 7.36767370e+00 2.42740989e-02\n",
      " 2.45303913e-01 1.16566781e+01], Loss = 0.3652\n",
      "Iteration 6047: Weights = [5.50000000e+01 3.50411705e+00 7.36746220e+00 2.42734020e-02\n",
      " 2.45296871e-01 1.16569015e+01], Loss = 0.3652\n",
      "Iteration 6048: Weights = [5.50000000e+01 3.50401646e+00 7.36725071e+00 2.42727053e-02\n",
      " 2.45289830e-01 1.16571250e+01], Loss = 0.3652\n",
      "Iteration 6049: Weights = [5.50000000e+01 3.50391587e+00 7.36703922e+00 2.42720085e-02\n",
      " 2.45282788e-01 1.16573484e+01], Loss = 0.3651\n",
      "Iteration 6050: Weights = [5.50000000e+01 3.50381529e+00 7.36682774e+00 2.42713117e-02\n",
      " 2.45275747e-01 1.16575718e+01], Loss = 0.3651\n",
      "Iteration 6051: Weights = [5.50000000e+01 3.50371471e+00 7.36661627e+00 2.42706150e-02\n",
      " 2.45268706e-01 1.16577952e+01], Loss = 0.3651\n",
      "Iteration 6052: Weights = [5.50000000e+01 3.50361413e+00 7.36640480e+00 2.42699183e-02\n",
      " 2.45261666e-01 1.16580186e+01], Loss = 0.3651\n",
      "Iteration 6053: Weights = [5.50000000e+01 3.50351355e+00 7.36619334e+00 2.42692216e-02\n",
      " 2.45254625e-01 1.16582421e+01], Loss = 0.3650\n",
      "Iteration 6054: Weights = [5.50000000e+01 3.50341298e+00 7.36598188e+00 2.42685249e-02\n",
      " 2.45247585e-01 1.16584655e+01], Loss = 0.3650\n",
      "Iteration 6055: Weights = [5.50000000e+01 3.50331241e+00 7.36577043e+00 2.42678282e-02\n",
      " 2.45240544e-01 1.16586888e+01], Loss = 0.3650\n",
      "Iteration 6056: Weights = [5.50000000e+01 3.50321184e+00 7.36555899e+00 2.42671316e-02\n",
      " 2.45233505e-01 1.16589122e+01], Loss = 0.3650\n",
      "Iteration 6057: Weights = [5.50000000e+01 3.50311128e+00 7.36534755e+00 2.42664350e-02\n",
      " 2.45226465e-01 1.16591356e+01], Loss = 0.3650\n",
      "Iteration 6058: Weights = [5.50000000e+01 3.50301072e+00 7.36513612e+00 2.42657384e-02\n",
      " 2.45219425e-01 1.16593590e+01], Loss = 0.3649\n",
      "Iteration 6059: Weights = [5.50000000e+01 3.50291016e+00 7.36492469e+00 2.42650418e-02\n",
      " 2.45212386e-01 1.16595824e+01], Loss = 0.3649\n",
      "Iteration 6060: Weights = [5.50000000e+01 3.50280960e+00 7.36471327e+00 2.42643452e-02\n",
      " 2.45205347e-01 1.16598057e+01], Loss = 0.3649\n",
      "Iteration 6061: Weights = [5.50000000e+01 3.50270905e+00 7.36450186e+00 2.42636487e-02\n",
      " 2.45198308e-01 1.16600291e+01], Loss = 0.3649\n",
      "Iteration 6062: Weights = [5.50000000e+01 3.50260850e+00 7.36429045e+00 2.42629522e-02\n",
      " 2.45191269e-01 1.16602524e+01], Loss = 0.3649\n",
      "Iteration 6063: Weights = [5.50000000e+01 3.50250795e+00 7.36407905e+00 2.42622557e-02\n",
      " 2.45184231e-01 1.16604758e+01], Loss = 0.3648\n",
      "Iteration 6064: Weights = [5.50000000e+01 3.50240741e+00 7.36386765e+00 2.42615592e-02\n",
      " 2.45177192e-01 1.16606991e+01], Loss = 0.3648\n",
      "Iteration 6065: Weights = [5.50000000e+01 3.50230687e+00 7.36365626e+00 2.42608627e-02\n",
      " 2.45170154e-01 1.16609224e+01], Loss = 0.3648\n",
      "Iteration 6066: Weights = [5.50000000e+01 3.50220633e+00 7.36344488e+00 2.42601663e-02\n",
      " 2.45163116e-01 1.16611458e+01], Loss = 0.3648\n",
      "Iteration 6067: Weights = [5.50000000e+01 3.50210579e+00 7.36323350e+00 2.42594699e-02\n",
      " 2.45156078e-01 1.16613691e+01], Loss = 0.3648\n",
      "Iteration 6068: Weights = [5.50000000e+01 3.50200526e+00 7.36302213e+00 2.42587735e-02\n",
      " 2.45149041e-01 1.16615924e+01], Loss = 0.3647\n",
      "Iteration 6069: Weights = [5.50000000e+01 3.50190473e+00 7.36281076e+00 2.42580771e-02\n",
      " 2.45142004e-01 1.16618157e+01], Loss = 0.3647\n",
      "Iteration 6070: Weights = [5.50000000e+01 3.50180420e+00 7.36259941e+00 2.42573807e-02\n",
      " 2.45134966e-01 1.16620390e+01], Loss = 0.3647\n",
      "Iteration 6071: Weights = [5.50000000e+01 3.50170368e+00 7.36238805e+00 2.42566844e-02\n",
      " 2.45127930e-01 1.16622623e+01], Loss = 0.3647\n",
      "Iteration 6072: Weights = [5.50000000e+01 3.50160316e+00 7.36217671e+00 2.42559881e-02\n",
      " 2.45120893e-01 1.16624856e+01], Loss = 0.3647\n",
      "Iteration 6073: Weights = [5.50000000e+01 3.50150264e+00 7.36196536e+00 2.42552918e-02\n",
      " 2.45113856e-01 1.16627088e+01], Loss = 0.3646\n",
      "Iteration 6074: Weights = [5.50000000e+01 3.50140213e+00 7.36175403e+00 2.42545955e-02\n",
      " 2.45106820e-01 1.16629321e+01], Loss = 0.3646\n",
      "Iteration 6075: Weights = [5.50000000e+01 3.50130161e+00 7.36154270e+00 2.42538992e-02\n",
      " 2.45099784e-01 1.16631554e+01], Loss = 0.3646\n",
      "Iteration 6076: Weights = [5.50000000e+01 3.50120110e+00 7.36133138e+00 2.42532030e-02\n",
      " 2.45092748e-01 1.16633786e+01], Loss = 0.3646\n",
      "Iteration 6077: Weights = [5.50000000e+01 3.50110060e+00 7.36112006e+00 2.42525068e-02\n",
      " 2.45085712e-01 1.16636019e+01], Loss = 0.3645\n",
      "Iteration 6078: Weights = [5.50000000e+01 3.50100009e+00 7.36090875e+00 2.42518106e-02\n",
      " 2.45078677e-01 1.16638251e+01], Loss = 0.3645\n",
      "Iteration 6079: Weights = [5.50000000e+01 3.50089959e+00 7.36069745e+00 2.42511144e-02\n",
      " 2.45071641e-01 1.16640484e+01], Loss = 0.3645\n",
      "Iteration 6080: Weights = [5.50000000e+01 3.50079909e+00 7.36048615e+00 2.42504182e-02\n",
      " 2.45064606e-01 1.16642716e+01], Loss = 0.3645\n",
      "Iteration 6081: Weights = [5.50000000e+01 3.50069860e+00 7.36027486e+00 2.42497221e-02\n",
      " 2.45057571e-01 1.16644948e+01], Loss = 0.3645\n",
      "Iteration 6082: Weights = [5.50000000e+01 3.50059811e+00 7.36006357e+00 2.42490260e-02\n",
      " 2.45050537e-01 1.16647181e+01], Loss = 0.3644\n",
      "Iteration 6083: Weights = [5.50000000e+01 3.50049762e+00 7.35985229e+00 2.42483299e-02\n",
      " 2.45043502e-01 1.16649413e+01], Loss = 0.3644\n",
      "Iteration 6084: Weights = [5.50000000e+01 3.50039713e+00 7.35964102e+00 2.42476338e-02\n",
      " 2.45036468e-01 1.16651645e+01], Loss = 0.3644\n",
      "Iteration 6085: Weights = [5.50000000e+01 3.50029665e+00 7.35942975e+00 2.42469377e-02\n",
      " 2.45029434e-01 1.16653877e+01], Loss = 0.3644\n",
      "Iteration 6086: Weights = [5.50000000e+01 3.50019617e+00 7.35921848e+00 2.42462417e-02\n",
      " 2.45022400e-01 1.16656109e+01], Loss = 0.3644\n",
      "Iteration 6087: Weights = [5.50000000e+01 3.50009569e+00 7.35900723e+00 2.42455457e-02\n",
      " 2.45015366e-01 1.16658341e+01], Loss = 0.3643\n",
      "Iteration 6088: Weights = [5.50000000e+01 3.49999522e+00 7.35879598e+00 2.42448497e-02\n",
      " 2.45008333e-01 1.16660572e+01], Loss = 0.3643\n",
      "Iteration 6089: Weights = [5.50000000e+01 3.49989474e+00 7.35858474e+00 2.42441537e-02\n",
      " 2.45001300e-01 1.16662804e+01], Loss = 0.3643\n",
      "Iteration 6090: Weights = [5.50000000e+01 3.49979427e+00 7.35837350e+00 2.42434577e-02\n",
      " 2.44994266e-01 1.16665036e+01], Loss = 0.3643\n",
      "Iteration 6091: Weights = [5.50000000e+01 3.49969381e+00 7.35816227e+00 2.42427618e-02\n",
      " 2.44987234e-01 1.16667267e+01], Loss = 0.3643\n",
      "Iteration 6092: Weights = [5.50000000e+01 3.49959335e+00 7.35795104e+00 2.42420659e-02\n",
      " 2.44980201e-01 1.16669499e+01], Loss = 0.3642\n",
      "Iteration 6093: Weights = [5.50000000e+01 3.49949288e+00 7.35773982e+00 2.42413700e-02\n",
      " 2.44973168e-01 1.16671731e+01], Loss = 0.3642\n",
      "Iteration 6094: Weights = [5.50000000e+01 3.49939243e+00 7.35752861e+00 2.42406741e-02\n",
      " 2.44966136e-01 1.16673962e+01], Loss = 0.3642\n",
      "Iteration 6095: Weights = [5.50000000e+01 3.49929197e+00 7.35731740e+00 2.42399782e-02\n",
      " 2.44959104e-01 1.16676193e+01], Loss = 0.3642\n",
      "Iteration 6096: Weights = [5.50000000e+01 3.49919152e+00 7.35710620e+00 2.42392824e-02\n",
      " 2.44952072e-01 1.16678425e+01], Loss = 0.3641\n",
      "Iteration 6097: Weights = [5.50000000e+01 3.49909107e+00 7.35689500e+00 2.42385866e-02\n",
      " 2.44945040e-01 1.16680656e+01], Loss = 0.3641\n",
      "Iteration 6098: Weights = [5.50000000e+01 3.49899063e+00 7.35668381e+00 2.42378908e-02\n",
      " 2.44938009e-01 1.16682887e+01], Loss = 0.3641\n",
      "Iteration 6099: Weights = [5.50000000e+01 3.49889018e+00 7.35647263e+00 2.42371950e-02\n",
      " 2.44930978e-01 1.16685118e+01], Loss = 0.3641\n",
      "Iteration 6100: Weights = [5.50000000e+01 3.49878974e+00 7.35626145e+00 2.42364992e-02\n",
      " 2.44923947e-01 1.16687349e+01], Loss = 0.3641\n",
      "Iteration 6101: Weights = [5.50000000e+01 3.49868931e+00 7.35605028e+00 2.42358035e-02\n",
      " 2.44916916e-01 1.16689580e+01], Loss = 0.3640\n",
      "Iteration 6102: Weights = [5.50000000e+01 3.49858887e+00 7.35583912e+00 2.42351078e-02\n",
      " 2.44909885e-01 1.16691811e+01], Loss = 0.3640\n",
      "Iteration 6103: Weights = [5.50000000e+01 3.49848844e+00 7.35562796e+00 2.42344121e-02\n",
      " 2.44902855e-01 1.16694042e+01], Loss = 0.3640\n",
      "Iteration 6104: Weights = [5.50000000e+01 3.49838801e+00 7.35541680e+00 2.42337164e-02\n",
      " 2.44895824e-01 1.16696273e+01], Loss = 0.3640\n",
      "Iteration 6105: Weights = [5.50000000e+01 3.49828758e+00 7.35520566e+00 2.42330207e-02\n",
      " 2.44888794e-01 1.16698504e+01], Loss = 0.3640\n",
      "Iteration 6106: Weights = [5.50000000e+01 3.49818716e+00 7.35499452e+00 2.42323251e-02\n",
      " 2.44881765e-01 1.16700734e+01], Loss = 0.3639\n",
      "Iteration 6107: Weights = [5.50000000e+01 3.49808674e+00 7.35478338e+00 2.42316294e-02\n",
      " 2.44874735e-01 1.16702965e+01], Loss = 0.3639\n",
      "Iteration 6108: Weights = [5.50000000e+01 3.49798632e+00 7.35457225e+00 2.42309338e-02\n",
      " 2.44867705e-01 1.16705195e+01], Loss = 0.3639\n",
      "Iteration 6109: Weights = [5.50000000e+01 3.49788591e+00 7.35436113e+00 2.42302383e-02\n",
      " 2.44860676e-01 1.16707426e+01], Loss = 0.3639\n",
      "Iteration 6110: Weights = [5.50000000e+01 3.49778550e+00 7.35415001e+00 2.42295427e-02\n",
      " 2.44853647e-01 1.16709656e+01], Loss = 0.3639\n",
      "Iteration 6111: Weights = [5.50000000e+01 3.49768509e+00 7.35393890e+00 2.42288472e-02\n",
      " 2.44846618e-01 1.16711887e+01], Loss = 0.3638\n",
      "Iteration 6112: Weights = [5.50000000e+01 3.49758468e+00 7.35372780e+00 2.42281516e-02\n",
      " 2.44839590e-01 1.16714117e+01], Loss = 0.3638\n",
      "Iteration 6113: Weights = [5.50000000e+01 3.49748428e+00 7.35351670e+00 2.42274561e-02\n",
      " 2.44832561e-01 1.16716347e+01], Loss = 0.3638\n",
      "Iteration 6114: Weights = [5.50000000e+01 3.49738388e+00 7.35330561e+00 2.42267607e-02\n",
      " 2.44825533e-01 1.16718577e+01], Loss = 0.3638\n",
      "Iteration 6115: Weights = [5.50000000e+01 3.49728349e+00 7.35309452e+00 2.42260652e-02\n",
      " 2.44818505e-01 1.16720807e+01], Loss = 0.3638\n",
      "Iteration 6116: Weights = [5.50000000e+01 3.49718309e+00 7.35288344e+00 2.42253698e-02\n",
      " 2.44811477e-01 1.16723037e+01], Loss = 0.3637\n",
      "Iteration 6117: Weights = [5.50000000e+01 3.49708270e+00 7.35267237e+00 2.42246743e-02\n",
      " 2.44804449e-01 1.16725267e+01], Loss = 0.3637\n",
      "Iteration 6118: Weights = [5.50000000e+01 3.49698231e+00 7.35246130e+00 2.42239789e-02\n",
      " 2.44797422e-01 1.16727497e+01], Loss = 0.3637\n",
      "Iteration 6119: Weights = [5.50000000e+01 3.49688193e+00 7.35225024e+00 2.42232836e-02\n",
      " 2.44790395e-01 1.16729727e+01], Loss = 0.3637\n",
      "Iteration 6120: Weights = [5.50000000e+01 3.49678154e+00 7.35203918e+00 2.42225882e-02\n",
      " 2.44783368e-01 1.16731957e+01], Loss = 0.3636\n",
      "Iteration 6121: Weights = [5.50000000e+01 3.49668116e+00 7.35182813e+00 2.42218929e-02\n",
      " 2.44776341e-01 1.16734187e+01], Loss = 0.3636\n",
      "Iteration 6122: Weights = [5.50000000e+01 3.49658079e+00 7.35161709e+00 2.42211975e-02\n",
      " 2.44769314e-01 1.16736416e+01], Loss = 0.3636\n",
      "Iteration 6123: Weights = [5.50000000e+01 3.49648041e+00 7.35140605e+00 2.42205022e-02\n",
      " 2.44762288e-01 1.16738646e+01], Loss = 0.3636\n",
      "Iteration 6124: Weights = [5.50000000e+01 3.49638004e+00 7.35119502e+00 2.42198070e-02\n",
      " 2.44755262e-01 1.16740875e+01], Loss = 0.3636\n",
      "Iteration 6125: Weights = [5.50000000e+01 3.49627967e+00 7.35098399e+00 2.42191117e-02\n",
      " 2.44748236e-01 1.16743105e+01], Loss = 0.3635\n",
      "Iteration 6126: Weights = [5.50000000e+01 3.49617931e+00 7.35077297e+00 2.42184164e-02\n",
      " 2.44741210e-01 1.16745334e+01], Loss = 0.3635\n",
      "Iteration 6127: Weights = [5.50000000e+01 3.49607895e+00 7.35056196e+00 2.42177212e-02\n",
      " 2.44734184e-01 1.16747563e+01], Loss = 0.3635\n",
      "Iteration 6128: Weights = [5.50000000e+01 3.49597859e+00 7.35035095e+00 2.42170260e-02\n",
      " 2.44727159e-01 1.16749793e+01], Loss = 0.3635\n",
      "Iteration 6129: Weights = [5.50000000e+01 3.49587823e+00 7.35013995e+00 2.42163308e-02\n",
      " 2.44720134e-01 1.16752022e+01], Loss = 0.3635\n",
      "Iteration 6130: Weights = [5.50000000e+01 3.49577788e+00 7.34992896e+00 2.42156357e-02\n",
      " 2.44713109e-01 1.16754251e+01], Loss = 0.3634\n",
      "Iteration 6131: Weights = [5.50000000e+01 3.49567753e+00 7.34971797e+00 2.42149405e-02\n",
      " 2.44706084e-01 1.16756480e+01], Loss = 0.3634\n",
      "Iteration 6132: Weights = [5.50000000e+01 3.49557718e+00 7.34950698e+00 2.42142454e-02\n",
      " 2.44699059e-01 1.16758709e+01], Loss = 0.3634\n",
      "Iteration 6133: Weights = [5.50000000e+01 3.49547683e+00 7.34929601e+00 2.42135503e-02\n",
      " 2.44692035e-01 1.16760938e+01], Loss = 0.3634\n",
      "Iteration 6134: Weights = [5.50000000e+01 3.49537649e+00 7.34908503e+00 2.42128552e-02\n",
      " 2.44685011e-01 1.16763167e+01], Loss = 0.3634\n",
      "Iteration 6135: Weights = [5.50000000e+01 3.49527615e+00 7.34887407e+00 2.42121602e-02\n",
      " 2.44677987e-01 1.16765396e+01], Loss = 0.3633\n",
      "Iteration 6136: Weights = [5.50000000e+01 3.49517581e+00 7.34866311e+00 2.42114651e-02\n",
      " 2.44670963e-01 1.16767625e+01], Loss = 0.3633\n",
      "Iteration 6137: Weights = [5.50000000e+01 3.49507548e+00 7.34845216e+00 2.42107701e-02\n",
      " 2.44663939e-01 1.16769853e+01], Loss = 0.3633\n",
      "Iteration 6138: Weights = [5.50000000e+01 3.49497515e+00 7.34824121e+00 2.42100751e-02\n",
      " 2.44656916e-01 1.16772082e+01], Loss = 0.3633\n",
      "Iteration 6139: Weights = [5.50000000e+01 3.49487482e+00 7.34803027e+00 2.42093801e-02\n",
      " 2.44649893e-01 1.16774310e+01], Loss = 0.3633\n",
      "Iteration 6140: Weights = [5.50000000e+01 3.49477450e+00 7.34781933e+00 2.42086852e-02\n",
      " 2.44642870e-01 1.16776539e+01], Loss = 0.3632\n",
      "Iteration 6141: Weights = [5.50000000e+01 3.49467417e+00 7.34760841e+00 2.42079902e-02\n",
      " 2.44635847e-01 1.16778767e+01], Loss = 0.3632\n",
      "Iteration 6142: Weights = [5.50000000e+01 3.49457386e+00 7.34739748e+00 2.42072953e-02\n",
      " 2.44628824e-01 1.16780996e+01], Loss = 0.3632\n",
      "Iteration 6143: Weights = [5.50000000e+01 3.49447354e+00 7.34718657e+00 2.42066004e-02\n",
      " 2.44621802e-01 1.16783224e+01], Loss = 0.3632\n",
      "Iteration 6144: Weights = [5.50000000e+01 3.49437323e+00 7.34697566e+00 2.42059055e-02\n",
      " 2.44614780e-01 1.16785452e+01], Loss = 0.3631\n",
      "Iteration 6145: Weights = [5.50000000e+01 3.49427292e+00 7.34676475e+00 2.42052107e-02\n",
      " 2.44607758e-01 1.16787680e+01], Loss = 0.3631\n",
      "Iteration 6146: Weights = [5.50000000e+01 3.49417261e+00 7.34655385e+00 2.42045158e-02\n",
      " 2.44600736e-01 1.16789909e+01], Loss = 0.3631\n",
      "Iteration 6147: Weights = [5.50000000e+01 3.49407230e+00 7.34634296e+00 2.42038210e-02\n",
      " 2.44593714e-01 1.16792137e+01], Loss = 0.3631\n",
      "Iteration 6148: Weights = [5.50000000e+01 3.49397200e+00 7.34613207e+00 2.42031262e-02\n",
      " 2.44586693e-01 1.16794365e+01], Loss = 0.3631\n",
      "Iteration 6149: Weights = [5.50000000e+01 3.49387170e+00 7.34592119e+00 2.42024314e-02\n",
      " 2.44579672e-01 1.16796592e+01], Loss = 0.3630\n",
      "Iteration 6150: Weights = [5.50000000e+01 3.49377141e+00 7.34571032e+00 2.42017366e-02\n",
      " 2.44572651e-01 1.16798820e+01], Loss = 0.3630\n",
      "Iteration 6151: Weights = [5.50000000e+01 3.49367111e+00 7.34549945e+00 2.42010419e-02\n",
      " 2.44565630e-01 1.16801048e+01], Loss = 0.3630\n",
      "Iteration 6152: Weights = [5.50000000e+01 3.49357082e+00 7.34528859e+00 2.42003472e-02\n",
      " 2.44558609e-01 1.16803276e+01], Loss = 0.3630\n",
      "Iteration 6153: Weights = [5.50000000e+01 3.49347053e+00 7.34507773e+00 2.41996525e-02\n",
      " 2.44551589e-01 1.16805503e+01], Loss = 0.3630\n",
      "Iteration 6154: Weights = [5.50000000e+01 3.49337025e+00 7.34486688e+00 2.41989578e-02\n",
      " 2.44544569e-01 1.16807731e+01], Loss = 0.3629\n",
      "Iteration 6155: Weights = [5.50000000e+01 3.49326997e+00 7.34465604e+00 2.41982631e-02\n",
      " 2.44537549e-01 1.16809959e+01], Loss = 0.3629\n",
      "Iteration 6156: Weights = [5.50000000e+01 3.49316969e+00 7.34444520e+00 2.41975685e-02\n",
      " 2.44530529e-01 1.16812186e+01], Loss = 0.3629\n",
      "Iteration 6157: Weights = [5.50000000e+01 3.49306941e+00 7.34423437e+00 2.41968739e-02\n",
      " 2.44523509e-01 1.16814413e+01], Loss = 0.3629\n",
      "Iteration 6158: Weights = [5.50000000e+01 3.49296914e+00 7.34402354e+00 2.41961793e-02\n",
      " 2.44516490e-01 1.16816641e+01], Loss = 0.3629\n",
      "Iteration 6159: Weights = [5.50000000e+01 3.49286887e+00 7.34381272e+00 2.41954847e-02\n",
      " 2.44509471e-01 1.16818868e+01], Loss = 0.3628\n",
      "Iteration 6160: Weights = [5.50000000e+01 3.49276860e+00 7.34360191e+00 2.41947901e-02\n",
      " 2.44502452e-01 1.16821095e+01], Loss = 0.3628\n",
      "Iteration 6161: Weights = [5.50000000e+01 3.49266834e+00 7.34339110e+00 2.41940956e-02\n",
      " 2.44495433e-01 1.16823322e+01], Loss = 0.3628\n",
      "Iteration 6162: Weights = [5.50000000e+01 3.49256808e+00 7.34318030e+00 2.41934011e-02\n",
      " 2.44488415e-01 1.16825550e+01], Loss = 0.3628\n",
      "Iteration 6163: Weights = [5.50000000e+01 3.49246782e+00 7.34296950e+00 2.41927065e-02\n",
      " 2.44481396e-01 1.16827777e+01], Loss = 0.3628\n",
      "Iteration 6164: Weights = [5.50000000e+01 3.49236756e+00 7.34275871e+00 2.41920121e-02\n",
      " 2.44474378e-01 1.16830004e+01], Loss = 0.3627\n",
      "Iteration 6165: Weights = [5.50000000e+01 3.49226731e+00 7.34254793e+00 2.41913176e-02\n",
      " 2.44467360e-01 1.16832230e+01], Loss = 0.3627\n",
      "Iteration 6166: Weights = [5.50000000e+01 3.49216706e+00 7.34233715e+00 2.41906232e-02\n",
      " 2.44460342e-01 1.16834457e+01], Loss = 0.3627\n",
      "Iteration 6167: Weights = [5.50000000e+01 3.49206681e+00 7.34212638e+00 2.41899287e-02\n",
      " 2.44453325e-01 1.16836684e+01], Loss = 0.3627\n",
      "Iteration 6168: Weights = [5.50000000e+01 3.49196657e+00 7.34191562e+00 2.41892343e-02\n",
      " 2.44446308e-01 1.16838911e+01], Loss = 0.3626\n",
      "Iteration 6169: Weights = [5.50000000e+01 3.49186633e+00 7.34170486e+00 2.41885399e-02\n",
      " 2.44439290e-01 1.16841137e+01], Loss = 0.3626\n",
      "Iteration 6170: Weights = [5.50000000e+01 3.49176609e+00 7.34149410e+00 2.41878456e-02\n",
      " 2.44432273e-01 1.16843364e+01], Loss = 0.3626\n",
      "Iteration 6171: Weights = [5.50000000e+01 3.49166585e+00 7.34128336e+00 2.41871512e-02\n",
      " 2.44425257e-01 1.16845590e+01], Loss = 0.3626\n",
      "Iteration 6172: Weights = [5.50000000e+01 3.49156562e+00 7.34107262e+00 2.41864569e-02\n",
      " 2.44418240e-01 1.16847817e+01], Loss = 0.3626\n",
      "Iteration 6173: Weights = [5.50000000e+01 3.49146539e+00 7.34086188e+00 2.41857626e-02\n",
      " 2.44411224e-01 1.16850043e+01], Loss = 0.3625\n",
      "Iteration 6174: Weights = [5.50000000e+01 3.49136516e+00 7.34065115e+00 2.41850683e-02\n",
      " 2.44404208e-01 1.16852270e+01], Loss = 0.3625\n",
      "Iteration 6175: Weights = [5.50000000e+01 3.49126494e+00 7.34044043e+00 2.41843741e-02\n",
      " 2.44397192e-01 1.16854496e+01], Loss = 0.3625\n",
      "Iteration 6176: Weights = [5.50000000e+01 3.49116472e+00 7.34022971e+00 2.41836798e-02\n",
      " 2.44390176e-01 1.16856722e+01], Loss = 0.3625\n",
      "Iteration 6177: Weights = [5.50000000e+01 3.49106450e+00 7.34001900e+00 2.41829856e-02\n",
      " 2.44383160e-01 1.16858948e+01], Loss = 0.3625\n",
      "Iteration 6178: Weights = [5.50000000e+01 3.49096428e+00 7.33980830e+00 2.41822914e-02\n",
      " 2.44376145e-01 1.16861174e+01], Loss = 0.3624\n",
      "Iteration 6179: Weights = [5.50000000e+01 3.49086407e+00 7.33959760e+00 2.41815972e-02\n",
      " 2.44369130e-01 1.16863400e+01], Loss = 0.3624\n",
      "Iteration 6180: Weights = [5.50000000e+01 3.49076386e+00 7.33938690e+00 2.41809030e-02\n",
      " 2.44362115e-01 1.16865626e+01], Loss = 0.3624\n",
      "Iteration 6181: Weights = [5.50000000e+01 3.49066365e+00 7.33917622e+00 2.41802089e-02\n",
      " 2.44355100e-01 1.16867852e+01], Loss = 0.3624\n",
      "Iteration 6182: Weights = [5.50000000e+01 3.49056345e+00 7.33896554e+00 2.41795148e-02\n",
      " 2.44348086e-01 1.16870078e+01], Loss = 0.3624\n",
      "Iteration 6183: Weights = [5.50000000e+01 3.49046325e+00 7.33875486e+00 2.41788207e-02\n",
      " 2.44341071e-01 1.16872304e+01], Loss = 0.3623\n",
      "Iteration 6184: Weights = [5.50000000e+01 3.49036305e+00 7.33854419e+00 2.41781266e-02\n",
      " 2.44334057e-01 1.16874529e+01], Loss = 0.3623\n",
      "Iteration 6185: Weights = [5.50000000e+01 3.49026285e+00 7.33833353e+00 2.41774325e-02\n",
      " 2.44327043e-01 1.16876755e+01], Loss = 0.3623\n",
      "Iteration 6186: Weights = [5.50000000e+01 3.49016266e+00 7.33812288e+00 2.41767385e-02\n",
      " 2.44320030e-01 1.16878980e+01], Loss = 0.3623\n",
      "Iteration 6187: Weights = [5.50000000e+01 3.49006247e+00 7.33791222e+00 2.41760444e-02\n",
      " 2.44313016e-01 1.16881206e+01], Loss = 0.3623\n",
      "Iteration 6188: Weights = [5.50000000e+01 3.48996228e+00 7.33770158e+00 2.41753504e-02\n",
      " 2.44306003e-01 1.16883431e+01], Loss = 0.3622\n",
      "Iteration 6189: Weights = [5.50000000e+01 3.48986210e+00 7.33749094e+00 2.41746565e-02\n",
      " 2.44298990e-01 1.16885657e+01], Loss = 0.3622\n",
      "Iteration 6190: Weights = [5.50000000e+01 3.48976192e+00 7.33728031e+00 2.41739625e-02\n",
      " 2.44291977e-01 1.16887882e+01], Loss = 0.3622\n",
      "Iteration 6191: Weights = [5.50000000e+01 3.48966174e+00 7.33706968e+00 2.41732685e-02\n",
      " 2.44284964e-01 1.16890107e+01], Loss = 0.3622\n",
      "Iteration 6192: Weights = [5.50000000e+01 3.48956157e+00 7.33685906e+00 2.41725746e-02\n",
      " 2.44277951e-01 1.16892332e+01], Loss = 0.3621\n",
      "Iteration 6193: Weights = [5.50000000e+01 3.48946139e+00 7.33664845e+00 2.41718807e-02\n",
      " 2.44270939e-01 1.16894558e+01], Loss = 0.3621\n",
      "Iteration 6194: Weights = [5.50000000e+01 3.48936122e+00 7.33643784e+00 2.41711868e-02\n",
      " 2.44263927e-01 1.16896783e+01], Loss = 0.3621\n",
      "Iteration 6195: Weights = [5.50000000e+01 3.48926106e+00 7.33622724e+00 2.41704930e-02\n",
      " 2.44256915e-01 1.16899008e+01], Loss = 0.3621\n",
      "Iteration 6196: Weights = [5.50000000e+01 3.48916089e+00 7.33601664e+00 2.41697991e-02\n",
      " 2.44249903e-01 1.16901232e+01], Loss = 0.3621\n",
      "Iteration 6197: Weights = [5.50000000e+01 3.48906073e+00 7.33580605e+00 2.41691053e-02\n",
      " 2.44242892e-01 1.16903457e+01], Loss = 0.3620\n",
      "Iteration 6198: Weights = [5.50000000e+01 3.48896057e+00 7.33559547e+00 2.41684115e-02\n",
      " 2.44235881e-01 1.16905682e+01], Loss = 0.3620\n",
      "Iteration 6199: Weights = [5.50000000e+01 3.48886042e+00 7.33538489e+00 2.41677177e-02\n",
      " 2.44228869e-01 1.16907907e+01], Loss = 0.3620\n",
      "Iteration 6200: Weights = [5.50000000e+01 3.48876027e+00 7.33517432e+00 2.41670239e-02\n",
      " 2.44221859e-01 1.16910131e+01], Loss = 0.3620\n",
      "Iteration 6201: Weights = [5.50000000e+01 3.48866012e+00 7.33496375e+00 2.41663302e-02\n",
      " 2.44214848e-01 1.16912356e+01], Loss = 0.3620\n",
      "Iteration 6202: Weights = [5.50000000e+01 3.48855997e+00 7.33475319e+00 2.41656365e-02\n",
      " 2.44207837e-01 1.16914581e+01], Loss = 0.3619\n",
      "Iteration 6203: Weights = [5.50000000e+01 3.48845983e+00 7.33454264e+00 2.41649428e-02\n",
      " 2.44200827e-01 1.16916805e+01], Loss = 0.3619\n",
      "Iteration 6204: Weights = [5.50000000e+01 3.48835969e+00 7.33433209e+00 2.41642491e-02\n",
      " 2.44193817e-01 1.16919029e+01], Loss = 0.3619\n",
      "Iteration 6205: Weights = [5.50000000e+01 3.48825955e+00 7.33412155e+00 2.41635554e-02\n",
      " 2.44186807e-01 1.16921254e+01], Loss = 0.3619\n",
      "Iteration 6206: Weights = [5.50000000e+01 3.48815941e+00 7.33391102e+00 2.41628618e-02\n",
      " 2.44179797e-01 1.16923478e+01], Loss = 0.3619\n",
      "Iteration 6207: Weights = [5.50000000e+01 3.48805928e+00 7.33370049e+00 2.41621681e-02\n",
      " 2.44172788e-01 1.16925702e+01], Loss = 0.3618\n",
      "Iteration 6208: Weights = [5.50000000e+01 3.48795915e+00 7.33348996e+00 2.41614745e-02\n",
      " 2.44165779e-01 1.16927926e+01], Loss = 0.3618\n",
      "Iteration 6209: Weights = [5.50000000e+01 3.48785903e+00 7.33327945e+00 2.41607809e-02\n",
      " 2.44158769e-01 1.16930150e+01], Loss = 0.3618\n",
      "Iteration 6210: Weights = [5.50000000e+01 3.48775890e+00 7.33306893e+00 2.41600874e-02\n",
      " 2.44151761e-01 1.16932375e+01], Loss = 0.3618\n",
      "Iteration 6211: Weights = [5.50000000e+01 3.48765878e+00 7.33285843e+00 2.41593938e-02\n",
      " 2.44144752e-01 1.16934598e+01], Loss = 0.3618\n",
      "Iteration 6212: Weights = [5.50000000e+01 3.48755866e+00 7.33264793e+00 2.41587003e-02\n",
      " 2.44137743e-01 1.16936822e+01], Loss = 0.3617\n",
      "Iteration 6213: Weights = [5.50000000e+01 3.48745855e+00 7.33243744e+00 2.41580068e-02\n",
      " 2.44130735e-01 1.16939046e+01], Loss = 0.3617\n",
      "Iteration 6214: Weights = [5.50000000e+01 3.48735844e+00 7.33222695e+00 2.41573133e-02\n",
      " 2.44123727e-01 1.16941270e+01], Loss = 0.3617\n",
      "Iteration 6215: Weights = [5.50000000e+01 3.48725833e+00 7.33201647e+00 2.41566198e-02\n",
      " 2.44116719e-01 1.16943494e+01], Loss = 0.3617\n",
      "Iteration 6216: Weights = [5.50000000e+01 3.48715822e+00 7.33180599e+00 2.41559264e-02\n",
      " 2.44109711e-01 1.16945717e+01], Loss = 0.3616\n",
      "Iteration 6217: Weights = [5.50000000e+01 3.48705812e+00 7.33159552e+00 2.41552330e-02\n",
      " 2.44102704e-01 1.16947941e+01], Loss = 0.3616\n",
      "Iteration 6218: Weights = [5.50000000e+01 3.48695802e+00 7.33138506e+00 2.41545396e-02\n",
      " 2.44095697e-01 1.16950164e+01], Loss = 0.3616\n",
      "Iteration 6219: Weights = [5.50000000e+01 3.48685792e+00 7.33117460e+00 2.41538462e-02\n",
      " 2.44088690e-01 1.16952388e+01], Loss = 0.3616\n",
      "Iteration 6220: Weights = [5.50000000e+01 3.48675782e+00 7.33096415e+00 2.41531528e-02\n",
      " 2.44081683e-01 1.16954611e+01], Loss = 0.3616\n",
      "Iteration 6221: Weights = [5.50000000e+01 3.48665773e+00 7.33075371e+00 2.41524595e-02\n",
      " 2.44074676e-01 1.16956835e+01], Loss = 0.3615\n",
      "Iteration 6222: Weights = [5.50000000e+01 3.48655764e+00 7.33054327e+00 2.41517661e-02\n",
      " 2.44067669e-01 1.16959058e+01], Loss = 0.3615\n",
      "Iteration 6223: Weights = [5.50000000e+01 3.48645756e+00 7.33033284e+00 2.41510728e-02\n",
      " 2.44060663e-01 1.16961281e+01], Loss = 0.3615\n",
      "Iteration 6224: Weights = [5.50000000e+01 3.48635747e+00 7.33012241e+00 2.41503795e-02\n",
      " 2.44053657e-01 1.16963504e+01], Loss = 0.3615\n",
      "Iteration 6225: Weights = [5.50000000e+01 3.48625739e+00 7.32991199e+00 2.41496863e-02\n",
      " 2.44046651e-01 1.16965727e+01], Loss = 0.3615\n",
      "Iteration 6226: Weights = [5.50000000e+01 3.48615732e+00 7.32970157e+00 2.41489930e-02\n",
      " 2.44039646e-01 1.16967950e+01], Loss = 0.3614\n",
      "Iteration 6227: Weights = [5.50000000e+01 3.48605724e+00 7.32949116e+00 2.41482998e-02\n",
      " 2.44032640e-01 1.16970173e+01], Loss = 0.3614\n",
      "Iteration 6228: Weights = [5.50000000e+01 3.48595717e+00 7.32928076e+00 2.41476066e-02\n",
      " 2.44025635e-01 1.16972396e+01], Loss = 0.3614\n",
      "Iteration 6229: Weights = [5.50000000e+01 3.48585710e+00 7.32907037e+00 2.41469134e-02\n",
      " 2.44018630e-01 1.16974619e+01], Loss = 0.3614\n",
      "Iteration 6230: Weights = [5.50000000e+01 3.48575703e+00 7.32885997e+00 2.41462202e-02\n",
      " 2.44011625e-01 1.16976841e+01], Loss = 0.3614\n",
      "Iteration 6231: Weights = [5.50000000e+01 3.48565697e+00 7.32864959e+00 2.41455271e-02\n",
      " 2.44004620e-01 1.16979064e+01], Loss = 0.3613\n",
      "Iteration 6232: Weights = [5.50000000e+01 3.48555691e+00 7.32843921e+00 2.41448339e-02\n",
      " 2.43997616e-01 1.16981287e+01], Loss = 0.3613\n",
      "Iteration 6233: Weights = [5.50000000e+01 3.48545685e+00 7.32822884e+00 2.41441408e-02\n",
      " 2.43990611e-01 1.16983509e+01], Loss = 0.3613\n",
      "Iteration 6234: Weights = [5.50000000e+01 3.48535680e+00 7.32801847e+00 2.41434477e-02\n",
      " 2.43983607e-01 1.16985732e+01], Loss = 0.3613\n",
      "Iteration 6235: Weights = [5.50000000e+01 3.48525675e+00 7.32780811e+00 2.41427547e-02\n",
      " 2.43976603e-01 1.16987954e+01], Loss = 0.3613\n",
      "Iteration 6236: Weights = [5.50000000e+01 3.48515670e+00 7.32759776e+00 2.41420616e-02\n",
      " 2.43969600e-01 1.16990177e+01], Loss = 0.3612\n",
      "Iteration 6237: Weights = [5.50000000e+01 3.48505665e+00 7.32738741e+00 2.41413686e-02\n",
      " 2.43962596e-01 1.16992399e+01], Loss = 0.3612\n",
      "Iteration 6238: Weights = [5.50000000e+01 3.48495661e+00 7.32717707e+00 2.41406756e-02\n",
      " 2.43955593e-01 1.16994621e+01], Loss = 0.3612\n",
      "Iteration 6239: Weights = [5.50000000e+01 3.48485657e+00 7.32696673e+00 2.41399826e-02\n",
      " 2.43948590e-01 1.16996843e+01], Loss = 0.3612\n",
      "Iteration 6240: Weights = [5.50000000e+01 3.48475653e+00 7.32675640e+00 2.41392896e-02\n",
      " 2.43941587e-01 1.16999065e+01], Loss = 0.3612\n",
      "Iteration 6241: Weights = [5.50000000e+01 3.48465650e+00 7.32654608e+00 2.41385967e-02\n",
      " 2.43934584e-01 1.17001287e+01], Loss = 0.3611\n",
      "Iteration 6242: Weights = [5.50000000e+01 3.48455647e+00 7.32633576e+00 2.41379037e-02\n",
      " 2.43927582e-01 1.17003509e+01], Loss = 0.3611\n",
      "Iteration 6243: Weights = [5.50000000e+01 3.48445644e+00 7.32612545e+00 2.41372108e-02\n",
      " 2.43920580e-01 1.17005731e+01], Loss = 0.3611\n",
      "Iteration 6244: Weights = [5.50000000e+01 3.48435641e+00 7.32591514e+00 2.41365179e-02\n",
      " 2.43913578e-01 1.17007953e+01], Loss = 0.3611\n",
      "Iteration 6245: Weights = [5.50000000e+01 3.48425639e+00 7.32570484e+00 2.41358251e-02\n",
      " 2.43906576e-01 1.17010175e+01], Loss = 0.3610\n",
      "Iteration 6246: Weights = [5.50000000e+01 3.48415637e+00 7.32549455e+00 2.41351322e-02\n",
      " 2.43899574e-01 1.17012397e+01], Loss = 0.3610\n",
      "Iteration 6247: Weights = [5.50000000e+01 3.48405635e+00 7.32528426e+00 2.41344394e-02\n",
      " 2.43892573e-01 1.17014618e+01], Loss = 0.3610\n",
      "Iteration 6248: Weights = [5.50000000e+01 3.48395634e+00 7.32507398e+00 2.41337466e-02\n",
      " 2.43885571e-01 1.17016840e+01], Loss = 0.3610\n",
      "Iteration 6249: Weights = [5.50000000e+01 3.48385632e+00 7.32486370e+00 2.41330538e-02\n",
      " 2.43878570e-01 1.17019061e+01], Loss = 0.3610\n",
      "Iteration 6250: Weights = [5.50000000e+01 3.48375632e+00 7.32465343e+00 2.41323610e-02\n",
      " 2.43871570e-01 1.17021283e+01], Loss = 0.3609\n",
      "Iteration 6251: Weights = [5.50000000e+01 3.48365631e+00 7.32444317e+00 2.41316683e-02\n",
      " 2.43864569e-01 1.17023504e+01], Loss = 0.3609\n",
      "Iteration 6252: Weights = [5.50000000e+01 3.48355631e+00 7.32423291e+00 2.41309755e-02\n",
      " 2.43857568e-01 1.17025726e+01], Loss = 0.3609\n",
      "Iteration 6253: Weights = [5.50000000e+01 3.48345631e+00 7.32402266e+00 2.41302828e-02\n",
      " 2.43850568e-01 1.17027947e+01], Loss = 0.3609\n",
      "Iteration 6254: Weights = [5.50000000e+01 3.48335631e+00 7.32381241e+00 2.41295901e-02\n",
      " 2.43843568e-01 1.17030168e+01], Loss = 0.3609\n",
      "Iteration 6255: Weights = [5.50000000e+01 3.48325632e+00 7.32360217e+00 2.41288975e-02\n",
      " 2.43836568e-01 1.17032389e+01], Loss = 0.3608\n",
      "Iteration 6256: Weights = [5.50000000e+01 3.48315632e+00 7.32339194e+00 2.41282048e-02\n",
      " 2.43829569e-01 1.17034610e+01], Loss = 0.3608\n",
      "Iteration 6257: Weights = [5.50000000e+01 3.48305634e+00 7.32318171e+00 2.41275122e-02\n",
      " 2.43822569e-01 1.17036831e+01], Loss = 0.3608\n",
      "Iteration 6258: Weights = [5.50000000e+01 3.48295635e+00 7.32297149e+00 2.41268196e-02\n",
      " 2.43815570e-01 1.17039052e+01], Loss = 0.3608\n",
      "Iteration 6259: Weights = [5.50000000e+01 3.48285637e+00 7.32276128e+00 2.41261270e-02\n",
      " 2.43808571e-01 1.17041273e+01], Loss = 0.3608\n",
      "Iteration 6260: Weights = [5.50000000e+01 3.48275639e+00 7.32255107e+00 2.41254344e-02\n",
      " 2.43801572e-01 1.17043494e+01], Loss = 0.3607\n",
      "Iteration 6261: Weights = [5.50000000e+01 3.48265641e+00 7.32234086e+00 2.41247419e-02\n",
      " 2.43794573e-01 1.17045715e+01], Loss = 0.3607\n",
      "Iteration 6262: Weights = [5.50000000e+01 3.48255644e+00 7.32213067e+00 2.41240493e-02\n",
      " 2.43787575e-01 1.17047936e+01], Loss = 0.3607\n",
      "Iteration 6263: Weights = [5.50000000e+01 3.48245646e+00 7.32192047e+00 2.41233568e-02\n",
      " 2.43780577e-01 1.17050156e+01], Loss = 0.3607\n",
      "Iteration 6264: Weights = [5.50000000e+01 3.48235650e+00 7.32171029e+00 2.41226643e-02\n",
      " 2.43773579e-01 1.17052377e+01], Loss = 0.3607\n",
      "Iteration 6265: Weights = [5.50000000e+01 3.48225653e+00 7.32150011e+00 2.41219718e-02\n",
      " 2.43766581e-01 1.17054597e+01], Loss = 0.3606\n",
      "Iteration 6266: Weights = [5.50000000e+01 3.48215657e+00 7.32128994e+00 2.41212794e-02\n",
      " 2.43759583e-01 1.17056818e+01], Loss = 0.3606\n",
      "Iteration 6267: Weights = [5.50000000e+01 3.48205661e+00 7.32107977e+00 2.41205870e-02\n",
      " 2.43752586e-01 1.17059038e+01], Loss = 0.3606\n",
      "Iteration 6268: Weights = [5.50000000e+01 3.48195665e+00 7.32086961e+00 2.41198945e-02\n",
      " 2.43745589e-01 1.17061258e+01], Loss = 0.3606\n",
      "Iteration 6269: Weights = [5.50000000e+01 3.48185670e+00 7.32065945e+00 2.41192021e-02\n",
      " 2.43738592e-01 1.17063479e+01], Loss = 0.3606\n",
      "Iteration 6270: Weights = [5.50000000e+01 3.48175675e+00 7.32044930e+00 2.41185098e-02\n",
      " 2.43731595e-01 1.17065699e+01], Loss = 0.3605\n",
      "Iteration 6271: Weights = [5.50000000e+01 3.48165680e+00 7.32023916e+00 2.41178174e-02\n",
      " 2.43724598e-01 1.17067919e+01], Loss = 0.3605\n",
      "Iteration 6272: Weights = [5.50000000e+01 3.48155685e+00 7.32002902e+00 2.41171251e-02\n",
      " 2.43717602e-01 1.17070139e+01], Loss = 0.3605\n",
      "Iteration 6273: Weights = [5.50000000e+01 3.48145691e+00 7.31981889e+00 2.41164328e-02\n",
      " 2.43710605e-01 1.17072359e+01], Loss = 0.3605\n",
      "Iteration 6274: Weights = [5.50000000e+01 3.48135697e+00 7.31960877e+00 2.41157405e-02\n",
      " 2.43703609e-01 1.17074579e+01], Loss = 0.3604\n",
      "Iteration 6275: Weights = [5.50000000e+01 3.48125703e+00 7.31939865e+00 2.41150482e-02\n",
      " 2.43696614e-01 1.17076799e+01], Loss = 0.3604\n",
      "Iteration 6276: Weights = [5.50000000e+01 3.48115710e+00 7.31918854e+00 2.41143560e-02\n",
      " 2.43689618e-01 1.17079019e+01], Loss = 0.3604\n",
      "Iteration 6277: Weights = [5.50000000e+01 3.48105717e+00 7.31897843e+00 2.41136637e-02\n",
      " 2.43682622e-01 1.17081238e+01], Loss = 0.3604\n",
      "Iteration 6278: Weights = [5.50000000e+01 3.48095724e+00 7.31876833e+00 2.41129715e-02\n",
      " 2.43675627e-01 1.17083458e+01], Loss = 0.3604\n",
      "Iteration 6279: Weights = [5.50000000e+01 3.48085731e+00 7.31855823e+00 2.41122793e-02\n",
      " 2.43668632e-01 1.17085678e+01], Loss = 0.3603\n",
      "Iteration 6280: Weights = [5.50000000e+01 3.48075739e+00 7.31834814e+00 2.41115871e-02\n",
      " 2.43661637e-01 1.17087897e+01], Loss = 0.3603\n",
      "Iteration 6281: Weights = [5.50000000e+01 3.48065747e+00 7.31813806e+00 2.41108950e-02\n",
      " 2.43654643e-01 1.17090117e+01], Loss = 0.3603\n",
      "Iteration 6282: Weights = [5.50000000e+01 3.48055755e+00 7.31792798e+00 2.41102028e-02\n",
      " 2.43647648e-01 1.17092336e+01], Loss = 0.3603\n",
      "Iteration 6283: Weights = [5.50000000e+01 3.48045764e+00 7.31771791e+00 2.41095107e-02\n",
      " 2.43640654e-01 1.17094556e+01], Loss = 0.3603\n",
      "Iteration 6284: Weights = [5.50000000e+01 3.48035773e+00 7.31750785e+00 2.41088186e-02\n",
      " 2.43633660e-01 1.17096775e+01], Loss = 0.3602\n",
      "Iteration 6285: Weights = [5.50000000e+01 3.48025782e+00 7.31729779e+00 2.41081266e-02\n",
      " 2.43626666e-01 1.17098994e+01], Loss = 0.3602\n",
      "Iteration 6286: Weights = [5.50000000e+01 3.48015792e+00 7.31708774e+00 2.41074345e-02\n",
      " 2.43619673e-01 1.17101213e+01], Loss = 0.3602\n",
      "Iteration 6287: Weights = [5.50000000e+01 3.48005801e+00 7.31687769e+00 2.41067425e-02\n",
      " 2.43612679e-01 1.17103432e+01], Loss = 0.3602\n",
      "Iteration 6288: Weights = [5.50000000e+01 3.47995811e+00 7.31666765e+00 2.41060505e-02\n",
      " 2.43605686e-01 1.17105651e+01], Loss = 0.3602\n",
      "Iteration 6289: Weights = [5.50000000e+01 3.47985822e+00 7.31645762e+00 2.41053585e-02\n",
      " 2.43598693e-01 1.17107870e+01], Loss = 0.3601\n",
      "Iteration 6290: Weights = [5.50000000e+01 3.47975832e+00 7.31624759e+00 2.41046665e-02\n",
      " 2.43591700e-01 1.17110089e+01], Loss = 0.3601\n",
      "Iteration 6291: Weights = [5.50000000e+01 3.47965843e+00 7.31603757e+00 2.41039745e-02\n",
      " 2.43584708e-01 1.17112308e+01], Loss = 0.3601\n",
      "Iteration 6292: Weights = [5.50000000e+01 3.47955854e+00 7.31582755e+00 2.41032826e-02\n",
      " 2.43577715e-01 1.17114527e+01], Loss = 0.3601\n",
      "Iteration 6293: Weights = [5.50000000e+01 3.47945866e+00 7.31561754e+00 2.41025907e-02\n",
      " 2.43570723e-01 1.17116746e+01], Loss = 0.3601\n",
      "Iteration 6294: Weights = [5.50000000e+01 3.47935878e+00 7.31540753e+00 2.41018988e-02\n",
      " 2.43563731e-01 1.17118964e+01], Loss = 0.3600\n",
      "Iteration 6295: Weights = [5.50000000e+01 3.47925890e+00 7.31519754e+00 2.41012069e-02\n",
      " 2.43556739e-01 1.17121183e+01], Loss = 0.3600\n",
      "Iteration 6296: Weights = [5.50000000e+01 3.47915902e+00 7.31498754e+00 2.41005150e-02\n",
      " 2.43549747e-01 1.17123402e+01], Loss = 0.3600\n",
      "Iteration 6297: Weights = [5.50000000e+01 3.47905915e+00 7.31477756e+00 2.40998232e-02\n",
      " 2.43542756e-01 1.17125620e+01], Loss = 0.3600\n",
      "Iteration 6298: Weights = [5.50000000e+01 3.47895927e+00 7.31456758e+00 2.40991314e-02\n",
      " 2.43535765e-01 1.17127838e+01], Loss = 0.3600\n",
      "Iteration 6299: Weights = [5.50000000e+01 3.47885941e+00 7.31435760e+00 2.40984396e-02\n",
      " 2.43528774e-01 1.17130057e+01], Loss = 0.3599\n",
      "Iteration 6300: Weights = [5.50000000e+01 3.47875954e+00 7.31414763e+00 2.40977478e-02\n",
      " 2.43521783e-01 1.17132275e+01], Loss = 0.3599\n",
      "Iteration 6301: Weights = [5.50000000e+01 3.47865968e+00 7.31393767e+00 2.40970561e-02\n",
      " 2.43514792e-01 1.17134493e+01], Loss = 0.3599\n",
      "Iteration 6302: Weights = [5.50000000e+01 3.47855982e+00 7.31372772e+00 2.40963643e-02\n",
      " 2.43507802e-01 1.17136711e+01], Loss = 0.3599\n",
      "Iteration 6303: Weights = [5.50000000e+01 3.47845996e+00 7.31351777e+00 2.40956726e-02\n",
      " 2.43500812e-01 1.17138929e+01], Loss = 0.3598\n",
      "Iteration 6304: Weights = [5.50000000e+01 3.47836011e+00 7.31330782e+00 2.40949809e-02\n",
      " 2.43493822e-01 1.17141148e+01], Loss = 0.3598\n",
      "Iteration 6305: Weights = [5.50000000e+01 3.47826026e+00 7.31309788e+00 2.40942892e-02\n",
      " 2.43486832e-01 1.17143365e+01], Loss = 0.3598\n",
      "Iteration 6306: Weights = [5.50000000e+01 3.47816041e+00 7.31288795e+00 2.40935976e-02\n",
      " 2.43479842e-01 1.17145583e+01], Loss = 0.3598\n",
      "Iteration 6307: Weights = [5.50000000e+01 3.47806057e+00 7.31267803e+00 2.40929059e-02\n",
      " 2.43472853e-01 1.17147801e+01], Loss = 0.3598\n",
      "Iteration 6308: Weights = [5.50000000e+01 3.47796072e+00 7.31246811e+00 2.40922143e-02\n",
      " 2.43465864e-01 1.17150019e+01], Loss = 0.3597\n",
      "Iteration 6309: Weights = [5.50000000e+01 3.47786088e+00 7.31225819e+00 2.40915227e-02\n",
      " 2.43458875e-01 1.17152237e+01], Loss = 0.3597\n",
      "Iteration 6310: Weights = [5.50000000e+01 3.47776105e+00 7.31204828e+00 2.40908311e-02\n",
      " 2.43451886e-01 1.17154454e+01], Loss = 0.3597\n",
      "Iteration 6311: Weights = [5.50000000e+01 3.47766121e+00 7.31183838e+00 2.40901396e-02\n",
      " 2.43444897e-01 1.17156672e+01], Loss = 0.3597\n",
      "Iteration 6312: Weights = [5.50000000e+01 3.47756138e+00 7.31162849e+00 2.40894480e-02\n",
      " 2.43437909e-01 1.17158889e+01], Loss = 0.3597\n",
      "Iteration 6313: Weights = [5.50000000e+01 3.47746155e+00 7.31141860e+00 2.40887565e-02\n",
      " 2.43430921e-01 1.17161107e+01], Loss = 0.3596\n",
      "Iteration 6314: Weights = [5.50000000e+01 3.47736173e+00 7.31120871e+00 2.40880650e-02\n",
      " 2.43423933e-01 1.17163324e+01], Loss = 0.3596\n",
      "Iteration 6315: Weights = [5.50000000e+01 3.47726191e+00 7.31099883e+00 2.40873735e-02\n",
      " 2.43416945e-01 1.17165542e+01], Loss = 0.3596\n",
      "Iteration 6316: Weights = [5.50000000e+01 3.47716209e+00 7.31078896e+00 2.40866821e-02\n",
      " 2.43409957e-01 1.17167759e+01], Loss = 0.3596\n",
      "Iteration 6317: Weights = [5.50000000e+01 3.47706227e+00 7.31057910e+00 2.40859906e-02\n",
      " 2.43402970e-01 1.17169976e+01], Loss = 0.3596\n",
      "Iteration 6318: Weights = [5.50000000e+01 3.47696246e+00 7.31036924e+00 2.40852992e-02\n",
      " 2.43395983e-01 1.17172193e+01], Loss = 0.3595\n",
      "Iteration 6319: Weights = [5.50000000e+01 3.47686265e+00 7.31015938e+00 2.40846078e-02\n",
      " 2.43388996e-01 1.17174410e+01], Loss = 0.3595\n",
      "Iteration 6320: Weights = [5.50000000e+01 3.47676284e+00 7.30994954e+00 2.40839164e-02\n",
      " 2.43382009e-01 1.17176627e+01], Loss = 0.3595\n",
      "Iteration 6321: Weights = [5.50000000e+01 3.47666303e+00 7.30973969e+00 2.40832251e-02\n",
      " 2.43375022e-01 1.17178844e+01], Loss = 0.3595\n",
      "Iteration 6322: Weights = [5.50000000e+01 3.47656323e+00 7.30952986e+00 2.40825337e-02\n",
      " 2.43368036e-01 1.17181061e+01], Loss = 0.3595\n",
      "Iteration 6323: Weights = [5.50000000e+01 3.47646343e+00 7.30932003e+00 2.40818424e-02\n",
      " 2.43361050e-01 1.17183278e+01], Loss = 0.3594\n",
      "Iteration 6324: Weights = [5.50000000e+01 3.47636364e+00 7.30911020e+00 2.40811511e-02\n",
      " 2.43354064e-01 1.17185495e+01], Loss = 0.3594\n",
      "Iteration 6325: Weights = [5.50000000e+01 3.47626384e+00 7.30890039e+00 2.40804598e-02\n",
      " 2.43347078e-01 1.17187711e+01], Loss = 0.3594\n",
      "Iteration 6326: Weights = [5.50000000e+01 3.47616405e+00 7.30869058e+00 2.40797686e-02\n",
      " 2.43340092e-01 1.17189928e+01], Loss = 0.3594\n",
      "Iteration 6327: Weights = [5.50000000e+01 3.47606426e+00 7.30848077e+00 2.40790773e-02\n",
      " 2.43333107e-01 1.17192145e+01], Loss = 0.3594\n",
      "Iteration 6328: Weights = [5.50000000e+01 3.47596448e+00 7.30827097e+00 2.40783861e-02\n",
      " 2.43326122e-01 1.17194361e+01], Loss = 0.3593\n",
      "Iteration 6329: Weights = [5.50000000e+01 3.47586470e+00 7.30806118e+00 2.40776949e-02\n",
      " 2.43319137e-01 1.17196577e+01], Loss = 0.3593\n",
      "Iteration 6330: Weights = [5.50000000e+01 3.47576492e+00 7.30785139e+00 2.40770037e-02\n",
      " 2.43312152e-01 1.17198794e+01], Loss = 0.3593\n",
      "Iteration 6331: Weights = [5.50000000e+01 3.47566514e+00 7.30764161e+00 2.40763126e-02\n",
      " 2.43305167e-01 1.17201010e+01], Loss = 0.3593\n",
      "Iteration 6332: Weights = [5.50000000e+01 3.47556537e+00 7.30743183e+00 2.40756214e-02\n",
      " 2.43298183e-01 1.17203226e+01], Loss = 0.3592\n",
      "Iteration 6333: Weights = [5.50000000e+01 3.47546560e+00 7.30722206e+00 2.40749303e-02\n",
      " 2.43291199e-01 1.17205443e+01], Loss = 0.3592\n",
      "Iteration 6334: Weights = [5.50000000e+01 3.47536583e+00 7.30701230e+00 2.40742392e-02\n",
      " 2.43284215e-01 1.17207659e+01], Loss = 0.3592\n",
      "Iteration 6335: Weights = [5.50000000e+01 3.47526606e+00 7.30680254e+00 2.40735481e-02\n",
      " 2.43277231e-01 1.17209875e+01], Loss = 0.3592\n",
      "Iteration 6336: Weights = [5.50000000e+01 3.47516630e+00 7.30659279e+00 2.40728571e-02\n",
      " 2.43270247e-01 1.17212091e+01], Loss = 0.3592\n",
      "Iteration 6337: Weights = [5.50000000e+01 3.47506654e+00 7.30638305e+00 2.40721660e-02\n",
      " 2.43263264e-01 1.17214307e+01], Loss = 0.3591\n",
      "Iteration 6338: Weights = [5.50000000e+01 3.47496679e+00 7.30617331e+00 2.40714750e-02\n",
      " 2.43256281e-01 1.17216523e+01], Loss = 0.3591\n",
      "Iteration 6339: Weights = [5.50000000e+01 3.47486703e+00 7.30596357e+00 2.40707840e-02\n",
      " 2.43249298e-01 1.17218738e+01], Loss = 0.3591\n",
      "Iteration 6340: Weights = [5.50000000e+01 3.47476728e+00 7.30575385e+00 2.40700930e-02\n",
      " 2.43242315e-01 1.17220954e+01], Loss = 0.3591\n",
      "Iteration 6341: Weights = [5.50000000e+01 3.47466754e+00 7.30554413e+00 2.40694020e-02\n",
      " 2.43235332e-01 1.17223170e+01], Loss = 0.3591\n",
      "Iteration 6342: Weights = [5.50000000e+01 3.47456779e+00 7.30533441e+00 2.40687111e-02\n",
      " 2.43228350e-01 1.17225385e+01], Loss = 0.3590\n",
      "Iteration 6343: Weights = [5.50000000e+01 3.47446805e+00 7.30512470e+00 2.40680202e-02\n",
      " 2.43221368e-01 1.17227601e+01], Loss = 0.3590\n",
      "Iteration 6344: Weights = [5.50000000e+01 3.47436831e+00 7.30491500e+00 2.40673293e-02\n",
      " 2.43214386e-01 1.17229816e+01], Loss = 0.3590\n",
      "Iteration 6345: Weights = [5.50000000e+01 3.47426857e+00 7.30470530e+00 2.40666384e-02\n",
      " 2.43207404e-01 1.17232032e+01], Loss = 0.3590\n",
      "Iteration 6346: Weights = [5.50000000e+01 3.47416884e+00 7.30449561e+00 2.40659475e-02\n",
      " 2.43200422e-01 1.17234247e+01], Loss = 0.3590\n",
      "Iteration 6347: Weights = [5.50000000e+01 3.47406911e+00 7.30428592e+00 2.40652567e-02\n",
      " 2.43193441e-01 1.17236462e+01], Loss = 0.3589\n",
      "Iteration 6348: Weights = [5.50000000e+01 3.47396938e+00 7.30407625e+00 2.40645659e-02\n",
      " 2.43186460e-01 1.17238678e+01], Loss = 0.3589\n",
      "Iteration 6349: Weights = [5.50000000e+01 3.47386966e+00 7.30386657e+00 2.40638750e-02\n",
      " 2.43179479e-01 1.17240893e+01], Loss = 0.3589\n",
      "Iteration 6350: Weights = [5.50000000e+01 3.47376993e+00 7.30365691e+00 2.40631843e-02\n",
      " 2.43172498e-01 1.17243108e+01], Loss = 0.3589\n",
      "Iteration 6351: Weights = [5.50000000e+01 3.47367022e+00 7.30344724e+00 2.40624935e-02\n",
      " 2.43165518e-01 1.17245323e+01], Loss = 0.3589\n",
      "Iteration 6352: Weights = [5.50000000e+01 3.47357050e+00 7.30323759e+00 2.40618028e-02\n",
      " 2.43158537e-01 1.17247538e+01], Loss = 0.3588\n",
      "Iteration 6353: Weights = [5.50000000e+01 3.47347079e+00 7.30302794e+00 2.40611120e-02\n",
      " 2.43151557e-01 1.17249753e+01], Loss = 0.3588\n",
      "Iteration 6354: Weights = [5.50000000e+01 3.47337107e+00 7.30281830e+00 2.40604213e-02\n",
      " 2.43144577e-01 1.17251968e+01], Loss = 0.3588\n",
      "Iteration 6355: Weights = [5.50000000e+01 3.47327137e+00 7.30260866e+00 2.40597306e-02\n",
      " 2.43137597e-01 1.17254182e+01], Loss = 0.3588\n",
      "Iteration 6356: Weights = [5.50000000e+01 3.47317166e+00 7.30239903e+00 2.40590400e-02\n",
      " 2.43130618e-01 1.17256397e+01], Loss = 0.3588\n",
      "Iteration 6357: Weights = [5.50000000e+01 3.47307196e+00 7.30218940e+00 2.40583493e-02\n",
      " 2.43123638e-01 1.17258612e+01], Loss = 0.3587\n",
      "Iteration 6358: Weights = [5.50000000e+01 3.47297226e+00 7.30197979e+00 2.40576587e-02\n",
      " 2.43116659e-01 1.17260826e+01], Loss = 0.3587\n",
      "Iteration 6359: Weights = [5.50000000e+01 3.47287257e+00 7.30177017e+00 2.40569681e-02\n",
      " 2.43109680e-01 1.17263041e+01], Loss = 0.3587\n",
      "Iteration 6360: Weights = [5.50000000e+01 3.47277287e+00 7.30156057e+00 2.40562775e-02\n",
      " 2.43102701e-01 1.17265255e+01], Loss = 0.3587\n",
      "Iteration 6361: Weights = [5.50000000e+01 3.47267318e+00 7.30135096e+00 2.40555869e-02\n",
      " 2.43095723e-01 1.17267470e+01], Loss = 0.3587\n",
      "Iteration 6362: Weights = [5.50000000e+01 3.47257349e+00 7.30114137e+00 2.40548964e-02\n",
      " 2.43088744e-01 1.17269684e+01], Loss = 0.3586\n",
      "Iteration 6363: Weights = [5.50000000e+01 3.47247381e+00 7.30093178e+00 2.40542059e-02\n",
      " 2.43081766e-01 1.17271898e+01], Loss = 0.3586\n",
      "Iteration 6364: Weights = [5.50000000e+01 3.47237413e+00 7.30072220e+00 2.40535154e-02\n",
      " 2.43074788e-01 1.17274113e+01], Loss = 0.3586\n",
      "Iteration 6365: Weights = [5.50000000e+01 3.47227445e+00 7.30051262e+00 2.40528249e-02\n",
      " 2.43067810e-01 1.17276327e+01], Loss = 0.3586\n",
      "Iteration 6366: Weights = [5.50000000e+01 3.47217477e+00 7.30030305e+00 2.40521344e-02\n",
      " 2.43060833e-01 1.17278541e+01], Loss = 0.3585\n",
      "Iteration 6367: Weights = [5.50000000e+01 3.47207510e+00 7.30009349e+00 2.40514440e-02\n",
      " 2.43053855e-01 1.17280755e+01], Loss = 0.3585\n",
      "Iteration 6368: Weights = [5.50000000e+01 3.47197543e+00 7.29988393e+00 2.40507535e-02\n",
      " 2.43046878e-01 1.17282969e+01], Loss = 0.3585\n",
      "Iteration 6369: Weights = [5.50000000e+01 3.47187576e+00 7.29967437e+00 2.40500631e-02\n",
      " 2.43039901e-01 1.17285183e+01], Loss = 0.3585\n",
      "Iteration 6370: Weights = [5.50000000e+01 3.47177610e+00 7.29946483e+00 2.40493727e-02\n",
      " 2.43032925e-01 1.17287397e+01], Loss = 0.3585\n",
      "Iteration 6371: Weights = [5.50000000e+01 3.47167643e+00 7.29925529e+00 2.40486824e-02\n",
      " 2.43025948e-01 1.17289610e+01], Loss = 0.3584\n",
      "Iteration 6372: Weights = [5.50000000e+01 3.47157677e+00 7.29904575e+00 2.40479920e-02\n",
      " 2.43018972e-01 1.17291824e+01], Loss = 0.3584\n",
      "Iteration 6373: Weights = [5.50000000e+01 3.47147712e+00 7.29883622e+00 2.40473017e-02\n",
      " 2.43011995e-01 1.17294038e+01], Loss = 0.3584\n",
      "Iteration 6374: Weights = [5.50000000e+01 3.47137747e+00 7.29862670e+00 2.40466114e-02\n",
      " 2.43005019e-01 1.17296251e+01], Loss = 0.3584\n",
      "Iteration 6375: Weights = [5.50000000e+01 3.47127781e+00 7.29841718e+00 2.40459211e-02\n",
      " 2.42998044e-01 1.17298465e+01], Loss = 0.3584\n",
      "Iteration 6376: Weights = [5.50000000e+01 3.47117817e+00 7.29820767e+00 2.40452308e-02\n",
      " 2.42991068e-01 1.17300678e+01], Loss = 0.3583\n",
      "Iteration 6377: Weights = [5.50000000e+01 3.47107852e+00 7.29799817e+00 2.40445406e-02\n",
      " 2.42984093e-01 1.17302892e+01], Loss = 0.3583\n",
      "Iteration 6378: Weights = [5.50000000e+01 3.47097888e+00 7.29778867e+00 2.40438503e-02\n",
      " 2.42977118e-01 1.17305105e+01], Loss = 0.3583\n",
      "Iteration 6379: Weights = [5.50000000e+01 3.47087924e+00 7.29757918e+00 2.40431601e-02\n",
      " 2.42970143e-01 1.17307318e+01], Loss = 0.3583\n",
      "Iteration 6380: Weights = [5.50000000e+01 3.47077961e+00 7.29736969e+00 2.40424699e-02\n",
      " 2.42963168e-01 1.17309531e+01], Loss = 0.3583\n",
      "Iteration 6381: Weights = [5.50000000e+01 3.47067997e+00 7.29716021e+00 2.40417798e-02\n",
      " 2.42956193e-01 1.17311744e+01], Loss = 0.3582\n",
      "Iteration 6382: Weights = [5.50000000e+01 3.47058034e+00 7.29695074e+00 2.40410896e-02\n",
      " 2.42949219e-01 1.17313957e+01], Loss = 0.3582\n",
      "Iteration 6383: Weights = [5.50000000e+01 3.47048071e+00 7.29674127e+00 2.40403995e-02\n",
      " 2.42942245e-01 1.17316170e+01], Loss = 0.3582\n",
      "Iteration 6384: Weights = [5.50000000e+01 3.47038109e+00 7.29653181e+00 2.40397094e-02\n",
      " 2.42935271e-01 1.17318383e+01], Loss = 0.3582\n",
      "Iteration 6385: Weights = [5.50000000e+01 3.47028147e+00 7.29632235e+00 2.40390193e-02\n",
      " 2.42928297e-01 1.17320596e+01], Loss = 0.3582\n",
      "Iteration 6386: Weights = [5.50000000e+01 3.47018185e+00 7.29611290e+00 2.40383292e-02\n",
      " 2.42921323e-01 1.17322809e+01], Loss = 0.3581\n",
      "Iteration 6387: Weights = [5.50000000e+01 3.47008223e+00 7.29590345e+00 2.40376392e-02\n",
      " 2.42914350e-01 1.17325022e+01], Loss = 0.3581\n",
      "Iteration 6388: Weights = [5.50000000e+01 3.46998262e+00 7.29569402e+00 2.40369491e-02\n",
      " 2.42907377e-01 1.17327235e+01], Loss = 0.3581\n",
      "Iteration 6389: Weights = [5.50000000e+01 3.46988301e+00 7.29548458e+00 2.40362591e-02\n",
      " 2.42900404e-01 1.17329447e+01], Loss = 0.3581\n",
      "Iteration 6390: Weights = [5.50000000e+01 3.46978340e+00 7.29527516e+00 2.40355691e-02\n",
      " 2.42893431e-01 1.17331660e+01], Loss = 0.3581\n",
      "Iteration 6391: Weights = [5.50000000e+01 3.46968380e+00 7.29506574e+00 2.40348791e-02\n",
      " 2.42886458e-01 1.17333872e+01], Loss = 0.3580\n",
      "Iteration 6392: Weights = [5.50000000e+01 3.46958420e+00 7.29485632e+00 2.40341892e-02\n",
      " 2.42879486e-01 1.17336085e+01], Loss = 0.3580\n",
      "Iteration 6393: Weights = [5.50000000e+01 3.46948460e+00 7.29464691e+00 2.40334993e-02\n",
      " 2.42872514e-01 1.17338297e+01], Loss = 0.3580\n",
      "Iteration 6394: Weights = [5.50000000e+01 3.46938500e+00 7.29443751e+00 2.40328093e-02\n",
      " 2.42865542e-01 1.17340509e+01], Loss = 0.3580\n",
      "Iteration 6395: Weights = [5.50000000e+01 3.46928541e+00 7.29422811e+00 2.40321195e-02\n",
      " 2.42858570e-01 1.17342722e+01], Loss = 0.3580\n",
      "Iteration 6396: Weights = [5.50000000e+01 3.46918582e+00 7.29401872e+00 2.40314296e-02\n",
      " 2.42851599e-01 1.17344934e+01], Loss = 0.3579\n",
      "Iteration 6397: Weights = [5.50000000e+01 3.46908623e+00 7.29380934e+00 2.40307397e-02\n",
      " 2.42844627e-01 1.17347146e+01], Loss = 0.3579\n",
      "Iteration 6398: Weights = [5.50000000e+01 3.46898664e+00 7.29359996e+00 2.40300499e-02\n",
      " 2.42837656e-01 1.17349358e+01], Loss = 0.3579\n",
      "Iteration 6399: Weights = [5.50000000e+01 3.46888706e+00 7.29339059e+00 2.40293601e-02\n",
      " 2.42830685e-01 1.17351570e+01], Loss = 0.3579\n",
      "Iteration 6400: Weights = [5.50000000e+01 3.46878748e+00 7.29318122e+00 2.40286703e-02\n",
      " 2.42823714e-01 1.17353782e+01], Loss = 0.3578\n",
      "Iteration 6401: Weights = [5.50000000e+01 3.46868791e+00 7.29297186e+00 2.40279805e-02\n",
      " 2.42816744e-01 1.17355994e+01], Loss = 0.3578\n",
      "Iteration 6402: Weights = [5.50000000e+01 3.46858833e+00 7.29276251e+00 2.40272908e-02\n",
      " 2.42809773e-01 1.17358205e+01], Loss = 0.3578\n",
      "Iteration 6403: Weights = [5.50000000e+01 3.46848876e+00 7.29255316e+00 2.40266010e-02\n",
      " 2.42802803e-01 1.17360417e+01], Loss = 0.3578\n",
      "Iteration 6404: Weights = [5.50000000e+01 3.46838920e+00 7.29234382e+00 2.40259113e-02\n",
      " 2.42795833e-01 1.17362629e+01], Loss = 0.3578\n",
      "Iteration 6405: Weights = [5.50000000e+01 3.46828963e+00 7.29213448e+00 2.40252216e-02\n",
      " 2.42788863e-01 1.17364840e+01], Loss = 0.3577\n",
      "Iteration 6406: Weights = [5.50000000e+01 3.46819007e+00 7.29192515e+00 2.40245319e-02\n",
      " 2.42781894e-01 1.17367052e+01], Loss = 0.3577\n",
      "Iteration 6407: Weights = [5.50000000e+01 3.46809051e+00 7.29171583e+00 2.40238423e-02\n",
      " 2.42774924e-01 1.17369263e+01], Loss = 0.3577\n",
      "Iteration 6408: Weights = [5.50000000e+01 3.46799095e+00 7.29150651e+00 2.40231526e-02\n",
      " 2.42767955e-01 1.17371475e+01], Loss = 0.3577\n",
      "Iteration 6409: Weights = [5.50000000e+01 3.46789140e+00 7.29129720e+00 2.40224630e-02\n",
      " 2.42760986e-01 1.17373686e+01], Loss = 0.3577\n",
      "Iteration 6410: Weights = [5.50000000e+01 3.46779185e+00 7.29108789e+00 2.40217734e-02\n",
      " 2.42754018e-01 1.17375898e+01], Loss = 0.3576\n",
      "Iteration 6411: Weights = [5.50000000e+01 3.46769230e+00 7.29087859e+00 2.40210839e-02\n",
      " 2.42747049e-01 1.17378109e+01], Loss = 0.3576\n",
      "Iteration 6412: Weights = [5.50000000e+01 3.46759276e+00 7.29066930e+00 2.40203943e-02\n",
      " 2.42740081e-01 1.17380320e+01], Loss = 0.3576\n",
      "Iteration 6413: Weights = [5.50000000e+01 3.46749322e+00 7.29046001e+00 2.40197048e-02\n",
      " 2.42733112e-01 1.17382531e+01], Loss = 0.3576\n",
      "Iteration 6414: Weights = [5.50000000e+01 3.46739368e+00 7.29025073e+00 2.40190152e-02\n",
      " 2.42726144e-01 1.17384742e+01], Loss = 0.3576\n",
      "Iteration 6415: Weights = [5.50000000e+01 3.46729414e+00 7.29004145e+00 2.40183257e-02\n",
      " 2.42719177e-01 1.17386953e+01], Loss = 0.3575\n",
      "Iteration 6416: Weights = [5.50000000e+01 3.46719461e+00 7.28983218e+00 2.40176363e-02\n",
      " 2.42712209e-01 1.17389164e+01], Loss = 0.3575\n",
      "Iteration 6417: Weights = [5.50000000e+01 3.46709508e+00 7.28962291e+00 2.40169468e-02\n",
      " 2.42705242e-01 1.17391375e+01], Loss = 0.3575\n",
      "Iteration 6418: Weights = [5.50000000e+01 3.46699555e+00 7.28941366e+00 2.40162574e-02\n",
      " 2.42698275e-01 1.17393586e+01], Loss = 0.3575\n",
      "Iteration 6419: Weights = [5.50000000e+01 3.46689603e+00 7.28920440e+00 2.40155680e-02\n",
      " 2.42691308e-01 1.17395796e+01], Loss = 0.3575\n",
      "Iteration 6420: Weights = [5.50000000e+01 3.46679650e+00 7.28899516e+00 2.40148786e-02\n",
      " 2.42684341e-01 1.17398007e+01], Loss = 0.3574\n",
      "Iteration 6421: Weights = [5.50000000e+01 3.46669699e+00 7.28878592e+00 2.40141892e-02\n",
      " 2.42677374e-01 1.17400217e+01], Loss = 0.3574\n",
      "Iteration 6422: Weights = [5.50000000e+01 3.46659747e+00 7.28857668e+00 2.40134998e-02\n",
      " 2.42670408e-01 1.17402428e+01], Loss = 0.3574\n",
      "Iteration 6423: Weights = [5.50000000e+01 3.46649796e+00 7.28836746e+00 2.40128105e-02\n",
      " 2.42663442e-01 1.17404638e+01], Loss = 0.3574\n",
      "Iteration 6424: Weights = [5.50000000e+01 3.46639845e+00 7.28815823e+00 2.40121212e-02\n",
      " 2.42656476e-01 1.17406849e+01], Loss = 0.3574\n",
      "Iteration 6425: Weights = [5.50000000e+01 3.46629894e+00 7.28794902e+00 2.40114319e-02\n",
      " 2.42649510e-01 1.17409059e+01], Loss = 0.3573\n",
      "Iteration 6426: Weights = [5.50000000e+01 3.46619943e+00 7.28773981e+00 2.40107426e-02\n",
      " 2.42642544e-01 1.17411269e+01], Loss = 0.3573\n",
      "Iteration 6427: Weights = [5.50000000e+01 3.46609993e+00 7.28753060e+00 2.40100533e-02\n",
      " 2.42635579e-01 1.17413480e+01], Loss = 0.3573\n",
      "Iteration 6428: Weights = [5.50000000e+01 3.46600043e+00 7.28732141e+00 2.40093641e-02\n",
      " 2.42628614e-01 1.17415690e+01], Loss = 0.3573\n",
      "Iteration 6429: Weights = [5.50000000e+01 3.46590094e+00 7.28711221e+00 2.40086749e-02\n",
      " 2.42621649e-01 1.17417900e+01], Loss = 0.3573\n",
      "Iteration 6430: Weights = [5.50000000e+01 3.46580144e+00 7.28690303e+00 2.40079857e-02\n",
      " 2.42614684e-01 1.17420110e+01], Loss = 0.3572\n",
      "Iteration 6431: Weights = [5.50000000e+01 3.46570195e+00 7.28669385e+00 2.40072965e-02\n",
      " 2.42607720e-01 1.17422320e+01], Loss = 0.3572\n",
      "Iteration 6432: Weights = [5.50000000e+01 3.46560247e+00 7.28648467e+00 2.40066073e-02\n",
      " 2.42600755e-01 1.17424530e+01], Loss = 0.3572\n",
      "Iteration 6433: Weights = [5.50000000e+01 3.46550298e+00 7.28627550e+00 2.40059182e-02\n",
      " 2.42593791e-01 1.17426740e+01], Loss = 0.3572\n",
      "Iteration 6434: Weights = [5.50000000e+01 3.46540350e+00 7.28606634e+00 2.40052291e-02\n",
      " 2.42586827e-01 1.17428949e+01], Loss = 0.3572\n",
      "Iteration 6435: Weights = [5.50000000e+01 3.46530402e+00 7.28585719e+00 2.40045400e-02\n",
      " 2.42579863e-01 1.17431159e+01], Loss = 0.3571\n",
      "Iteration 6436: Weights = [5.50000000e+01 3.46520454e+00 7.28564804e+00 2.40038509e-02\n",
      " 2.42572900e-01 1.17433369e+01], Loss = 0.3571\n",
      "Iteration 6437: Weights = [5.50000000e+01 3.46510507e+00 7.28543889e+00 2.40031618e-02\n",
      " 2.42565936e-01 1.17435578e+01], Loss = 0.3571\n",
      "Iteration 6438: Weights = [5.50000000e+01 3.46500560e+00 7.28522975e+00 2.40024728e-02\n",
      " 2.42558973e-01 1.17437788e+01], Loss = 0.3571\n",
      "Iteration 6439: Weights = [5.50000000e+01 3.46490613e+00 7.28502062e+00 2.40017837e-02\n",
      " 2.42552010e-01 1.17439997e+01], Loss = 0.3570\n",
      "Iteration 6440: Weights = [5.50000000e+01 3.46480667e+00 7.28481150e+00 2.40010947e-02\n",
      " 2.42545047e-01 1.17442207e+01], Loss = 0.3570\n",
      "Iteration 6441: Weights = [5.50000000e+01 3.46470721e+00 7.28460238e+00 2.40004058e-02\n",
      " 2.42538085e-01 1.17444416e+01], Loss = 0.3570\n",
      "Iteration 6442: Weights = [5.50000000e+01 3.46460775e+00 7.28439326e+00 2.39997168e-02\n",
      " 2.42531122e-01 1.17446625e+01], Loss = 0.3570\n",
      "Iteration 6443: Weights = [5.50000000e+01 3.46450829e+00 7.28418415e+00 2.39990279e-02\n",
      " 2.42524160e-01 1.17448834e+01], Loss = 0.3570\n",
      "Iteration 6444: Weights = [5.50000000e+01 3.46440884e+00 7.28397505e+00 2.39983389e-02\n",
      " 2.42517198e-01 1.17451044e+01], Loss = 0.3569\n",
      "Iteration 6445: Weights = [5.50000000e+01 3.46430939e+00 7.28376596e+00 2.39976500e-02\n",
      " 2.42510237e-01 1.17453253e+01], Loss = 0.3569\n",
      "Iteration 6446: Weights = [5.50000000e+01 3.46420994e+00 7.28355687e+00 2.39969611e-02\n",
      " 2.42503275e-01 1.17455462e+01], Loss = 0.3569\n",
      "Iteration 6447: Weights = [5.50000000e+01 3.46411050e+00 7.28334778e+00 2.39962723e-02\n",
      " 2.42496314e-01 1.17457671e+01], Loss = 0.3569\n",
      "Iteration 6448: Weights = [5.50000000e+01 3.46401105e+00 7.28313870e+00 2.39955834e-02\n",
      " 2.42489352e-01 1.17459879e+01], Loss = 0.3569\n",
      "Iteration 6449: Weights = [5.50000000e+01 3.46391162e+00 7.28292963e+00 2.39948946e-02\n",
      " 2.42482391e-01 1.17462088e+01], Loss = 0.3568\n",
      "Iteration 6450: Weights = [5.50000000e+01 3.46381218e+00 7.28272057e+00 2.39942058e-02\n",
      " 2.42475431e-01 1.17464297e+01], Loss = 0.3568\n",
      "Iteration 6451: Weights = [5.50000000e+01 3.46371275e+00 7.28251151e+00 2.39935170e-02\n",
      " 2.42468470e-01 1.17466506e+01], Loss = 0.3568\n",
      "Iteration 6452: Weights = [5.50000000e+01 3.46361332e+00 7.28230245e+00 2.39928283e-02\n",
      " 2.42461510e-01 1.17468714e+01], Loss = 0.3568\n",
      "Iteration 6453: Weights = [5.50000000e+01 3.46351389e+00 7.28209340e+00 2.39921395e-02\n",
      " 2.42454550e-01 1.17470923e+01], Loss = 0.3568\n",
      "Iteration 6454: Weights = [5.50000000e+01 3.46341446e+00 7.28188436e+00 2.39914508e-02\n",
      " 2.42447590e-01 1.17473131e+01], Loss = 0.3567\n",
      "Iteration 6455: Weights = [5.50000000e+01 3.46331504e+00 7.28167533e+00 2.39907621e-02\n",
      " 2.42440630e-01 1.17475340e+01], Loss = 0.3567\n",
      "Iteration 6456: Weights = [5.50000000e+01 3.46321562e+00 7.28146630e+00 2.39900734e-02\n",
      " 2.42433670e-01 1.17477548e+01], Loss = 0.3567\n",
      "Iteration 6457: Weights = [5.50000000e+01 3.46311621e+00 7.28125727e+00 2.39893847e-02\n",
      " 2.42426711e-01 1.17479756e+01], Loss = 0.3567\n",
      "Iteration 6458: Weights = [5.50000000e+01 3.46301679e+00 7.28104825e+00 2.39886961e-02\n",
      " 2.42419752e-01 1.17481965e+01], Loss = 0.3567\n",
      "Iteration 6459: Weights = [5.50000000e+01 3.46291738e+00 7.28083924e+00 2.39880075e-02\n",
      " 2.42412793e-01 1.17484173e+01], Loss = 0.3566\n",
      "Iteration 6460: Weights = [5.50000000e+01 3.46281798e+00 7.28063024e+00 2.39873188e-02\n",
      " 2.42405834e-01 1.17486381e+01], Loss = 0.3566\n",
      "Iteration 6461: Weights = [5.50000000e+01 3.46271857e+00 7.28042124e+00 2.39866303e-02\n",
      " 2.42398875e-01 1.17488589e+01], Loss = 0.3566\n",
      "Iteration 6462: Weights = [5.50000000e+01 3.46261917e+00 7.28021224e+00 2.39859417e-02\n",
      " 2.42391917e-01 1.17490797e+01], Loss = 0.3566\n",
      "Iteration 6463: Weights = [5.50000000e+01 3.46251977e+00 7.28000325e+00 2.39852531e-02\n",
      " 2.42384959e-01 1.17493005e+01], Loss = 0.3566\n",
      "Iteration 6464: Weights = [5.50000000e+01 3.46242037e+00 7.27979427e+00 2.39845646e-02\n",
      " 2.42378001e-01 1.17495213e+01], Loss = 0.3565\n",
      "Iteration 6465: Weights = [5.50000000e+01 3.46232098e+00 7.27958530e+00 2.39838761e-02\n",
      " 2.42371043e-01 1.17497421e+01], Loss = 0.3565\n",
      "Iteration 6466: Weights = [5.50000000e+01 3.46222159e+00 7.27937633e+00 2.39831876e-02\n",
      " 2.42364085e-01 1.17499628e+01], Loss = 0.3565\n",
      "Iteration 6467: Weights = [5.50000000e+01 3.46212220e+00 7.27916736e+00 2.39824991e-02\n",
      " 2.42357128e-01 1.17501836e+01], Loss = 0.3565\n",
      "Iteration 6468: Weights = [5.50000000e+01 3.46202282e+00 7.27895840e+00 2.39818107e-02\n",
      " 2.42350171e-01 1.17504044e+01], Loss = 0.3565\n",
      "Iteration 6469: Weights = [5.50000000e+01 3.46192344e+00 7.27874945e+00 2.39811223e-02\n",
      " 2.42343214e-01 1.17506251e+01], Loss = 0.3564\n",
      "Iteration 6470: Weights = [5.50000000e+01 3.46182406e+00 7.27854051e+00 2.39804339e-02\n",
      " 2.42336257e-01 1.17508459e+01], Loss = 0.3564\n",
      "Iteration 6471: Weights = [5.50000000e+01 3.46172468e+00 7.27833157e+00 2.39797455e-02\n",
      " 2.42329301e-01 1.17510666e+01], Loss = 0.3564\n",
      "Iteration 6472: Weights = [5.50000000e+01 3.46162531e+00 7.27812263e+00 2.39790571e-02\n",
      " 2.42322344e-01 1.17512873e+01], Loss = 0.3564\n",
      "Iteration 6473: Weights = [5.50000000e+01 3.46152594e+00 7.27791370e+00 2.39783688e-02\n",
      " 2.42315388e-01 1.17515081e+01], Loss = 0.3564\n",
      "Iteration 6474: Weights = [5.50000000e+01 3.46142657e+00 7.27770478e+00 2.39776804e-02\n",
      " 2.42308432e-01 1.17517288e+01], Loss = 0.3563\n",
      "Iteration 6475: Weights = [5.50000000e+01 3.46132720e+00 7.27749587e+00 2.39769921e-02\n",
      " 2.42301476e-01 1.17519495e+01], Loss = 0.3563\n",
      "Iteration 6476: Weights = [5.50000000e+01 3.46122784e+00 7.27728696e+00 2.39763038e-02\n",
      " 2.42294521e-01 1.17521702e+01], Loss = 0.3563\n",
      "Iteration 6477: Weights = [5.50000000e+01 3.46112848e+00 7.27707805e+00 2.39756155e-02\n",
      " 2.42287565e-01 1.17523909e+01], Loss = 0.3563\n",
      "Iteration 6478: Weights = [5.50000000e+01 3.46102913e+00 7.27686915e+00 2.39749273e-02\n",
      " 2.42280610e-01 1.17526116e+01], Loss = 0.3563\n",
      "Iteration 6479: Weights = [5.50000000e+01 3.46092977e+00 7.27666026e+00 2.39742391e-02\n",
      " 2.42273655e-01 1.17528323e+01], Loss = 0.3562\n",
      "Iteration 6480: Weights = [5.50000000e+01 3.46083042e+00 7.27645138e+00 2.39735509e-02\n",
      " 2.42266700e-01 1.17530530e+01], Loss = 0.3562\n",
      "Iteration 6481: Weights = [5.50000000e+01 3.46073108e+00 7.27624249e+00 2.39728627e-02\n",
      " 2.42259746e-01 1.17532737e+01], Loss = 0.3562\n",
      "Iteration 6482: Weights = [5.50000000e+01 3.46063173e+00 7.27603362e+00 2.39721745e-02\n",
      " 2.42252791e-01 1.17534943e+01], Loss = 0.3562\n",
      "Iteration 6483: Weights = [5.50000000e+01 3.46053239e+00 7.27582475e+00 2.39714863e-02\n",
      " 2.42245837e-01 1.17537150e+01], Loss = 0.3561\n",
      "Iteration 6484: Weights = [5.50000000e+01 3.46043305e+00 7.27561589e+00 2.39707982e-02\n",
      " 2.42238883e-01 1.17539357e+01], Loss = 0.3561\n",
      "Iteration 6485: Weights = [5.50000000e+01 3.46033371e+00 7.27540703e+00 2.39701101e-02\n",
      " 2.42231929e-01 1.17541563e+01], Loss = 0.3561\n",
      "Iteration 6486: Weights = [5.50000000e+01 3.46023438e+00 7.27519818e+00 2.39694220e-02\n",
      " 2.42224976e-01 1.17543770e+01], Loss = 0.3561\n",
      "Iteration 6487: Weights = [5.50000000e+01 3.46013505e+00 7.27498934e+00 2.39687339e-02\n",
      " 2.42218022e-01 1.17545976e+01], Loss = 0.3561\n",
      "Iteration 6488: Weights = [5.50000000e+01 3.46003572e+00 7.27478050e+00 2.39680459e-02\n",
      " 2.42211069e-01 1.17548182e+01], Loss = 0.3560\n",
      "Iteration 6489: Weights = [5.50000000e+01 3.45993640e+00 7.27457167e+00 2.39673578e-02\n",
      " 2.42204116e-01 1.17550389e+01], Loss = 0.3560\n",
      "Iteration 6490: Weights = [5.50000000e+01 3.45983707e+00 7.27436284e+00 2.39666698e-02\n",
      " 2.42197163e-01 1.17552595e+01], Loss = 0.3560\n",
      "Iteration 6491: Weights = [5.50000000e+01 3.45973776e+00 7.27415402e+00 2.39659818e-02\n",
      " 2.42190211e-01 1.17554801e+01], Loss = 0.3560\n",
      "Iteration 6492: Weights = [5.50000000e+01 3.45963844e+00 7.27394521e+00 2.39652938e-02\n",
      " 2.42183258e-01 1.17557007e+01], Loss = 0.3560\n",
      "Iteration 6493: Weights = [5.50000000e+01 3.45953913e+00 7.27373640e+00 2.39646059e-02\n",
      " 2.42176306e-01 1.17559213e+01], Loss = 0.3559\n",
      "Iteration 6494: Weights = [5.50000000e+01 3.45943981e+00 7.27352760e+00 2.39639180e-02\n",
      " 2.42169354e-01 1.17561419e+01], Loss = 0.3559\n",
      "Iteration 6495: Weights = [5.50000000e+01 3.45934051e+00 7.27331880e+00 2.39632300e-02\n",
      " 2.42162403e-01 1.17563625e+01], Loss = 0.3559\n",
      "Iteration 6496: Weights = [5.50000000e+01 3.45924120e+00 7.27311001e+00 2.39625421e-02\n",
      " 2.42155451e-01 1.17565831e+01], Loss = 0.3559\n",
      "Iteration 6497: Weights = [5.50000000e+01 3.45914190e+00 7.27290123e+00 2.39618543e-02\n",
      " 2.42148500e-01 1.17568037e+01], Loss = 0.3559\n",
      "Iteration 6498: Weights = [5.50000000e+01 3.45904260e+00 7.27269245e+00 2.39611664e-02\n",
      " 2.42141548e-01 1.17570242e+01], Loss = 0.3558\n",
      "Iteration 6499: Weights = [5.50000000e+01 3.45894330e+00 7.27248368e+00 2.39604786e-02\n",
      " 2.42134597e-01 1.17572448e+01], Loss = 0.3558\n",
      "Iteration 6500: Weights = [5.50000000e+01 3.45884401e+00 7.27227491e+00 2.39597908e-02\n",
      " 2.42127647e-01 1.17574654e+01], Loss = 0.3558\n",
      "Iteration 6501: Weights = [5.50000000e+01 3.45874472e+00 7.27206615e+00 2.39591030e-02\n",
      " 2.42120696e-01 1.17576859e+01], Loss = 0.3558\n",
      "Iteration 6502: Weights = [5.50000000e+01 3.45864543e+00 7.27185740e+00 2.39584152e-02\n",
      " 2.42113746e-01 1.17579065e+01], Loss = 0.3558\n",
      "Iteration 6503: Weights = [5.50000000e+01 3.45854615e+00 7.27164865e+00 2.39577274e-02\n",
      " 2.42106795e-01 1.17581270e+01], Loss = 0.3557\n",
      "Iteration 6504: Weights = [5.50000000e+01 3.45844687e+00 7.27143991e+00 2.39570397e-02\n",
      " 2.42099845e-01 1.17583475e+01], Loss = 0.3557\n",
      "Iteration 6505: Weights = [5.50000000e+01 3.45834759e+00 7.27123117e+00 2.39563520e-02\n",
      " 2.42092896e-01 1.17585681e+01], Loss = 0.3557\n",
      "Iteration 6506: Weights = [5.50000000e+01 3.45824831e+00 7.27102244e+00 2.39556643e-02\n",
      " 2.42085946e-01 1.17587886e+01], Loss = 0.3557\n",
      "Iteration 6507: Weights = [5.50000000e+01 3.45814904e+00 7.27081372e+00 2.39549766e-02\n",
      " 2.42078997e-01 1.17590091e+01], Loss = 0.3557\n",
      "Iteration 6508: Weights = [5.50000000e+01 3.45804977e+00 7.27060500e+00 2.39542889e-02\n",
      " 2.42072047e-01 1.17592296e+01], Loss = 0.3556\n",
      "Iteration 6509: Weights = [5.50000000e+01 3.45795050e+00 7.27039629e+00 2.39536013e-02\n",
      " 2.42065098e-01 1.17594501e+01], Loss = 0.3556\n",
      "Iteration 6510: Weights = [5.50000000e+01 3.45785123e+00 7.27018758e+00 2.39529137e-02\n",
      " 2.42058150e-01 1.17596706e+01], Loss = 0.3556\n",
      "Iteration 6511: Weights = [5.50000000e+01 3.45775197e+00 7.26997888e+00 2.39522261e-02\n",
      " 2.42051201e-01 1.17598911e+01], Loss = 0.3556\n",
      "Iteration 6512: Weights = [5.50000000e+01 3.45765271e+00 7.26977019e+00 2.39515385e-02\n",
      " 2.42044253e-01 1.17601116e+01], Loss = 0.3556\n",
      "Iteration 6513: Weights = [5.50000000e+01 3.45755346e+00 7.26956150e+00 2.39508509e-02\n",
      " 2.42037304e-01 1.17603320e+01], Loss = 0.3555\n",
      "Iteration 6514: Weights = [5.50000000e+01 3.45745420e+00 7.26935282e+00 2.39501634e-02\n",
      " 2.42030356e-01 1.17605525e+01], Loss = 0.3555\n",
      "Iteration 6515: Weights = [5.50000000e+01 3.45735495e+00 7.26914414e+00 2.39494759e-02\n",
      " 2.42023409e-01 1.17607730e+01], Loss = 0.3555\n",
      "Iteration 6516: Weights = [5.50000000e+01 3.45725570e+00 7.26893547e+00 2.39487884e-02\n",
      " 2.42016461e-01 1.17609934e+01], Loss = 0.3555\n",
      "Iteration 6517: Weights = [5.50000000e+01 3.45715646e+00 7.26872680e+00 2.39481009e-02\n",
      " 2.42009514e-01 1.17612139e+01], Loss = 0.3555\n",
      "Iteration 6518: Weights = [5.50000000e+01 3.45705722e+00 7.26851815e+00 2.39474134e-02\n",
      " 2.42002566e-01 1.17614343e+01], Loss = 0.3554\n",
      "Iteration 6519: Weights = [5.50000000e+01 3.45695798e+00 7.26830949e+00 2.39467260e-02\n",
      " 2.41995619e-01 1.17616548e+01], Loss = 0.3554\n",
      "Iteration 6520: Weights = [5.50000000e+01 3.45685874e+00 7.26810085e+00 2.39460386e-02\n",
      " 2.41988673e-01 1.17618752e+01], Loss = 0.3554\n",
      "Iteration 6521: Weights = [5.50000000e+01 3.45675951e+00 7.26789221e+00 2.39453512e-02\n",
      " 2.41981726e-01 1.17620956e+01], Loss = 0.3554\n",
      "Iteration 6522: Weights = [5.50000000e+01 3.45666028e+00 7.26768357e+00 2.39446638e-02\n",
      " 2.41974780e-01 1.17623160e+01], Loss = 0.3554\n",
      "Iteration 6523: Weights = [5.50000000e+01 3.45656105e+00 7.26747494e+00 2.39439764e-02\n",
      " 2.41967833e-01 1.17625365e+01], Loss = 0.3553\n",
      "Iteration 6524: Weights = [5.50000000e+01 3.45646182e+00 7.26726632e+00 2.39432891e-02\n",
      " 2.41960887e-01 1.17627569e+01], Loss = 0.3553\n",
      "Iteration 6525: Weights = [5.50000000e+01 3.45636260e+00 7.26705771e+00 2.39426018e-02\n",
      " 2.41953942e-01 1.17629773e+01], Loss = 0.3553\n",
      "Iteration 6526: Weights = [5.50000000e+01 3.45626338e+00 7.26684910e+00 2.39419145e-02\n",
      " 2.41946996e-01 1.17631977e+01], Loss = 0.3553\n",
      "Iteration 6527: Weights = [5.50000000e+01 3.45616416e+00 7.26664049e+00 2.39412272e-02\n",
      " 2.41940051e-01 1.17634180e+01], Loss = 0.3552\n",
      "Iteration 6528: Weights = [5.50000000e+01 3.45606495e+00 7.26643189e+00 2.39405399e-02\n",
      " 2.41933105e-01 1.17636384e+01], Loss = 0.3552\n",
      "Iteration 6529: Weights = [5.50000000e+01 3.45596574e+00 7.26622330e+00 2.39398527e-02\n",
      " 2.41926160e-01 1.17638588e+01], Loss = 0.3552\n",
      "Iteration 6530: Weights = [5.50000000e+01 3.45586653e+00 7.26601471e+00 2.39391654e-02\n",
      " 2.41919216e-01 1.17640792e+01], Loss = 0.3552\n",
      "Iteration 6531: Weights = [5.50000000e+01 3.45576733e+00 7.26580613e+00 2.39384782e-02\n",
      " 2.41912271e-01 1.17642995e+01], Loss = 0.3552\n",
      "Iteration 6532: Weights = [5.50000000e+01 3.45566812e+00 7.26559756e+00 2.39377910e-02\n",
      " 2.41905327e-01 1.17645199e+01], Loss = 0.3551\n",
      "Iteration 6533: Weights = [5.50000000e+01 3.45556892e+00 7.26538899e+00 2.39371039e-02\n",
      " 2.41898382e-01 1.17647402e+01], Loss = 0.3551\n",
      "Iteration 6534: Weights = [5.50000000e+01 3.45546973e+00 7.26518043e+00 2.39364167e-02\n",
      " 2.41891438e-01 1.17649606e+01], Loss = 0.3551\n",
      "Iteration 6535: Weights = [5.50000000e+01 3.45537053e+00 7.26497187e+00 2.39357296e-02\n",
      " 2.41884495e-01 1.17651809e+01], Loss = 0.3551\n",
      "Iteration 6536: Weights = [5.50000000e+01 3.45527134e+00 7.26476332e+00 2.39350425e-02\n",
      " 2.41877551e-01 1.17654012e+01], Loss = 0.3551\n",
      "Iteration 6537: Weights = [5.50000000e+01 3.45517215e+00 7.26455478e+00 2.39343554e-02\n",
      " 2.41870608e-01 1.17656216e+01], Loss = 0.3550\n",
      "Iteration 6538: Weights = [5.50000000e+01 3.45507297e+00 7.26434624e+00 2.39336683e-02\n",
      " 2.41863664e-01 1.17658419e+01], Loss = 0.3550\n",
      "Iteration 6539: Weights = [5.50000000e+01 3.45497379e+00 7.26413771e+00 2.39329813e-02\n",
      " 2.41856721e-01 1.17660622e+01], Loss = 0.3550\n",
      "Iteration 6540: Weights = [5.50000000e+01 3.45487461e+00 7.26392918e+00 2.39322943e-02\n",
      " 2.41849779e-01 1.17662825e+01], Loss = 0.3550\n",
      "Iteration 6541: Weights = [5.50000000e+01 3.45477543e+00 7.26372066e+00 2.39316073e-02\n",
      " 2.41842836e-01 1.17665028e+01], Loss = 0.3550\n",
      "Iteration 6542: Weights = [5.50000000e+01 3.45467626e+00 7.26351214e+00 2.39309203e-02\n",
      " 2.41835893e-01 1.17667231e+01], Loss = 0.3549\n",
      "Iteration 6543: Weights = [5.50000000e+01 3.45457709e+00 7.26330363e+00 2.39302333e-02\n",
      " 2.41828951e-01 1.17669434e+01], Loss = 0.3549\n",
      "Iteration 6544: Weights = [5.50000000e+01 3.45447792e+00 7.26309513e+00 2.39295464e-02\n",
      " 2.41822009e-01 1.17671637e+01], Loss = 0.3549\n",
      "Iteration 6545: Weights = [5.50000000e+01 3.45437875e+00 7.26288664e+00 2.39288594e-02\n",
      " 2.41815067e-01 1.17673839e+01], Loss = 0.3549\n",
      "Iteration 6546: Weights = [5.50000000e+01 3.45427959e+00 7.26267814e+00 2.39281725e-02\n",
      " 2.41808126e-01 1.17676042e+01], Loss = 0.3549\n",
      "Iteration 6547: Weights = [5.50000000e+01 3.45418043e+00 7.26246966e+00 2.39274856e-02\n",
      " 2.41801184e-01 1.17678245e+01], Loss = 0.3548\n",
      "Iteration 6548: Weights = [5.50000000e+01 3.45408127e+00 7.26226118e+00 2.39267988e-02\n",
      " 2.41794243e-01 1.17680447e+01], Loss = 0.3548\n",
      "Iteration 6549: Weights = [5.50000000e+01 3.45398212e+00 7.26205271e+00 2.39261119e-02\n",
      " 2.41787302e-01 1.17682650e+01], Loss = 0.3548\n",
      "Iteration 6550: Weights = [5.50000000e+01 3.45388297e+00 7.26184424e+00 2.39254251e-02\n",
      " 2.41780361e-01 1.17684852e+01], Loss = 0.3548\n",
      "Iteration 6551: Weights = [5.50000000e+01 3.45378382e+00 7.26163578e+00 2.39247383e-02\n",
      " 2.41773421e-01 1.17687054e+01], Loss = 0.3548\n",
      "Iteration 6552: Weights = [5.50000000e+01 3.45368468e+00 7.26142733e+00 2.39240515e-02\n",
      " 2.41766480e-01 1.17689257e+01], Loss = 0.3547\n",
      "Iteration 6553: Weights = [5.50000000e+01 3.45358553e+00 7.26121888e+00 2.39233647e-02\n",
      " 2.41759540e-01 1.17691459e+01], Loss = 0.3547\n",
      "Iteration 6554: Weights = [5.50000000e+01 3.45348639e+00 7.26101044e+00 2.39226780e-02\n",
      " 2.41752600e-01 1.17693661e+01], Loss = 0.3547\n",
      "Iteration 6555: Weights = [5.50000000e+01 3.45338726e+00 7.26080200e+00 2.39219912e-02\n",
      " 2.41745660e-01 1.17695863e+01], Loss = 0.3547\n",
      "Iteration 6556: Weights = [5.50000000e+01 3.45328812e+00 7.26059357e+00 2.39213045e-02\n",
      " 2.41738721e-01 1.17698065e+01], Loss = 0.3547\n",
      "Iteration 6557: Weights = [5.50000000e+01 3.45318899e+00 7.26038514e+00 2.39206178e-02\n",
      " 2.41731781e-01 1.17700267e+01], Loss = 0.3546\n",
      "Iteration 6558: Weights = [5.50000000e+01 3.45308986e+00 7.26017672e+00 2.39199311e-02\n",
      " 2.41724842e-01 1.17702469e+01], Loss = 0.3546\n",
      "Iteration 6559: Weights = [5.50000000e+01 3.45299074e+00 7.25996831e+00 2.39192445e-02\n",
      " 2.41717903e-01 1.17704671e+01], Loss = 0.3546\n",
      "Iteration 6560: Weights = [5.50000000e+01 3.45289161e+00 7.25975990e+00 2.39185579e-02\n",
      " 2.41710964e-01 1.17706873e+01], Loss = 0.3546\n",
      "Iteration 6561: Weights = [5.50000000e+01 3.45279249e+00 7.25955150e+00 2.39178712e-02\n",
      " 2.41704025e-01 1.17709074e+01], Loss = 0.3546\n",
      "Iteration 6562: Weights = [5.50000000e+01 3.45269338e+00 7.25934311e+00 2.39171847e-02\n",
      " 2.41697087e-01 1.17711276e+01], Loss = 0.3545\n",
      "Iteration 6563: Weights = [5.50000000e+01 3.45259426e+00 7.25913472e+00 2.39164981e-02\n",
      " 2.41690149e-01 1.17713478e+01], Loss = 0.3545\n",
      "Iteration 6564: Weights = [5.50000000e+01 3.45249515e+00 7.25892634e+00 2.39158115e-02\n",
      " 2.41683211e-01 1.17715679e+01], Loss = 0.3545\n",
      "Iteration 6565: Weights = [5.50000000e+01 3.45239604e+00 7.25871796e+00 2.39151250e-02\n",
      " 2.41676273e-01 1.17717881e+01], Loss = 0.3545\n",
      "Iteration 6566: Weights = [5.50000000e+01 3.45229694e+00 7.25850959e+00 2.39144385e-02\n",
      " 2.41669335e-01 1.17720082e+01], Loss = 0.3545\n",
      "Iteration 6567: Weights = [5.50000000e+01 3.45219784e+00 7.25830122e+00 2.39137520e-02\n",
      " 2.41662398e-01 1.17722283e+01], Loss = 0.3544\n",
      "Iteration 6568: Weights = [5.50000000e+01 3.45209874e+00 7.25809286e+00 2.39130655e-02\n",
      " 2.41655461e-01 1.17724485e+01], Loss = 0.3544\n",
      "Iteration 6569: Weights = [5.50000000e+01 3.45199964e+00 7.25788451e+00 2.39123790e-02\n",
      " 2.41648524e-01 1.17726686e+01], Loss = 0.3544\n",
      "Iteration 6570: Weights = [5.50000000e+01 3.45190054e+00 7.25767616e+00 2.39116926e-02\n",
      " 2.41641587e-01 1.17728887e+01], Loss = 0.3544\n",
      "Iteration 6571: Weights = [5.50000000e+01 3.45180145e+00 7.25746782e+00 2.39110062e-02\n",
      " 2.41634650e-01 1.17731088e+01], Loss = 0.3544\n",
      "Iteration 6572: Weights = [5.50000000e+01 3.45170237e+00 7.25725949e+00 2.39103198e-02\n",
      " 2.41627714e-01 1.17733289e+01], Loss = 0.3543\n",
      "Iteration 6573: Weights = [5.50000000e+01 3.45160328e+00 7.25705116e+00 2.39096334e-02\n",
      " 2.41620777e-01 1.17735490e+01], Loss = 0.3543\n",
      "Iteration 6574: Weights = [5.50000000e+01 3.45150420e+00 7.25684284e+00 2.39089471e-02\n",
      " 2.41613841e-01 1.17737691e+01], Loss = 0.3543\n",
      "Iteration 6575: Weights = [5.50000000e+01 3.45140512e+00 7.25663452e+00 2.39082607e-02\n",
      " 2.41606906e-01 1.17739892e+01], Loss = 0.3543\n",
      "Iteration 6576: Weights = [5.50000000e+01 3.45130604e+00 7.25642621e+00 2.39075744e-02\n",
      " 2.41599970e-01 1.17742093e+01], Loss = 0.3543\n",
      "Iteration 6577: Weights = [5.50000000e+01 3.45120697e+00 7.25621790e+00 2.39068881e-02\n",
      " 2.41593034e-01 1.17744293e+01], Loss = 0.3542\n",
      "Iteration 6578: Weights = [5.50000000e+01 3.45110789e+00 7.25600960e+00 2.39062018e-02\n",
      " 2.41586099e-01 1.17746494e+01], Loss = 0.3542\n",
      "Iteration 6579: Weights = [5.50000000e+01 3.45100883e+00 7.25580131e+00 2.39055156e-02\n",
      " 2.41579164e-01 1.17748695e+01], Loss = 0.3542\n",
      "Iteration 6580: Weights = [5.50000000e+01 3.45090976e+00 7.25559302e+00 2.39048293e-02\n",
      " 2.41572229e-01 1.17750895e+01], Loss = 0.3542\n",
      "Iteration 6581: Weights = [5.50000000e+01 3.45081070e+00 7.25538474e+00 2.39041431e-02\n",
      " 2.41565295e-01 1.17753096e+01], Loss = 0.3541\n",
      "Iteration 6582: Weights = [5.50000000e+01 3.45071164e+00 7.25517647e+00 2.39034569e-02\n",
      " 2.41558360e-01 1.17755296e+01], Loss = 0.3541\n",
      "Iteration 6583: Weights = [5.50000000e+01 3.45061258e+00 7.25496820e+00 2.39027707e-02\n",
      " 2.41551426e-01 1.17757496e+01], Loss = 0.3541\n",
      "Iteration 6584: Weights = [5.50000000e+01 3.45051353e+00 7.25475993e+00 2.39020846e-02\n",
      " 2.41544492e-01 1.17759697e+01], Loss = 0.3541\n",
      "Iteration 6585: Weights = [5.50000000e+01 3.45041447e+00 7.25455168e+00 2.39013984e-02\n",
      " 2.41537558e-01 1.17761897e+01], Loss = 0.3541\n",
      "Iteration 6586: Weights = [5.50000000e+01 3.45031543e+00 7.25434342e+00 2.39007123e-02\n",
      " 2.41530624e-01 1.17764097e+01], Loss = 0.3540\n",
      "Iteration 6587: Weights = [5.50000000e+01 3.45021638e+00 7.25413518e+00 2.39000262e-02\n",
      " 2.41523691e-01 1.17766297e+01], Loss = 0.3540\n",
      "Iteration 6588: Weights = [5.50000000e+01 3.45011734e+00 7.25392694e+00 2.38993401e-02\n",
      " 2.41516758e-01 1.17768497e+01], Loss = 0.3540\n",
      "Iteration 6589: Weights = [5.50000000e+01 3.45001830e+00 7.25371871e+00 2.38986541e-02\n",
      " 2.41509825e-01 1.17770697e+01], Loss = 0.3540\n",
      "Iteration 6590: Weights = [5.50000000e+01 3.44991926e+00 7.25351048e+00 2.38979680e-02\n",
      " 2.41502892e-01 1.17772897e+01], Loss = 0.3540\n",
      "Iteration 6591: Weights = [5.50000000e+01 3.44982022e+00 7.25330226e+00 2.38972820e-02\n",
      " 2.41495959e-01 1.17775097e+01], Loss = 0.3539\n",
      "Iteration 6592: Weights = [5.50000000e+01 3.44972119e+00 7.25309404e+00 2.38965960e-02\n",
      " 2.41489027e-01 1.17777296e+01], Loss = 0.3539\n",
      "Iteration 6593: Weights = [5.50000000e+01 3.44962216e+00 7.25288583e+00 2.38959100e-02\n",
      " 2.41482094e-01 1.17779496e+01], Loss = 0.3539\n",
      "Iteration 6594: Weights = [5.50000000e+01 3.44952314e+00 7.25267763e+00 2.38952241e-02\n",
      " 2.41475162e-01 1.17781696e+01], Loss = 0.3539\n",
      "Iteration 6595: Weights = [5.50000000e+01 3.44942412e+00 7.25246943e+00 2.38945381e-02\n",
      " 2.41468231e-01 1.17783895e+01], Loss = 0.3539\n",
      "Iteration 6596: Weights = [5.50000000e+01 3.44932509e+00 7.25226124e+00 2.38938522e-02\n",
      " 2.41461299e-01 1.17786095e+01], Loss = 0.3538\n",
      "Iteration 6597: Weights = [5.50000000e+01 3.44922608e+00 7.25205305e+00 2.38931663e-02\n",
      " 2.41454367e-01 1.17788294e+01], Loss = 0.3538\n",
      "Iteration 6598: Weights = [5.50000000e+01 3.44912706e+00 7.25184487e+00 2.38924804e-02\n",
      " 2.41447436e-01 1.17790494e+01], Loss = 0.3538\n",
      "Iteration 6599: Weights = [5.50000000e+01 3.44902805e+00 7.25163670e+00 2.38917945e-02\n",
      " 2.41440505e-01 1.17792693e+01], Loss = 0.3538\n",
      "Iteration 6600: Weights = [5.50000000e+01 3.44892904e+00 7.25142853e+00 2.38911087e-02\n",
      " 2.41433574e-01 1.17794892e+01], Loss = 0.3538\n",
      "Iteration 6601: Weights = [5.50000000e+01 3.44883004e+00 7.25122037e+00 2.38904229e-02\n",
      " 2.41426644e-01 1.17797092e+01], Loss = 0.3537\n",
      "Iteration 6602: Weights = [5.50000000e+01 3.44873103e+00 7.25101221e+00 2.38897371e-02\n",
      " 2.41419713e-01 1.17799291e+01], Loss = 0.3537\n",
      "Iteration 6603: Weights = [5.50000000e+01 3.44863203e+00 7.25080406e+00 2.38890513e-02\n",
      " 2.41412783e-01 1.17801490e+01], Loss = 0.3537\n",
      "Iteration 6604: Weights = [5.50000000e+01 3.44853304e+00 7.25059592e+00 2.38883655e-02\n",
      " 2.41405853e-01 1.17803689e+01], Loss = 0.3537\n",
      "Iteration 6605: Weights = [5.50000000e+01 3.44843404e+00 7.25038778e+00 2.38876798e-02\n",
      " 2.41398923e-01 1.17805888e+01], Loss = 0.3537\n",
      "Iteration 6606: Weights = [5.50000000e+01 3.44833505e+00 7.25017965e+00 2.38869940e-02\n",
      " 2.41391993e-01 1.17808087e+01], Loss = 0.3536\n",
      "Iteration 6607: Weights = [5.50000000e+01 3.44823606e+00 7.24997153e+00 2.38863083e-02\n",
      " 2.41385064e-01 1.17810285e+01], Loss = 0.3536\n",
      "Iteration 6608: Weights = [5.50000000e+01 3.44813707e+00 7.24976341e+00 2.38856226e-02\n",
      " 2.41378134e-01 1.17812484e+01], Loss = 0.3536\n",
      "Iteration 6609: Weights = [5.50000000e+01 3.44803809e+00 7.24955529e+00 2.38849370e-02\n",
      " 2.41371205e-01 1.17814683e+01], Loss = 0.3536\n",
      "Iteration 6610: Weights = [5.50000000e+01 3.44793911e+00 7.24934718e+00 2.38842513e-02\n",
      " 2.41364276e-01 1.17816881e+01], Loss = 0.3536\n",
      "Iteration 6611: Weights = [5.50000000e+01 3.44784013e+00 7.24913908e+00 2.38835657e-02\n",
      " 2.41357348e-01 1.17819080e+01], Loss = 0.3535\n",
      "Iteration 6612: Weights = [5.50000000e+01 3.44774116e+00 7.24893099e+00 2.38828801e-02\n",
      " 2.41350419e-01 1.17821278e+01], Loss = 0.3535\n",
      "Iteration 6613: Weights = [5.50000000e+01 3.44764219e+00 7.24872290e+00 2.38821945e-02\n",
      " 2.41343491e-01 1.17823477e+01], Loss = 0.3535\n",
      "Iteration 6614: Weights = [5.50000000e+01 3.44754322e+00 7.24851481e+00 2.38815089e-02\n",
      " 2.41336563e-01 1.17825675e+01], Loss = 0.3535\n",
      "Iteration 6615: Weights = [5.50000000e+01 3.44744425e+00 7.24830673e+00 2.38808234e-02\n",
      " 2.41329635e-01 1.17827874e+01], Loss = 0.3535\n",
      "Iteration 6616: Weights = [5.50000000e+01 3.44734529e+00 7.24809866e+00 2.38801378e-02\n",
      " 2.41322707e-01 1.17830072e+01], Loss = 0.3534\n",
      "Iteration 6617: Weights = [5.50000000e+01 3.44724633e+00 7.24789059e+00 2.38794523e-02\n",
      " 2.41315780e-01 1.17832270e+01], Loss = 0.3534\n",
      "Iteration 6618: Weights = [5.50000000e+01 3.44714737e+00 7.24768253e+00 2.38787668e-02\n",
      " 2.41308853e-01 1.17834468e+01], Loss = 0.3534\n",
      "Iteration 6619: Weights = [5.50000000e+01 3.44704841e+00 7.24747448e+00 2.38780814e-02\n",
      " 2.41301926e-01 1.17836666e+01], Loss = 0.3534\n",
      "Iteration 6620: Weights = [5.50000000e+01 3.44694946e+00 7.24726643e+00 2.38773959e-02\n",
      " 2.41294999e-01 1.17838864e+01], Loss = 0.3534\n",
      "Iteration 6621: Weights = [5.50000000e+01 3.44685051e+00 7.24705839e+00 2.38767105e-02\n",
      " 2.41288072e-01 1.17841062e+01], Loss = 0.3533\n",
      "Iteration 6622: Weights = [5.50000000e+01 3.44675157e+00 7.24685035e+00 2.38760251e-02\n",
      " 2.41281145e-01 1.17843260e+01], Loss = 0.3533\n",
      "Iteration 6623: Weights = [5.50000000e+01 3.44665262e+00 7.24664232e+00 2.38753397e-02\n",
      " 2.41274219e-01 1.17845458e+01], Loss = 0.3533\n",
      "Iteration 6624: Weights = [5.50000000e+01 3.44655368e+00 7.24643430e+00 2.38746543e-02\n",
      " 2.41267293e-01 1.17847656e+01], Loss = 0.3533\n",
      "Iteration 6625: Weights = [5.50000000e+01 3.44645474e+00 7.24622628e+00 2.38739690e-02\n",
      " 2.41260367e-01 1.17849853e+01], Loss = 0.3533\n",
      "Iteration 6626: Weights = [5.50000000e+01 3.44635581e+00 7.24601827e+00 2.38732836e-02\n",
      " 2.41253442e-01 1.17852051e+01], Loss = 0.3532\n",
      "Iteration 6627: Weights = [5.50000000e+01 3.44625688e+00 7.24581026e+00 2.38725983e-02\n",
      " 2.41246516e-01 1.17854248e+01], Loss = 0.3532\n",
      "Iteration 6628: Weights = [5.50000000e+01 3.44615795e+00 7.24560226e+00 2.38719130e-02\n",
      " 2.41239591e-01 1.17856446e+01], Loss = 0.3532\n",
      "Iteration 6629: Weights = [5.50000000e+01 3.44605902e+00 7.24539427e+00 2.38712277e-02\n",
      " 2.41232666e-01 1.17858643e+01], Loss = 0.3532\n",
      "Iteration 6630: Weights = [5.50000000e+01 3.44596010e+00 7.24518628e+00 2.38705425e-02\n",
      " 2.41225741e-01 1.17860841e+01], Loss = 0.3532\n",
      "Iteration 6631: Weights = [5.50000000e+01 3.44586118e+00 7.24497830e+00 2.38698572e-02\n",
      " 2.41218816e-01 1.17863038e+01], Loss = 0.3531\n",
      "Iteration 6632: Weights = [5.50000000e+01 3.44576226e+00 7.24477032e+00 2.38691720e-02\n",
      " 2.41211892e-01 1.17865235e+01], Loss = 0.3531\n",
      "Iteration 6633: Weights = [5.50000000e+01 3.44566334e+00 7.24456235e+00 2.38684868e-02\n",
      " 2.41204967e-01 1.17867432e+01], Loss = 0.3531\n",
      "Iteration 6634: Weights = [5.50000000e+01 3.44556443e+00 7.24435438e+00 2.38678017e-02\n",
      " 2.41198043e-01 1.17869630e+01], Loss = 0.3531\n",
      "Iteration 6635: Weights = [5.50000000e+01 3.44546552e+00 7.24414643e+00 2.38671165e-02\n",
      " 2.41191119e-01 1.17871827e+01], Loss = 0.3531\n",
      "Iteration 6636: Weights = [5.50000000e+01 3.44536662e+00 7.24393847e+00 2.38664314e-02\n",
      " 2.41184195e-01 1.17874024e+01], Loss = 0.3530\n",
      "Iteration 6637: Weights = [5.50000000e+01 3.44526771e+00 7.24373053e+00 2.38657462e-02\n",
      " 2.41177272e-01 1.17876221e+01], Loss = 0.3530\n",
      "Iteration 6638: Weights = [5.50000000e+01 3.44516881e+00 7.24352258e+00 2.38650612e-02\n",
      " 2.41170349e-01 1.17878417e+01], Loss = 0.3530\n",
      "Iteration 6639: Weights = [5.50000000e+01 3.44506991e+00 7.24331465e+00 2.38643761e-02\n",
      " 2.41163426e-01 1.17880614e+01], Loss = 0.3530\n",
      "Iteration 6640: Weights = [5.50000000e+01 3.44497102e+00 7.24310672e+00 2.38636910e-02\n",
      " 2.41156503e-01 1.17882811e+01], Loss = 0.3530\n",
      "Iteration 6641: Weights = [5.50000000e+01 3.44487213e+00 7.24289880e+00 2.38630060e-02\n",
      " 2.41149580e-01 1.17885008e+01], Loss = 0.3529\n",
      "Iteration 6642: Weights = [5.50000000e+01 3.44477324e+00 7.24269088e+00 2.38623210e-02\n",
      " 2.41142657e-01 1.17887204e+01], Loss = 0.3529\n",
      "Iteration 6643: Weights = [5.50000000e+01 3.44467435e+00 7.24248297e+00 2.38616360e-02\n",
      " 2.41135735e-01 1.17889401e+01], Loss = 0.3529\n",
      "Iteration 6644: Weights = [5.50000000e+01 3.44457546e+00 7.24227507e+00 2.38609510e-02\n",
      " 2.41128813e-01 1.17891597e+01], Loss = 0.3529\n",
      "Iteration 6645: Weights = [5.50000000e+01 3.44447658e+00 7.24206717e+00 2.38602660e-02\n",
      " 2.41121891e-01 1.17893794e+01], Loss = 0.3529\n",
      "Iteration 6646: Weights = [5.50000000e+01 3.44437771e+00 7.24185927e+00 2.38595811e-02\n",
      " 2.41114969e-01 1.17895990e+01], Loss = 0.3528\n",
      "Iteration 6647: Weights = [5.50000000e+01 3.44427883e+00 7.24165139e+00 2.38588962e-02\n",
      " 2.41108048e-01 1.17898186e+01], Loss = 0.3528\n",
      "Iteration 6648: Weights = [5.50000000e+01 3.44417996e+00 7.24144351e+00 2.38582113e-02\n",
      " 2.41101127e-01 1.17900383e+01], Loss = 0.3528\n",
      "Iteration 6649: Weights = [5.50000000e+01 3.44408109e+00 7.24123563e+00 2.38575264e-02\n",
      " 2.41094205e-01 1.17902579e+01], Loss = 0.3528\n",
      "Iteration 6650: Weights = [5.50000000e+01 3.44398222e+00 7.24102776e+00 2.38568415e-02\n",
      " 2.41087284e-01 1.17904775e+01], Loss = 0.3527\n",
      "Iteration 6651: Weights = [5.50000000e+01 3.44388336e+00 7.24081990e+00 2.38561567e-02\n",
      " 2.41080364e-01 1.17906971e+01], Loss = 0.3527\n",
      "Iteration 6652: Weights = [5.50000000e+01 3.44378450e+00 7.24061204e+00 2.38554719e-02\n",
      " 2.41073443e-01 1.17909167e+01], Loss = 0.3527\n",
      "Iteration 6653: Weights = [5.50000000e+01 3.44368564e+00 7.24040419e+00 2.38547870e-02\n",
      " 2.41066523e-01 1.17911363e+01], Loss = 0.3527\n",
      "Iteration 6654: Weights = [5.50000000e+01 3.44358678e+00 7.24019634e+00 2.38541023e-02\n",
      " 2.41059603e-01 1.17913559e+01], Loss = 0.3527\n",
      "Iteration 6655: Weights = [5.50000000e+01 3.44348793e+00 7.23998851e+00 2.38534175e-02\n",
      " 2.41052683e-01 1.17915754e+01], Loss = 0.3526\n",
      "Iteration 6656: Weights = [5.50000000e+01 3.44338908e+00 7.23978067e+00 2.38527328e-02\n",
      " 2.41045763e-01 1.17917950e+01], Loss = 0.3526\n",
      "Iteration 6657: Weights = [5.50000000e+01 3.44329023e+00 7.23957284e+00 2.38520480e-02\n",
      " 2.41038844e-01 1.17920146e+01], Loss = 0.3526\n",
      "Iteration 6658: Weights = [5.50000000e+01 3.44319139e+00 7.23936502e+00 2.38513633e-02\n",
      " 2.41031924e-01 1.17922341e+01], Loss = 0.3526\n",
      "Iteration 6659: Weights = [5.50000000e+01 3.44309255e+00 7.23915721e+00 2.38506786e-02\n",
      " 2.41025005e-01 1.17924537e+01], Loss = 0.3526\n",
      "Iteration 6660: Weights = [5.50000000e+01 3.44299371e+00 7.23894940e+00 2.38499940e-02\n",
      " 2.41018086e-01 1.17926732e+01], Loss = 0.3525\n",
      "Iteration 6661: Weights = [5.50000000e+01 3.44289487e+00 7.23874159e+00 2.38493093e-02\n",
      " 2.41011167e-01 1.17928928e+01], Loss = 0.3525\n",
      "Iteration 6662: Weights = [5.50000000e+01 3.44279604e+00 7.23853380e+00 2.38486247e-02\n",
      " 2.41004249e-01 1.17931123e+01], Loss = 0.3525\n",
      "Iteration 6663: Weights = [5.50000000e+01 3.44269721e+00 7.23832601e+00 2.38479401e-02\n",
      " 2.40997331e-01 1.17933318e+01], Loss = 0.3525\n",
      "Iteration 6664: Weights = [5.50000000e+01 3.44259838e+00 7.23811822e+00 2.38472555e-02\n",
      " 2.40990412e-01 1.17935514e+01], Loss = 0.3525\n",
      "Iteration 6665: Weights = [5.50000000e+01 3.44249956e+00 7.23791044e+00 2.38465710e-02\n",
      " 2.40983494e-01 1.17937709e+01], Loss = 0.3524\n",
      "Iteration 6666: Weights = [5.50000000e+01 3.44240074e+00 7.23770267e+00 2.38458864e-02\n",
      " 2.40976577e-01 1.17939904e+01], Loss = 0.3524\n",
      "Iteration 6667: Weights = [5.50000000e+01 3.44230192e+00 7.23749490e+00 2.38452019e-02\n",
      " 2.40969659e-01 1.17942099e+01], Loss = 0.3524\n",
      "Iteration 6668: Weights = [5.50000000e+01 3.44220310e+00 7.23728714e+00 2.38445174e-02\n",
      " 2.40962742e-01 1.17944294e+01], Loss = 0.3524\n",
      "Iteration 6669: Weights = [5.50000000e+01 3.44210429e+00 7.23707938e+00 2.38438329e-02\n",
      " 2.40955825e-01 1.17946489e+01], Loss = 0.3524\n",
      "Iteration 6670: Weights = [5.50000000e+01 3.44200548e+00 7.23687163e+00 2.38431484e-02\n",
      " 2.40948908e-01 1.17948684e+01], Loss = 0.3523\n",
      "Iteration 6671: Weights = [5.50000000e+01 3.44190667e+00 7.23666389e+00 2.38424640e-02\n",
      " 2.40941991e-01 1.17950878e+01], Loss = 0.3523\n",
      "Iteration 6672: Weights = [5.50000000e+01 3.44180787e+00 7.23645615e+00 2.38417795e-02\n",
      " 2.40935074e-01 1.17953073e+01], Loss = 0.3523\n",
      "Iteration 6673: Weights = [5.50000000e+01 3.44170907e+00 7.23624842e+00 2.38410951e-02\n",
      " 2.40928158e-01 1.17955268e+01], Loss = 0.3523\n",
      "Iteration 6674: Weights = [5.50000000e+01 3.44161027e+00 7.23604069e+00 2.38404107e-02\n",
      " 2.40921242e-01 1.17957462e+01], Loss = 0.3523\n",
      "Iteration 6675: Weights = [5.50000000e+01 3.44151147e+00 7.23583297e+00 2.38397264e-02\n",
      " 2.40914326e-01 1.17959657e+01], Loss = 0.3522\n",
      "Iteration 6676: Weights = [5.50000000e+01 3.44141268e+00 7.23562526e+00 2.38390420e-02\n",
      " 2.40907410e-01 1.17961851e+01], Loss = 0.3522\n",
      "Iteration 6677: Weights = [5.50000000e+01 3.44131389e+00 7.23541755e+00 2.38383577e-02\n",
      " 2.40900495e-01 1.17964046e+01], Loss = 0.3522\n",
      "Iteration 6678: Weights = [5.50000000e+01 3.44121510e+00 7.23520985e+00 2.38376734e-02\n",
      " 2.40893579e-01 1.17966240e+01], Loss = 0.3522\n",
      "Iteration 6679: Weights = [5.50000000e+01 3.44111632e+00 7.23500215e+00 2.38369891e-02\n",
      " 2.40886664e-01 1.17968434e+01], Loss = 0.3522\n",
      "Iteration 6680: Weights = [5.50000000e+01 3.44101753e+00 7.23479446e+00 2.38363048e-02\n",
      " 2.40879749e-01 1.17970629e+01], Loss = 0.3521\n",
      "Iteration 6681: Weights = [5.50000000e+01 3.44091876e+00 7.23458678e+00 2.38356206e-02\n",
      " 2.40872834e-01 1.17972823e+01], Loss = 0.3521\n",
      "Iteration 6682: Weights = [5.50000000e+01 3.44081998e+00 7.23437910e+00 2.38349363e-02\n",
      " 2.40865920e-01 1.17975017e+01], Loss = 0.3521\n",
      "Iteration 6683: Weights = [5.50000000e+01 3.44072121e+00 7.23417143e+00 2.38342521e-02\n",
      " 2.40859005e-01 1.17977211e+01], Loss = 0.3521\n",
      "Iteration 6684: Weights = [5.50000000e+01 3.44062244e+00 7.23396376e+00 2.38335679e-02\n",
      " 2.40852091e-01 1.17979405e+01], Loss = 0.3521\n",
      "Iteration 6685: Weights = [5.50000000e+01 3.44052367e+00 7.23375610e+00 2.38328837e-02\n",
      " 2.40845177e-01 1.17981599e+01], Loss = 0.3520\n",
      "Iteration 6686: Weights = [5.50000000e+01 3.44042490e+00 7.23354844e+00 2.38321996e-02\n",
      " 2.40838263e-01 1.17983793e+01], Loss = 0.3520\n",
      "Iteration 6687: Weights = [5.50000000e+01 3.44032614e+00 7.23334080e+00 2.38315155e-02\n",
      " 2.40831350e-01 1.17985986e+01], Loss = 0.3520\n",
      "Iteration 6688: Weights = [5.50000000e+01 3.44022738e+00 7.23313315e+00 2.38308313e-02\n",
      " 2.40824436e-01 1.17988180e+01], Loss = 0.3520\n",
      "Iteration 6689: Weights = [5.50000000e+01 3.44012863e+00 7.23292552e+00 2.38301472e-02\n",
      " 2.40817523e-01 1.17990374e+01], Loss = 0.3520\n",
      "Iteration 6690: Weights = [5.50000000e+01 3.44002987e+00 7.23271789e+00 2.38294632e-02\n",
      " 2.40810610e-01 1.17992567e+01], Loss = 0.3519\n",
      "Iteration 6691: Weights = [5.50000000e+01 3.43993112e+00 7.23251026e+00 2.38287791e-02\n",
      " 2.40803698e-01 1.17994761e+01], Loss = 0.3519\n",
      "Iteration 6692: Weights = [5.50000000e+01 3.43983237e+00 7.23230264e+00 2.38280951e-02\n",
      " 2.40796785e-01 1.17996954e+01], Loss = 0.3519\n",
      "Iteration 6693: Weights = [5.50000000e+01 3.43973363e+00 7.23209503e+00 2.38274111e-02\n",
      " 2.40789873e-01 1.17999148e+01], Loss = 0.3519\n",
      "Iteration 6694: Weights = [5.50000000e+01 3.43963489e+00 7.23188742e+00 2.38267271e-02\n",
      " 2.40782960e-01 1.18001341e+01], Loss = 0.3519\n",
      "Iteration 6695: Weights = [5.50000000e+01 3.43953615e+00 7.23167982e+00 2.38260431e-02\n",
      " 2.40776048e-01 1.18003534e+01], Loss = 0.3518\n",
      "Iteration 6696: Weights = [5.50000000e+01 3.43943741e+00 7.23147223e+00 2.38253591e-02\n",
      " 2.40769137e-01 1.18005727e+01], Loss = 0.3518\n",
      "Iteration 6697: Weights = [5.50000000e+01 3.43933868e+00 7.23126464e+00 2.38246752e-02\n",
      " 2.40762225e-01 1.18007921e+01], Loss = 0.3518\n",
      "Iteration 6698: Weights = [5.50000000e+01 3.43923995e+00 7.23105706e+00 2.38239913e-02\n",
      " 2.40755314e-01 1.18010114e+01], Loss = 0.3518\n",
      "Iteration 6699: Weights = [5.50000000e+01 3.43914122e+00 7.23084948e+00 2.38233074e-02\n",
      " 2.40748402e-01 1.18012307e+01], Loss = 0.3518\n",
      "Iteration 6700: Weights = [5.50000000e+01 3.43904250e+00 7.23064191e+00 2.38226235e-02\n",
      " 2.40741491e-01 1.18014500e+01], Loss = 0.3517\n",
      "Iteration 6701: Weights = [5.50000000e+01 3.43894377e+00 7.23043434e+00 2.38219396e-02\n",
      " 2.40734581e-01 1.18016693e+01], Loss = 0.3517\n",
      "Iteration 6702: Weights = [5.50000000e+01 3.43884505e+00 7.23022678e+00 2.38212558e-02\n",
      " 2.40727670e-01 1.18018885e+01], Loss = 0.3517\n",
      "Iteration 6703: Weights = [5.50000000e+01 3.43874634e+00 7.23001923e+00 2.38205720e-02\n",
      " 2.40720760e-01 1.18021078e+01], Loss = 0.3517\n",
      "Iteration 6704: Weights = [5.50000000e+01 3.43864762e+00 7.22981168e+00 2.38198882e-02\n",
      " 2.40713849e-01 1.18023271e+01], Loss = 0.3517\n",
      "Iteration 6705: Weights = [5.50000000e+01 3.43854891e+00 7.22960414e+00 2.38192044e-02\n",
      " 2.40706939e-01 1.18025463e+01], Loss = 0.3516\n",
      "Iteration 6706: Weights = [5.50000000e+01 3.43845020e+00 7.22939661e+00 2.38185206e-02\n",
      " 2.40700030e-01 1.18027656e+01], Loss = 0.3516\n",
      "Iteration 6707: Weights = [5.50000000e+01 3.43835150e+00 7.22918908e+00 2.38178369e-02\n",
      " 2.40693120e-01 1.18029849e+01], Loss = 0.3516\n",
      "Iteration 6708: Weights = [5.50000000e+01 3.43825280e+00 7.22898155e+00 2.38171532e-02\n",
      " 2.40686211e-01 1.18032041e+01], Loss = 0.3516\n",
      "Iteration 6709: Weights = [5.50000000e+01 3.43815410e+00 7.22877404e+00 2.38164695e-02\n",
      " 2.40679301e-01 1.18034233e+01], Loss = 0.3516\n",
      "Iteration 6710: Weights = [5.50000000e+01 3.43805540e+00 7.22856653e+00 2.38157858e-02\n",
      " 2.40672392e-01 1.18036426e+01], Loss = 0.3515\n",
      "Iteration 6711: Weights = [5.50000000e+01 3.43795671e+00 7.22835902e+00 2.38151021e-02\n",
      " 2.40665484e-01 1.18038618e+01], Loss = 0.3515\n",
      "Iteration 6712: Weights = [5.50000000e+01 3.43785802e+00 7.22815152e+00 2.38144185e-02\n",
      " 2.40658575e-01 1.18040810e+01], Loss = 0.3515\n",
      "Iteration 6713: Weights = [5.50000000e+01 3.43775933e+00 7.22794403e+00 2.38137349e-02\n",
      " 2.40651666e-01 1.18043002e+01], Loss = 0.3515\n",
      "Iteration 6714: Weights = [5.50000000e+01 3.43766064e+00 7.22773654e+00 2.38130512e-02\n",
      " 2.40644758e-01 1.18045194e+01], Loss = 0.3515\n",
      "Iteration 6715: Weights = [5.50000000e+01 3.43756196e+00 7.22752906e+00 2.38123677e-02\n",
      " 2.40637850e-01 1.18047386e+01], Loss = 0.3514\n",
      "Iteration 6716: Weights = [5.50000000e+01 3.43746328e+00 7.22732158e+00 2.38116841e-02\n",
      " 2.40630942e-01 1.18049578e+01], Loss = 0.3514\n",
      "Iteration 6717: Weights = [5.50000000e+01 3.43736460e+00 7.22711411e+00 2.38110006e-02\n",
      " 2.40624035e-01 1.18051770e+01], Loss = 0.3514\n",
      "Iteration 6718: Weights = [5.50000000e+01 3.43726593e+00 7.22690665e+00 2.38103170e-02\n",
      " 2.40617127e-01 1.18053962e+01], Loss = 0.3514\n",
      "Iteration 6719: Weights = [5.50000000e+01 3.43716726e+00 7.22669919e+00 2.38096335e-02\n",
      " 2.40610220e-01 1.18056154e+01], Loss = 0.3514\n",
      "Iteration 6720: Weights = [5.50000000e+01 3.43706859e+00 7.22649174e+00 2.38089500e-02\n",
      " 2.40603313e-01 1.18058346e+01], Loss = 0.3513\n",
      "Iteration 6721: Weights = [5.50000000e+01 3.43696992e+00 7.22628429e+00 2.38082666e-02\n",
      " 2.40596406e-01 1.18060537e+01], Loss = 0.3513\n",
      "Iteration 6722: Weights = [5.50000000e+01 3.43687126e+00 7.22607685e+00 2.38075831e-02\n",
      " 2.40589500e-01 1.18062729e+01], Loss = 0.3513\n",
      "Iteration 6723: Weights = [5.50000000e+01 3.43677260e+00 7.22586942e+00 2.38068997e-02\n",
      " 2.40582593e-01 1.18064920e+01], Loss = 0.3513\n",
      "Iteration 6724: Weights = [5.50000000e+01 3.43667394e+00 7.22566199e+00 2.38062163e-02\n",
      " 2.40575687e-01 1.18067112e+01], Loss = 0.3513\n",
      "Iteration 6725: Weights = [5.50000000e+01 3.43657529e+00 7.22545457e+00 2.38055329e-02\n",
      " 2.40568781e-01 1.18069303e+01], Loss = 0.3512\n",
      "Iteration 6726: Weights = [5.50000000e+01 3.43647664e+00 7.22524715e+00 2.38048495e-02\n",
      " 2.40561875e-01 1.18071494e+01], Loss = 0.3512\n",
      "Iteration 6727: Weights = [5.50000000e+01 3.43637799e+00 7.22503974e+00 2.38041662e-02\n",
      " 2.40554969e-01 1.18073686e+01], Loss = 0.3512\n",
      "Iteration 6728: Weights = [5.50000000e+01 3.43627934e+00 7.22483234e+00 2.38034828e-02\n",
      " 2.40548064e-01 1.18075877e+01], Loss = 0.3512\n",
      "Iteration 6729: Weights = [5.50000000e+01 3.43618070e+00 7.22462494e+00 2.38027995e-02\n",
      " 2.40541159e-01 1.18078068e+01], Loss = 0.3512\n",
      "Iteration 6730: Weights = [5.50000000e+01 3.43608206e+00 7.22441755e+00 2.38021162e-02\n",
      " 2.40534254e-01 1.18080259e+01], Loss = 0.3511\n",
      "Iteration 6731: Weights = [5.50000000e+01 3.43598342e+00 7.22421016e+00 2.38014330e-02\n",
      " 2.40527349e-01 1.18082450e+01], Loss = 0.3511\n",
      "Iteration 6732: Weights = [5.50000000e+01 3.43588479e+00 7.22400278e+00 2.38007497e-02\n",
      " 2.40520444e-01 1.18084641e+01], Loss = 0.3511\n",
      "Iteration 6733: Weights = [5.50000000e+01 3.43578616e+00 7.22379541e+00 2.38000665e-02\n",
      " 2.40513540e-01 1.18086832e+01], Loss = 0.3511\n",
      "Iteration 6734: Weights = [5.50000000e+01 3.43568753e+00 7.22358804e+00 2.37993833e-02\n",
      " 2.40506635e-01 1.18089023e+01], Loss = 0.3511\n",
      "Iteration 6735: Weights = [5.50000000e+01 3.43558890e+00 7.22338068e+00 2.37987001e-02\n",
      " 2.40499731e-01 1.18091213e+01], Loss = 0.3510\n",
      "Iteration 6736: Weights = [5.50000000e+01 3.43549028e+00 7.22317332e+00 2.37980169e-02\n",
      " 2.40492828e-01 1.18093404e+01], Loss = 0.3510\n",
      "Iteration 6737: Weights = [5.50000000e+01 3.43539166e+00 7.22296597e+00 2.37973338e-02\n",
      " 2.40485924e-01 1.18095595e+01], Loss = 0.3510\n",
      "Iteration 6738: Weights = [5.50000000e+01 3.43529304e+00 7.22275862e+00 2.37966506e-02\n",
      " 2.40479020e-01 1.18097785e+01], Loss = 0.3510\n",
      "Iteration 6739: Weights = [5.50000000e+01 3.43519443e+00 7.22255129e+00 2.37959675e-02\n",
      " 2.40472117e-01 1.18099976e+01], Loss = 0.3510\n",
      "Iteration 6740: Weights = [5.50000000e+01 3.43509582e+00 7.22234395e+00 2.37952844e-02\n",
      " 2.40465214e-01 1.18102166e+01], Loss = 0.3509\n",
      "Iteration 6741: Weights = [5.50000000e+01 3.43499721e+00 7.22213663e+00 2.37946013e-02\n",
      " 2.40458311e-01 1.18104357e+01], Loss = 0.3509\n",
      "Iteration 6742: Weights = [5.50000000e+01 3.43489860e+00 7.22192931e+00 2.37939183e-02\n",
      " 2.40451409e-01 1.18106547e+01], Loss = 0.3509\n",
      "Iteration 6743: Weights = [5.50000000e+01 3.43480000e+00 7.22172199e+00 2.37932353e-02\n",
      " 2.40444506e-01 1.18108737e+01], Loss = 0.3509\n",
      "Iteration 6744: Weights = [5.50000000e+01 3.43470140e+00 7.22151468e+00 2.37925522e-02\n",
      " 2.40437604e-01 1.18110927e+01], Loss = 0.3509\n",
      "Iteration 6745: Weights = [5.50000000e+01 3.43460280e+00 7.22130738e+00 2.37918692e-02\n",
      " 2.40430702e-01 1.18113117e+01], Loss = 0.3508\n",
      "Iteration 6746: Weights = [5.50000000e+01 3.43450421e+00 7.22110008e+00 2.37911863e-02\n",
      " 2.40423800e-01 1.18115308e+01], Loss = 0.3508\n",
      "Iteration 6747: Weights = [5.50000000e+01 3.43440561e+00 7.22089279e+00 2.37905033e-02\n",
      " 2.40416898e-01 1.18117498e+01], Loss = 0.3508\n",
      "Iteration 6748: Weights = [5.50000000e+01 3.43430702e+00 7.22068550e+00 2.37898204e-02\n",
      " 2.40409997e-01 1.18119687e+01], Loss = 0.3508\n",
      "Iteration 6749: Weights = [5.50000000e+01 3.43420844e+00 7.22047823e+00 2.37891375e-02\n",
      " 2.40403095e-01 1.18121877e+01], Loss = 0.3508\n",
      "Iteration 6750: Weights = [5.50000000e+01 3.43410985e+00 7.22027095e+00 2.37884546e-02\n",
      " 2.40396194e-01 1.18124067e+01], Loss = 0.3507\n",
      "Iteration 6751: Weights = [5.50000000e+01 3.43401127e+00 7.22006368e+00 2.37877717e-02\n",
      " 2.40389293e-01 1.18126257e+01], Loss = 0.3507\n",
      "Iteration 6752: Weights = [5.50000000e+01 3.43391270e+00 7.21985642e+00 2.37870888e-02\n",
      " 2.40382393e-01 1.18128447e+01], Loss = 0.3507\n",
      "Iteration 6753: Weights = [5.50000000e+01 3.43381412e+00 7.21964917e+00 2.37864060e-02\n",
      " 2.40375492e-01 1.18130636e+01], Loss = 0.3507\n",
      "Iteration 6754: Weights = [5.50000000e+01 3.43371555e+00 7.21944192e+00 2.37857232e-02\n",
      " 2.40368592e-01 1.18132826e+01], Loss = 0.3506\n",
      "Iteration 6755: Weights = [5.50000000e+01 3.43361698e+00 7.21923468e+00 2.37850404e-02\n",
      " 2.40361692e-01 1.18135015e+01], Loss = 0.3506\n",
      "Iteration 6756: Weights = [5.50000000e+01 3.43351841e+00 7.21902744e+00 2.37843576e-02\n",
      " 2.40354792e-01 1.18137205e+01], Loss = 0.3506\n",
      "Iteration 6757: Weights = [5.50000000e+01 3.43341985e+00 7.21882021e+00 2.37836748e-02\n",
      " 2.40347892e-01 1.18139394e+01], Loss = 0.3506\n",
      "Iteration 6758: Weights = [5.50000000e+01 3.43332129e+00 7.21861298e+00 2.37829921e-02\n",
      " 2.40340993e-01 1.18141583e+01], Loss = 0.3506\n",
      "Iteration 6759: Weights = [5.50000000e+01 3.43322273e+00 7.21840576e+00 2.37823093e-02\n",
      " 2.40334093e-01 1.18143773e+01], Loss = 0.3505\n",
      "Iteration 6760: Weights = [5.50000000e+01 3.43312418e+00 7.21819855e+00 2.37816266e-02\n",
      " 2.40327194e-01 1.18145962e+01], Loss = 0.3505\n",
      "Iteration 6761: Weights = [5.50000000e+01 3.43302562e+00 7.21799134e+00 2.37809440e-02\n",
      " 2.40320295e-01 1.18148151e+01], Loss = 0.3505\n",
      "Iteration 6762: Weights = [5.50000000e+01 3.43292707e+00 7.21778414e+00 2.37802613e-02\n",
      " 2.40313397e-01 1.18150340e+01], Loss = 0.3505\n",
      "Iteration 6763: Weights = [5.50000000e+01 3.43282853e+00 7.21757694e+00 2.37795787e-02\n",
      " 2.40306498e-01 1.18152529e+01], Loss = 0.3505\n",
      "Iteration 6764: Weights = [5.50000000e+01 3.43272998e+00 7.21736975e+00 2.37788960e-02\n",
      " 2.40299600e-01 1.18154718e+01], Loss = 0.3504\n",
      "Iteration 6765: Weights = [5.50000000e+01 3.43263144e+00 7.21716257e+00 2.37782134e-02\n",
      " 2.40292702e-01 1.18156907e+01], Loss = 0.3504\n",
      "Iteration 6766: Weights = [5.50000000e+01 3.43253290e+00 7.21695539e+00 2.37775308e-02\n",
      " 2.40285804e-01 1.18159096e+01], Loss = 0.3504\n",
      "Iteration 6767: Weights = [5.50000000e+01 3.43243437e+00 7.21674822e+00 2.37768483e-02\n",
      " 2.40278906e-01 1.18161284e+01], Loss = 0.3504\n",
      "Iteration 6768: Weights = [5.50000000e+01 3.43233584e+00 7.21654105e+00 2.37761657e-02\n",
      " 2.40272009e-01 1.18163473e+01], Loss = 0.3504\n",
      "Iteration 6769: Weights = [5.50000000e+01 3.43223731e+00 7.21633389e+00 2.37754832e-02\n",
      " 2.40265111e-01 1.18165662e+01], Loss = 0.3503\n",
      "Iteration 6770: Weights = [5.50000000e+01 3.43213878e+00 7.21612674e+00 2.37748007e-02\n",
      " 2.40258214e-01 1.18167850e+01], Loss = 0.3503\n",
      "Iteration 6771: Weights = [5.50000000e+01 3.43204026e+00 7.21591959e+00 2.37741182e-02\n",
      " 2.40251317e-01 1.18170039e+01], Loss = 0.3503\n",
      "Iteration 6772: Weights = [5.50000000e+01 3.43194173e+00 7.21571245e+00 2.37734357e-02\n",
      " 2.40244421e-01 1.18172227e+01], Loss = 0.3503\n",
      "Iteration 6773: Weights = [5.50000000e+01 3.43184322e+00 7.21550531e+00 2.37727533e-02\n",
      " 2.40237524e-01 1.18174415e+01], Loss = 0.3503\n",
      "Iteration 6774: Weights = [5.50000000e+01 3.43174470e+00 7.21529818e+00 2.37720709e-02\n",
      " 2.40230628e-01 1.18176604e+01], Loss = 0.3502\n",
      "Iteration 6775: Weights = [5.50000000e+01 3.43164619e+00 7.21509105e+00 2.37713885e-02\n",
      " 2.40223732e-01 1.18178792e+01], Loss = 0.3502\n",
      "Iteration 6776: Weights = [5.50000000e+01 3.43154768e+00 7.21488393e+00 2.37707061e-02\n",
      " 2.40216836e-01 1.18180980e+01], Loss = 0.3502\n",
      "Iteration 6777: Weights = [5.50000000e+01 3.43144917e+00 7.21467682e+00 2.37700237e-02\n",
      " 2.40209940e-01 1.18183168e+01], Loss = 0.3502\n",
      "Iteration 6778: Weights = [5.50000000e+01 3.43135067e+00 7.21446972e+00 2.37693414e-02\n",
      " 2.40203044e-01 1.18185356e+01], Loss = 0.3502\n",
      "Iteration 6779: Weights = [5.50000000e+01 3.43125217e+00 7.21426261e+00 2.37686590e-02\n",
      " 2.40196149e-01 1.18187544e+01], Loss = 0.3501\n",
      "Iteration 6780: Weights = [5.50000000e+01 3.43115367e+00 7.21405552e+00 2.37679767e-02\n",
      " 2.40189254e-01 1.18189732e+01], Loss = 0.3501\n",
      "Iteration 6781: Weights = [5.50000000e+01 3.43105517e+00 7.21384843e+00 2.37672944e-02\n",
      " 2.40182359e-01 1.18191920e+01], Loss = 0.3501\n",
      "Iteration 6782: Weights = [5.50000000e+01 3.43095668e+00 7.21364135e+00 2.37666122e-02\n",
      " 2.40175464e-01 1.18194108e+01], Loss = 0.3501\n",
      "Iteration 6783: Weights = [5.50000000e+01 3.43085819e+00 7.21343427e+00 2.37659299e-02\n",
      " 2.40168570e-01 1.18196296e+01], Loss = 0.3501\n",
      "Iteration 6784: Weights = [5.50000000e+01 3.43075970e+00 7.21322720e+00 2.37652477e-02\n",
      " 2.40161675e-01 1.18198483e+01], Loss = 0.3500\n",
      "Iteration 6785: Weights = [5.50000000e+01 3.43066122e+00 7.21302013e+00 2.37645655e-02\n",
      " 2.40154781e-01 1.18200671e+01], Loss = 0.3500\n",
      "Iteration 6786: Weights = [5.50000000e+01 3.43056273e+00 7.21281308e+00 2.37638833e-02\n",
      " 2.40147887e-01 1.18202858e+01], Loss = 0.3500\n",
      "Iteration 6787: Weights = [5.50000000e+01 3.43046426e+00 7.21260602e+00 2.37632011e-02\n",
      " 2.40140993e-01 1.18205046e+01], Loss = 0.3500\n",
      "Iteration 6788: Weights = [5.50000000e+01 3.43036578e+00 7.21239897e+00 2.37625189e-02\n",
      " 2.40134100e-01 1.18207233e+01], Loss = 0.3500\n",
      "Iteration 6789: Weights = [5.50000000e+01 3.43026731e+00 7.21219193e+00 2.37618368e-02\n",
      " 2.40127206e-01 1.18209421e+01], Loss = 0.3499\n",
      "Iteration 6790: Weights = [5.50000000e+01 3.43016884e+00 7.21198490e+00 2.37611547e-02\n",
      " 2.40120313e-01 1.18211608e+01], Loss = 0.3499\n",
      "Iteration 6791: Weights = [5.50000000e+01 3.43007037e+00 7.21177787e+00 2.37604726e-02\n",
      " 2.40113420e-01 1.18213795e+01], Loss = 0.3499\n",
      "Iteration 6792: Weights = [5.50000000e+01 3.42997190e+00 7.21157085e+00 2.37597905e-02\n",
      " 2.40106528e-01 1.18215982e+01], Loss = 0.3499\n",
      "Iteration 6793: Weights = [5.50000000e+01 3.42987344e+00 7.21136383e+00 2.37591085e-02\n",
      " 2.40099635e-01 1.18218170e+01], Loss = 0.3499\n",
      "Iteration 6794: Weights = [5.50000000e+01 3.42977498e+00 7.21115682e+00 2.37584264e-02\n",
      " 2.40092743e-01 1.18220357e+01], Loss = 0.3498\n",
      "Iteration 6795: Weights = [5.50000000e+01 3.42967653e+00 7.21094981e+00 2.37577444e-02\n",
      " 2.40085850e-01 1.18222544e+01], Loss = 0.3498\n",
      "Iteration 6796: Weights = [5.50000000e+01 3.42957807e+00 7.21074281e+00 2.37570624e-02\n",
      " 2.40078958e-01 1.18224730e+01], Loss = 0.3498\n",
      "Iteration 6797: Weights = [5.50000000e+01 3.42947962e+00 7.21053582e+00 2.37563804e-02\n",
      " 2.40072067e-01 1.18226917e+01], Loss = 0.3498\n",
      "Iteration 6798: Weights = [5.50000000e+01 3.42938118e+00 7.21032883e+00 2.37556985e-02\n",
      " 2.40065175e-01 1.18229104e+01], Loss = 0.3498\n",
      "Iteration 6799: Weights = [5.50000000e+01 3.42928273e+00 7.21012185e+00 2.37550165e-02\n",
      " 2.40058284e-01 1.18231291e+01], Loss = 0.3497\n",
      "Iteration 6800: Weights = [5.50000000e+01 3.42918429e+00 7.20991487e+00 2.37543346e-02\n",
      " 2.40051393e-01 1.18233478e+01], Loss = 0.3497\n",
      "Iteration 6801: Weights = [5.50000000e+01 3.42908585e+00 7.20970790e+00 2.37536527e-02\n",
      " 2.40044502e-01 1.18235664e+01], Loss = 0.3497\n",
      "Iteration 6802: Weights = [5.50000000e+01 3.42898741e+00 7.20950094e+00 2.37529708e-02\n",
      " 2.40037611e-01 1.18237851e+01], Loss = 0.3497\n",
      "Iteration 6803: Weights = [5.50000000e+01 3.42888898e+00 7.20929398e+00 2.37522890e-02\n",
      " 2.40030720e-01 1.18240037e+01], Loss = 0.3497\n",
      "Iteration 6804: Weights = [5.50000000e+01 3.42879055e+00 7.20908703e+00 2.37516071e-02\n",
      " 2.40023830e-01 1.18242224e+01], Loss = 0.3496\n",
      "Iteration 6805: Weights = [5.50000000e+01 3.42869212e+00 7.20888008e+00 2.37509253e-02\n",
      " 2.40016940e-01 1.18244410e+01], Loss = 0.3496\n",
      "Iteration 6806: Weights = [5.50000000e+01 3.42859370e+00 7.20867314e+00 2.37502435e-02\n",
      " 2.40010050e-01 1.18246596e+01], Loss = 0.3496\n",
      "Iteration 6807: Weights = [5.50000000e+01 3.42849527e+00 7.20846621e+00 2.37495617e-02\n",
      " 2.40003160e-01 1.18248782e+01], Loss = 0.3496\n",
      "Iteration 6808: Weights = [5.50000000e+01 3.42839685e+00 7.20825928e+00 2.37488800e-02\n",
      " 2.39996270e-01 1.18250969e+01], Loss = 0.3496\n",
      "Iteration 6809: Weights = [5.50000000e+01 3.42829844e+00 7.20805235e+00 2.37481982e-02\n",
      " 2.39989381e-01 1.18253155e+01], Loss = 0.3495\n",
      "Iteration 6810: Weights = [5.50000000e+01 3.42820002e+00 7.20784544e+00 2.37475165e-02\n",
      " 2.39982492e-01 1.18255341e+01], Loss = 0.3495\n",
      "Iteration 6811: Weights = [5.50000000e+01 3.42810161e+00 7.20763853e+00 2.37468348e-02\n",
      " 2.39975603e-01 1.18257527e+01], Loss = 0.3495\n",
      "Iteration 6812: Weights = [5.50000000e+01 3.42800320e+00 7.20743162e+00 2.37461531e-02\n",
      " 2.39968714e-01 1.18259713e+01], Loss = 0.3495\n",
      "Iteration 6813: Weights = [5.50000000e+01 3.42790480e+00 7.20722472e+00 2.37454715e-02\n",
      " 2.39961825e-01 1.18261898e+01], Loss = 0.3495\n",
      "Iteration 6814: Weights = [5.50000000e+01 3.42780640e+00 7.20701783e+00 2.37447898e-02\n",
      " 2.39954937e-01 1.18264084e+01], Loss = 0.3494\n",
      "Iteration 6815: Weights = [5.50000000e+01 3.42770800e+00 7.20681094e+00 2.37441082e-02\n",
      " 2.39948048e-01 1.18266270e+01], Loss = 0.3494\n",
      "Iteration 6816: Weights = [5.50000000e+01 3.42760960e+00 7.20660406e+00 2.37434266e-02\n",
      " 2.39941160e-01 1.18268456e+01], Loss = 0.3494\n",
      "Iteration 6817: Weights = [5.50000000e+01 3.42751121e+00 7.20639719e+00 2.37427450e-02\n",
      " 2.39934273e-01 1.18270641e+01], Loss = 0.3494\n",
      "Iteration 6818: Weights = [5.50000000e+01 3.42741281e+00 7.20619032e+00 2.37420634e-02\n",
      " 2.39927385e-01 1.18272827e+01], Loss = 0.3494\n",
      "Iteration 6819: Weights = [5.50000000e+01 3.42731443e+00 7.20598346e+00 2.37413819e-02\n",
      " 2.39920498e-01 1.18275012e+01], Loss = 0.3493\n",
      "Iteration 6820: Weights = [5.50000000e+01 3.42721604e+00 7.20577660e+00 2.37407004e-02\n",
      " 2.39913610e-01 1.18277198e+01], Loss = 0.3493\n",
      "Iteration 6821: Weights = [5.50000000e+01 3.42711766e+00 7.20556975e+00 2.37400188e-02\n",
      " 2.39906723e-01 1.18279383e+01], Loss = 0.3493\n",
      "Iteration 6822: Weights = [5.50000000e+01 3.42701928e+00 7.20536290e+00 2.37393374e-02\n",
      " 2.39899836e-01 1.18281568e+01], Loss = 0.3493\n",
      "Iteration 6823: Weights = [5.50000000e+01 3.42692090e+00 7.20515606e+00 2.37386559e-02\n",
      " 2.39892950e-01 1.18283754e+01], Loss = 0.3493\n",
      "Iteration 6824: Weights = [5.50000000e+01 3.42682253e+00 7.20494923e+00 2.37379744e-02\n",
      " 2.39886063e-01 1.18285939e+01], Loss = 0.3492\n",
      "Iteration 6825: Weights = [5.50000000e+01 3.42672416e+00 7.20474240e+00 2.37372930e-02\n",
      " 2.39879177e-01 1.18288124e+01], Loss = 0.3492\n",
      "Iteration 6826: Weights = [5.50000000e+01 3.42662579e+00 7.20453558e+00 2.37366116e-02\n",
      " 2.39872291e-01 1.18290309e+01], Loss = 0.3492\n",
      "Iteration 6827: Weights = [5.50000000e+01 3.42652742e+00 7.20432876e+00 2.37359302e-02\n",
      " 2.39865405e-01 1.18292494e+01], Loss = 0.3492\n",
      "Iteration 6828: Weights = [5.50000000e+01 3.42642906e+00 7.20412195e+00 2.37352488e-02\n",
      " 2.39858520e-01 1.18294679e+01], Loss = 0.3492\n",
      "Iteration 6829: Weights = [5.50000000e+01 3.42633070e+00 7.20391515e+00 2.37345675e-02\n",
      " 2.39851634e-01 1.18296864e+01], Loss = 0.3491\n",
      "Iteration 6830: Weights = [5.50000000e+01 3.42623234e+00 7.20370835e+00 2.37338862e-02\n",
      " 2.39844749e-01 1.18299048e+01], Loss = 0.3491\n",
      "Iteration 6831: Weights = [5.50000000e+01 3.42613399e+00 7.20350156e+00 2.37332048e-02\n",
      " 2.39837864e-01 1.18301233e+01], Loss = 0.3491\n",
      "Iteration 6832: Weights = [5.50000000e+01 3.42603563e+00 7.20329478e+00 2.37325235e-02\n",
      " 2.39830979e-01 1.18303418e+01], Loss = 0.3491\n",
      "Iteration 6833: Weights = [5.50000000e+01 3.42593729e+00 7.20308800e+00 2.37318423e-02\n",
      " 2.39824094e-01 1.18305602e+01], Loss = 0.3491\n",
      "Iteration 6834: Weights = [5.50000000e+01 3.42583894e+00 7.20288122e+00 2.37311610e-02\n",
      " 2.39817210e-01 1.18307787e+01], Loss = 0.3490\n",
      "Iteration 6835: Weights = [5.50000000e+01 3.42574060e+00 7.20267445e+00 2.37304798e-02\n",
      " 2.39810326e-01 1.18309971e+01], Loss = 0.3490\n",
      "Iteration 6836: Weights = [5.50000000e+01 3.42564226e+00 7.20246769e+00 2.37297986e-02\n",
      " 2.39803441e-01 1.18312156e+01], Loss = 0.3490\n",
      "Iteration 6837: Weights = [5.50000000e+01 3.42554392e+00 7.20226093e+00 2.37291174e-02\n",
      " 2.39796558e-01 1.18314340e+01], Loss = 0.3490\n",
      "Iteration 6838: Weights = [5.50000000e+01 3.42544558e+00 7.20205418e+00 2.37284362e-02\n",
      " 2.39789674e-01 1.18316524e+01], Loss = 0.3490\n",
      "Iteration 6839: Weights = [5.50000000e+01 3.42534725e+00 7.20184744e+00 2.37277550e-02\n",
      " 2.39782790e-01 1.18318709e+01], Loss = 0.3489\n",
      "Iteration 6840: Weights = [5.50000000e+01 3.42524892e+00 7.20164070e+00 2.37270739e-02\n",
      " 2.39775907e-01 1.18320893e+01], Loss = 0.3489\n",
      "Iteration 6841: Weights = [5.50000000e+01 3.42515060e+00 7.20143397e+00 2.37263928e-02\n",
      " 2.39769024e-01 1.18323077e+01], Loss = 0.3489\n",
      "Iteration 6842: Weights = [5.50000000e+01 3.42505227e+00 7.20122724e+00 2.37257117e-02\n",
      " 2.39762141e-01 1.18325261e+01], Loss = 0.3489\n",
      "Iteration 6843: Weights = [5.50000000e+01 3.42495395e+00 7.20102052e+00 2.37250306e-02\n",
      " 2.39755259e-01 1.18327445e+01], Loss = 0.3489\n",
      "Iteration 6844: Weights = [5.50000000e+01 3.42485563e+00 7.20081381e+00 2.37243496e-02\n",
      " 2.39748376e-01 1.18329629e+01], Loss = 0.3488\n",
      "Iteration 6845: Weights = [5.50000000e+01 3.42475732e+00 7.20060710e+00 2.37236685e-02\n",
      " 2.39741494e-01 1.18331813e+01], Loss = 0.3488\n",
      "Iteration 6846: Weights = [5.50000000e+01 3.42465901e+00 7.20040040e+00 2.37229875e-02\n",
      " 2.39734612e-01 1.18333996e+01], Loss = 0.3488\n",
      "Iteration 6847: Weights = [5.50000000e+01 3.42456070e+00 7.20019370e+00 2.37223065e-02\n",
      " 2.39727730e-01 1.18336180e+01], Loss = 0.3488\n",
      "Iteration 6848: Weights = [5.50000000e+01 3.42446239e+00 7.19998701e+00 2.37216255e-02\n",
      " 2.39720848e-01 1.18338364e+01], Loss = 0.3488\n",
      "Iteration 6849: Weights = [5.50000000e+01 3.42436409e+00 7.19978032e+00 2.37209446e-02\n",
      " 2.39713967e-01 1.18340547e+01], Loss = 0.3487\n",
      "Iteration 6850: Weights = [5.50000000e+01 3.42426579e+00 7.19957364e+00 2.37202636e-02\n",
      " 2.39707085e-01 1.18342731e+01], Loss = 0.3487\n",
      "Iteration 6851: Weights = [5.50000000e+01 3.42416749e+00 7.19936697e+00 2.37195827e-02\n",
      " 2.39700204e-01 1.18344914e+01], Loss = 0.3487\n",
      "Iteration 6852: Weights = [5.50000000e+01 3.42406919e+00 7.19916030e+00 2.37189018e-02\n",
      " 2.39693323e-01 1.18347098e+01], Loss = 0.3487\n",
      "Iteration 6853: Weights = [5.50000000e+01 3.42397090e+00 7.19895364e+00 2.37182209e-02\n",
      " 2.39686443e-01 1.18349281e+01], Loss = 0.3487\n",
      "Iteration 6854: Weights = [5.50000000e+01 3.42387261e+00 7.19874699e+00 2.37175401e-02\n",
      " 2.39679562e-01 1.18351464e+01], Loss = 0.3486\n",
      "Iteration 6855: Weights = [5.50000000e+01 3.42377433e+00 7.19854034e+00 2.37168592e-02\n",
      " 2.39672682e-01 1.18353648e+01], Loss = 0.3486\n",
      "Iteration 6856: Weights = [5.50000000e+01 3.42367604e+00 7.19833369e+00 2.37161784e-02\n",
      " 2.39665802e-01 1.18355831e+01], Loss = 0.3486\n",
      "Iteration 6857: Weights = [5.50000000e+01 3.42357776e+00 7.19812706e+00 2.37154976e-02\n",
      " 2.39658922e-01 1.18358014e+01], Loss = 0.3486\n",
      "Iteration 6858: Weights = [5.50000000e+01 3.42347948e+00 7.19792042e+00 2.37148168e-02\n",
      " 2.39652042e-01 1.18360197e+01], Loss = 0.3486\n",
      "Iteration 6859: Weights = [5.50000000e+01 3.42338121e+00 7.19771380e+00 2.37141360e-02\n",
      " 2.39645162e-01 1.18362380e+01], Loss = 0.3485\n",
      "Iteration 6860: Weights = [5.50000000e+01 3.42328293e+00 7.19750718e+00 2.37134553e-02\n",
      " 2.39638283e-01 1.18364563e+01], Loss = 0.3485\n",
      "Iteration 6861: Weights = [5.50000000e+01 3.42318466e+00 7.19730056e+00 2.37127746e-02\n",
      " 2.39631404e-01 1.18366746e+01], Loss = 0.3485\n",
      "Iteration 6862: Weights = [5.50000000e+01 3.42308640e+00 7.19709396e+00 2.37120939e-02\n",
      " 2.39624525e-01 1.18368928e+01], Loss = 0.3485\n",
      "Iteration 6863: Weights = [5.50000000e+01 3.42298813e+00 7.19688735e+00 2.37114132e-02\n",
      " 2.39617646e-01 1.18371111e+01], Loss = 0.3485\n",
      "Iteration 6864: Weights = [5.50000000e+01 3.42288987e+00 7.19668076e+00 2.37107325e-02\n",
      " 2.39610768e-01 1.18373294e+01], Loss = 0.3484\n",
      "Iteration 6865: Weights = [5.50000000e+01 3.42279161e+00 7.19647417e+00 2.37100519e-02\n",
      " 2.39603889e-01 1.18375476e+01], Loss = 0.3484\n",
      "Iteration 6866: Weights = [5.50000000e+01 3.42269336e+00 7.19626758e+00 2.37093712e-02\n",
      " 2.39597011e-01 1.18377659e+01], Loss = 0.3484\n",
      "Iteration 6867: Weights = [5.50000000e+01 3.42259510e+00 7.19606101e+00 2.37086906e-02\n",
      " 2.39590133e-01 1.18379841e+01], Loss = 0.3484\n",
      "Iteration 6868: Weights = [5.50000000e+01 3.42249685e+00 7.19585443e+00 2.37080100e-02\n",
      " 2.39583256e-01 1.18382024e+01], Loss = 0.3484\n",
      "Iteration 6869: Weights = [5.50000000e+01 3.42239861e+00 7.19564787e+00 2.37073295e-02\n",
      " 2.39576378e-01 1.18384206e+01], Loss = 0.3483\n",
      "Iteration 6870: Weights = [5.50000000e+01 3.42230036e+00 7.19544131e+00 2.37066489e-02\n",
      " 2.39569501e-01 1.18386388e+01], Loss = 0.3483\n",
      "Iteration 6871: Weights = [5.50000000e+01 3.42220212e+00 7.19523475e+00 2.37059684e-02\n",
      " 2.39562624e-01 1.18388571e+01], Loss = 0.3483\n",
      "Iteration 6872: Weights = [5.50000000e+01 3.42210388e+00 7.19502820e+00 2.37052879e-02\n",
      " 2.39555747e-01 1.18390753e+01], Loss = 0.3483\n",
      "Iteration 6873: Weights = [5.50000000e+01 3.42200565e+00 7.19482166e+00 2.37046074e-02\n",
      " 2.39548870e-01 1.18392935e+01], Loss = 0.3483\n",
      "Iteration 6874: Weights = [5.50000000e+01 3.42190741e+00 7.19461512e+00 2.37039269e-02\n",
      " 2.39541993e-01 1.18395117e+01], Loss = 0.3482\n",
      "Iteration 6875: Weights = [5.50000000e+01 3.42180918e+00 7.19440859e+00 2.37032465e-02\n",
      " 2.39535117e-01 1.18397299e+01], Loss = 0.3482\n",
      "Iteration 6876: Weights = [5.50000000e+01 3.42171096e+00 7.19420207e+00 2.37025660e-02\n",
      " 2.39528241e-01 1.18399481e+01], Loss = 0.3482\n",
      "Iteration 6877: Weights = [5.50000000e+01 3.42161273e+00 7.19399555e+00 2.37018856e-02\n",
      " 2.39521365e-01 1.18401663e+01], Loss = 0.3482\n",
      "Iteration 6878: Weights = [5.50000000e+01 3.42151451e+00 7.19378904e+00 2.37012052e-02\n",
      " 2.39514489e-01 1.18403844e+01], Loss = 0.3482\n",
      "Iteration 6879: Weights = [5.50000000e+01 3.42141629e+00 7.19358253e+00 2.37005248e-02\n",
      " 2.39507613e-01 1.18406026e+01], Loss = 0.3481\n",
      "Iteration 6880: Weights = [5.50000000e+01 3.42131807e+00 7.19337603e+00 2.36998445e-02\n",
      " 2.39500738e-01 1.18408208e+01], Loss = 0.3481\n",
      "Iteration 6881: Weights = [5.50000000e+01 3.42121986e+00 7.19316953e+00 2.36991642e-02\n",
      " 2.39493863e-01 1.18410389e+01], Loss = 0.3481\n",
      "Iteration 6882: Weights = [5.50000000e+01 3.42112165e+00 7.19296304e+00 2.36984838e-02\n",
      " 2.39486988e-01 1.18412571e+01], Loss = 0.3481\n",
      "Iteration 6883: Weights = [5.50000000e+01 3.42102344e+00 7.19275656e+00 2.36978035e-02\n",
      " 2.39480113e-01 1.18414752e+01], Loss = 0.3481\n",
      "Iteration 6884: Weights = [5.50000000e+01 3.42092524e+00 7.19255008e+00 2.36971233e-02\n",
      " 2.39473238e-01 1.18416934e+01], Loss = 0.3480\n",
      "Iteration 6885: Weights = [5.50000000e+01 3.42082703e+00 7.19234361e+00 2.36964430e-02\n",
      " 2.39466364e-01 1.18419115e+01], Loss = 0.3480\n",
      "Iteration 6886: Weights = [5.50000000e+01 3.42072884e+00 7.19213715e+00 2.36957628e-02\n",
      " 2.39459490e-01 1.18421296e+01], Loss = 0.3480\n",
      "Iteration 6887: Weights = [5.50000000e+01 3.42063064e+00 7.19193069e+00 2.36950826e-02\n",
      " 2.39452616e-01 1.18423478e+01], Loss = 0.3480\n",
      "Iteration 6888: Weights = [5.50000000e+01 3.42053245e+00 7.19172423e+00 2.36944024e-02\n",
      " 2.39445742e-01 1.18425659e+01], Loss = 0.3480\n",
      "Iteration 6889: Weights = [5.50000000e+01 3.42043425e+00 7.19151778e+00 2.36937222e-02\n",
      " 2.39438868e-01 1.18427840e+01], Loss = 0.3479\n",
      "Iteration 6890: Weights = [5.50000000e+01 3.42033607e+00 7.19131134e+00 2.36930420e-02\n",
      " 2.39431995e-01 1.18430021e+01], Loss = 0.3479\n",
      "Iteration 6891: Weights = [5.50000000e+01 3.42023788e+00 7.19110491e+00 2.36923619e-02\n",
      " 2.39425122e-01 1.18432202e+01], Loss = 0.3479\n",
      "Iteration 6892: Weights = [5.50000000e+01 3.42013970e+00 7.19089848e+00 2.36916818e-02\n",
      " 2.39418249e-01 1.18434383e+01], Loss = 0.3479\n",
      "Iteration 6893: Weights = [5.50000000e+01 3.42004152e+00 7.19069205e+00 2.36910017e-02\n",
      " 2.39411376e-01 1.18436564e+01], Loss = 0.3479\n",
      "Iteration 6894: Weights = [5.50000000e+01 3.41994334e+00 7.19048563e+00 2.36903216e-02\n",
      " 2.39404503e-01 1.18438744e+01], Loss = 0.3478\n",
      "Iteration 6895: Weights = [5.50000000e+01 3.41984517e+00 7.19027922e+00 2.36896415e-02\n",
      " 2.39397631e-01 1.18440925e+01], Loss = 0.3478\n",
      "Iteration 6896: Weights = [5.50000000e+01 3.41974700e+00 7.19007281e+00 2.36889615e-02\n",
      " 2.39390759e-01 1.18443106e+01], Loss = 0.3478\n",
      "Iteration 6897: Weights = [5.50000000e+01 3.41964883e+00 7.18986641e+00 2.36882814e-02\n",
      " 2.39383887e-01 1.18445286e+01], Loss = 0.3478\n",
      "Iteration 6898: Weights = [5.50000000e+01 3.41955066e+00 7.18966002e+00 2.36876014e-02\n",
      " 2.39377015e-01 1.18447467e+01], Loss = 0.3478\n",
      "Iteration 6899: Weights = [5.50000000e+01 3.41945250e+00 7.18945363e+00 2.36869215e-02\n",
      " 2.39370143e-01 1.18449647e+01], Loss = 0.3477\n",
      "Iteration 6900: Weights = [5.50000000e+01 3.41935434e+00 7.18924725e+00 2.36862415e-02\n",
      " 2.39363272e-01 1.18451828e+01], Loss = 0.3477\n",
      "Iteration 6901: Weights = [5.50000000e+01 3.41925618e+00 7.18904087e+00 2.36855616e-02\n",
      " 2.39356401e-01 1.18454008e+01], Loss = 0.3477\n",
      "Iteration 6902: Weights = [5.50000000e+01 3.41915803e+00 7.18883450e+00 2.36848816e-02\n",
      " 2.39349530e-01 1.18456188e+01], Loss = 0.3477\n",
      "Iteration 6903: Weights = [5.50000000e+01 3.41905988e+00 7.18862814e+00 2.36842017e-02\n",
      " 2.39342659e-01 1.18458368e+01], Loss = 0.3477\n",
      "Iteration 6904: Weights = [5.50000000e+01 3.41896173e+00 7.18842178e+00 2.36835218e-02\n",
      " 2.39335788e-01 1.18460549e+01], Loss = 0.3476\n",
      "Iteration 6905: Weights = [5.50000000e+01 3.41886358e+00 7.18821542e+00 2.36828420e-02\n",
      " 2.39328918e-01 1.18462729e+01], Loss = 0.3476\n",
      "Iteration 6906: Weights = [5.50000000e+01 3.41876544e+00 7.18800908e+00 2.36821621e-02\n",
      " 2.39322047e-01 1.18464909e+01], Loss = 0.3476\n",
      "Iteration 6907: Weights = [5.50000000e+01 3.41866730e+00 7.18780274e+00 2.36814823e-02\n",
      " 2.39315177e-01 1.18467089e+01], Loss = 0.3476\n",
      "Iteration 6908: Weights = [5.50000000e+01 3.41856916e+00 7.18759640e+00 2.36808025e-02\n",
      " 2.39308307e-01 1.18469269e+01], Loss = 0.3476\n",
      "Iteration 6909: Weights = [5.50000000e+01 3.41847103e+00 7.18739007e+00 2.36801227e-02\n",
      " 2.39301438e-01 1.18471448e+01], Loss = 0.3475\n",
      "Iteration 6910: Weights = [5.50000000e+01 3.41837290e+00 7.18718375e+00 2.36794429e-02\n",
      " 2.39294568e-01 1.18473628e+01], Loss = 0.3475\n",
      "Iteration 6911: Weights = [5.50000000e+01 3.41827477e+00 7.18697743e+00 2.36787632e-02\n",
      " 2.39287699e-01 1.18475808e+01], Loss = 0.3475\n",
      "Iteration 6912: Weights = [5.50000000e+01 3.41817664e+00 7.18677112e+00 2.36780834e-02\n",
      " 2.39280830e-01 1.18477988e+01], Loss = 0.3475\n",
      "Iteration 6913: Weights = [5.50000000e+01 3.41807852e+00 7.18656481e+00 2.36774037e-02\n",
      " 2.39273961e-01 1.18480167e+01], Loss = 0.3475\n",
      "Iteration 6914: Weights = [5.50000000e+01 3.41798040e+00 7.18635851e+00 2.36767240e-02\n",
      " 2.39267092e-01 1.18482347e+01], Loss = 0.3474\n",
      "Iteration 6915: Weights = [5.50000000e+01 3.41788228e+00 7.18615222e+00 2.36760444e-02\n",
      " 2.39260224e-01 1.18484526e+01], Loss = 0.3474\n",
      "Iteration 6916: Weights = [5.50000000e+01 3.41778417e+00 7.18594593e+00 2.36753647e-02\n",
      " 2.39253356e-01 1.18486706e+01], Loss = 0.3474\n",
      "Iteration 6917: Weights = [5.50000000e+01 3.41768605e+00 7.18573965e+00 2.36746851e-02\n",
      " 2.39246488e-01 1.18488885e+01], Loss = 0.3474\n",
      "Iteration 6918: Weights = [5.50000000e+01 3.41758795e+00 7.18553337e+00 2.36740055e-02\n",
      " 2.39239620e-01 1.18491064e+01], Loss = 0.3474\n",
      "Iteration 6919: Weights = [5.50000000e+01 3.41748984e+00 7.18532710e+00 2.36733259e-02\n",
      " 2.39232752e-01 1.18493243e+01], Loss = 0.3473\n",
      "Iteration 6920: Weights = [5.50000000e+01 3.41739174e+00 7.18512084e+00 2.36726463e-02\n",
      " 2.39225885e-01 1.18495422e+01], Loss = 0.3473\n",
      "Iteration 6921: Weights = [5.50000000e+01 3.41729363e+00 7.18491458e+00 2.36719668e-02\n",
      " 2.39219017e-01 1.18497602e+01], Loss = 0.3473\n",
      "Iteration 6922: Weights = [5.50000000e+01 3.41719554e+00 7.18470833e+00 2.36712872e-02\n",
      " 2.39212150e-01 1.18499781e+01], Loss = 0.3473\n",
      "Iteration 6923: Weights = [5.50000000e+01 3.41709744e+00 7.18450208e+00 2.36706077e-02\n",
      " 2.39205283e-01 1.18501960e+01], Loss = 0.3473\n",
      "Iteration 6924: Weights = [5.50000000e+01 3.41699935e+00 7.18429584e+00 2.36699282e-02\n",
      " 2.39198417e-01 1.18504138e+01], Loss = 0.3472\n",
      "Iteration 6925: Weights = [5.50000000e+01 3.41690126e+00 7.18408961e+00 2.36692487e-02\n",
      " 2.39191550e-01 1.18506317e+01], Loss = 0.3472\n",
      "Iteration 6926: Weights = [5.50000000e+01 3.41680317e+00 7.18388338e+00 2.36685693e-02\n",
      " 2.39184684e-01 1.18508496e+01], Loss = 0.3472\n",
      "Iteration 6927: Weights = [5.50000000e+01 3.41670509e+00 7.18367716e+00 2.36678898e-02\n",
      " 2.39177818e-01 1.18510675e+01], Loss = 0.3472\n",
      "Iteration 6928: Weights = [5.50000000e+01 3.41660701e+00 7.18347094e+00 2.36672104e-02\n",
      " 2.39170952e-01 1.18512853e+01], Loss = 0.3472\n",
      "Iteration 6929: Weights = [5.50000000e+01 3.41650893e+00 7.18326473e+00 2.36665310e-02\n",
      " 2.39164086e-01 1.18515032e+01], Loss = 0.3471\n",
      "Iteration 6930: Weights = [5.50000000e+01 3.41641085e+00 7.18305852e+00 2.36658516e-02\n",
      " 2.39157221e-01 1.18517211e+01], Loss = 0.3471\n",
      "Iteration 6931: Weights = [5.50000000e+01 3.41631278e+00 7.18285232e+00 2.36651723e-02\n",
      " 2.39150355e-01 1.18519389e+01], Loss = 0.3471\n",
      "Iteration 6932: Weights = [5.50000000e+01 3.41621471e+00 7.18264613e+00 2.36644929e-02\n",
      " 2.39143490e-01 1.18521567e+01], Loss = 0.3471\n",
      "Iteration 6933: Weights = [5.50000000e+01 3.41611665e+00 7.18243994e+00 2.36638136e-02\n",
      " 2.39136625e-01 1.18523746e+01], Loss = 0.3471\n",
      "Iteration 6934: Weights = [5.50000000e+01 3.41601858e+00 7.18223376e+00 2.36631343e-02\n",
      " 2.39129760e-01 1.18525924e+01], Loss = 0.3470\n",
      "Iteration 6935: Weights = [5.50000000e+01 3.41592052e+00 7.18202759e+00 2.36624550e-02\n",
      " 2.39122896e-01 1.18528102e+01], Loss = 0.3470\n",
      "Iteration 6936: Weights = [5.50000000e+01 3.41582246e+00 7.18182142e+00 2.36617758e-02\n",
      " 2.39116032e-01 1.18530280e+01], Loss = 0.3470\n",
      "Iteration 6937: Weights = [5.50000000e+01 3.41572441e+00 7.18161525e+00 2.36610965e-02\n",
      " 2.39109167e-01 1.18532458e+01], Loss = 0.3470\n",
      "Iteration 6938: Weights = [5.50000000e+01 3.41562635e+00 7.18140910e+00 2.36604173e-02\n",
      " 2.39102304e-01 1.18534636e+01], Loss = 0.3470\n",
      "Iteration 6939: Weights = [5.50000000e+01 3.41552830e+00 7.18120294e+00 2.36597381e-02\n",
      " 2.39095440e-01 1.18536814e+01], Loss = 0.3469\n",
      "Iteration 6940: Weights = [5.50000000e+01 3.41543026e+00 7.18099680e+00 2.36590589e-02\n",
      " 2.39088576e-01 1.18538992e+01], Loss = 0.3469\n",
      "Iteration 6941: Weights = [5.50000000e+01 3.41533221e+00 7.18079066e+00 2.36583798e-02\n",
      " 2.39081713e-01 1.18541170e+01], Loss = 0.3469\n",
      "Iteration 6942: Weights = [5.50000000e+01 3.41523417e+00 7.18058452e+00 2.36577006e-02\n",
      " 2.39074850e-01 1.18543348e+01], Loss = 0.3469\n",
      "Iteration 6943: Weights = [5.50000000e+01 3.41513613e+00 7.18037840e+00 2.36570215e-02\n",
      " 2.39067987e-01 1.18545526e+01], Loss = 0.3469\n",
      "Iteration 6944: Weights = [5.50000000e+01 3.41503810e+00 7.18017227e+00 2.36563424e-02\n",
      " 2.39061124e-01 1.18547703e+01], Loss = 0.3468\n",
      "Iteration 6945: Weights = [5.50000000e+01 3.41494006e+00 7.17996616e+00 2.36556633e-02\n",
      " 2.39054261e-01 1.18549881e+01], Loss = 0.3468\n",
      "Iteration 6946: Weights = [5.50000000e+01 3.41484203e+00 7.17976005e+00 2.36549842e-02\n",
      " 2.39047399e-01 1.18552058e+01], Loss = 0.3468\n",
      "Iteration 6947: Weights = [5.50000000e+01 3.41474400e+00 7.17955394e+00 2.36543052e-02\n",
      " 2.39040537e-01 1.18554236e+01], Loss = 0.3468\n",
      "Iteration 6948: Weights = [5.50000000e+01 3.41464598e+00 7.17934784e+00 2.36536262e-02\n",
      " 2.39033675e-01 1.18556413e+01], Loss = 0.3468\n",
      "Iteration 6949: Weights = [5.50000000e+01 3.41454796e+00 7.17914175e+00 2.36529472e-02\n",
      " 2.39026813e-01 1.18558591e+01], Loss = 0.3467\n",
      "Iteration 6950: Weights = [5.50000000e+01 3.41444994e+00 7.17893566e+00 2.36522682e-02\n",
      " 2.39019952e-01 1.18560768e+01], Loss = 0.3467\n",
      "Iteration 6951: Weights = [5.50000000e+01 3.41435192e+00 7.17872958e+00 2.36515892e-02\n",
      " 2.39013090e-01 1.18562945e+01], Loss = 0.3467\n",
      "Iteration 6952: Weights = [5.50000000e+01 3.41425391e+00 7.17852351e+00 2.36509102e-02\n",
      " 2.39006229e-01 1.18565122e+01], Loss = 0.3467\n",
      "Iteration 6953: Weights = [5.50000000e+01 3.41415590e+00 7.17831744e+00 2.36502313e-02\n",
      " 2.38999368e-01 1.18567299e+01], Loss = 0.3467\n",
      "Iteration 6954: Weights = [5.50000000e+01 3.41405789e+00 7.17811138e+00 2.36495524e-02\n",
      " 2.38992507e-01 1.18569476e+01], Loss = 0.3466\n",
      "Iteration 6955: Weights = [5.50000000e+01 3.41395989e+00 7.17790532e+00 2.36488735e-02\n",
      " 2.38985647e-01 1.18571653e+01], Loss = 0.3466\n",
      "Iteration 6956: Weights = [5.50000000e+01 3.41386188e+00 7.17769927e+00 2.36481946e-02\n",
      " 2.38978786e-01 1.18573830e+01], Loss = 0.3466\n",
      "Iteration 6957: Weights = [5.50000000e+01 3.41376388e+00 7.17749322e+00 2.36475158e-02\n",
      " 2.38971926e-01 1.18576007e+01], Loss = 0.3466\n",
      "Iteration 6958: Weights = [5.50000000e+01 3.41366589e+00 7.17728718e+00 2.36468370e-02\n",
      " 2.38965066e-01 1.18578184e+01], Loss = 0.3466\n",
      "Iteration 6959: Weights = [5.50000000e+01 3.41356789e+00 7.17708115e+00 2.36461581e-02\n",
      " 2.38958206e-01 1.18580361e+01], Loss = 0.3465\n",
      "Iteration 6960: Weights = [5.50000000e+01 3.41346990e+00 7.17687512e+00 2.36454794e-02\n",
      " 2.38951347e-01 1.18582537e+01], Loss = 0.3465\n",
      "Iteration 6961: Weights = [5.50000000e+01 3.41337191e+00 7.17666910e+00 2.36448006e-02\n",
      " 2.38944487e-01 1.18584714e+01], Loss = 0.3465\n",
      "Iteration 6962: Weights = [5.50000000e+01 3.41327393e+00 7.17646309e+00 2.36441218e-02\n",
      " 2.38937628e-01 1.18586890e+01], Loss = 0.3465\n",
      "Iteration 6963: Weights = [5.50000000e+01 3.41317595e+00 7.17625708e+00 2.36434431e-02\n",
      " 2.38930769e-01 1.18589067e+01], Loss = 0.3465\n",
      "Iteration 6964: Weights = [5.50000000e+01 3.41307797e+00 7.17605107e+00 2.36427644e-02\n",
      " 2.38923910e-01 1.18591243e+01], Loss = 0.3464\n",
      "Iteration 6965: Weights = [5.50000000e+01 3.41297999e+00 7.17584507e+00 2.36420857e-02\n",
      " 2.38917052e-01 1.18593419e+01], Loss = 0.3464\n",
      "Iteration 6966: Weights = [5.50000000e+01 3.41288202e+00 7.17563908e+00 2.36414070e-02\n",
      " 2.38910193e-01 1.18595596e+01], Loss = 0.3464\n",
      "Iteration 6967: Weights = [5.50000000e+01 3.41278405e+00 7.17543310e+00 2.36407283e-02\n",
      " 2.38903335e-01 1.18597772e+01], Loss = 0.3464\n",
      "Iteration 6968: Weights = [5.50000000e+01 3.41268608e+00 7.17522712e+00 2.36400497e-02\n",
      " 2.38896477e-01 1.18599948e+01], Loss = 0.3464\n",
      "Iteration 6969: Weights = [5.50000000e+01 3.41258811e+00 7.17502114e+00 2.36393711e-02\n",
      " 2.38889619e-01 1.18602124e+01], Loss = 0.3463\n",
      "Iteration 6970: Weights = [5.50000000e+01 3.41249015e+00 7.17481517e+00 2.36386925e-02\n",
      " 2.38882761e-01 1.18604300e+01], Loss = 0.3463\n",
      "Iteration 6971: Weights = [5.50000000e+01 3.41239219e+00 7.17460921e+00 2.36380139e-02\n",
      " 2.38875904e-01 1.18606476e+01], Loss = 0.3463\n",
      "Iteration 6972: Weights = [5.50000000e+01 3.41229423e+00 7.17440325e+00 2.36373353e-02\n",
      " 2.38869047e-01 1.18608652e+01], Loss = 0.3463\n",
      "Iteration 6973: Weights = [5.50000000e+01 3.41219628e+00 7.17419730e+00 2.36366568e-02\n",
      " 2.38862190e-01 1.18610828e+01], Loss = 0.3463\n",
      "Iteration 6974: Weights = [5.50000000e+01 3.41209833e+00 7.17399136e+00 2.36359783e-02\n",
      " 2.38855333e-01 1.18613004e+01], Loss = 0.3462\n",
      "Iteration 6975: Weights = [5.50000000e+01 3.41200038e+00 7.17378542e+00 2.36352998e-02\n",
      " 2.38848476e-01 1.18615179e+01], Loss = 0.3462\n",
      "Iteration 6976: Weights = [5.50000000e+01 3.41190243e+00 7.17357949e+00 2.36346213e-02\n",
      " 2.38841620e-01 1.18617355e+01], Loss = 0.3462\n",
      "Iteration 6977: Weights = [5.50000000e+01 3.41180449e+00 7.17337356e+00 2.36339428e-02\n",
      " 2.38834763e-01 1.18619531e+01], Loss = 0.3462\n",
      "Iteration 6978: Weights = [5.50000000e+01 3.41170655e+00 7.17316764e+00 2.36332644e-02\n",
      " 2.38827907e-01 1.18621706e+01], Loss = 0.3462\n",
      "Iteration 6979: Weights = [5.50000000e+01 3.41160861e+00 7.17296172e+00 2.36325860e-02\n",
      " 2.38821051e-01 1.18623882e+01], Loss = 0.3461\n",
      "Iteration 6980: Weights = [5.50000000e+01 3.41151067e+00 7.17275582e+00 2.36319076e-02\n",
      " 2.38814196e-01 1.18626057e+01], Loss = 0.3461\n",
      "Iteration 6981: Weights = [5.50000000e+01 3.41141274e+00 7.17254991e+00 2.36312292e-02\n",
      " 2.38807340e-01 1.18628232e+01], Loss = 0.3461\n",
      "Iteration 6982: Weights = [5.50000000e+01 3.41131481e+00 7.17234401e+00 2.36305508e-02\n",
      " 2.38800485e-01 1.18630408e+01], Loss = 0.3461\n",
      "Iteration 6983: Weights = [5.50000000e+01 3.41121689e+00 7.17213812e+00 2.36298725e-02\n",
      " 2.38793630e-01 1.18632583e+01], Loss = 0.3461\n",
      "Iteration 6984: Weights = [5.50000000e+01 3.41111896e+00 7.17193224e+00 2.36291941e-02\n",
      " 2.38786775e-01 1.18634758e+01], Loss = 0.3460\n",
      "Iteration 6985: Weights = [5.50000000e+01 3.41102104e+00 7.17172636e+00 2.36285158e-02\n",
      " 2.38779920e-01 1.18636933e+01], Loss = 0.3460\n",
      "Iteration 6986: Weights = [5.50000000e+01 3.41092313e+00 7.17152048e+00 2.36278375e-02\n",
      " 2.38773066e-01 1.18639108e+01], Loss = 0.3460\n",
      "Iteration 6987: Weights = [5.50000000e+01 3.41082521e+00 7.17131462e+00 2.36271593e-02\n",
      " 2.38766212e-01 1.18641283e+01], Loss = 0.3460\n",
      "Iteration 6988: Weights = [5.50000000e+01 3.41072730e+00 7.17110875e+00 2.36264810e-02\n",
      " 2.38759358e-01 1.18643458e+01], Loss = 0.3460\n",
      "Iteration 6989: Weights = [5.50000000e+01 3.41062939e+00 7.17090290e+00 2.36258028e-02\n",
      " 2.38752504e-01 1.18645633e+01], Loss = 0.3460\n",
      "Iteration 6990: Weights = [5.50000000e+01 3.41053148e+00 7.17069705e+00 2.36251246e-02\n",
      " 2.38745650e-01 1.18647808e+01], Loss = 0.3459\n",
      "Iteration 6991: Weights = [5.50000000e+01 3.41043358e+00 7.17049120e+00 2.36244464e-02\n",
      " 2.38738796e-01 1.18649982e+01], Loss = 0.3459\n",
      "Iteration 6992: Weights = [5.50000000e+01 3.41033568e+00 7.17028537e+00 2.36237682e-02\n",
      " 2.38731943e-01 1.18652157e+01], Loss = 0.3459\n",
      "Iteration 6993: Weights = [5.50000000e+01 3.41023778e+00 7.17007953e+00 2.36230901e-02\n",
      " 2.38725090e-01 1.18654331e+01], Loss = 0.3459\n",
      "Iteration 6994: Weights = [5.50000000e+01 3.41013988e+00 7.16987371e+00 2.36224119e-02\n",
      " 2.38718237e-01 1.18656506e+01], Loss = 0.3459\n",
      "Iteration 6995: Weights = [5.50000000e+01 3.41004199e+00 7.16966789e+00 2.36217338e-02\n",
      " 2.38711384e-01 1.18658680e+01], Loss = 0.3458\n",
      "Iteration 6996: Weights = [5.50000000e+01 3.40994410e+00 7.16946207e+00 2.36210557e-02\n",
      " 2.38704532e-01 1.18660855e+01], Loss = 0.3458\n",
      "Iteration 6997: Weights = [5.50000000e+01 3.40984622e+00 7.16925626e+00 2.36203777e-02\n",
      " 2.38697680e-01 1.18663029e+01], Loss = 0.3458\n",
      "Iteration 6998: Weights = [5.50000000e+01 3.40974833e+00 7.16905046e+00 2.36196996e-02\n",
      " 2.38690827e-01 1.18665203e+01], Loss = 0.3458\n",
      "Iteration 6999: Weights = [5.50000000e+01 3.40965045e+00 7.16884466e+00 2.36190216e-02\n",
      " 2.38683975e-01 1.18667378e+01], Loss = 0.3458\n",
      "Iteration 7000: Weights = [5.50000000e+01 3.40955257e+00 7.16863887e+00 2.36183436e-02\n",
      " 2.38677124e-01 1.18669552e+01], Loss = 0.3457\n",
      "Iteration 7001: Weights = [5.50000000e+01 3.40945470e+00 7.16843309e+00 2.36176656e-02\n",
      " 2.38670272e-01 1.18671726e+01], Loss = 0.3457\n",
      "Iteration 7002: Weights = [5.50000000e+01 3.40935682e+00 7.16822731e+00 2.36169876e-02\n",
      " 2.38663421e-01 1.18673900e+01], Loss = 0.3457\n",
      "Iteration 7003: Weights = [5.50000000e+01 3.40925895e+00 7.16802153e+00 2.36163096e-02\n",
      " 2.38656570e-01 1.18676074e+01], Loss = 0.3457\n",
      "Iteration 7004: Weights = [5.50000000e+01 3.40916109e+00 7.16781577e+00 2.36156317e-02\n",
      " 2.38649719e-01 1.18678248e+01], Loss = 0.3457\n",
      "Iteration 7005: Weights = [5.50000000e+01 3.40906322e+00 7.16761000e+00 2.36149538e-02\n",
      " 2.38642868e-01 1.18680422e+01], Loss = 0.3456\n",
      "Iteration 7006: Weights = [5.50000000e+01 3.40896536e+00 7.16740425e+00 2.36142759e-02\n",
      " 2.38636017e-01 1.18682595e+01], Loss = 0.3456\n",
      "Iteration 7007: Weights = [5.50000000e+01 3.40886750e+00 7.16719850e+00 2.36135980e-02\n",
      " 2.38629167e-01 1.18684769e+01], Loss = 0.3456\n",
      "Iteration 7008: Weights = [5.50000000e+01 3.40876964e+00 7.16699276e+00 2.36129201e-02\n",
      " 2.38622317e-01 1.18686943e+01], Loss = 0.3456\n",
      "Iteration 7009: Weights = [5.50000000e+01 3.40867179e+00 7.16678702e+00 2.36122423e-02\n",
      " 2.38615467e-01 1.18689116e+01], Loss = 0.3456\n",
      "Iteration 7010: Weights = [5.50000000e+01 3.40857394e+00 7.16658129e+00 2.36115645e-02\n",
      " 2.38608617e-01 1.18691290e+01], Loss = 0.3455\n",
      "Iteration 7011: Weights = [5.50000000e+01 3.40847609e+00 7.16637556e+00 2.36108867e-02\n",
      " 2.38601768e-01 1.18693463e+01], Loss = 0.3455\n",
      "Iteration 7012: Weights = [5.50000000e+01 3.40837825e+00 7.16616984e+00 2.36102089e-02\n",
      " 2.38594918e-01 1.18695637e+01], Loss = 0.3455\n",
      "Iteration 7013: Weights = [5.50000000e+01 3.40828041e+00 7.16596412e+00 2.36095311e-02\n",
      " 2.38588069e-01 1.18697810e+01], Loss = 0.3455\n",
      "Iteration 7014: Weights = [5.50000000e+01 3.40818257e+00 7.16575842e+00 2.36088534e-02\n",
      " 2.38581220e-01 1.18699983e+01], Loss = 0.3455\n",
      "Iteration 7015: Weights = [5.50000000e+01 3.40808473e+00 7.16555271e+00 2.36081757e-02\n",
      " 2.38574371e-01 1.18702157e+01], Loss = 0.3454\n",
      "Iteration 7016: Weights = [5.50000000e+01 3.40798690e+00 7.16534702e+00 2.36074980e-02\n",
      " 2.38567523e-01 1.18704330e+01], Loss = 0.3454\n",
      "Iteration 7017: Weights = [5.50000000e+01 3.40788907e+00 7.16514133e+00 2.36068203e-02\n",
      " 2.38560674e-01 1.18706503e+01], Loss = 0.3454\n",
      "Iteration 7018: Weights = [5.50000000e+01 3.40779124e+00 7.16493564e+00 2.36061426e-02\n",
      " 2.38553826e-01 1.18708676e+01], Loss = 0.3454\n",
      "Iteration 7019: Weights = [5.50000000e+01 3.40769341e+00 7.16472996e+00 2.36054650e-02\n",
      " 2.38546978e-01 1.18710849e+01], Loss = 0.3454\n",
      "Iteration 7020: Weights = [5.50000000e+01 3.40759559e+00 7.16452429e+00 2.36047874e-02\n",
      " 2.38540130e-01 1.18713022e+01], Loss = 0.3453\n",
      "Iteration 7021: Weights = [5.50000000e+01 3.40749777e+00 7.16431862e+00 2.36041097e-02\n",
      " 2.38533283e-01 1.18715195e+01], Loss = 0.3453\n",
      "Iteration 7022: Weights = [5.50000000e+01 3.40739996e+00 7.16411296e+00 2.36034322e-02\n",
      " 2.38526435e-01 1.18717367e+01], Loss = 0.3453\n",
      "Iteration 7023: Weights = [5.50000000e+01 3.40730214e+00 7.16390731e+00 2.36027546e-02\n",
      " 2.38519588e-01 1.18719540e+01], Loss = 0.3453\n",
      "Iteration 7024: Weights = [5.50000000e+01 3.40720433e+00 7.16370166e+00 2.36020770e-02\n",
      " 2.38512741e-01 1.18721713e+01], Loss = 0.3453\n",
      "Iteration 7025: Weights = [5.50000000e+01 3.40710652e+00 7.16349601e+00 2.36013995e-02\n",
      " 2.38505894e-01 1.18723885e+01], Loss = 0.3452\n",
      "Iteration 7026: Weights = [5.50000000e+01 3.40700872e+00 7.16329038e+00 2.36007220e-02\n",
      " 2.38499048e-01 1.18726058e+01], Loss = 0.3452\n",
      "Iteration 7027: Weights = [5.50000000e+01 3.40691091e+00 7.16308474e+00 2.36000445e-02\n",
      " 2.38492201e-01 1.18728230e+01], Loss = 0.3452\n",
      "Iteration 7028: Weights = [5.50000000e+01 3.40681311e+00 7.16287912e+00 2.35993670e-02\n",
      " 2.38485355e-01 1.18730403e+01], Loss = 0.3452\n",
      "Iteration 7029: Weights = [5.50000000e+01 3.40671532e+00 7.16267350e+00 2.35986896e-02\n",
      " 2.38478509e-01 1.18732575e+01], Loss = 0.3452\n",
      "Iteration 7030: Weights = [5.50000000e+01 3.40661752e+00 7.16246789e+00 2.35980122e-02\n",
      " 2.38471663e-01 1.18734747e+01], Loss = 0.3451\n",
      "Iteration 7031: Weights = [5.50000000e+01 3.40651973e+00 7.16226228e+00 2.35973348e-02\n",
      " 2.38464817e-01 1.18736920e+01], Loss = 0.3451\n",
      "Iteration 7032: Weights = [5.50000000e+01 3.40642194e+00 7.16205668e+00 2.35966574e-02\n",
      " 2.38457972e-01 1.18739092e+01], Loss = 0.3451\n",
      "Iteration 7033: Weights = [5.50000000e+01 3.40632416e+00 7.16185108e+00 2.35959800e-02\n",
      " 2.38451127e-01 1.18741264e+01], Loss = 0.3451\n",
      "Iteration 7034: Weights = [5.50000000e+01 3.40622637e+00 7.16164549e+00 2.35953026e-02\n",
      " 2.38444282e-01 1.18743436e+01], Loss = 0.3451\n",
      "Iteration 7035: Weights = [5.50000000e+01 3.40612859e+00 7.16143990e+00 2.35946253e-02\n",
      " 2.38437437e-01 1.18745608e+01], Loss = 0.3450\n",
      "Iteration 7036: Weights = [5.50000000e+01 3.40603082e+00 7.16123433e+00 2.35939480e-02\n",
      " 2.38430592e-01 1.18747780e+01], Loss = 0.3450\n",
      "Iteration 7037: Weights = [5.50000000e+01 3.40593304e+00 7.16102875e+00 2.35932707e-02\n",
      " 2.38423748e-01 1.18749952e+01], Loss = 0.3450\n",
      "Iteration 7038: Weights = [5.50000000e+01 3.40583527e+00 7.16082319e+00 2.35925934e-02\n",
      " 2.38416903e-01 1.18752123e+01], Loss = 0.3450\n",
      "Iteration 7039: Weights = [5.50000000e+01 3.40573750e+00 7.16061763e+00 2.35919162e-02\n",
      " 2.38410059e-01 1.18754295e+01], Loss = 0.3450\n",
      "Iteration 7040: Weights = [5.50000000e+01 3.40563974e+00 7.16041207e+00 2.35912389e-02\n",
      " 2.38403215e-01 1.18756467e+01], Loss = 0.3449\n",
      "Iteration 7041: Weights = [5.50000000e+01 3.40554197e+00 7.16020652e+00 2.35905617e-02\n",
      " 2.38396372e-01 1.18758638e+01], Loss = 0.3449\n",
      "Iteration 7042: Weights = [5.50000000e+01 3.40544421e+00 7.16000098e+00 2.35898845e-02\n",
      " 2.38389528e-01 1.18760810e+01], Loss = 0.3449\n",
      "Iteration 7043: Weights = [5.50000000e+01 3.40534645e+00 7.15979544e+00 2.35892073e-02\n",
      " 2.38382685e-01 1.18762981e+01], Loss = 0.3449\n",
      "Iteration 7044: Weights = [5.50000000e+01 3.40524870e+00 7.15958991e+00 2.35885302e-02\n",
      " 2.38375842e-01 1.18765153e+01], Loss = 0.3449\n",
      "Iteration 7045: Weights = [5.50000000e+01 3.40515095e+00 7.15938438e+00 2.35878530e-02\n",
      " 2.38368999e-01 1.18767324e+01], Loss = 0.3448\n",
      "Iteration 7046: Weights = [5.50000000e+01 3.40505320e+00 7.15917887e+00 2.35871759e-02\n",
      " 2.38362156e-01 1.18769495e+01], Loss = 0.3448\n",
      "Iteration 7047: Weights = [5.50000000e+01 3.40495545e+00 7.15897335e+00 2.35864988e-02\n",
      " 2.38355314e-01 1.18771667e+01], Loss = 0.3448\n",
      "Iteration 7048: Weights = [5.50000000e+01 3.40485771e+00 7.15876784e+00 2.35858217e-02\n",
      " 2.38348472e-01 1.18773838e+01], Loss = 0.3448\n",
      "Iteration 7049: Weights = [5.50000000e+01 3.40475997e+00 7.15856234e+00 2.35851447e-02\n",
      " 2.38341629e-01 1.18776009e+01], Loss = 0.3448\n",
      "Iteration 7050: Weights = [5.50000000e+01 3.40466223e+00 7.15835685e+00 2.35844676e-02\n",
      " 2.38334788e-01 1.18778180e+01], Loss = 0.3447\n",
      "Iteration 7051: Weights = [5.50000000e+01 3.40456449e+00 7.15815136e+00 2.35837906e-02\n",
      " 2.38327946e-01 1.18780351e+01], Loss = 0.3447\n",
      "Iteration 7052: Weights = [5.50000000e+01 3.40446676e+00 7.15794587e+00 2.35831136e-02\n",
      " 2.38321104e-01 1.18782522e+01], Loss = 0.3447\n",
      "Iteration 7053: Weights = [5.50000000e+01 3.40436903e+00 7.15774039e+00 2.35824366e-02\n",
      " 2.38314263e-01 1.18784693e+01], Loss = 0.3447\n",
      "Iteration 7054: Weights = [5.50000000e+01 3.40427130e+00 7.15753492e+00 2.35817596e-02\n",
      " 2.38307422e-01 1.18786863e+01], Loss = 0.3447\n",
      "Iteration 7055: Weights = [5.50000000e+01 3.40417358e+00 7.15732946e+00 2.35810827e-02\n",
      " 2.38300581e-01 1.18789034e+01], Loss = 0.3446\n",
      "Iteration 7056: Weights = [5.50000000e+01 3.40407586e+00 7.15712399e+00 2.35804058e-02\n",
      " 2.38293740e-01 1.18791205e+01], Loss = 0.3446\n",
      "Iteration 7057: Weights = [5.50000000e+01 3.40397814e+00 7.15691854e+00 2.35797289e-02\n",
      " 2.38286900e-01 1.18793375e+01], Loss = 0.3446\n",
      "Iteration 7058: Weights = [5.50000000e+01 3.40388042e+00 7.15671309e+00 2.35790520e-02\n",
      " 2.38280059e-01 1.18795546e+01], Loss = 0.3446\n",
      "Iteration 7059: Weights = [5.50000000e+01 3.40378271e+00 7.15650765e+00 2.35783751e-02\n",
      " 2.38273219e-01 1.18797716e+01], Loss = 0.3446\n",
      "Iteration 7060: Weights = [5.50000000e+01 3.40368500e+00 7.15630221e+00 2.35776983e-02\n",
      " 2.38266379e-01 1.18799887e+01], Loss = 0.3445\n",
      "Iteration 7061: Weights = [5.50000000e+01 3.40358729e+00 7.15609678e+00 2.35770214e-02\n",
      " 2.38259540e-01 1.18802057e+01], Loss = 0.3445\n",
      "Iteration 7062: Weights = [5.50000000e+01 3.40348959e+00 7.15589136e+00 2.35763446e-02\n",
      " 2.38252700e-01 1.18804227e+01], Loss = 0.3445\n",
      "Iteration 7063: Weights = [5.50000000e+01 3.40339189e+00 7.15568594e+00 2.35756678e-02\n",
      " 2.38245861e-01 1.18806398e+01], Loss = 0.3445\n",
      "Iteration 7064: Weights = [5.50000000e+01 3.40329419e+00 7.15548052e+00 2.35749911e-02\n",
      " 2.38239021e-01 1.18808568e+01], Loss = 0.3445\n",
      "Iteration 7065: Weights = [5.50000000e+01 3.40319649e+00 7.15527512e+00 2.35743143e-02\n",
      " 2.38232183e-01 1.18810738e+01], Loss = 0.3444\n",
      "Iteration 7066: Weights = [5.50000000e+01 3.40309880e+00 7.15506971e+00 2.35736376e-02\n",
      " 2.38225344e-01 1.18812908e+01], Loss = 0.3444\n",
      "Iteration 7067: Weights = [5.50000000e+01 3.40300111e+00 7.15486432e+00 2.35729609e-02\n",
      " 2.38218505e-01 1.18815078e+01], Loss = 0.3444\n",
      "Iteration 7068: Weights = [5.50000000e+01 3.40290342e+00 7.15465893e+00 2.35722842e-02\n",
      " 2.38211667e-01 1.18817248e+01], Loss = 0.3444\n",
      "Iteration 7069: Weights = [5.50000000e+01 3.40280574e+00 7.15445354e+00 2.35716075e-02\n",
      " 2.38204829e-01 1.18819418e+01], Loss = 0.3444\n",
      "Iteration 7070: Weights = [5.50000000e+01 3.40270806e+00 7.15424817e+00 2.35709309e-02\n",
      " 2.38197991e-01 1.18821587e+01], Loss = 0.3443\n",
      "Iteration 7071: Weights = [5.50000000e+01 3.40261038e+00 7.15404279e+00 2.35702542e-02\n",
      " 2.38191153e-01 1.18823757e+01], Loss = 0.3443\n",
      "Iteration 7072: Weights = [5.50000000e+01 3.40251270e+00 7.15383743e+00 2.35695776e-02\n",
      " 2.38184315e-01 1.18825927e+01], Loss = 0.3443\n",
      "Iteration 7073: Weights = [5.50000000e+01 3.40241503e+00 7.15363207e+00 2.35689010e-02\n",
      " 2.38177478e-01 1.18828096e+01], Loss = 0.3443\n",
      "Iteration 7074: Weights = [5.50000000e+01 3.40231736e+00 7.15342671e+00 2.35682244e-02\n",
      " 2.38170641e-01 1.18830266e+01], Loss = 0.3443\n",
      "Iteration 7075: Weights = [5.50000000e+01 3.40221969e+00 7.15322137e+00 2.35675479e-02\n",
      " 2.38163804e-01 1.18832435e+01], Loss = 0.3442\n",
      "Iteration 7076: Weights = [5.50000000e+01 3.40212202e+00 7.15301602e+00 2.35668713e-02\n",
      " 2.38156967e-01 1.18834605e+01], Loss = 0.3442\n",
      "Iteration 7077: Weights = [5.50000000e+01 3.40202436e+00 7.15281069e+00 2.35661948e-02\n",
      " 2.38150130e-01 1.18836774e+01], Loss = 0.3442\n",
      "Iteration 7078: Weights = [5.50000000e+01 3.40192670e+00 7.15260536e+00 2.35655183e-02\n",
      " 2.38143294e-01 1.18838943e+01], Loss = 0.3442\n",
      "Iteration 7079: Weights = [5.50000000e+01 3.40182904e+00 7.15240003e+00 2.35648418e-02\n",
      " 2.38136458e-01 1.18841113e+01], Loss = 0.3442\n",
      "Iteration 7080: Weights = [5.50000000e+01 3.40173139e+00 7.15219471e+00 2.35641654e-02\n",
      " 2.38129622e-01 1.18843282e+01], Loss = 0.3441\n",
      "Iteration 7081: Weights = [5.50000000e+01 3.40163374e+00 7.15198940e+00 2.35634889e-02\n",
      " 2.38122786e-01 1.18845451e+01], Loss = 0.3441\n",
      "Iteration 7082: Weights = [5.50000000e+01 3.40153609e+00 7.15178409e+00 2.35628125e-02\n",
      " 2.38115950e-01 1.18847620e+01], Loss = 0.3441\n",
      "Iteration 7083: Weights = [5.50000000e+01 3.40143844e+00 7.15157879e+00 2.35621361e-02\n",
      " 2.38109115e-01 1.18849789e+01], Loss = 0.3441\n",
      "Iteration 7084: Weights = [5.50000000e+01 3.40134080e+00 7.15137349e+00 2.35614597e-02\n",
      " 2.38102280e-01 1.18851958e+01], Loss = 0.3441\n",
      "Iteration 7085: Weights = [5.50000000e+01 3.40124316e+00 7.15116820e+00 2.35607834e-02\n",
      " 2.38095444e-01 1.18854127e+01], Loss = 0.3440\n",
      "Iteration 7086: Weights = [5.50000000e+01 3.40114552e+00 7.15096292e+00 2.35601070e-02\n",
      " 2.38088610e-01 1.18856295e+01], Loss = 0.3440\n",
      "Iteration 7087: Weights = [5.50000000e+01 3.40104789e+00 7.15075764e+00 2.35594307e-02\n",
      " 2.38081775e-01 1.18858464e+01], Loss = 0.3440\n",
      "Iteration 7088: Weights = [5.50000000e+01 3.40095026e+00 7.15055237e+00 2.35587544e-02\n",
      " 2.38074941e-01 1.18860633e+01], Loss = 0.3440\n",
      "Iteration 7089: Weights = [5.50000000e+01 3.40085263e+00 7.15034711e+00 2.35580781e-02\n",
      " 2.38068106e-01 1.18862801e+01], Loss = 0.3440\n",
      "Iteration 7090: Weights = [5.50000000e+01 3.40075500e+00 7.15014185e+00 2.35574019e-02\n",
      " 2.38061272e-01 1.18864970e+01], Loss = 0.3439\n",
      "Iteration 7091: Weights = [5.50000000e+01 3.40065738e+00 7.14993659e+00 2.35567256e-02\n",
      " 2.38054438e-01 1.18867138e+01], Loss = 0.3439\n",
      "Iteration 7092: Weights = [5.50000000e+01 3.40055976e+00 7.14973134e+00 2.35560494e-02\n",
      " 2.38047605e-01 1.18869307e+01], Loss = 0.3439\n",
      "Iteration 7093: Weights = [5.50000000e+01 3.40046214e+00 7.14952610e+00 2.35553732e-02\n",
      " 2.38040771e-01 1.18871475e+01], Loss = 0.3439\n",
      "Iteration 7094: Weights = [5.50000000e+01 3.40036453e+00 7.14932086e+00 2.35546970e-02\n",
      " 2.38033938e-01 1.18873643e+01], Loss = 0.3439\n",
      "Iteration 7095: Weights = [5.50000000e+01 3.40026692e+00 7.14911563e+00 2.35540208e-02\n",
      " 2.38027105e-01 1.18875812e+01], Loss = 0.3439\n",
      "Iteration 7096: Weights = [5.50000000e+01 3.40016931e+00 7.14891041e+00 2.35533447e-02\n",
      " 2.38020272e-01 1.18877980e+01], Loss = 0.3438\n",
      "Iteration 7097: Weights = [5.50000000e+01 3.40007170e+00 7.14870519e+00 2.35526685e-02\n",
      " 2.38013439e-01 1.18880148e+01], Loss = 0.3438\n",
      "Iteration 7098: Weights = [5.50000000e+01 3.39997410e+00 7.14849998e+00 2.35519924e-02\n",
      " 2.38006607e-01 1.18882316e+01], Loss = 0.3438\n",
      "Iteration 7099: Weights = [5.50000000e+01 3.39987650e+00 7.14829477e+00 2.35513163e-02\n",
      " 2.37999775e-01 1.18884484e+01], Loss = 0.3438\n",
      "Iteration 7100: Weights = [5.50000000e+01 3.39977890e+00 7.14808957e+00 2.35506403e-02\n",
      " 2.37992942e-01 1.18886652e+01], Loss = 0.3438\n",
      "Iteration 7101: Weights = [5.50000000e+01 3.39968130e+00 7.14788437e+00 2.35499642e-02\n",
      " 2.37986111e-01 1.18888820e+01], Loss = 0.3437\n",
      "Iteration 7102: Weights = [5.50000000e+01 3.39958371e+00 7.14767918e+00 2.35492882e-02\n",
      " 2.37979279e-01 1.18890988e+01], Loss = 0.3437\n",
      "Iteration 7103: Weights = [5.50000000e+01 3.39948612e+00 7.14747400e+00 2.35486122e-02\n",
      " 2.37972447e-01 1.18893155e+01], Loss = 0.3437\n",
      "Iteration 7104: Weights = [5.50000000e+01 3.39938854e+00 7.14726882e+00 2.35479362e-02\n",
      " 2.37965616e-01 1.18895323e+01], Loss = 0.3437\n",
      "Iteration 7105: Weights = [5.50000000e+01 3.39929095e+00 7.14706365e+00 2.35472602e-02\n",
      " 2.37958785e-01 1.18897491e+01], Loss = 0.3437\n",
      "Iteration 7106: Weights = [5.50000000e+01 3.39919337e+00 7.14685849e+00 2.35465842e-02\n",
      " 2.37951954e-01 1.18899658e+01], Loss = 0.3436\n",
      "Iteration 7107: Weights = [5.50000000e+01 3.39909579e+00 7.14665333e+00 2.35459083e-02\n",
      " 2.37945123e-01 1.18901826e+01], Loss = 0.3436\n",
      "Iteration 7108: Weights = [5.50000000e+01 3.39899822e+00 7.14644817e+00 2.35452324e-02\n",
      " 2.37938293e-01 1.18903993e+01], Loss = 0.3436\n",
      "Iteration 7109: Weights = [5.50000000e+01 3.39890064e+00 7.14624302e+00 2.35445565e-02\n",
      " 2.37931462e-01 1.18906160e+01], Loss = 0.3436\n",
      "Iteration 7110: Weights = [5.50000000e+01 3.39880307e+00 7.14603788e+00 2.35438806e-02\n",
      " 2.37924632e-01 1.18908328e+01], Loss = 0.3436\n",
      "Iteration 7111: Weights = [5.50000000e+01 3.39870551e+00 7.14583274e+00 2.35432048e-02\n",
      " 2.37917802e-01 1.18910495e+01], Loss = 0.3435\n",
      "Iteration 7112: Weights = [5.50000000e+01 3.39860794e+00 7.14562761e+00 2.35425289e-02\n",
      " 2.37910973e-01 1.18912662e+01], Loss = 0.3435\n",
      "Iteration 7113: Weights = [5.50000000e+01 3.39851038e+00 7.14542249e+00 2.35418531e-02\n",
      " 2.37904143e-01 1.18914829e+01], Loss = 0.3435\n",
      "Iteration 7114: Weights = [5.50000000e+01 3.39841282e+00 7.14521737e+00 2.35411773e-02\n",
      " 2.37897314e-01 1.18916996e+01], Loss = 0.3435\n",
      "Iteration 7115: Weights = [5.50000000e+01 3.39831527e+00 7.14501226e+00 2.35405015e-02\n",
      " 2.37890485e-01 1.18919163e+01], Loss = 0.3435\n",
      "Iteration 7116: Weights = [5.50000000e+01 3.39821771e+00 7.14480715e+00 2.35398258e-02\n",
      " 2.37883656e-01 1.18921330e+01], Loss = 0.3434\n",
      "Iteration 7117: Weights = [5.50000000e+01 3.39812016e+00 7.14460205e+00 2.35391500e-02\n",
      " 2.37876827e-01 1.18923497e+01], Loss = 0.3434\n",
      "Iteration 7118: Weights = [5.50000000e+01 3.39802262e+00 7.14439696e+00 2.35384743e-02\n",
      " 2.37869998e-01 1.18925664e+01], Loss = 0.3434\n",
      "Iteration 7119: Weights = [5.50000000e+01 3.39792507e+00 7.14419187e+00 2.35377986e-02\n",
      " 2.37863170e-01 1.18927831e+01], Loss = 0.3434\n",
      "Iteration 7120: Weights = [5.50000000e+01 3.39782753e+00 7.14398678e+00 2.35371229e-02\n",
      " 2.37856342e-01 1.18929997e+01], Loss = 0.3434\n",
      "Iteration 7121: Weights = [5.50000000e+01 3.39772999e+00 7.14378170e+00 2.35364473e-02\n",
      " 2.37849514e-01 1.18932164e+01], Loss = 0.3433\n",
      "Iteration 7122: Weights = [5.50000000e+01 3.39763245e+00 7.14357663e+00 2.35357716e-02\n",
      " 2.37842686e-01 1.18934330e+01], Loss = 0.3433\n",
      "Iteration 7123: Weights = [5.50000000e+01 3.39753492e+00 7.14337157e+00 2.35350960e-02\n",
      " 2.37835858e-01 1.18936497e+01], Loss = 0.3433\n",
      "Iteration 7124: Weights = [5.50000000e+01 3.39743739e+00 7.14316651e+00 2.35344204e-02\n",
      " 2.37829031e-01 1.18938663e+01], Loss = 0.3433\n",
      "Iteration 7125: Weights = [5.50000000e+01 3.39733986e+00 7.14296145e+00 2.35337448e-02\n",
      " 2.37822204e-01 1.18940830e+01], Loss = 0.3433\n",
      "Iteration 7126: Weights = [5.50000000e+01 3.39724234e+00 7.14275641e+00 2.35330692e-02\n",
      " 2.37815377e-01 1.18942996e+01], Loss = 0.3432\n",
      "Iteration 7127: Weights = [5.50000000e+01 3.39714481e+00 7.14255136e+00 2.35323937e-02\n",
      " 2.37808550e-01 1.18945162e+01], Loss = 0.3432\n",
      "Iteration 7128: Weights = [5.50000000e+01 3.39704729e+00 7.14234633e+00 2.35317181e-02\n",
      " 2.37801723e-01 1.18947328e+01], Loss = 0.3432\n",
      "Iteration 7129: Weights = [5.50000000e+01 3.39694978e+00 7.14214130e+00 2.35310426e-02\n",
      " 2.37794897e-01 1.18949494e+01], Loss = 0.3432\n",
      "Iteration 7130: Weights = [5.50000000e+01 3.39685226e+00 7.14193627e+00 2.35303672e-02\n",
      " 2.37788071e-01 1.18951661e+01], Loss = 0.3432\n",
      "Iteration 7131: Weights = [5.50000000e+01 3.39675475e+00 7.14173125e+00 2.35296917e-02\n",
      " 2.37781245e-01 1.18953827e+01], Loss = 0.3431\n",
      "Iteration 7132: Weights = [5.50000000e+01 3.39665724e+00 7.14152624e+00 2.35290162e-02\n",
      " 2.37774419e-01 1.18955992e+01], Loss = 0.3431\n",
      "Iteration 7133: Weights = [5.50000000e+01 3.39655974e+00 7.14132123e+00 2.35283408e-02\n",
      " 2.37767593e-01 1.18958158e+01], Loss = 0.3431\n",
      "Iteration 7134: Weights = [5.50000000e+01 3.39646224e+00 7.14111623e+00 2.35276654e-02\n",
      " 2.37760768e-01 1.18960324e+01], Loss = 0.3431\n",
      "Iteration 7135: Weights = [5.50000000e+01 3.39636474e+00 7.14091124e+00 2.35269900e-02\n",
      " 2.37753943e-01 1.18962490e+01], Loss = 0.3431\n",
      "Iteration 7136: Weights = [5.50000000e+01 3.39626724e+00 7.14070625e+00 2.35263146e-02\n",
      " 2.37747118e-01 1.18964656e+01], Loss = 0.3430\n",
      "Iteration 7137: Weights = [5.50000000e+01 3.39616975e+00 7.14050127e+00 2.35256393e-02\n",
      " 2.37740293e-01 1.18966821e+01], Loss = 0.3430\n",
      "Iteration 7138: Weights = [5.50000000e+01 3.39607225e+00 7.14029629e+00 2.35249639e-02\n",
      " 2.37733468e-01 1.18968987e+01], Loss = 0.3430\n",
      "Iteration 7139: Weights = [5.50000000e+01 3.39597477e+00 7.14009132e+00 2.35242886e-02\n",
      " 2.37726644e-01 1.18971152e+01], Loss = 0.3430\n",
      "Iteration 7140: Weights = [5.50000000e+01 3.39587728e+00 7.13988635e+00 2.35236133e-02\n",
      " 2.37719819e-01 1.18973318e+01], Loss = 0.3430\n",
      "Iteration 7141: Weights = [5.50000000e+01 3.39577980e+00 7.13968139e+00 2.35229380e-02\n",
      " 2.37712995e-01 1.18975483e+01], Loss = 0.3429\n",
      "Iteration 7142: Weights = [5.50000000e+01 3.39568232e+00 7.13947644e+00 2.35222628e-02\n",
      " 2.37706171e-01 1.18977648e+01], Loss = 0.3429\n",
      "Iteration 7143: Weights = [5.50000000e+01 3.39558484e+00 7.13927149e+00 2.35215876e-02\n",
      " 2.37699348e-01 1.18979814e+01], Loss = 0.3429\n",
      "Iteration 7144: Weights = [5.50000000e+01 3.39548736e+00 7.13906655e+00 2.35209123e-02\n",
      " 2.37692524e-01 1.18981979e+01], Loss = 0.3429\n",
      "Iteration 7145: Weights = [5.50000000e+01 3.39538989e+00 7.13886161e+00 2.35202371e-02\n",
      " 2.37685701e-01 1.18984144e+01], Loss = 0.3429\n",
      "Iteration 7146: Weights = [5.50000000e+01 3.39529242e+00 7.13865668e+00 2.35195620e-02\n",
      " 2.37678878e-01 1.18986309e+01], Loss = 0.3428\n",
      "Iteration 7147: Weights = [5.50000000e+01 3.39519496e+00 7.13845176e+00 2.35188868e-02\n",
      " 2.37672055e-01 1.18988474e+01], Loss = 0.3428\n",
      "Iteration 7148: Weights = [5.50000000e+01 3.39509749e+00 7.13824684e+00 2.35182117e-02\n",
      " 2.37665232e-01 1.18990639e+01], Loss = 0.3428\n",
      "Iteration 7149: Weights = [5.50000000e+01 3.39500003e+00 7.13804192e+00 2.35175365e-02\n",
      " 2.37658410e-01 1.18992804e+01], Loss = 0.3428\n",
      "Iteration 7150: Weights = [5.50000000e+01 3.39490257e+00 7.13783702e+00 2.35168614e-02\n",
      " 2.37651588e-01 1.18994968e+01], Loss = 0.3428\n",
      "Iteration 7151: Weights = [5.50000000e+01 3.39480512e+00 7.13763212e+00 2.35161864e-02\n",
      " 2.37644766e-01 1.18997133e+01], Loss = 0.3427\n",
      "Iteration 7152: Weights = [5.50000000e+01 3.39470767e+00 7.13742722e+00 2.35155113e-02\n",
      " 2.37637944e-01 1.18999298e+01], Loss = 0.3427\n",
      "Iteration 7153: Weights = [5.50000000e+01 3.39461022e+00 7.13722233e+00 2.35148362e-02\n",
      " 2.37631122e-01 1.19001463e+01], Loss = 0.3427\n",
      "Iteration 7154: Weights = [5.50000000e+01 3.39451277e+00 7.13701745e+00 2.35141612e-02\n",
      " 2.37624300e-01 1.19003627e+01], Loss = 0.3427\n",
      "Iteration 7155: Weights = [5.50000000e+01 3.39441533e+00 7.13681257e+00 2.35134862e-02\n",
      " 2.37617479e-01 1.19005792e+01], Loss = 0.3427\n",
      "Iteration 7156: Weights = [5.50000000e+01 3.39431789e+00 7.13660770e+00 2.35128112e-02\n",
      " 2.37610658e-01 1.19007956e+01], Loss = 0.3426\n",
      "Iteration 7157: Weights = [5.50000000e+01 3.39422045e+00 7.13640283e+00 2.35121363e-02\n",
      " 2.37603837e-01 1.19010120e+01], Loss = 0.3426\n",
      "Iteration 7158: Weights = [5.50000000e+01 3.39412301e+00 7.13619797e+00 2.35114613e-02\n",
      " 2.37597016e-01 1.19012285e+01], Loss = 0.3426\n",
      "Iteration 7159: Weights = [5.50000000e+01 3.39402558e+00 7.13599312e+00 2.35107864e-02\n",
      " 2.37590196e-01 1.19014449e+01], Loss = 0.3426\n",
      "Iteration 7160: Weights = [5.50000000e+01 3.39392815e+00 7.13578827e+00 2.35101115e-02\n",
      " 2.37583375e-01 1.19016613e+01], Loss = 0.3426\n",
      "Iteration 7161: Weights = [5.50000000e+01 3.39383072e+00 7.13558343e+00 2.35094366e-02\n",
      " 2.37576555e-01 1.19018777e+01], Loss = 0.3426\n",
      "Iteration 7162: Weights = [5.50000000e+01 3.39373330e+00 7.13537859e+00 2.35087617e-02\n",
      " 2.37569735e-01 1.19020941e+01], Loss = 0.3425\n",
      "Iteration 7163: Weights = [5.50000000e+01 3.39363588e+00 7.13517376e+00 2.35080869e-02\n",
      " 2.37562916e-01 1.19023105e+01], Loss = 0.3425\n",
      "Iteration 7164: Weights = [5.50000000e+01 3.39353846e+00 7.13496894e+00 2.35074120e-02\n",
      " 2.37556096e-01 1.19025269e+01], Loss = 0.3425\n",
      "Iteration 7165: Weights = [5.50000000e+01 3.39344104e+00 7.13476412e+00 2.35067372e-02\n",
      " 2.37549277e-01 1.19027433e+01], Loss = 0.3425\n",
      "Iteration 7166: Weights = [5.50000000e+01 3.39334363e+00 7.13455931e+00 2.35060624e-02\n",
      " 2.37542458e-01 1.19029597e+01], Loss = 0.3425\n",
      "Iteration 7167: Weights = [5.50000000e+01 3.39324622e+00 7.13435450e+00 2.35053877e-02\n",
      " 2.37535639e-01 1.19031761e+01], Loss = 0.3424\n",
      "Iteration 7168: Weights = [5.50000000e+01 3.39314881e+00 7.13414970e+00 2.35047129e-02\n",
      " 2.37528820e-01 1.19033924e+01], Loss = 0.3424\n",
      "Iteration 7169: Weights = [5.50000000e+01 3.39305141e+00 7.13394491e+00 2.35040382e-02\n",
      " 2.37522001e-01 1.19036088e+01], Loss = 0.3424\n",
      "Iteration 7170: Weights = [5.50000000e+01 3.39295400e+00 7.13374012e+00 2.35033635e-02\n",
      " 2.37515183e-01 1.19038252e+01], Loss = 0.3424\n",
      "Iteration 7171: Weights = [5.50000000e+01 3.39285660e+00 7.13353533e+00 2.35026888e-02\n",
      " 2.37508365e-01 1.19040415e+01], Loss = 0.3424\n",
      "Iteration 7172: Weights = [5.50000000e+01 3.39275921e+00 7.13333056e+00 2.35020141e-02\n",
      " 2.37501547e-01 1.19042579e+01], Loss = 0.3423\n",
      "Iteration 7173: Weights = [5.50000000e+01 3.39266181e+00 7.13312578e+00 2.35013394e-02\n",
      " 2.37494729e-01 1.19044742e+01], Loss = 0.3423\n",
      "Iteration 7174: Weights = [5.50000000e+01 3.39256442e+00 7.13292102e+00 2.35006648e-02\n",
      " 2.37487911e-01 1.19046905e+01], Loss = 0.3423\n",
      "Iteration 7175: Weights = [5.50000000e+01 3.39246704e+00 7.13271626e+00 2.34999902e-02\n",
      " 2.37481094e-01 1.19049069e+01], Loss = 0.3423\n",
      "Iteration 7176: Weights = [5.50000000e+01 3.39236965e+00 7.13251150e+00 2.34993156e-02\n",
      " 2.37474277e-01 1.19051232e+01], Loss = 0.3423\n",
      "Iteration 7177: Weights = [5.50000000e+01 3.39227227e+00 7.13230676e+00 2.34986410e-02\n",
      " 2.37467460e-01 1.19053395e+01], Loss = 0.3422\n",
      "Iteration 7178: Weights = [5.50000000e+01 3.39217489e+00 7.13210201e+00 2.34979665e-02\n",
      " 2.37460643e-01 1.19055558e+01], Loss = 0.3422\n",
      "Iteration 7179: Weights = [5.50000000e+01 3.39207751e+00 7.13189728e+00 2.34972919e-02\n",
      " 2.37453826e-01 1.19057721e+01], Loss = 0.3422\n",
      "Iteration 7180: Weights = [5.50000000e+01 3.39198014e+00 7.13169255e+00 2.34966174e-02\n",
      " 2.37447010e-01 1.19059884e+01], Loss = 0.3422\n",
      "Iteration 7181: Weights = [5.50000000e+01 3.39188277e+00 7.13148782e+00 2.34959429e-02\n",
      " 2.37440194e-01 1.19062047e+01], Loss = 0.3422\n",
      "Iteration 7182: Weights = [5.50000000e+01 3.39178540e+00 7.13128310e+00 2.34952684e-02\n",
      " 2.37433378e-01 1.19064210e+01], Loss = 0.3421\n",
      "Iteration 7183: Weights = [5.50000000e+01 3.39168803e+00 7.13107839e+00 2.34945939e-02\n",
      " 2.37426562e-01 1.19066372e+01], Loss = 0.3421\n",
      "Iteration 7184: Weights = [5.50000000e+01 3.39159067e+00 7.13087368e+00 2.34939195e-02\n",
      " 2.37419746e-01 1.19068535e+01], Loss = 0.3421\n",
      "Iteration 7185: Weights = [5.50000000e+01 3.39149331e+00 7.13066898e+00 2.34932451e-02\n",
      " 2.37412931e-01 1.19070698e+01], Loss = 0.3421\n",
      "Iteration 7186: Weights = [5.50000000e+01 3.39139595e+00 7.13046429e+00 2.34925707e-02\n",
      " 2.37406115e-01 1.19072860e+01], Loss = 0.3421\n",
      "Iteration 7187: Weights = [5.50000000e+01 3.39129860e+00 7.13025960e+00 2.34918963e-02\n",
      " 2.37399300e-01 1.19075023e+01], Loss = 0.3420\n",
      "Iteration 7188: Weights = [5.50000000e+01 3.39120125e+00 7.13005492e+00 2.34912219e-02\n",
      " 2.37392485e-01 1.19077185e+01], Loss = 0.3420\n",
      "Iteration 7189: Weights = [5.50000000e+01 3.39110390e+00 7.12985024e+00 2.34905476e-02\n",
      " 2.37385671e-01 1.19079348e+01], Loss = 0.3420\n",
      "Iteration 7190: Weights = [5.50000000e+01 3.39100655e+00 7.12964557e+00 2.34898733e-02\n",
      " 2.37378856e-01 1.19081510e+01], Loss = 0.3420\n",
      "Iteration 7191: Weights = [5.50000000e+01 3.39090921e+00 7.12944090e+00 2.34891989e-02\n",
      " 2.37372042e-01 1.19083672e+01], Loss = 0.3420\n",
      "Iteration 7192: Weights = [5.50000000e+01 3.39081187e+00 7.12923624e+00 2.34885247e-02\n",
      " 2.37365228e-01 1.19085834e+01], Loss = 0.3419\n",
      "Iteration 7193: Weights = [5.50000000e+01 3.39071453e+00 7.12903159e+00 2.34878504e-02\n",
      " 2.37358414e-01 1.19087996e+01], Loss = 0.3419\n",
      "Iteration 7194: Weights = [5.50000000e+01 3.39061719e+00 7.12882694e+00 2.34871761e-02\n",
      " 2.37351600e-01 1.19090159e+01], Loss = 0.3419\n",
      "Iteration 7195: Weights = [5.50000000e+01 3.39051986e+00 7.12862230e+00 2.34865019e-02\n",
      " 2.37344787e-01 1.19092321e+01], Loss = 0.3419\n",
      "Iteration 7196: Weights = [5.50000000e+01 3.39042253e+00 7.12841766e+00 2.34858277e-02\n",
      " 2.37337974e-01 1.19094483e+01], Loss = 0.3419\n",
      "Iteration 7197: Weights = [5.50000000e+01 3.39032521e+00 7.12821303e+00 2.34851535e-02\n",
      " 2.37331161e-01 1.19096644e+01], Loss = 0.3418\n",
      "Iteration 7198: Weights = [5.50000000e+01 3.39022788e+00 7.12800840e+00 2.34844793e-02\n",
      " 2.37324348e-01 1.19098806e+01], Loss = 0.3418\n",
      "Iteration 7199: Weights = [5.50000000e+01 3.39013056e+00 7.12780379e+00 2.34838052e-02\n",
      " 2.37317535e-01 1.19100968e+01], Loss = 0.3418\n",
      "Iteration 7200: Weights = [5.50000000e+01 3.39003324e+00 7.12759917e+00 2.34831310e-02\n",
      " 2.37310722e-01 1.19103130e+01], Loss = 0.3418\n",
      "Iteration 7201: Weights = [5.50000000e+01 3.38993593e+00 7.12739457e+00 2.34824569e-02\n",
      " 2.37303910e-01 1.19105291e+01], Loss = 0.3418\n",
      "Iteration 7202: Weights = [5.50000000e+01 3.38983862e+00 7.12718996e+00 2.34817828e-02\n",
      " 2.37297098e-01 1.19107453e+01], Loss = 0.3417\n",
      "Iteration 7203: Weights = [5.50000000e+01 3.38974131e+00 7.12698537e+00 2.34811088e-02\n",
      " 2.37290286e-01 1.19109614e+01], Loss = 0.3417\n",
      "Iteration 7204: Weights = [5.50000000e+01 3.38964400e+00 7.12678078e+00 2.34804347e-02\n",
      " 2.37283474e-01 1.19111776e+01], Loss = 0.3417\n",
      "Iteration 7205: Weights = [5.50000000e+01 3.38954669e+00 7.12657620e+00 2.34797607e-02\n",
      " 2.37276663e-01 1.19113937e+01], Loss = 0.3417\n",
      "Iteration 7206: Weights = [5.50000000e+01 3.38944939e+00 7.12637162e+00 2.34790867e-02\n",
      " 2.37269851e-01 1.19116099e+01], Loss = 0.3417\n",
      "Iteration 7207: Weights = [5.50000000e+01 3.38935209e+00 7.12616705e+00 2.34784127e-02\n",
      " 2.37263040e-01 1.19118260e+01], Loss = 0.3416\n",
      "Iteration 7208: Weights = [5.50000000e+01 3.38925480e+00 7.12596248e+00 2.34777387e-02\n",
      " 2.37256229e-01 1.19120421e+01], Loss = 0.3416\n",
      "Iteration 7209: Weights = [5.50000000e+01 3.38915751e+00 7.12575792e+00 2.34770647e-02\n",
      " 2.37249419e-01 1.19122582e+01], Loss = 0.3416\n",
      "Iteration 7210: Weights = [5.50000000e+01 3.38906022e+00 7.12555337e+00 2.34763908e-02\n",
      " 2.37242608e-01 1.19124743e+01], Loss = 0.3416\n",
      "Iteration 7211: Weights = [5.50000000e+01 3.38896293e+00 7.12534882e+00 2.34757169e-02\n",
      " 2.37235798e-01 1.19126904e+01], Loss = 0.3416\n",
      "Iteration 7212: Weights = [5.50000000e+01 3.38886564e+00 7.12514428e+00 2.34750430e-02\n",
      " 2.37228988e-01 1.19129065e+01], Loss = 0.3415\n",
      "Iteration 7213: Weights = [5.50000000e+01 3.38876836e+00 7.12493974e+00 2.34743691e-02\n",
      " 2.37222178e-01 1.19131226e+01], Loss = 0.3415\n",
      "Iteration 7214: Weights = [5.50000000e+01 3.38867108e+00 7.12473521e+00 2.34736952e-02\n",
      " 2.37215368e-01 1.19133387e+01], Loss = 0.3415\n",
      "Iteration 7215: Weights = [5.50000000e+01 3.38857381e+00 7.12453068e+00 2.34730214e-02\n",
      " 2.37208558e-01 1.19135548e+01], Loss = 0.3415\n",
      "Iteration 7216: Weights = [5.50000000e+01 3.38847653e+00 7.12432616e+00 2.34723475e-02\n",
      " 2.37201749e-01 1.19137709e+01], Loss = 0.3415\n",
      "Iteration 7217: Weights = [5.50000000e+01 3.38837926e+00 7.12412165e+00 2.34716737e-02\n",
      " 2.37194940e-01 1.19139869e+01], Loss = 0.3415\n",
      "Iteration 7218: Weights = [5.50000000e+01 3.38828199e+00 7.12391714e+00 2.34710000e-02\n",
      " 2.37188131e-01 1.19142030e+01], Loss = 0.3414\n",
      "Iteration 7219: Weights = [5.50000000e+01 3.38818473e+00 7.12371264e+00 2.34703262e-02\n",
      " 2.37181322e-01 1.19144190e+01], Loss = 0.3414\n",
      "Iteration 7220: Weights = [5.50000000e+01 3.38808747e+00 7.12350815e+00 2.34696524e-02\n",
      " 2.37174513e-01 1.19146351e+01], Loss = 0.3414\n",
      "Iteration 7221: Weights = [5.50000000e+01 3.38799021e+00 7.12330366e+00 2.34689787e-02\n",
      " 2.37167705e-01 1.19148511e+01], Loss = 0.3414\n",
      "Iteration 7222: Weights = [5.50000000e+01 3.38789295e+00 7.12309917e+00 2.34683050e-02\n",
      " 2.37160897e-01 1.19150671e+01], Loss = 0.3414\n",
      "Iteration 7223: Weights = [5.50000000e+01 3.38779570e+00 7.12289470e+00 2.34676313e-02\n",
      " 2.37154089e-01 1.19152832e+01], Loss = 0.3413\n",
      "Iteration 7224: Weights = [5.50000000e+01 3.38769845e+00 7.12269022e+00 2.34669577e-02\n",
      " 2.37147281e-01 1.19154992e+01], Loss = 0.3413\n",
      "Iteration 7225: Weights = [5.50000000e+01 3.38760120e+00 7.12248576e+00 2.34662840e-02\n",
      " 2.37140473e-01 1.19157152e+01], Loss = 0.3413\n",
      "Iteration 7226: Weights = [5.50000000e+01 3.38750395e+00 7.12228130e+00 2.34656104e-02\n",
      " 2.37133666e-01 1.19159312e+01], Loss = 0.3413\n",
      "Iteration 7227: Weights = [5.50000000e+01 3.38740671e+00 7.12207684e+00 2.34649368e-02\n",
      " 2.37126859e-01 1.19161472e+01], Loss = 0.3413\n",
      "Iteration 7228: Weights = [5.50000000e+01 3.38730947e+00 7.12187239e+00 2.34642632e-02\n",
      " 2.37120052e-01 1.19163632e+01], Loss = 0.3412\n",
      "Iteration 7229: Weights = [5.50000000e+01 3.38721223e+00 7.12166795e+00 2.34635896e-02\n",
      " 2.37113245e-01 1.19165792e+01], Loss = 0.3412\n",
      "Iteration 7230: Weights = [5.50000000e+01 3.38711500e+00 7.12146351e+00 2.34629160e-02\n",
      " 2.37106438e-01 1.19167952e+01], Loss = 0.3412\n",
      "Iteration 7231: Weights = [5.50000000e+01 3.38701777e+00 7.12125908e+00 2.34622425e-02\n",
      " 2.37099632e-01 1.19170112e+01], Loss = 0.3412\n",
      "Iteration 7232: Weights = [5.50000000e+01 3.38692054e+00 7.12105466e+00 2.34615690e-02\n",
      " 2.37092825e-01 1.19172271e+01], Loss = 0.3412\n",
      "Iteration 7233: Weights = [5.50000000e+01 3.38682331e+00 7.12085024e+00 2.34608955e-02\n",
      " 2.37086019e-01 1.19174431e+01], Loss = 0.3411\n",
      "Iteration 7234: Weights = [5.50000000e+01 3.38672609e+00 7.12064583e+00 2.34602220e-02\n",
      " 2.37079213e-01 1.19176591e+01], Loss = 0.3411\n",
      "Iteration 7235: Weights = [5.50000000e+01 3.38662887e+00 7.12044142e+00 2.34595486e-02\n",
      " 2.37072408e-01 1.19178750e+01], Loss = 0.3411\n",
      "Iteration 7236: Weights = [5.50000000e+01 3.38653165e+00 7.12023702e+00 2.34588751e-02\n",
      " 2.37065602e-01 1.19180910e+01], Loss = 0.3411\n",
      "Iteration 7237: Weights = [5.50000000e+01 3.38643444e+00 7.12003262e+00 2.34582017e-02\n",
      " 2.37058797e-01 1.19183069e+01], Loss = 0.3411\n",
      "Iteration 7238: Weights = [5.50000000e+01 3.38633722e+00 7.11982823e+00 2.34575283e-02\n",
      " 2.37051992e-01 1.19185228e+01], Loss = 0.3410\n",
      "Iteration 7239: Weights = [5.50000000e+01 3.38624001e+00 7.11962385e+00 2.34568549e-02\n",
      " 2.37045187e-01 1.19187388e+01], Loss = 0.3410\n",
      "Iteration 7240: Weights = [5.50000000e+01 3.38614281e+00 7.11941947e+00 2.34561816e-02\n",
      " 2.37038382e-01 1.19189547e+01], Loss = 0.3410\n",
      "Iteration 7241: Weights = [5.50000000e+01 3.38604560e+00 7.11921510e+00 2.34555082e-02\n",
      " 2.37031578e-01 1.19191706e+01], Loss = 0.3410\n",
      "Iteration 7242: Weights = [5.50000000e+01 3.38594840e+00 7.11901073e+00 2.34548349e-02\n",
      " 2.37024774e-01 1.19193865e+01], Loss = 0.3410\n",
      "Iteration 7243: Weights = [5.50000000e+01 3.38585121e+00 7.11880637e+00 2.34541616e-02\n",
      " 2.37017969e-01 1.19196024e+01], Loss = 0.3409\n",
      "Iteration 7244: Weights = [5.50000000e+01 3.38575401e+00 7.11860202e+00 2.34534883e-02\n",
      " 2.37011165e-01 1.19198183e+01], Loss = 0.3409\n",
      "Iteration 7245: Weights = [5.50000000e+01 3.38565682e+00 7.11839767e+00 2.34528151e-02\n",
      " 2.37004362e-01 1.19200342e+01], Loss = 0.3409\n",
      "Iteration 7246: Weights = [5.50000000e+01 3.38555963e+00 7.11819332e+00 2.34521418e-02\n",
      " 2.36997558e-01 1.19202501e+01], Loss = 0.3409\n",
      "Iteration 7247: Weights = [5.50000000e+01 3.38546244e+00 7.11798899e+00 2.34514686e-02\n",
      " 2.36990755e-01 1.19204660e+01], Loss = 0.3409\n",
      "Iteration 7248: Weights = [5.50000000e+01 3.38536526e+00 7.11778466e+00 2.34507954e-02\n",
      " 2.36983952e-01 1.19206818e+01], Loss = 0.3408\n",
      "Iteration 7249: Weights = [5.50000000e+01 3.38526808e+00 7.11758033e+00 2.34501222e-02\n",
      " 2.36977149e-01 1.19208977e+01], Loss = 0.3408\n",
      "Iteration 7250: Weights = [5.50000000e+01 3.38517090e+00 7.11737601e+00 2.34494490e-02\n",
      " 2.36970346e-01 1.19211136e+01], Loss = 0.3408\n",
      "Iteration 7251: Weights = [5.50000000e+01 3.38507372e+00 7.11717170e+00 2.34487759e-02\n",
      " 2.36963544e-01 1.19213294e+01], Loss = 0.3408\n",
      "Iteration 7252: Weights = [5.50000000e+01 3.38497655e+00 7.11696739e+00 2.34481028e-02\n",
      " 2.36956741e-01 1.19215453e+01], Loss = 0.3408\n",
      "Iteration 7253: Weights = [5.50000000e+01 3.38487938e+00 7.11676309e+00 2.34474297e-02\n",
      " 2.36949939e-01 1.19217611e+01], Loss = 0.3407\n",
      "Iteration 7254: Weights = [5.50000000e+01 3.38478221e+00 7.11655879e+00 2.34467566e-02\n",
      " 2.36943137e-01 1.19219770e+01], Loss = 0.3407\n",
      "Iteration 7255: Weights = [5.50000000e+01 3.38468505e+00 7.11635450e+00 2.34460835e-02\n",
      " 2.36936335e-01 1.19221928e+01], Loss = 0.3407\n",
      "Iteration 7256: Weights = [5.50000000e+01 3.38458788e+00 7.11615022e+00 2.34454104e-02\n",
      " 2.36929534e-01 1.19224086e+01], Loss = 0.3407\n",
      "Iteration 7257: Weights = [5.50000000e+01 3.38449073e+00 7.11594594e+00 2.34447374e-02\n",
      " 2.36922732e-01 1.19226244e+01], Loss = 0.3407\n",
      "Iteration 7258: Weights = [5.50000000e+01 3.38439357e+00 7.11574167e+00 2.34440644e-02\n",
      " 2.36915931e-01 1.19228402e+01], Loss = 0.3406\n",
      "Iteration 7259: Weights = [5.50000000e+01 3.38429642e+00 7.11553740e+00 2.34433914e-02\n",
      " 2.36909130e-01 1.19230560e+01], Loss = 0.3406\n",
      "Iteration 7260: Weights = [5.50000000e+01 3.38419926e+00 7.11533314e+00 2.34427184e-02\n",
      " 2.36902329e-01 1.19232718e+01], Loss = 0.3406\n",
      "Iteration 7261: Weights = [5.50000000e+01 3.38410212e+00 7.11512888e+00 2.34420455e-02\n",
      " 2.36895529e-01 1.19234876e+01], Loss = 0.3406\n",
      "Iteration 7262: Weights = [5.50000000e+01 3.38400497e+00 7.11492463e+00 2.34413726e-02\n",
      " 2.36888728e-01 1.19237034e+01], Loss = 0.3406\n",
      "Iteration 7263: Weights = [5.50000000e+01 3.38390783e+00 7.11472039e+00 2.34406996e-02\n",
      " 2.36881928e-01 1.19239192e+01], Loss = 0.3406\n",
      "Iteration 7264: Weights = [5.50000000e+01 3.38381069e+00 7.11451615e+00 2.34400267e-02\n",
      " 2.36875128e-01 1.19241350e+01], Loss = 0.3405\n",
      "Iteration 7265: Weights = [5.50000000e+01 3.38371355e+00 7.11431192e+00 2.34393539e-02\n",
      " 2.36868328e-01 1.19243507e+01], Loss = 0.3405\n",
      "Iteration 7266: Weights = [5.50000000e+01 3.38361642e+00 7.11410770e+00 2.34386810e-02\n",
      " 2.36861529e-01 1.19245665e+01], Loss = 0.3405\n",
      "Iteration 7267: Weights = [5.50000000e+01 3.38351929e+00 7.11390348e+00 2.34380082e-02\n",
      " 2.36854729e-01 1.19247823e+01], Loss = 0.3405\n",
      "Iteration 7268: Weights = [5.50000000e+01 3.38342216e+00 7.11369926e+00 2.34373353e-02\n",
      " 2.36847930e-01 1.19249980e+01], Loss = 0.3405\n",
      "Iteration 7269: Weights = [5.50000000e+01 3.38332503e+00 7.11349506e+00 2.34366626e-02\n",
      " 2.36841131e-01 1.19252137e+01], Loss = 0.3404\n",
      "Iteration 7270: Weights = [5.50000000e+01 3.38322791e+00 7.11329085e+00 2.34359898e-02\n",
      " 2.36834332e-01 1.19254295e+01], Loss = 0.3404\n",
      "Iteration 7271: Weights = [5.50000000e+01 3.38313079e+00 7.11308666e+00 2.34353170e-02\n",
      " 2.36827534e-01 1.19256452e+01], Loss = 0.3404\n",
      "Iteration 7272: Weights = [5.50000000e+01 3.38303367e+00 7.11288247e+00 2.34346443e-02\n",
      " 2.36820735e-01 1.19258609e+01], Loss = 0.3404\n",
      "Iteration 7273: Weights = [5.50000000e+01 3.38293656e+00 7.11267828e+00 2.34339715e-02\n",
      " 2.36813937e-01 1.19260767e+01], Loss = 0.3404\n",
      "Iteration 7274: Weights = [5.50000000e+01 3.38283945e+00 7.11247410e+00 2.34332988e-02\n",
      " 2.36807139e-01 1.19262924e+01], Loss = 0.3403\n",
      "Iteration 7275: Weights = [5.50000000e+01 3.38274234e+00 7.11226993e+00 2.34326262e-02\n",
      " 2.36800341e-01 1.19265081e+01], Loss = 0.3403\n",
      "Iteration 7276: Weights = [5.50000000e+01 3.38264523e+00 7.11206576e+00 2.34319535e-02\n",
      " 2.36793543e-01 1.19267238e+01], Loss = 0.3403\n",
      "Iteration 7277: Weights = [5.50000000e+01 3.38254813e+00 7.11186160e+00 2.34312809e-02\n",
      " 2.36786746e-01 1.19269395e+01], Loss = 0.3403\n",
      "Iteration 7278: Weights = [5.50000000e+01 3.38245103e+00 7.11165745e+00 2.34306082e-02\n",
      " 2.36779949e-01 1.19271551e+01], Loss = 0.3403\n",
      "Iteration 7279: Weights = [5.50000000e+01 3.38235393e+00 7.11145330e+00 2.34299356e-02\n",
      " 2.36773152e-01 1.19273708e+01], Loss = 0.3402\n",
      "Iteration 7280: Weights = [5.50000000e+01 3.38225684e+00 7.11124915e+00 2.34292630e-02\n",
      " 2.36766355e-01 1.19275865e+01], Loss = 0.3402\n",
      "Iteration 7281: Weights = [5.50000000e+01 3.38215975e+00 7.11104502e+00 2.34285905e-02\n",
      " 2.36759558e-01 1.19278022e+01], Loss = 0.3402\n",
      "Iteration 7282: Weights = [5.50000000e+01 3.38206266e+00 7.11084088e+00 2.34279179e-02\n",
      " 2.36752762e-01 1.19280178e+01], Loss = 0.3402\n",
      "Iteration 7283: Weights = [5.50000000e+01 3.38196557e+00 7.11063676e+00 2.34272454e-02\n",
      " 2.36745965e-01 1.19282335e+01], Loss = 0.3402\n",
      "Iteration 7284: Weights = [5.50000000e+01 3.38186849e+00 7.11043264e+00 2.34265729e-02\n",
      " 2.36739169e-01 1.19284491e+01], Loss = 0.3401\n",
      "Iteration 7285: Weights = [5.50000000e+01 3.38177140e+00 7.11022852e+00 2.34259004e-02\n",
      " 2.36732373e-01 1.19286648e+01], Loss = 0.3401\n",
      "Iteration 7286: Weights = [5.50000000e+01 3.38167433e+00 7.11002442e+00 2.34252279e-02\n",
      " 2.36725578e-01 1.19288804e+01], Loss = 0.3401\n",
      "Iteration 7287: Weights = [5.50000000e+01 3.38157725e+00 7.10982031e+00 2.34245555e-02\n",
      " 2.36718782e-01 1.19290961e+01], Loss = 0.3401\n",
      "Iteration 7288: Weights = [5.50000000e+01 3.38148018e+00 7.10961622e+00 2.34238830e-02\n",
      " 2.36711987e-01 1.19293117e+01], Loss = 0.3401\n",
      "Iteration 7289: Weights = [5.50000000e+01 3.38138311e+00 7.10941212e+00 2.34232106e-02\n",
      " 2.36705192e-01 1.19295273e+01], Loss = 0.3400\n",
      "Iteration 7290: Weights = [5.50000000e+01 3.38128604e+00 7.10920804e+00 2.34225382e-02\n",
      " 2.36698397e-01 1.19297429e+01], Loss = 0.3400\n",
      "Iteration 7291: Weights = [5.50000000e+01 3.38118898e+00 7.10900396e+00 2.34218658e-02\n",
      " 2.36691602e-01 1.19299585e+01], Loss = 0.3400\n",
      "Iteration 7292: Weights = [5.50000000e+01 3.38109192e+00 7.10879989e+00 2.34211935e-02\n",
      " 2.36684807e-01 1.19301741e+01], Loss = 0.3400\n",
      "Iteration 7293: Weights = [5.50000000e+01 3.38099486e+00 7.10859582e+00 2.34205212e-02\n",
      " 2.36678013e-01 1.19303897e+01], Loss = 0.3400\n",
      "Iteration 7294: Weights = [5.50000000e+01 3.38089780e+00 7.10839176e+00 2.34198488e-02\n",
      " 2.36671219e-01 1.19306053e+01], Loss = 0.3399\n",
      "Iteration 7295: Weights = [5.50000000e+01 3.38080075e+00 7.10818770e+00 2.34191765e-02\n",
      " 2.36664425e-01 1.19308209e+01], Loss = 0.3399\n",
      "Iteration 7296: Weights = [5.50000000e+01 3.38070370e+00 7.10798365e+00 2.34185043e-02\n",
      " 2.36657631e-01 1.19310365e+01], Loss = 0.3399\n",
      "Iteration 7297: Weights = [5.50000000e+01 3.38060665e+00 7.10777961e+00 2.34178320e-02\n",
      " 2.36650838e-01 1.19312520e+01], Loss = 0.3399\n",
      "Iteration 7298: Weights = [5.50000000e+01 3.38050961e+00 7.10757557e+00 2.34171598e-02\n",
      " 2.36644044e-01 1.19314676e+01], Loss = 0.3399\n",
      "Iteration 7299: Weights = [5.50000000e+01 3.38041256e+00 7.10737154e+00 2.34164875e-02\n",
      " 2.36637251e-01 1.19316831e+01], Loss = 0.3398\n",
      "Iteration 7300: Weights = [5.50000000e+01 3.38031552e+00 7.10716751e+00 2.34158153e-02\n",
      " 2.36630458e-01 1.19318987e+01], Loss = 0.3398\n",
      "Iteration 7301: Weights = [5.50000000e+01 3.38021849e+00 7.10696349e+00 2.34151432e-02\n",
      " 2.36623665e-01 1.19321142e+01], Loss = 0.3398\n",
      "Iteration 7302: Weights = [5.50000000e+01 3.38012145e+00 7.10675948e+00 2.34144710e-02\n",
      " 2.36616873e-01 1.19323298e+01], Loss = 0.3398\n",
      "Iteration 7303: Weights = [5.50000000e+01 3.38002442e+00 7.10655547e+00 2.34137989e-02\n",
      " 2.36610080e-01 1.19325453e+01], Loss = 0.3398\n",
      "Iteration 7304: Weights = [5.50000000e+01 3.37992740e+00 7.10635147e+00 2.34131267e-02\n",
      " 2.36603288e-01 1.19327608e+01], Loss = 0.3397\n",
      "Iteration 7305: Weights = [5.50000000e+01 3.37983037e+00 7.10614747e+00 2.34124546e-02\n",
      " 2.36596496e-01 1.19329764e+01], Loss = 0.3397\n",
      "Iteration 7306: Weights = [5.50000000e+01 3.37973335e+00 7.10594348e+00 2.34117825e-02\n",
      " 2.36589704e-01 1.19331919e+01], Loss = 0.3397\n",
      "Iteration 7307: Weights = [5.50000000e+01 3.37963633e+00 7.10573949e+00 2.34111105e-02\n",
      " 2.36582913e-01 1.19334074e+01], Loss = 0.3397\n",
      "Iteration 7308: Weights = [5.50000000e+01 3.37953931e+00 7.10553551e+00 2.34104384e-02\n",
      " 2.36576121e-01 1.19336229e+01], Loss = 0.3397\n",
      "Iteration 7309: Weights = [5.50000000e+01 3.37944230e+00 7.10533154e+00 2.34097664e-02\n",
      " 2.36569330e-01 1.19338384e+01], Loss = 0.3397\n",
      "Iteration 7310: Weights = [5.50000000e+01 3.37934529e+00 7.10512757e+00 2.34090944e-02\n",
      " 2.36562539e-01 1.19340539e+01], Loss = 0.3396\n",
      "Iteration 7311: Weights = [5.50000000e+01 3.37924828e+00 7.10492361e+00 2.34084224e-02\n",
      " 2.36555748e-01 1.19342693e+01], Loss = 0.3396\n",
      "Iteration 7312: Weights = [5.50000000e+01 3.37915127e+00 7.10471965e+00 2.34077504e-02\n",
      " 2.36548957e-01 1.19344848e+01], Loss = 0.3396\n",
      "Iteration 7313: Weights = [5.50000000e+01 3.37905427e+00 7.10451570e+00 2.34070785e-02\n",
      " 2.36542167e-01 1.19347003e+01], Loss = 0.3396\n",
      "Iteration 7314: Weights = [5.50000000e+01 3.37895727e+00 7.10431176e+00 2.34064066e-02\n",
      " 2.36535377e-01 1.19349158e+01], Loss = 0.3396\n",
      "Iteration 7315: Weights = [5.50000000e+01 3.37886027e+00 7.10410782e+00 2.34057346e-02\n",
      " 2.36528587e-01 1.19351312e+01], Loss = 0.3395\n",
      "Iteration 7316: Weights = [5.50000000e+01 3.37876328e+00 7.10390389e+00 2.34050628e-02\n",
      " 2.36521797e-01 1.19353467e+01], Loss = 0.3395\n",
      "Iteration 7317: Weights = [5.50000000e+01 3.37866628e+00 7.10369996e+00 2.34043909e-02\n",
      " 2.36515007e-01 1.19355621e+01], Loss = 0.3395\n",
      "Iteration 7318: Weights = [5.50000000e+01 3.37856930e+00 7.10349604e+00 2.34037190e-02\n",
      " 2.36508218e-01 1.19357775e+01], Loss = 0.3395\n",
      "Iteration 7319: Weights = [5.50000000e+01 3.37847231e+00 7.10329212e+00 2.34030472e-02\n",
      " 2.36501428e-01 1.19359930e+01], Loss = 0.3395\n",
      "Iteration 7320: Weights = [5.50000000e+01 3.37837533e+00 7.10308821e+00 2.34023754e-02\n",
      " 2.36494639e-01 1.19362084e+01], Loss = 0.3394\n",
      "Iteration 7321: Weights = [5.50000000e+01 3.37827835e+00 7.10288431e+00 2.34017036e-02\n",
      " 2.36487850e-01 1.19364238e+01], Loss = 0.3394\n",
      "Iteration 7322: Weights = [5.50000000e+01 3.37818137e+00 7.10268041e+00 2.34010318e-02\n",
      " 2.36481062e-01 1.19366392e+01], Loss = 0.3394\n",
      "Iteration 7323: Weights = [5.50000000e+01 3.37808439e+00 7.10247652e+00 2.34003600e-02\n",
      " 2.36474273e-01 1.19368546e+01], Loss = 0.3394\n",
      "Iteration 7324: Weights = [5.50000000e+01 3.37798742e+00 7.10227264e+00 2.33996883e-02\n",
      " 2.36467485e-01 1.19370701e+01], Loss = 0.3394\n",
      "Iteration 7325: Weights = [5.50000000e+01 3.37789045e+00 7.10206876e+00 2.33990166e-02\n",
      " 2.36460697e-01 1.19372854e+01], Loss = 0.3393\n",
      "Iteration 7326: Weights = [5.50000000e+01 3.37779348e+00 7.10186488e+00 2.33983449e-02\n",
      " 2.36453909e-01 1.19375008e+01], Loss = 0.3393\n",
      "Iteration 7327: Weights = [5.50000000e+01 3.37769652e+00 7.10166101e+00 2.33976732e-02\n",
      " 2.36447121e-01 1.19377162e+01], Loss = 0.3393\n",
      "Iteration 7328: Weights = [5.50000000e+01 3.37759956e+00 7.10145715e+00 2.33970016e-02\n",
      " 2.36440334e-01 1.19379316e+01], Loss = 0.3393\n",
      "Iteration 7329: Weights = [5.50000000e+01 3.37750260e+00 7.10125329e+00 2.33963299e-02\n",
      " 2.36433546e-01 1.19381470e+01], Loss = 0.3393\n",
      "Iteration 7330: Weights = [5.50000000e+01 3.37740564e+00 7.10104944e+00 2.33956583e-02\n",
      " 2.36426759e-01 1.19383623e+01], Loss = 0.3392\n",
      "Iteration 7331: Weights = [5.50000000e+01 3.37730869e+00 7.10084560e+00 2.33949867e-02\n",
      " 2.36419972e-01 1.19385777e+01], Loss = 0.3392\n",
      "Iteration 7332: Weights = [5.50000000e+01 3.37721174e+00 7.10064176e+00 2.33943151e-02\n",
      " 2.36413186e-01 1.19387930e+01], Loss = 0.3392\n",
      "Iteration 7333: Weights = [5.50000000e+01 3.37711479e+00 7.10043793e+00 2.33936435e-02\n",
      " 2.36406399e-01 1.19390084e+01], Loss = 0.3392\n",
      "Iteration 7334: Weights = [5.50000000e+01 3.37701785e+00 7.10023410e+00 2.33929720e-02\n",
      " 2.36399613e-01 1.19392237e+01], Loss = 0.3392\n",
      "Iteration 7335: Weights = [5.50000000e+01 3.37692091e+00 7.10003028e+00 2.33923005e-02\n",
      " 2.36392826e-01 1.19394391e+01], Loss = 0.3391\n",
      "Iteration 7336: Weights = [5.50000000e+01 3.37682397e+00 7.09982646e+00 2.33916290e-02\n",
      " 2.36386041e-01 1.19396544e+01], Loss = 0.3391\n",
      "Iteration 7337: Weights = [5.50000000e+01 3.37672703e+00 7.09962265e+00 2.33909575e-02\n",
      " 2.36379255e-01 1.19398697e+01], Loss = 0.3391\n",
      "Iteration 7338: Weights = [5.50000000e+01 3.37663010e+00 7.09941885e+00 2.33902860e-02\n",
      " 2.36372469e-01 1.19400850e+01], Loss = 0.3391\n",
      "Iteration 7339: Weights = [5.50000000e+01 3.37653317e+00 7.09921505e+00 2.33896146e-02\n",
      " 2.36365684e-01 1.19403003e+01], Loss = 0.3391\n",
      "Iteration 7340: Weights = [5.50000000e+01 3.37643624e+00 7.09901126e+00 2.33889431e-02\n",
      " 2.36358899e-01 1.19405156e+01], Loss = 0.3390\n",
      "Iteration 7341: Weights = [5.50000000e+01 3.37633932e+00 7.09880747e+00 2.33882717e-02\n",
      " 2.36352114e-01 1.19407309e+01], Loss = 0.3390\n",
      "Iteration 7342: Weights = [5.50000000e+01 3.37624239e+00 7.09860369e+00 2.33876003e-02\n",
      " 2.36345329e-01 1.19409462e+01], Loss = 0.3390\n",
      "Iteration 7343: Weights = [5.50000000e+01 3.37614547e+00 7.09839992e+00 2.33869290e-02\n",
      " 2.36338544e-01 1.19411615e+01], Loss = 0.3390\n",
      "Iteration 7344: Weights = [5.50000000e+01 3.37604856e+00 7.09819615e+00 2.33862576e-02\n",
      " 2.36331760e-01 1.19413768e+01], Loss = 0.3390\n",
      "Iteration 7345: Weights = [5.50000000e+01 3.37595164e+00 7.09799238e+00 2.33855863e-02\n",
      " 2.36324976e-01 1.19415921e+01], Loss = 0.3390\n",
      "Iteration 7346: Weights = [5.50000000e+01 3.37585473e+00 7.09778863e+00 2.33849150e-02\n",
      " 2.36318192e-01 1.19418073e+01], Loss = 0.3389\n",
      "Iteration 7347: Weights = [5.50000000e+01 3.37575782e+00 7.09758488e+00 2.33842437e-02\n",
      " 2.36311408e-01 1.19420226e+01], Loss = 0.3389\n",
      "Iteration 7348: Weights = [5.50000000e+01 3.37566092e+00 7.09738113e+00 2.33835724e-02\n",
      " 2.36304624e-01 1.19422378e+01], Loss = 0.3389\n",
      "Iteration 7349: Weights = [5.50000000e+01 3.37556402e+00 7.09717739e+00 2.33829011e-02\n",
      " 2.36297841e-01 1.19424531e+01], Loss = 0.3389\n",
      "Iteration 7350: Weights = [5.50000000e+01 3.37546712e+00 7.09697366e+00 2.33822299e-02\n",
      " 2.36291057e-01 1.19426683e+01], Loss = 0.3389\n",
      "Iteration 7351: Weights = [5.50000000e+01 3.37537022e+00 7.09676993e+00 2.33815587e-02\n",
      " 2.36284274e-01 1.19428836e+01], Loss = 0.3388\n",
      "Iteration 7352: Weights = [5.50000000e+01 3.37527332e+00 7.09656621e+00 2.33808875e-02\n",
      " 2.36277492e-01 1.19430988e+01], Loss = 0.3388\n",
      "Iteration 7353: Weights = [5.50000000e+01 3.37517643e+00 7.09636249e+00 2.33802163e-02\n",
      " 2.36270709e-01 1.19433140e+01], Loss = 0.3388\n",
      "Iteration 7354: Weights = [5.50000000e+01 3.37507954e+00 7.09615878e+00 2.33795451e-02\n",
      " 2.36263926e-01 1.19435292e+01], Loss = 0.3388\n",
      "Iteration 7355: Weights = [5.50000000e+01 3.37498266e+00 7.09595508e+00 2.33788740e-02\n",
      " 2.36257144e-01 1.19437445e+01], Loss = 0.3388\n",
      "Iteration 7356: Weights = [5.50000000e+01 3.37488577e+00 7.09575138e+00 2.33782029e-02\n",
      " 2.36250362e-01 1.19439597e+01], Loss = 0.3387\n",
      "Iteration 7357: Weights = [5.50000000e+01 3.37478889e+00 7.09554768e+00 2.33775318e-02\n",
      " 2.36243580e-01 1.19441749e+01], Loss = 0.3387\n",
      "Iteration 7358: Weights = [5.50000000e+01 3.37469202e+00 7.09534400e+00 2.33768607e-02\n",
      " 2.36236799e-01 1.19443900e+01], Loss = 0.3387\n",
      "Iteration 7359: Weights = [5.50000000e+01 3.37459514e+00 7.09514032e+00 2.33761896e-02\n",
      " 2.36230017e-01 1.19446052e+01], Loss = 0.3387\n",
      "Iteration 7360: Weights = [5.50000000e+01 3.37449827e+00 7.09493664e+00 2.33755186e-02\n",
      " 2.36223236e-01 1.19448204e+01], Loss = 0.3387\n",
      "Iteration 7361: Weights = [5.50000000e+01 3.37440140e+00 7.09473297e+00 2.33748476e-02\n",
      " 2.36216455e-01 1.19450356e+01], Loss = 0.3386\n",
      "Iteration 7362: Weights = [5.50000000e+01 3.37430453e+00 7.09452931e+00 2.33741766e-02\n",
      " 2.36209674e-01 1.19452508e+01], Loss = 0.3386\n",
      "Iteration 7363: Weights = [5.50000000e+01 3.37420767e+00 7.09432565e+00 2.33735056e-02\n",
      " 2.36202893e-01 1.19454659e+01], Loss = 0.3386\n",
      "Iteration 7364: Weights = [5.50000000e+01 3.37411081e+00 7.09412200e+00 2.33728346e-02\n",
      " 2.36196113e-01 1.19456811e+01], Loss = 0.3386\n",
      "Iteration 7365: Weights = [5.50000000e+01 3.37401395e+00 7.09391835e+00 2.33721637e-02\n",
      " 2.36189332e-01 1.19458962e+01], Loss = 0.3386\n",
      "Iteration 7366: Weights = [5.50000000e+01 3.37391709e+00 7.09371471e+00 2.33714927e-02\n",
      " 2.36182552e-01 1.19461114e+01], Loss = 0.3385\n",
      "Iteration 7367: Weights = [5.50000000e+01 3.37382024e+00 7.09351108e+00 2.33708218e-02\n",
      " 2.36175772e-01 1.19463265e+01], Loss = 0.3385\n",
      "Iteration 7368: Weights = [5.50000000e+01 3.37372339e+00 7.09330745e+00 2.33701509e-02\n",
      " 2.36168992e-01 1.19465416e+01], Loss = 0.3385\n",
      "Iteration 7369: Weights = [5.50000000e+01 3.37362654e+00 7.09310383e+00 2.33694801e-02\n",
      " 2.36162213e-01 1.19467568e+01], Loss = 0.3385\n",
      "Iteration 7370: Weights = [5.50000000e+01 3.37352970e+00 7.09290021e+00 2.33688092e-02\n",
      " 2.36155434e-01 1.19469719e+01], Loss = 0.3385\n",
      "Iteration 7371: Weights = [5.50000000e+01 3.37343286e+00 7.09269660e+00 2.33681384e-02\n",
      " 2.36148654e-01 1.19471870e+01], Loss = 0.3384\n",
      "Iteration 7372: Weights = [5.50000000e+01 3.37333602e+00 7.09249299e+00 2.33674676e-02\n",
      " 2.36141875e-01 1.19474021e+01], Loss = 0.3384\n",
      "Iteration 7373: Weights = [5.50000000e+01 3.37323918e+00 7.09228939e+00 2.33667968e-02\n",
      " 2.36135097e-01 1.19476172e+01], Loss = 0.3384\n",
      "Iteration 7374: Weights = [5.50000000e+01 3.37314235e+00 7.09208580e+00 2.33661260e-02\n",
      " 2.36128318e-01 1.19478323e+01], Loss = 0.3384\n",
      "Iteration 7375: Weights = [5.50000000e+01 3.37304552e+00 7.09188221e+00 2.33654552e-02\n",
      " 2.36121540e-01 1.19480474e+01], Loss = 0.3384\n",
      "Iteration 7376: Weights = [5.50000000e+01 3.37294869e+00 7.09167863e+00 2.33647845e-02\n",
      " 2.36114762e-01 1.19482624e+01], Loss = 0.3383\n",
      "Iteration 7377: Weights = [5.50000000e+01 3.37285187e+00 7.09147505e+00 2.33641138e-02\n",
      " 2.36107984e-01 1.19484775e+01], Loss = 0.3383\n",
      "Iteration 7378: Weights = [5.50000000e+01 3.37275505e+00 7.09127148e+00 2.33634431e-02\n",
      " 2.36101206e-01 1.19486926e+01], Loss = 0.3383\n",
      "Iteration 7379: Weights = [5.50000000e+01 3.37265823e+00 7.09106792e+00 2.33627724e-02\n",
      " 2.36094428e-01 1.19489077e+01], Loss = 0.3383\n",
      "Iteration 7380: Weights = [5.50000000e+01 3.37256141e+00 7.09086436e+00 2.33621017e-02\n",
      " 2.36087651e-01 1.19491227e+01], Loss = 0.3383\n",
      "Iteration 7381: Weights = [5.50000000e+01 3.37246460e+00 7.09066081e+00 2.33614311e-02\n",
      " 2.36080874e-01 1.19493378e+01], Loss = 0.3383\n",
      "Iteration 7382: Weights = [5.50000000e+01 3.37236778e+00 7.09045726e+00 2.33607605e-02\n",
      " 2.36074097e-01 1.19495528e+01], Loss = 0.3382\n",
      "Iteration 7383: Weights = [5.50000000e+01 3.37227098e+00 7.09025372e+00 2.33600899e-02\n",
      " 2.36067320e-01 1.19497678e+01], Loss = 0.3382\n",
      "Iteration 7384: Weights = [5.50000000e+01 3.37217417e+00 7.09005019e+00 2.33594193e-02\n",
      " 2.36060543e-01 1.19499829e+01], Loss = 0.3382\n",
      "Iteration 7385: Weights = [5.50000000e+01 3.37207737e+00 7.08984666e+00 2.33587487e-02\n",
      " 2.36053767e-01 1.19501979e+01], Loss = 0.3382\n",
      "Iteration 7386: Weights = [5.50000000e+01 3.37198057e+00 7.08964313e+00 2.33580782e-02\n",
      " 2.36046990e-01 1.19504129e+01], Loss = 0.3382\n",
      "Iteration 7387: Weights = [5.50000000e+01 3.37188377e+00 7.08943962e+00 2.33574077e-02\n",
      " 2.36040214e-01 1.19506279e+01], Loss = 0.3381\n",
      "Iteration 7388: Weights = [5.50000000e+01 3.37178698e+00 7.08923611e+00 2.33567372e-02\n",
      " 2.36033439e-01 1.19508429e+01], Loss = 0.3381\n",
      "Iteration 7389: Weights = [5.50000000e+01 3.37169019e+00 7.08903260e+00 2.33560667e-02\n",
      " 2.36026663e-01 1.19510579e+01], Loss = 0.3381\n",
      "Iteration 7390: Weights = [5.50000000e+01 3.37159340e+00 7.08882910e+00 2.33553962e-02\n",
      " 2.36019888e-01 1.19512729e+01], Loss = 0.3381\n",
      "Iteration 7391: Weights = [5.50000000e+01 3.37149661e+00 7.08862561e+00 2.33547258e-02\n",
      " 2.36013112e-01 1.19514879e+01], Loss = 0.3381\n",
      "Iteration 7392: Weights = [5.50000000e+01 3.37139983e+00 7.08842212e+00 2.33540553e-02\n",
      " 2.36006337e-01 1.19517029e+01], Loss = 0.3380\n",
      "Iteration 7393: Weights = [5.50000000e+01 3.37130305e+00 7.08821863e+00 2.33533849e-02\n",
      " 2.35999562e-01 1.19519179e+01], Loss = 0.3380\n",
      "Iteration 7394: Weights = [5.50000000e+01 3.37120627e+00 7.08801516e+00 2.33527145e-02\n",
      " 2.35992788e-01 1.19521328e+01], Loss = 0.3380\n",
      "Iteration 7395: Weights = [5.50000000e+01 3.37110949e+00 7.08781169e+00 2.33520442e-02\n",
      " 2.35986013e-01 1.19523478e+01], Loss = 0.3380\n",
      "Iteration 7396: Weights = [5.50000000e+01 3.37101272e+00 7.08760822e+00 2.33513738e-02\n",
      " 2.35979239e-01 1.19525628e+01], Loss = 0.3380\n",
      "Iteration 7397: Weights = [5.50000000e+01 3.37091595e+00 7.08740476e+00 2.33507035e-02\n",
      " 2.35972465e-01 1.19527777e+01], Loss = 0.3379\n",
      "Iteration 7398: Weights = [5.50000000e+01 3.37081919e+00 7.08720131e+00 2.33500332e-02\n",
      " 2.35965691e-01 1.19529927e+01], Loss = 0.3379\n",
      "Iteration 7399: Weights = [5.50000000e+01 3.37072242e+00 7.08699786e+00 2.33493629e-02\n",
      " 2.35958917e-01 1.19532076e+01], Loss = 0.3379\n",
      "Iteration 7400: Weights = [5.50000000e+01 3.37062566e+00 7.08679442e+00 2.33486926e-02\n",
      " 2.35952144e-01 1.19534225e+01], Loss = 0.3379\n",
      "Iteration 7401: Weights = [5.50000000e+01 3.37052890e+00 7.08659099e+00 2.33480224e-02\n",
      " 2.35945370e-01 1.19536375e+01], Loss = 0.3379\n",
      "Iteration 7402: Weights = [5.50000000e+01 3.37043215e+00 7.08638756e+00 2.33473521e-02\n",
      " 2.35938597e-01 1.19538524e+01], Loss = 0.3378\n",
      "Iteration 7403: Weights = [5.50000000e+01 3.37033540e+00 7.08618413e+00 2.33466819e-02\n",
      " 2.35931824e-01 1.19540673e+01], Loss = 0.3378\n",
      "Iteration 7404: Weights = [5.50000000e+01 3.37023865e+00 7.08598071e+00 2.33460117e-02\n",
      " 2.35925052e-01 1.19542822e+01], Loss = 0.3378\n",
      "Iteration 7405: Weights = [5.50000000e+01 3.37014190e+00 7.08577730e+00 2.33453415e-02\n",
      " 2.35918279e-01 1.19544971e+01], Loss = 0.3378\n",
      "Iteration 7406: Weights = [5.50000000e+01 3.37004515e+00 7.08557389e+00 2.33446714e-02\n",
      " 2.35911507e-01 1.19547120e+01], Loss = 0.3378\n",
      "Iteration 7407: Weights = [5.50000000e+01 3.36994841e+00 7.08537049e+00 2.33440012e-02\n",
      " 2.35904735e-01 1.19549269e+01], Loss = 0.3377\n",
      "Iteration 7408: Weights = [5.50000000e+01 3.36985167e+00 7.08516710e+00 2.33433311e-02\n",
      " 2.35897963e-01 1.19551418e+01], Loss = 0.3377\n",
      "Iteration 7409: Weights = [5.50000000e+01 3.36975494e+00 7.08496371e+00 2.33426610e-02\n",
      " 2.35891191e-01 1.19553567e+01], Loss = 0.3377\n",
      "Iteration 7410: Weights = [5.50000000e+01 3.36965820e+00 7.08476033e+00 2.33419909e-02\n",
      " 2.35884419e-01 1.19555715e+01], Loss = 0.3377\n",
      "Iteration 7411: Weights = [5.50000000e+01 3.36956147e+00 7.08455695e+00 2.33413209e-02\n",
      " 2.35877648e-01 1.19557864e+01], Loss = 0.3377\n",
      "Iteration 7412: Weights = [5.50000000e+01 3.36946475e+00 7.08435358e+00 2.33406508e-02\n",
      " 2.35870877e-01 1.19560012e+01], Loss = 0.3376\n",
      "Iteration 7413: Weights = [5.50000000e+01 3.36936802e+00 7.08415021e+00 2.33399808e-02\n",
      " 2.35864106e-01 1.19562161e+01], Loss = 0.3376\n",
      "Iteration 7414: Weights = [5.50000000e+01 3.36927130e+00 7.08394685e+00 2.33393108e-02\n",
      " 2.35857335e-01 1.19564309e+01], Loss = 0.3376\n",
      "Iteration 7415: Weights = [5.50000000e+01 3.36917458e+00 7.08374350e+00 2.33386408e-02\n",
      " 2.35850564e-01 1.19566458e+01], Loss = 0.3376\n",
      "Iteration 7416: Weights = [5.50000000e+01 3.36907786e+00 7.08354015e+00 2.33379708e-02\n",
      " 2.35843794e-01 1.19568606e+01], Loss = 0.3376\n",
      "Iteration 7417: Weights = [5.50000000e+01 3.36898115e+00 7.08333681e+00 2.33373009e-02\n",
      " 2.35837024e-01 1.19570754e+01], Loss = 0.3376\n",
      "Iteration 7418: Weights = [5.50000000e+01 3.36888444e+00 7.08313347e+00 2.33366310e-02\n",
      " 2.35830254e-01 1.19572903e+01], Loss = 0.3375\n",
      "Iteration 7419: Weights = [5.50000000e+01 3.36878773e+00 7.08293014e+00 2.33359611e-02\n",
      " 2.35823484e-01 1.19575051e+01], Loss = 0.3375\n",
      "Iteration 7420: Weights = [5.50000000e+01 3.36869103e+00 7.08272682e+00 2.33352912e-02\n",
      " 2.35816714e-01 1.19577199e+01], Loss = 0.3375\n",
      "Iteration 7421: Weights = [5.50000000e+01 3.36859432e+00 7.08252350e+00 2.33346213e-02\n",
      " 2.35809945e-01 1.19579347e+01], Loss = 0.3375\n",
      "Iteration 7422: Weights = [5.50000000e+01 3.36849762e+00 7.08232018e+00 2.33339514e-02\n",
      " 2.35803176e-01 1.19581495e+01], Loss = 0.3375\n",
      "Iteration 7423: Weights = [5.50000000e+01 3.36840093e+00 7.08211688e+00 2.33332816e-02\n",
      " 2.35796407e-01 1.19583643e+01], Loss = 0.3374\n",
      "Iteration 7424: Weights = [5.50000000e+01 3.36830423e+00 7.08191358e+00 2.33326118e-02\n",
      " 2.35789638e-01 1.19585791e+01], Loss = 0.3374\n",
      "Iteration 7425: Weights = [5.50000000e+01 3.36820754e+00 7.08171028e+00 2.33319420e-02\n",
      " 2.35782869e-01 1.19587939e+01], Loss = 0.3374\n",
      "Iteration 7426: Weights = [5.50000000e+01 3.36811085e+00 7.08150699e+00 2.33312722e-02\n",
      " 2.35776101e-01 1.19590086e+01], Loss = 0.3374\n",
      "Iteration 7427: Weights = [5.50000000e+01 3.36801416e+00 7.08130371e+00 2.33306025e-02\n",
      " 2.35769332e-01 1.19592234e+01], Loss = 0.3374\n",
      "Iteration 7428: Weights = [5.50000000e+01 3.36791748e+00 7.08110043e+00 2.33299327e-02\n",
      " 2.35762564e-01 1.19594381e+01], Loss = 0.3373\n",
      "Iteration 7429: Weights = [5.50000000e+01 3.36782080e+00 7.08089716e+00 2.33292630e-02\n",
      " 2.35755796e-01 1.19596529e+01], Loss = 0.3373\n",
      "Iteration 7430: Weights = [5.50000000e+01 3.36772412e+00 7.08069389e+00 2.33285933e-02\n",
      " 2.35749029e-01 1.19598677e+01], Loss = 0.3373\n",
      "Iteration 7431: Weights = [5.50000000e+01 3.36762745e+00 7.08049063e+00 2.33279237e-02\n",
      " 2.35742261e-01 1.19600824e+01], Loss = 0.3373\n",
      "Iteration 7432: Weights = [5.50000000e+01 3.36753078e+00 7.08028737e+00 2.33272540e-02\n",
      " 2.35735494e-01 1.19602971e+01], Loss = 0.3373\n",
      "Iteration 7433: Weights = [5.50000000e+01 3.36743411e+00 7.08008413e+00 2.33265844e-02\n",
      " 2.35728727e-01 1.19605119e+01], Loss = 0.3372\n",
      "Iteration 7434: Weights = [5.50000000e+01 3.36733744e+00 7.07988088e+00 2.33259147e-02\n",
      " 2.35721960e-01 1.19607266e+01], Loss = 0.3372\n",
      "Iteration 7435: Weights = [5.50000000e+01 3.36724078e+00 7.07967764e+00 2.33252451e-02\n",
      " 2.35715193e-01 1.19609413e+01], Loss = 0.3372\n",
      "Iteration 7436: Weights = [5.50000000e+01 3.36714412e+00 7.07947441e+00 2.33245756e-02\n",
      " 2.35708427e-01 1.19611560e+01], Loss = 0.3372\n",
      "Iteration 7437: Weights = [5.50000000e+01 3.36704746e+00 7.07927119e+00 2.33239060e-02\n",
      " 2.35701660e-01 1.19613707e+01], Loss = 0.3372\n",
      "Iteration 7438: Weights = [5.50000000e+01 3.36695080e+00 7.07906797e+00 2.33232364e-02\n",
      " 2.35694894e-01 1.19615854e+01], Loss = 0.3371\n",
      "Iteration 7439: Weights = [5.50000000e+01 3.36685415e+00 7.07886475e+00 2.33225669e-02\n",
      " 2.35688128e-01 1.19618001e+01], Loss = 0.3371\n",
      "Iteration 7440: Weights = [5.50000000e+01 3.36675750e+00 7.07866155e+00 2.33218974e-02\n",
      " 2.35681363e-01 1.19620148e+01], Loss = 0.3371\n",
      "Iteration 7441: Weights = [5.50000000e+01 3.36666085e+00 7.07845834e+00 2.33212279e-02\n",
      " 2.35674597e-01 1.19622295e+01], Loss = 0.3371\n",
      "Iteration 7442: Weights = [5.50000000e+01 3.36656421e+00 7.07825515e+00 2.33205585e-02\n",
      " 2.35667832e-01 1.19624441e+01], Loss = 0.3371\n",
      "Iteration 7443: Weights = [5.50000000e+01 3.36646757e+00 7.07805196e+00 2.33198890e-02\n",
      " 2.35661067e-01 1.19626588e+01], Loss = 0.3370\n",
      "Iteration 7444: Weights = [5.50000000e+01 3.36637093e+00 7.07784877e+00 2.33192196e-02\n",
      " 2.35654302e-01 1.19628735e+01], Loss = 0.3370\n",
      "Iteration 7445: Weights = [5.50000000e+01 3.36627429e+00 7.07764559e+00 2.33185502e-02\n",
      " 2.35647537e-01 1.19630881e+01], Loss = 0.3370\n",
      "Iteration 7446: Weights = [5.50000000e+01 3.36617766e+00 7.07744242e+00 2.33178808e-02\n",
      " 2.35640772e-01 1.19633028e+01], Loss = 0.3370\n",
      "Iteration 7447: Weights = [5.50000000e+01 3.36608103e+00 7.07723925e+00 2.33172114e-02\n",
      " 2.35634008e-01 1.19635174e+01], Loss = 0.3370\n",
      "Iteration 7448: Weights = [5.50000000e+01 3.36598440e+00 7.07703609e+00 2.33165421e-02\n",
      " 2.35627244e-01 1.19637321e+01], Loss = 0.3370\n",
      "Iteration 7449: Weights = [5.50000000e+01 3.36588777e+00 7.07683294e+00 2.33158727e-02\n",
      " 2.35620480e-01 1.19639467e+01], Loss = 0.3369\n",
      "Iteration 7450: Weights = [5.50000000e+01 3.36579115e+00 7.07662979e+00 2.33152034e-02\n",
      " 2.35613716e-01 1.19641613e+01], Loss = 0.3369\n",
      "Iteration 7451: Weights = [5.50000000e+01 3.36569453e+00 7.07642664e+00 2.33145341e-02\n",
      " 2.35606952e-01 1.19643759e+01], Loss = 0.3369\n",
      "Iteration 7452: Weights = [5.50000000e+01 3.36559792e+00 7.07622350e+00 2.33138649e-02\n",
      " 2.35600189e-01 1.19645905e+01], Loss = 0.3369\n",
      "Iteration 7453: Weights = [5.50000000e+01 3.36550130e+00 7.07602037e+00 2.33131956e-02\n",
      " 2.35593426e-01 1.19648051e+01], Loss = 0.3369\n",
      "Iteration 7454: Weights = [5.50000000e+01 3.36540469e+00 7.07581725e+00 2.33125264e-02\n",
      " 2.35586663e-01 1.19650197e+01], Loss = 0.3368\n",
      "Iteration 7455: Weights = [5.50000000e+01 3.36530808e+00 7.07561412e+00 2.33118572e-02\n",
      " 2.35579900e-01 1.19652343e+01], Loss = 0.3368\n",
      "Iteration 7456: Weights = [5.50000000e+01 3.36521148e+00 7.07541101e+00 2.33111880e-02\n",
      " 2.35573137e-01 1.19654489e+01], Loss = 0.3368\n",
      "Iteration 7457: Weights = [5.50000000e+01 3.36511487e+00 7.07520790e+00 2.33105188e-02\n",
      " 2.35566375e-01 1.19656635e+01], Loss = 0.3368\n",
      "Iteration 7458: Weights = [5.50000000e+01 3.36501827e+00 7.07500480e+00 2.33098496e-02\n",
      " 2.35559613e-01 1.19658781e+01], Loss = 0.3368\n",
      "Iteration 7459: Weights = [5.50000000e+01 3.36492168e+00 7.07480170e+00 2.33091805e-02\n",
      " 2.35552851e-01 1.19660927e+01], Loss = 0.3367\n",
      "Iteration 7460: Weights = [5.50000000e+01 3.36482508e+00 7.07459861e+00 2.33085114e-02\n",
      " 2.35546089e-01 1.19663072e+01], Loss = 0.3367\n",
      "Iteration 7461: Weights = [5.50000000e+01 3.36472849e+00 7.07439552e+00 2.33078423e-02\n",
      " 2.35539327e-01 1.19665218e+01], Loss = 0.3367\n",
      "Iteration 7462: Weights = [5.50000000e+01 3.36463190e+00 7.07419244e+00 2.33071732e-02\n",
      " 2.35532566e-01 1.19667363e+01], Loss = 0.3367\n",
      "Iteration 7463: Weights = [5.50000000e+01 3.36453532e+00 7.07398937e+00 2.33065041e-02\n",
      " 2.35525804e-01 1.19669509e+01], Loss = 0.3367\n",
      "Iteration 7464: Weights = [5.50000000e+01 3.36443873e+00 7.07378630e+00 2.33058351e-02\n",
      " 2.35519043e-01 1.19671654e+01], Loss = 0.3366\n",
      "Iteration 7465: Weights = [5.50000000e+01 3.36434215e+00 7.07358324e+00 2.33051660e-02\n",
      " 2.35512282e-01 1.19673799e+01], Loss = 0.3366\n",
      "Iteration 7466: Weights = [5.50000000e+01 3.36424557e+00 7.07338018e+00 2.33044970e-02\n",
      " 2.35505522e-01 1.19675945e+01], Loss = 0.3366\n",
      "Iteration 7467: Weights = [5.50000000e+01 3.36414900e+00 7.07317713e+00 2.33038281e-02\n",
      " 2.35498761e-01 1.19678090e+01], Loss = 0.3366\n",
      "Iteration 7468: Weights = [5.50000000e+01 3.36405243e+00 7.07297409e+00 2.33031591e-02\n",
      " 2.35492001e-01 1.19680235e+01], Loss = 0.3366\n",
      "Iteration 7469: Weights = [5.50000000e+01 3.36395586e+00 7.07277105e+00 2.33024901e-02\n",
      " 2.35485241e-01 1.19682380e+01], Loss = 0.3365\n",
      "Iteration 7470: Weights = [5.50000000e+01 3.36385929e+00 7.07256802e+00 2.33018212e-02\n",
      " 2.35478481e-01 1.19684525e+01], Loss = 0.3365\n",
      "Iteration 7471: Weights = [5.50000000e+01 3.36376273e+00 7.07236499e+00 2.33011523e-02\n",
      " 2.35471721e-01 1.19686670e+01], Loss = 0.3365\n",
      "Iteration 7472: Weights = [5.50000000e+01 3.36366616e+00 7.07216197e+00 2.33004834e-02\n",
      " 2.35464962e-01 1.19688815e+01], Loss = 0.3365\n",
      "Iteration 7473: Weights = [5.50000000e+01 3.36356961e+00 7.07195895e+00 2.32998145e-02\n",
      " 2.35458202e-01 1.19690960e+01], Loss = 0.3365\n",
      "Iteration 7474: Weights = [5.50000000e+01 3.36347305e+00 7.07175594e+00 2.32991457e-02\n",
      " 2.35451443e-01 1.19693105e+01], Loss = 0.3364\n",
      "Iteration 7475: Weights = [5.50000000e+01 3.36337650e+00 7.07155294e+00 2.32984769e-02\n",
      " 2.35444684e-01 1.19695249e+01], Loss = 0.3364\n",
      "Iteration 7476: Weights = [5.50000000e+01 3.36327995e+00 7.07134994e+00 2.32978080e-02\n",
      " 2.35437925e-01 1.19697394e+01], Loss = 0.3364\n",
      "Iteration 7477: Weights = [5.50000000e+01 3.36318340e+00 7.07114695e+00 2.32971392e-02\n",
      " 2.35431167e-01 1.19699538e+01], Loss = 0.3364\n",
      "Iteration 7478: Weights = [5.50000000e+01 3.36308686e+00 7.07094396e+00 2.32964705e-02\n",
      " 2.35424409e-01 1.19701683e+01], Loss = 0.3364\n",
      "Iteration 7479: Weights = [5.50000000e+01 3.36299031e+00 7.07074098e+00 2.32958017e-02\n",
      " 2.35417650e-01 1.19703827e+01], Loss = 0.3364\n",
      "Iteration 7480: Weights = [5.50000000e+01 3.36289377e+00 7.07053800e+00 2.32951330e-02\n",
      " 2.35410892e-01 1.19705972e+01], Loss = 0.3363\n",
      "Iteration 7481: Weights = [5.50000000e+01 3.36279724e+00 7.07033504e+00 2.32944643e-02\n",
      " 2.35404135e-01 1.19708116e+01], Loss = 0.3363\n",
      "Iteration 7482: Weights = [5.50000000e+01 3.36270070e+00 7.07013207e+00 2.32937956e-02\n",
      " 2.35397377e-01 1.19710260e+01], Loss = 0.3363\n",
      "Iteration 7483: Weights = [5.50000000e+01 3.36260417e+00 7.06992911e+00 2.32931269e-02\n",
      " 2.35390620e-01 1.19712405e+01], Loss = 0.3363\n",
      "Iteration 7484: Weights = [5.50000000e+01 3.36250765e+00 7.06972616e+00 2.32924582e-02\n",
      " 2.35383862e-01 1.19714549e+01], Loss = 0.3363\n",
      "Iteration 7485: Weights = [5.50000000e+01 3.36241112e+00 7.06952322e+00 2.32917896e-02\n",
      " 2.35377105e-01 1.19716693e+01], Loss = 0.3362\n",
      "Iteration 7486: Weights = [5.50000000e+01 3.36231460e+00 7.06932028e+00 2.32911210e-02\n",
      " 2.35370349e-01 1.19718837e+01], Loss = 0.3362\n",
      "Iteration 7487: Weights = [5.50000000e+01 3.36221808e+00 7.06911734e+00 2.32904524e-02\n",
      " 2.35363592e-01 1.19720981e+01], Loss = 0.3362\n",
      "Iteration 7488: Weights = [5.50000000e+01 3.36212156e+00 7.06891442e+00 2.32897838e-02\n",
      " 2.35356836e-01 1.19723125e+01], Loss = 0.3362\n",
      "Iteration 7489: Weights = [5.50000000e+01 3.36202505e+00 7.06871149e+00 2.32891152e-02\n",
      " 2.35350079e-01 1.19725269e+01], Loss = 0.3362\n",
      "Iteration 7490: Weights = [5.50000000e+01 3.36192854e+00 7.06850858e+00 2.32884467e-02\n",
      " 2.35343323e-01 1.19727412e+01], Loss = 0.3361\n",
      "Iteration 7491: Weights = [5.50000000e+01 3.36183203e+00 7.06830567e+00 2.32877781e-02\n",
      " 2.35336568e-01 1.19729556e+01], Loss = 0.3361\n",
      "Iteration 7492: Weights = [5.50000000e+01 3.36173552e+00 7.06810276e+00 2.32871096e-02\n",
      " 2.35329812e-01 1.19731700e+01], Loss = 0.3361\n",
      "Iteration 7493: Weights = [5.50000000e+01 3.36163902e+00 7.06789986e+00 2.32864412e-02\n",
      " 2.35323056e-01 1.19733843e+01], Loss = 0.3361\n",
      "Iteration 7494: Weights = [5.50000000e+01 3.36154252e+00 7.06769697e+00 2.32857727e-02\n",
      " 2.35316301e-01 1.19735987e+01], Loss = 0.3361\n",
      "Iteration 7495: Weights = [5.50000000e+01 3.36144602e+00 7.06749408e+00 2.32851042e-02\n",
      " 2.35309546e-01 1.19738130e+01], Loss = 0.3360\n",
      "Iteration 7496: Weights = [5.50000000e+01 3.36134953e+00 7.06729120e+00 2.32844358e-02\n",
      " 2.35302791e-01 1.19740274e+01], Loss = 0.3360\n",
      "Iteration 7497: Weights = [5.50000000e+01 3.36125304e+00 7.06708832e+00 2.32837674e-02\n",
      " 2.35296037e-01 1.19742417e+01], Loss = 0.3360\n",
      "Iteration 7498: Weights = [5.50000000e+01 3.36115655e+00 7.06688545e+00 2.32830990e-02\n",
      " 2.35289282e-01 1.19744560e+01], Loss = 0.3360\n",
      "Iteration 7499: Weights = [5.50000000e+01 3.36106006e+00 7.06668259e+00 2.32824306e-02\n",
      " 2.35282528e-01 1.19746704e+01], Loss = 0.3360\n",
      "Iteration 7500: Weights = [5.50000000e+01 3.36096358e+00 7.06647973e+00 2.32817623e-02\n",
      " 2.35275774e-01 1.19748847e+01], Loss = 0.3359\n",
      "Iteration 7501: Weights = [5.50000000e+01 3.36086709e+00 7.06627688e+00 2.32810939e-02\n",
      " 2.35269020e-01 1.19750990e+01], Loss = 0.3359\n",
      "Iteration 7502: Weights = [5.50000000e+01 3.36077062e+00 7.06607403e+00 2.32804256e-02\n",
      " 2.35262266e-01 1.19753133e+01], Loss = 0.3359\n",
      "Iteration 7503: Weights = [5.50000000e+01 3.36067414e+00 7.06587119e+00 2.32797573e-02\n",
      " 2.35255513e-01 1.19755276e+01], Loss = 0.3359\n",
      "Iteration 7504: Weights = [5.50000000e+01 3.36057767e+00 7.06566836e+00 2.32790891e-02\n",
      " 2.35248759e-01 1.19757419e+01], Loss = 0.3359\n",
      "Iteration 7505: Weights = [5.50000000e+01 3.36048120e+00 7.06546553e+00 2.32784208e-02\n",
      " 2.35242006e-01 1.19759562e+01], Loss = 0.3359\n",
      "Iteration 7506: Weights = [5.50000000e+01 3.36038473e+00 7.06526270e+00 2.32777526e-02\n",
      " 2.35235253e-01 1.19761705e+01], Loss = 0.3358\n",
      "Iteration 7507: Weights = [5.50000000e+01 3.36028827e+00 7.06505988e+00 2.32770843e-02\n",
      " 2.35228500e-01 1.19763847e+01], Loss = 0.3358\n",
      "Iteration 7508: Weights = [5.50000000e+01 3.36019181e+00 7.06485707e+00 2.32764162e-02\n",
      " 2.35221748e-01 1.19765990e+01], Loss = 0.3358\n",
      "Iteration 7509: Weights = [5.50000000e+01 3.36009535e+00 7.06465427e+00 2.32757480e-02\n",
      " 2.35214996e-01 1.19768133e+01], Loss = 0.3358\n",
      "Iteration 7510: Weights = [5.50000000e+01 3.35999889e+00 7.06445147e+00 2.32750798e-02\n",
      " 2.35208243e-01 1.19770275e+01], Loss = 0.3358\n",
      "Iteration 7511: Weights = [5.50000000e+01 3.35990244e+00 7.06424867e+00 2.32744117e-02\n",
      " 2.35201491e-01 1.19772418e+01], Loss = 0.3357\n",
      "Iteration 7512: Weights = [5.50000000e+01 3.35980599e+00 7.06404588e+00 2.32737435e-02\n",
      " 2.35194740e-01 1.19774560e+01], Loss = 0.3357\n",
      "Iteration 7513: Weights = [5.50000000e+01 3.35970954e+00 7.06384310e+00 2.32730754e-02\n",
      " 2.35187988e-01 1.19776702e+01], Loss = 0.3357\n",
      "Iteration 7514: Weights = [5.50000000e+01 3.35961310e+00 7.06364032e+00 2.32724074e-02\n",
      " 2.35181237e-01 1.19778845e+01], Loss = 0.3357\n",
      "Iteration 7515: Weights = [5.50000000e+01 3.35951665e+00 7.06343755e+00 2.32717393e-02\n",
      " 2.35174486e-01 1.19780987e+01], Loss = 0.3357\n",
      "Iteration 7516: Weights = [5.50000000e+01 3.35942021e+00 7.06323479e+00 2.32710712e-02\n",
      " 2.35167735e-01 1.19783129e+01], Loss = 0.3356\n",
      "Iteration 7517: Weights = [5.50000000e+01 3.35932378e+00 7.06303203e+00 2.32704032e-02\n",
      " 2.35160984e-01 1.19785271e+01], Loss = 0.3356\n",
      "Iteration 7518: Weights = [5.50000000e+01 3.35922734e+00 7.06282928e+00 2.32697352e-02\n",
      " 2.35154233e-01 1.19787413e+01], Loss = 0.3356\n",
      "Iteration 7519: Weights = [5.50000000e+01 3.35913091e+00 7.06262653e+00 2.32690672e-02\n",
      " 2.35147483e-01 1.19789555e+01], Loss = 0.3356\n",
      "Iteration 7520: Weights = [5.50000000e+01 3.35903448e+00 7.06242379e+00 2.32683993e-02\n",
      " 2.35140733e-01 1.19791697e+01], Loss = 0.3356\n",
      "Iteration 7521: Weights = [5.50000000e+01 3.35893806e+00 7.06222105e+00 2.32677313e-02\n",
      " 2.35133983e-01 1.19793839e+01], Loss = 0.3355\n",
      "Iteration 7522: Weights = [5.50000000e+01 3.35884164e+00 7.06201832e+00 2.32670634e-02\n",
      " 2.35127233e-01 1.19795981e+01], Loss = 0.3355\n",
      "Iteration 7523: Weights = [5.50000000e+01 3.35874522e+00 7.06181559e+00 2.32663955e-02\n",
      " 2.35120483e-01 1.19798123e+01], Loss = 0.3355\n",
      "Iteration 7524: Weights = [5.50000000e+01 3.35864880e+00 7.06161288e+00 2.32657276e-02\n",
      " 2.35113734e-01 1.19800264e+01], Loss = 0.3355\n",
      "Iteration 7525: Weights = [5.50000000e+01 3.35855239e+00 7.06141016e+00 2.32650597e-02\n",
      " 2.35106984e-01 1.19802406e+01], Loss = 0.3355\n",
      "Iteration 7526: Weights = [5.50000000e+01 3.35845597e+00 7.06120746e+00 2.32643918e-02\n",
      " 2.35100235e-01 1.19804548e+01], Loss = 0.3354\n",
      "Iteration 7527: Weights = [5.50000000e+01 3.35835956e+00 7.06100475e+00 2.32637240e-02\n",
      " 2.35093486e-01 1.19806689e+01], Loss = 0.3354\n",
      "Iteration 7528: Weights = [5.50000000e+01 3.35826316e+00 7.06080206e+00 2.32630562e-02\n",
      " 2.35086738e-01 1.19808831e+01], Loss = 0.3354\n",
      "Iteration 7529: Weights = [5.50000000e+01 3.35816676e+00 7.06059937e+00 2.32623884e-02\n",
      " 2.35079989e-01 1.19810972e+01], Loss = 0.3354\n",
      "Iteration 7530: Weights = [5.50000000e+01 3.35807035e+00 7.06039669e+00 2.32617206e-02\n",
      " 2.35073241e-01 1.19813113e+01], Loss = 0.3354\n",
      "Iteration 7531: Weights = [5.50000000e+01 3.35797396e+00 7.06019401e+00 2.32610529e-02\n",
      " 2.35066493e-01 1.19815254e+01], Loss = 0.3354\n",
      "Iteration 7532: Weights = [5.50000000e+01 3.35787756e+00 7.05999134e+00 2.32603851e-02\n",
      " 2.35059745e-01 1.19817396e+01], Loss = 0.3353\n",
      "Iteration 7533: Weights = [5.50000000e+01 3.35778117e+00 7.05978867e+00 2.32597174e-02\n",
      " 2.35052997e-01 1.19819537e+01], Loss = 0.3353\n",
      "Iteration 7534: Weights = [5.50000000e+01 3.35768478e+00 7.05958601e+00 2.32590497e-02\n",
      " 2.35046250e-01 1.19821678e+01], Loss = 0.3353\n",
      "Iteration 7535: Weights = [5.50000000e+01 3.35758839e+00 7.05938335e+00 2.32583820e-02\n",
      " 2.35039503e-01 1.19823819e+01], Loss = 0.3353\n",
      "Iteration 7536: Weights = [5.50000000e+01 3.35749201e+00 7.05918071e+00 2.32577144e-02\n",
      " 2.35032755e-01 1.19825960e+01], Loss = 0.3353\n",
      "Iteration 7537: Weights = [5.50000000e+01 3.35739563e+00 7.05897806e+00 2.32570467e-02\n",
      " 2.35026009e-01 1.19828101e+01], Loss = 0.3352\n",
      "Iteration 7538: Weights = [5.50000000e+01 3.35729925e+00 7.05877543e+00 2.32563791e-02\n",
      " 2.35019262e-01 1.19830242e+01], Loss = 0.3352\n",
      "Iteration 7539: Weights = [5.50000000e+01 3.35720287e+00 7.05857279e+00 2.32557115e-02\n",
      " 2.35012515e-01 1.19832382e+01], Loss = 0.3352\n",
      "Iteration 7540: Weights = [5.50000000e+01 3.35710650e+00 7.05837017e+00 2.32550439e-02\n",
      " 2.35005769e-01 1.19834523e+01], Loss = 0.3352\n",
      "Iteration 7541: Weights = [5.50000000e+01 3.35701013e+00 7.05816755e+00 2.32543763e-02\n",
      " 2.34999023e-01 1.19836664e+01], Loss = 0.3352\n",
      "Iteration 7542: Weights = [5.50000000e+01 3.35691376e+00 7.05796494e+00 2.32537088e-02\n",
      " 2.34992277e-01 1.19838804e+01], Loss = 0.3351\n",
      "Iteration 7543: Weights = [5.50000000e+01 3.35681740e+00 7.05776233e+00 2.32530413e-02\n",
      " 2.34985531e-01 1.19840945e+01], Loss = 0.3351\n",
      "Iteration 7544: Weights = [5.50000000e+01 3.35672104e+00 7.05755972e+00 2.32523738e-02\n",
      " 2.34978785e-01 1.19843085e+01], Loss = 0.3351\n",
      "Iteration 7545: Weights = [5.50000000e+01 3.35662468e+00 7.05735713e+00 2.32517063e-02\n",
      " 2.34972040e-01 1.19845226e+01], Loss = 0.3351\n",
      "Iteration 7546: Weights = [5.50000000e+01 3.35652832e+00 7.05715454e+00 2.32510388e-02\n",
      " 2.34965295e-01 1.19847366e+01], Loss = 0.3351\n",
      "Iteration 7547: Weights = [5.50000000e+01 3.35643197e+00 7.05695195e+00 2.32503713e-02\n",
      " 2.34958550e-01 1.19849506e+01], Loss = 0.3350\n",
      "Iteration 7548: Weights = [5.50000000e+01 3.35633562e+00 7.05674937e+00 2.32497039e-02\n",
      " 2.34951805e-01 1.19851646e+01], Loss = 0.3350\n",
      "Iteration 7549: Weights = [5.50000000e+01 3.35623927e+00 7.05654680e+00 2.32490365e-02\n",
      " 2.34945061e-01 1.19853787e+01], Loss = 0.3350\n",
      "Iteration 7550: Weights = [5.50000000e+01 3.35614292e+00 7.05634423e+00 2.32483691e-02\n",
      " 2.34938316e-01 1.19855927e+01], Loss = 0.3350\n",
      "Iteration 7551: Weights = [5.50000000e+01 3.35604658e+00 7.05614167e+00 2.32477017e-02\n",
      " 2.34931572e-01 1.19858067e+01], Loss = 0.3350\n",
      "Iteration 7552: Weights = [5.50000000e+01 3.35595024e+00 7.05593912e+00 2.32470344e-02\n",
      " 2.34924828e-01 1.19860207e+01], Loss = 0.3349\n",
      "Iteration 7553: Weights = [5.50000000e+01 3.35585390e+00 7.05573657e+00 2.32463670e-02\n",
      " 2.34918084e-01 1.19862347e+01], Loss = 0.3349\n",
      "Iteration 7554: Weights = [5.50000000e+01 3.35575757e+00 7.05553402e+00 2.32456997e-02\n",
      " 2.34911340e-01 1.19864486e+01], Loss = 0.3349\n",
      "Iteration 7555: Weights = [5.50000000e+01 3.35566124e+00 7.05533148e+00 2.32450324e-02\n",
      " 2.34904597e-01 1.19866626e+01], Loss = 0.3349\n",
      "Iteration 7556: Weights = [5.50000000e+01 3.35556491e+00 7.05512895e+00 2.32443651e-02\n",
      " 2.34897854e-01 1.19868766e+01], Loss = 0.3349\n",
      "Iteration 7557: Weights = [5.50000000e+01 3.35546858e+00 7.05492642e+00 2.32436979e-02\n",
      " 2.34891111e-01 1.19870906e+01], Loss = 0.3349\n",
      "Iteration 7558: Weights = [5.50000000e+01 3.35537226e+00 7.05472390e+00 2.32430306e-02\n",
      " 2.34884368e-01 1.19873045e+01], Loss = 0.3348\n",
      "Iteration 7559: Weights = [5.50000000e+01 3.35527594e+00 7.05452139e+00 2.32423634e-02\n",
      " 2.34877625e-01 1.19875185e+01], Loss = 0.3348\n",
      "Iteration 7560: Weights = [5.50000000e+01 3.35517962e+00 7.05431888e+00 2.32416962e-02\n",
      " 2.34870883e-01 1.19877324e+01], Loss = 0.3348\n",
      "Iteration 7561: Weights = [5.50000000e+01 3.35508331e+00 7.05411638e+00 2.32410290e-02\n",
      " 2.34864140e-01 1.19879464e+01], Loss = 0.3348\n",
      "Iteration 7562: Weights = [5.50000000e+01 3.35498700e+00 7.05391388e+00 2.32403619e-02\n",
      " 2.34857398e-01 1.19881603e+01], Loss = 0.3348\n",
      "Iteration 7563: Weights = [5.50000000e+01 3.35489069e+00 7.05371139e+00 2.32396947e-02\n",
      " 2.34850656e-01 1.19883742e+01], Loss = 0.3347\n",
      "Iteration 7564: Weights = [5.50000000e+01 3.35479438e+00 7.05350890e+00 2.32390276e-02\n",
      " 2.34843915e-01 1.19885882e+01], Loss = 0.3347\n",
      "Iteration 7565: Weights = [5.50000000e+01 3.35469808e+00 7.05330642e+00 2.32383605e-02\n",
      " 2.34837173e-01 1.19888021e+01], Loss = 0.3347\n",
      "Iteration 7566: Weights = [5.50000000e+01 3.35460178e+00 7.05310395e+00 2.32376934e-02\n",
      " 2.34830432e-01 1.19890160e+01], Loss = 0.3347\n",
      "Iteration 7567: Weights = [5.50000000e+01 3.35450548e+00 7.05290148e+00 2.32370263e-02\n",
      " 2.34823691e-01 1.19892299e+01], Loss = 0.3347\n",
      "Iteration 7568: Weights = [5.50000000e+01 3.35440918e+00 7.05269901e+00 2.32363593e-02\n",
      " 2.34816950e-01 1.19894438e+01], Loss = 0.3346\n",
      "Iteration 7569: Weights = [5.50000000e+01 3.35431289e+00 7.05249656e+00 2.32356923e-02\n",
      " 2.34810209e-01 1.19896577e+01], Loss = 0.3346\n",
      "Iteration 7570: Weights = [5.50000000e+01 3.35421660e+00 7.05229411e+00 2.32350252e-02\n",
      " 2.34803469e-01 1.19898716e+01], Loss = 0.3346\n",
      "Iteration 7571: Weights = [5.50000000e+01 3.35412031e+00 7.05209166e+00 2.32343582e-02\n",
      " 2.34796728e-01 1.19900854e+01], Loss = 0.3346\n",
      "Iteration 7572: Weights = [5.50000000e+01 3.35402403e+00 7.05188922e+00 2.32336913e-02\n",
      " 2.34789988e-01 1.19902993e+01], Loss = 0.3346\n",
      "Iteration 7573: Weights = [5.50000000e+01 3.35392775e+00 7.05168679e+00 2.32330243e-02\n",
      " 2.34783248e-01 1.19905132e+01], Loss = 0.3345\n",
      "Iteration 7574: Weights = [5.50000000e+01 3.35383147e+00 7.05148436e+00 2.32323574e-02\n",
      " 2.34776508e-01 1.19907271e+01], Loss = 0.3345\n",
      "Iteration 7575: Weights = [5.50000000e+01 3.35373519e+00 7.05128194e+00 2.32316905e-02\n",
      " 2.34769769e-01 1.19909409e+01], Loss = 0.3345\n",
      "Iteration 7576: Weights = [5.50000000e+01 3.35363892e+00 7.05107952e+00 2.32310236e-02\n",
      " 2.34763030e-01 1.19911548e+01], Loss = 0.3345\n",
      "Iteration 7577: Weights = [5.50000000e+01 3.35354265e+00 7.05087711e+00 2.32303567e-02\n",
      " 2.34756290e-01 1.19913686e+01], Loss = 0.3345\n",
      "Iteration 7578: Weights = [5.50000000e+01 3.35344638e+00 7.05067471e+00 2.32296898e-02\n",
      " 2.34749551e-01 1.19915824e+01], Loss = 0.3344\n",
      "Iteration 7579: Weights = [5.50000000e+01 3.35335011e+00 7.05047231e+00 2.32290230e-02\n",
      " 2.34742813e-01 1.19917963e+01], Loss = 0.3344\n",
      "Iteration 7580: Weights = [5.50000000e+01 3.35325385e+00 7.05026991e+00 2.32283562e-02\n",
      " 2.34736074e-01 1.19920101e+01], Loss = 0.3344\n",
      "Iteration 7581: Weights = [5.50000000e+01 3.35315759e+00 7.05006753e+00 2.32276894e-02\n",
      " 2.34729336e-01 1.19922239e+01], Loss = 0.3344\n",
      "Iteration 7582: Weights = [5.50000000e+01 3.35306134e+00 7.04986515e+00 2.32270226e-02\n",
      " 2.34722597e-01 1.19924377e+01], Loss = 0.3344\n",
      "Iteration 7583: Weights = [5.50000000e+01 3.35296508e+00 7.04966277e+00 2.32263558e-02\n",
      " 2.34715859e-01 1.19926515e+01], Loss = 0.3344\n",
      "Iteration 7584: Weights = [5.50000000e+01 3.35286883e+00 7.04946040e+00 2.32256891e-02\n",
      " 2.34709122e-01 1.19928653e+01], Loss = 0.3343\n",
      "Iteration 7585: Weights = [5.50000000e+01 3.35277258e+00 7.04925804e+00 2.32250224e-02\n",
      " 2.34702384e-01 1.19930791e+01], Loss = 0.3343\n",
      "Iteration 7586: Weights = [5.50000000e+01 3.35267634e+00 7.04905568e+00 2.32243557e-02\n",
      " 2.34695646e-01 1.19932929e+01], Loss = 0.3343\n",
      "Iteration 7587: Weights = [5.50000000e+01 3.35258009e+00 7.04885333e+00 2.32236890e-02\n",
      " 2.34688909e-01 1.19935067e+01], Loss = 0.3343\n",
      "Iteration 7588: Weights = [5.50000000e+01 3.35248385e+00 7.04865098e+00 2.32230223e-02\n",
      " 2.34682172e-01 1.19937205e+01], Loss = 0.3343\n",
      "Iteration 7589: Weights = [5.50000000e+01 3.35238762e+00 7.04844864e+00 2.32223557e-02\n",
      " 2.34675435e-01 1.19939342e+01], Loss = 0.3342\n",
      "Iteration 7590: Weights = [5.50000000e+01 3.35229138e+00 7.04824630e+00 2.32216890e-02\n",
      " 2.34668699e-01 1.19941480e+01], Loss = 0.3342\n",
      "Iteration 7591: Weights = [5.50000000e+01 3.35219515e+00 7.04804397e+00 2.32210224e-02\n",
      " 2.34661962e-01 1.19943618e+01], Loss = 0.3342\n",
      "Iteration 7592: Weights = [5.50000000e+01 3.35209892e+00 7.04784165e+00 2.32203558e-02\n",
      " 2.34655226e-01 1.19945755e+01], Loss = 0.3342\n",
      "Iteration 7593: Weights = [5.50000000e+01 3.35200269e+00 7.04763933e+00 2.32196893e-02\n",
      " 2.34648490e-01 1.19947893e+01], Loss = 0.3342\n",
      "Iteration 7594: Weights = [5.50000000e+01 3.35190647e+00 7.04743702e+00 2.32190227e-02\n",
      " 2.34641754e-01 1.19950030e+01], Loss = 0.3341\n",
      "Iteration 7595: Weights = [5.50000000e+01 3.35181025e+00 7.04723472e+00 2.32183562e-02\n",
      " 2.34635018e-01 1.19952167e+01], Loss = 0.3341\n",
      "Iteration 7596: Weights = [5.50000000e+01 3.35171403e+00 7.04703242e+00 2.32176897e-02\n",
      " 2.34628283e-01 1.19954305e+01], Loss = 0.3341\n",
      "Iteration 7597: Weights = [5.50000000e+01 3.35161782e+00 7.04683012e+00 2.32170232e-02\n",
      " 2.34621547e-01 1.19956442e+01], Loss = 0.3341\n",
      "Iteration 7598: Weights = [5.50000000e+01 3.35152160e+00 7.04662783e+00 2.32163567e-02\n",
      " 2.34614812e-01 1.19958579e+01], Loss = 0.3341\n",
      "Iteration 7599: Weights = [5.50000000e+01 3.35142539e+00 7.04642555e+00 2.32156902e-02\n",
      " 2.34608077e-01 1.19960716e+01], Loss = 0.3340\n",
      "Iteration 7600: Weights = [5.50000000e+01 3.35132919e+00 7.04622327e+00 2.32150238e-02\n",
      " 2.34601343e-01 1.19962853e+01], Loss = 0.3340\n",
      "Iteration 7601: Weights = [5.50000000e+01 3.35123298e+00 7.04602100e+00 2.32143574e-02\n",
      " 2.34594608e-01 1.19964990e+01], Loss = 0.3340\n",
      "Iteration 7602: Weights = [5.50000000e+01 3.35113678e+00 7.04581874e+00 2.32136910e-02\n",
      " 2.34587874e-01 1.19967127e+01], Loss = 0.3340\n",
      "Iteration 7603: Weights = [5.50000000e+01 3.35104058e+00 7.04561648e+00 2.32130246e-02\n",
      " 2.34581140e-01 1.19969264e+01], Loss = 0.3340\n",
      "Iteration 7604: Weights = [5.50000000e+01 3.35094439e+00 7.04541422e+00 2.32123583e-02\n",
      " 2.34574406e-01 1.19971401e+01], Loss = 0.3339\n",
      "Iteration 7605: Weights = [5.50000000e+01 3.35084819e+00 7.04521198e+00 2.32116919e-02\n",
      " 2.34567672e-01 1.19973537e+01], Loss = 0.3339\n",
      "Iteration 7606: Weights = [5.50000000e+01 3.35075200e+00 7.04500973e+00 2.32110256e-02\n",
      " 2.34560938e-01 1.19975674e+01], Loss = 0.3339\n",
      "Iteration 7607: Weights = [5.50000000e+01 3.35065581e+00 7.04480750e+00 2.32103593e-02\n",
      " 2.34554205e-01 1.19977811e+01], Loss = 0.3339\n",
      "Iteration 7608: Weights = [5.50000000e+01 3.35055963e+00 7.04460527e+00 2.32096930e-02\n",
      " 2.34547472e-01 1.19979947e+01], Loss = 0.3339\n",
      "Iteration 7609: Weights = [5.50000000e+01 3.35046345e+00 7.04440304e+00 2.32090267e-02\n",
      " 2.34540739e-01 1.19982084e+01], Loss = 0.3339\n",
      "Iteration 7610: Weights = [5.50000000e+01 3.35036727e+00 7.04420082e+00 2.32083605e-02\n",
      " 2.34534006e-01 1.19984220e+01], Loss = 0.3338\n",
      "Iteration 7611: Weights = [5.50000000e+01 3.35027109e+00 7.04399861e+00 2.32076943e-02\n",
      " 2.34527273e-01 1.19986356e+01], Loss = 0.3338\n",
      "Iteration 7612: Weights = [5.50000000e+01 3.35017492e+00 7.04379640e+00 2.32070281e-02\n",
      " 2.34520541e-01 1.19988493e+01], Loss = 0.3338\n",
      "Iteration 7613: Weights = [5.50000000e+01 3.35007875e+00 7.04359420e+00 2.32063619e-02\n",
      " 2.34513809e-01 1.19990629e+01], Loss = 0.3338\n",
      "Iteration 7614: Weights = [5.50000000e+01 3.34998258e+00 7.04339201e+00 2.32056957e-02\n",
      " 2.34507077e-01 1.19992765e+01], Loss = 0.3338\n",
      "Iteration 7615: Weights = [5.50000000e+01 3.34988641e+00 7.04318982e+00 2.32050296e-02\n",
      " 2.34500345e-01 1.19994901e+01], Loss = 0.3337\n",
      "Iteration 7616: Weights = [5.50000000e+01 3.34979025e+00 7.04298763e+00 2.32043634e-02\n",
      " 2.34493613e-01 1.19997037e+01], Loss = 0.3337\n",
      "Iteration 7617: Weights = [5.50000000e+01 3.34969409e+00 7.04278545e+00 2.32036973e-02\n",
      " 2.34486882e-01 1.19999173e+01], Loss = 0.3337\n",
      "Iteration 7618: Weights = [5.50000000e+01 3.34959793e+00 7.04258328e+00 2.32030312e-02\n",
      " 2.34480150e-01 1.20001309e+01], Loss = 0.3337\n",
      "Iteration 7619: Weights = [5.50000000e+01 3.34950178e+00 7.04238112e+00 2.32023651e-02\n",
      " 2.34473419e-01 1.20003445e+01], Loss = 0.3337\n",
      "Iteration 7620: Weights = [5.50000000e+01 3.34940563e+00 7.04217895e+00 2.32016991e-02\n",
      " 2.34466689e-01 1.20005581e+01], Loss = 0.3336\n",
      "Iteration 7621: Weights = [5.50000000e+01 3.34930948e+00 7.04197680e+00 2.32010331e-02\n",
      " 2.34459958e-01 1.20007716e+01], Loss = 0.3336\n",
      "Iteration 7622: Weights = [5.50000000e+01 3.34921333e+00 7.04177465e+00 2.32003670e-02\n",
      " 2.34453227e-01 1.20009852e+01], Loss = 0.3336\n",
      "Iteration 7623: Weights = [5.50000000e+01 3.34911719e+00 7.04157251e+00 2.31997010e-02\n",
      " 2.34446497e-01 1.20011988e+01], Loss = 0.3336\n",
      "Iteration 7624: Weights = [5.50000000e+01 3.34902105e+00 7.04137037e+00 2.31990351e-02\n",
      " 2.34439767e-01 1.20014123e+01], Loss = 0.3336\n",
      "Iteration 7625: Weights = [5.50000000e+01 3.34892491e+00 7.04116824e+00 2.31983691e-02\n",
      " 2.34433037e-01 1.20016259e+01], Loss = 0.3335\n",
      "Iteration 7626: Weights = [5.50000000e+01 3.34882877e+00 7.04096611e+00 2.31977032e-02\n",
      " 2.34426307e-01 1.20018394e+01], Loss = 0.3335\n",
      "Iteration 7627: Weights = [5.50000000e+01 3.34873264e+00 7.04076399e+00 2.31970372e-02\n",
      " 2.34419578e-01 1.20020529e+01], Loss = 0.3335\n",
      "Iteration 7628: Weights = [5.50000000e+01 3.34863651e+00 7.04056188e+00 2.31963713e-02\n",
      " 2.34412849e-01 1.20022665e+01], Loss = 0.3335\n",
      "Iteration 7629: Weights = [5.50000000e+01 3.34854038e+00 7.04035977e+00 2.31957055e-02\n",
      " 2.34406119e-01 1.20024800e+01], Loss = 0.3335\n",
      "Iteration 7630: Weights = [5.50000000e+01 3.34844426e+00 7.04015767e+00 2.31950396e-02\n",
      " 2.34399391e-01 1.20026935e+01], Loss = 0.3334\n",
      "Iteration 7631: Weights = [5.50000000e+01 3.34834814e+00 7.03995557e+00 2.31943738e-02\n",
      " 2.34392662e-01 1.20029070e+01], Loss = 0.3334\n",
      "Iteration 7632: Weights = [5.50000000e+01 3.34825202e+00 7.03975348e+00 2.31937079e-02\n",
      " 2.34385933e-01 1.20031205e+01], Loss = 0.3334\n",
      "Iteration 7633: Weights = [5.50000000e+01 3.34815590e+00 7.03955139e+00 2.31930421e-02\n",
      " 2.34379205e-01 1.20033340e+01], Loss = 0.3334\n",
      "Iteration 7634: Weights = [5.50000000e+01 3.34805979e+00 7.03934931e+00 2.31923763e-02\n",
      " 2.34372477e-01 1.20035475e+01], Loss = 0.3334\n",
      "Iteration 7635: Weights = [5.50000000e+01 3.34796368e+00 7.03914724e+00 2.31917106e-02\n",
      " 2.34365749e-01 1.20037610e+01], Loss = 0.3334\n",
      "Iteration 7636: Weights = [5.50000000e+01 3.34786757e+00 7.03894517e+00 2.31910448e-02\n",
      " 2.34359021e-01 1.20039745e+01], Loss = 0.3333\n",
      "Iteration 7637: Weights = [5.50000000e+01 3.34777147e+00 7.03874311e+00 2.31903791e-02\n",
      " 2.34352293e-01 1.20041880e+01], Loss = 0.3333\n",
      "Iteration 7638: Weights = [5.50000000e+01 3.34767536e+00 7.03854105e+00 2.31897134e-02\n",
      " 2.34345566e-01 1.20044014e+01], Loss = 0.3333\n",
      "Iteration 7639: Weights = [5.50000000e+01 3.34757926e+00 7.03833900e+00 2.31890477e-02\n",
      " 2.34338839e-01 1.20046149e+01], Loss = 0.3333\n",
      "Iteration 7640: Weights = [5.50000000e+01 3.34748317e+00 7.03813696e+00 2.31883820e-02\n",
      " 2.34332112e-01 1.20048284e+01], Loss = 0.3333\n",
      "Iteration 7641: Weights = [5.50000000e+01 3.34738707e+00 7.03793492e+00 2.31877164e-02\n",
      " 2.34325385e-01 1.20050418e+01], Loss = 0.3332\n",
      "Iteration 7642: Weights = [5.50000000e+01 3.34729098e+00 7.03773289e+00 2.31870507e-02\n",
      " 2.34318658e-01 1.20052553e+01], Loss = 0.3332\n",
      "Iteration 7643: Weights = [5.50000000e+01 3.34719489e+00 7.03753086e+00 2.31863851e-02\n",
      " 2.34311932e-01 1.20054687e+01], Loss = 0.3332\n",
      "Iteration 7644: Weights = [5.50000000e+01 3.34709881e+00 7.03732884e+00 2.31857195e-02\n",
      " 2.34305206e-01 1.20056821e+01], Loss = 0.3332\n",
      "Iteration 7645: Weights = [5.50000000e+01 3.34700273e+00 7.03712682e+00 2.31850540e-02\n",
      " 2.34298480e-01 1.20058956e+01], Loss = 0.3332\n",
      "Iteration 7646: Weights = [5.50000000e+01 3.34690665e+00 7.03692481e+00 2.31843884e-02\n",
      " 2.34291754e-01 1.20061090e+01], Loss = 0.3331\n",
      "Iteration 7647: Weights = [5.50000000e+01 3.34681057e+00 7.03672281e+00 2.31837229e-02\n",
      " 2.34285028e-01 1.20063224e+01], Loss = 0.3331\n",
      "Iteration 7648: Weights = [5.50000000e+01 3.34671449e+00 7.03652081e+00 2.31830573e-02\n",
      " 2.34278303e-01 1.20065358e+01], Loss = 0.3331\n",
      "Iteration 7649: Weights = [5.50000000e+01 3.34661842e+00 7.03631882e+00 2.31823918e-02\n",
      " 2.34271577e-01 1.20067492e+01], Loss = 0.3331\n",
      "Iteration 7650: Weights = [5.50000000e+01 3.34652235e+00 7.03611683e+00 2.31817264e-02\n",
      " 2.34264852e-01 1.20069626e+01], Loss = 0.3331\n",
      "Iteration 7651: Weights = [5.50000000e+01 3.34642629e+00 7.03591485e+00 2.31810609e-02\n",
      " 2.34258127e-01 1.20071760e+01], Loss = 0.3330\n",
      "Iteration 7652: Weights = [5.50000000e+01 3.34633022e+00 7.03571287e+00 2.31803955e-02\n",
      " 2.34251403e-01 1.20073894e+01], Loss = 0.3330\n",
      "Iteration 7653: Weights = [5.50000000e+01 3.34623416e+00 7.03551090e+00 2.31797300e-02\n",
      " 2.34244678e-01 1.20076028e+01], Loss = 0.3330\n",
      "Iteration 7654: Weights = [5.50000000e+01 3.34613810e+00 7.03530894e+00 2.31790646e-02\n",
      " 2.34237954e-01 1.20078161e+01], Loss = 0.3330\n",
      "Iteration 7655: Weights = [5.50000000e+01 3.34604205e+00 7.03510698e+00 2.31783992e-02\n",
      " 2.34231230e-01 1.20080295e+01], Loss = 0.3330\n",
      "Iteration 7656: Weights = [5.50000000e+01 3.34594600e+00 7.03490503e+00 2.31777339e-02\n",
      " 2.34224506e-01 1.20082428e+01], Loss = 0.3330\n",
      "Iteration 7657: Weights = [5.50000000e+01 3.34584995e+00 7.03470308e+00 2.31770685e-02\n",
      " 2.34217782e-01 1.20084562e+01], Loss = 0.3329\n",
      "Iteration 7658: Weights = [5.50000000e+01 3.34575390e+00 7.03450114e+00 2.31764032e-02\n",
      " 2.34211059e-01 1.20086695e+01], Loss = 0.3329\n",
      "Iteration 7659: Weights = [5.50000000e+01 3.34565786e+00 7.03429921e+00 2.31757379e-02\n",
      " 2.34204335e-01 1.20088829e+01], Loss = 0.3329\n",
      "Iteration 7660: Weights = [5.50000000e+01 3.34556181e+00 7.03409728e+00 2.31750726e-02\n",
      " 2.34197612e-01 1.20090962e+01], Loss = 0.3329\n",
      "Iteration 7661: Weights = [5.50000000e+01 3.34546578e+00 7.03389536e+00 2.31744073e-02\n",
      " 2.34190889e-01 1.20093096e+01], Loss = 0.3329\n",
      "Iteration 7662: Weights = [5.50000000e+01 3.34536974e+00 7.03369344e+00 2.31737421e-02\n",
      " 2.34184167e-01 1.20095229e+01], Loss = 0.3328\n",
      "Iteration 7663: Weights = [5.50000000e+01 3.34527371e+00 7.03349153e+00 2.31730768e-02\n",
      " 2.34177444e-01 1.20097362e+01], Loss = 0.3328\n",
      "Iteration 7664: Weights = [5.50000000e+01 3.34517768e+00 7.03328962e+00 2.31724116e-02\n",
      " 2.34170722e-01 1.20099495e+01], Loss = 0.3328\n",
      "Iteration 7665: Weights = [5.50000000e+01 3.34508165e+00 7.03308772e+00 2.31717464e-02\n",
      " 2.34163999e-01 1.20101628e+01], Loss = 0.3328\n",
      "Iteration 7666: Weights = [5.50000000e+01 3.34498562e+00 7.03288583e+00 2.31710813e-02\n",
      " 2.34157277e-01 1.20103761e+01], Loss = 0.3328\n",
      "Iteration 7667: Weights = [5.50000000e+01 3.34488960e+00 7.03268394e+00 2.31704161e-02\n",
      " 2.34150556e-01 1.20105894e+01], Loss = 0.3327\n",
      "Iteration 7668: Weights = [5.50000000e+01 3.34479358e+00 7.03248206e+00 2.31697510e-02\n",
      " 2.34143834e-01 1.20108027e+01], Loss = 0.3327\n",
      "Iteration 7669: Weights = [5.50000000e+01 3.34469757e+00 7.03228018e+00 2.31690858e-02\n",
      " 2.34137113e-01 1.20110160e+01], Loss = 0.3327\n",
      "Iteration 7670: Weights = [5.50000000e+01 3.34460155e+00 7.03207831e+00 2.31684207e-02\n",
      " 2.34130391e-01 1.20112292e+01], Loss = 0.3327\n",
      "Iteration 7671: Weights = [5.50000000e+01 3.34450554e+00 7.03187645e+00 2.31677557e-02\n",
      " 2.34123670e-01 1.20114425e+01], Loss = 0.3327\n",
      "Iteration 7672: Weights = [5.50000000e+01 3.34440953e+00 7.03167459e+00 2.31670906e-02\n",
      " 2.34116950e-01 1.20116558e+01], Loss = 0.3326\n",
      "Iteration 7673: Weights = [5.50000000e+01 3.34431353e+00 7.03147273e+00 2.31664256e-02\n",
      " 2.34110229e-01 1.20118690e+01], Loss = 0.3326\n",
      "Iteration 7674: Weights = [5.50000000e+01 3.34421752e+00 7.03127089e+00 2.31657605e-02\n",
      " 2.34103509e-01 1.20120823e+01], Loss = 0.3326\n",
      "Iteration 7675: Weights = [5.50000000e+01 3.34412152e+00 7.03106904e+00 2.31650955e-02\n",
      " 2.34096788e-01 1.20122955e+01], Loss = 0.3326\n",
      "Iteration 7676: Weights = [5.50000000e+01 3.34402553e+00 7.03086721e+00 2.31644306e-02\n",
      " 2.34090068e-01 1.20125087e+01], Loss = 0.3326\n",
      "Iteration 7677: Weights = [5.50000000e+01 3.34392953e+00 7.03066538e+00 2.31637656e-02\n",
      " 2.34083348e-01 1.20127220e+01], Loss = 0.3326\n",
      "Iteration 7678: Weights = [5.50000000e+01 3.34383354e+00 7.03046355e+00 2.31631006e-02\n",
      " 2.34076629e-01 1.20129352e+01], Loss = 0.3325\n",
      "Iteration 7679: Weights = [5.50000000e+01 3.34373755e+00 7.03026174e+00 2.31624357e-02\n",
      " 2.34069909e-01 1.20131484e+01], Loss = 0.3325\n",
      "Iteration 7680: Weights = [5.50000000e+01 3.34364156e+00 7.03005992e+00 2.31617708e-02\n",
      " 2.34063190e-01 1.20133616e+01], Loss = 0.3325\n",
      "Iteration 7681: Weights = [5.50000000e+01 3.34354558e+00 7.02985812e+00 2.31611059e-02\n",
      " 2.34056471e-01 1.20135748e+01], Loss = 0.3325\n",
      "Iteration 7682: Weights = [5.50000000e+01 3.34344960e+00 7.02965631e+00 2.31604410e-02\n",
      " 2.34049752e-01 1.20137880e+01], Loss = 0.3325\n",
      "Iteration 7683: Weights = [5.50000000e+01 3.34335362e+00 7.02945452e+00 2.31597762e-02\n",
      " 2.34043033e-01 1.20140012e+01], Loss = 0.3324\n",
      "Iteration 7684: Weights = [5.50000000e+01 3.34325765e+00 7.02925273e+00 2.31591114e-02\n",
      " 2.34036315e-01 1.20142144e+01], Loss = 0.3324\n",
      "Iteration 7685: Weights = [5.50000000e+01 3.34316167e+00 7.02905095e+00 2.31584466e-02\n",
      " 2.34029596e-01 1.20144276e+01], Loss = 0.3324\n",
      "Iteration 7686: Weights = [5.50000000e+01 3.34306570e+00 7.02884917e+00 2.31577818e-02\n",
      " 2.34022878e-01 1.20146408e+01], Loss = 0.3324\n",
      "Iteration 7687: Weights = [5.50000000e+01 3.34296974e+00 7.02864739e+00 2.31571170e-02\n",
      " 2.34016160e-01 1.20148539e+01], Loss = 0.3324\n",
      "Iteration 7688: Weights = [5.50000000e+01 3.34287377e+00 7.02844563e+00 2.31564522e-02\n",
      " 2.34009443e-01 1.20150671e+01], Loss = 0.3323\n",
      "Iteration 7689: Weights = [5.50000000e+01 3.34277781e+00 7.02824387e+00 2.31557875e-02\n",
      " 2.34002725e-01 1.20152803e+01], Loss = 0.3323\n",
      "Iteration 7690: Weights = [5.50000000e+01 3.34268185e+00 7.02804211e+00 2.31551228e-02\n",
      " 2.33996008e-01 1.20154934e+01], Loss = 0.3323\n",
      "Iteration 7691: Weights = [5.50000000e+01 3.34258590e+00 7.02784036e+00 2.31544581e-02\n",
      " 2.33989291e-01 1.20157066e+01], Loss = 0.3323\n",
      "Iteration 7692: Weights = [5.50000000e+01 3.34248994e+00 7.02763862e+00 2.31537934e-02\n",
      " 2.33982574e-01 1.20159197e+01], Loss = 0.3323\n",
      "Iteration 7693: Weights = [5.50000000e+01 3.34239399e+00 7.02743688e+00 2.31531287e-02\n",
      " 2.33975857e-01 1.20161328e+01], Loss = 0.3322\n",
      "Iteration 7694: Weights = [5.50000000e+01 3.34229804e+00 7.02723515e+00 2.31524641e-02\n",
      " 2.33969140e-01 1.20163460e+01], Loss = 0.3322\n",
      "Iteration 7695: Weights = [5.50000000e+01 3.34220210e+00 7.02703342e+00 2.31517995e-02\n",
      " 2.33962424e-01 1.20165591e+01], Loss = 0.3322\n",
      "Iteration 7696: Weights = [5.50000000e+01 3.34210616e+00 7.02683170e+00 2.31511349e-02\n",
      " 2.33955708e-01 1.20167722e+01], Loss = 0.3322\n",
      "Iteration 7697: Weights = [5.50000000e+01 3.34201022e+00 7.02662999e+00 2.31504703e-02\n",
      " 2.33948992e-01 1.20169853e+01], Loss = 0.3322\n",
      "Iteration 7698: Weights = [5.50000000e+01 3.34191428e+00 7.02642828e+00 2.31498057e-02\n",
      " 2.33942276e-01 1.20171984e+01], Loss = 0.3322\n",
      "Iteration 7699: Weights = [5.50000000e+01 3.34181835e+00 7.02622658e+00 2.31491412e-02\n",
      " 2.33935560e-01 1.20174115e+01], Loss = 0.3321\n",
      "Iteration 7700: Weights = [5.50000000e+01 3.34172241e+00 7.02602488e+00 2.31484767e-02\n",
      " 2.33928845e-01 1.20176246e+01], Loss = 0.3321\n",
      "Iteration 7701: Weights = [5.50000000e+01 3.34162649e+00 7.02582319e+00 2.31478121e-02\n",
      " 2.33922130e-01 1.20178377e+01], Loss = 0.3321\n",
      "Iteration 7702: Weights = [5.50000000e+01 3.34153056e+00 7.02562150e+00 2.31471477e-02\n",
      " 2.33915415e-01 1.20180507e+01], Loss = 0.3321\n",
      "Iteration 7703: Weights = [5.50000000e+01 3.34143464e+00 7.02541983e+00 2.31464832e-02\n",
      " 2.33908700e-01 1.20182638e+01], Loss = 0.3321\n",
      "Iteration 7704: Weights = [5.50000000e+01 3.34133872e+00 7.02521815e+00 2.31458187e-02\n",
      " 2.33901985e-01 1.20184769e+01], Loss = 0.3320\n",
      "Iteration 7705: Weights = [5.50000000e+01 3.34124280e+00 7.02501648e+00 2.31451543e-02\n",
      " 2.33895271e-01 1.20186899e+01], Loss = 0.3320\n",
      "Iteration 7706: Weights = [5.50000000e+01 3.34114689e+00 7.02481482e+00 2.31444899e-02\n",
      " 2.33888556e-01 1.20189030e+01], Loss = 0.3320\n",
      "Iteration 7707: Weights = [5.50000000e+01 3.34105097e+00 7.02461316e+00 2.31438255e-02\n",
      " 2.33881842e-01 1.20191160e+01], Loss = 0.3320\n",
      "Iteration 7708: Weights = [5.50000000e+01 3.34095506e+00 7.02441151e+00 2.31431611e-02\n",
      " 2.33875128e-01 1.20193291e+01], Loss = 0.3320\n",
      "Iteration 7709: Weights = [5.50000000e+01 3.34085916e+00 7.02420987e+00 2.31424968e-02\n",
      " 2.33868415e-01 1.20195421e+01], Loss = 0.3319\n",
      "Iteration 7710: Weights = [5.50000000e+01 3.34076325e+00 7.02400823e+00 2.31418324e-02\n",
      " 2.33861701e-01 1.20197551e+01], Loss = 0.3319\n",
      "Iteration 7711: Weights = [5.50000000e+01 3.34066735e+00 7.02380660e+00 2.31411681e-02\n",
      " 2.33854988e-01 1.20199682e+01], Loss = 0.3319\n",
      "Iteration 7712: Weights = [5.50000000e+01 3.34057145e+00 7.02360497e+00 2.31405038e-02\n",
      " 2.33848275e-01 1.20201812e+01], Loss = 0.3319\n",
      "Iteration 7713: Weights = [5.50000000e+01 3.34047556e+00 7.02340335e+00 2.31398395e-02\n",
      " 2.33841562e-01 1.20203942e+01], Loss = 0.3319\n",
      "Iteration 7714: Weights = [5.50000000e+01 3.34037967e+00 7.02320173e+00 2.31391753e-02\n",
      " 2.33834849e-01 1.20206072e+01], Loss = 0.3318\n",
      "Iteration 7715: Weights = [5.50000000e+01 3.34028378e+00 7.02300012e+00 2.31385110e-02\n",
      " 2.33828137e-01 1.20208202e+01], Loss = 0.3318\n",
      "Iteration 7716: Weights = [5.50000000e+01 3.34018789e+00 7.02279852e+00 2.31378468e-02\n",
      " 2.33821424e-01 1.20210332e+01], Loss = 0.3318\n",
      "Iteration 7717: Weights = [5.50000000e+01 3.34009200e+00 7.02259692e+00 2.31371826e-02\n",
      " 2.33814712e-01 1.20212462e+01], Loss = 0.3318\n",
      "Iteration 7718: Weights = [5.50000000e+01 3.33999612e+00 7.02239532e+00 2.31365184e-02\n",
      " 2.33808000e-01 1.20214592e+01], Loss = 0.3318\n",
      "Iteration 7719: Weights = [5.50000000e+01 3.33990024e+00 7.02219374e+00 2.31358543e-02\n",
      " 2.33801288e-01 1.20216721e+01], Loss = 0.3318\n",
      "Iteration 7720: Weights = [5.50000000e+01 3.33980437e+00 7.02199216e+00 2.31351901e-02\n",
      " 2.33794577e-01 1.20218851e+01], Loss = 0.3317\n",
      "Iteration 7721: Weights = [5.50000000e+01 3.33970849e+00 7.02179058e+00 2.31345260e-02\n",
      " 2.33787865e-01 1.20220981e+01], Loss = 0.3317\n",
      "Iteration 7722: Weights = [5.50000000e+01 3.33961262e+00 7.02158901e+00 2.31338619e-02\n",
      " 2.33781154e-01 1.20223110e+01], Loss = 0.3317\n",
      "Iteration 7723: Weights = [5.50000000e+01 3.33951676e+00 7.02138745e+00 2.31331978e-02\n",
      " 2.33774443e-01 1.20225240e+01], Loss = 0.3317\n",
      "Iteration 7724: Weights = [5.50000000e+01 3.33942089e+00 7.02118589e+00 2.31325337e-02\n",
      " 2.33767732e-01 1.20227369e+01], Loss = 0.3317\n",
      "Iteration 7725: Weights = [5.50000000e+01 3.33932503e+00 7.02098434e+00 2.31318697e-02\n",
      " 2.33761022e-01 1.20229498e+01], Loss = 0.3316\n",
      "Iteration 7726: Weights = [5.50000000e+01 3.33922917e+00 7.02078279e+00 2.31312057e-02\n",
      " 2.33754311e-01 1.20231628e+01], Loss = 0.3316\n",
      "Iteration 7727: Weights = [5.50000000e+01 3.33913331e+00 7.02058125e+00 2.31305417e-02\n",
      " 2.33747601e-01 1.20233757e+01], Loss = 0.3316\n",
      "Iteration 7728: Weights = [5.50000000e+01 3.33903746e+00 7.02037971e+00 2.31298777e-02\n",
      " 2.33740891e-01 1.20235886e+01], Loss = 0.3316\n",
      "Iteration 7729: Weights = [5.50000000e+01 3.33894161e+00 7.02017819e+00 2.31292137e-02\n",
      " 2.33734181e-01 1.20238015e+01], Loss = 0.3316\n",
      "Iteration 7730: Weights = [5.50000000e+01 3.33884576e+00 7.01997666e+00 2.31285497e-02\n",
      " 2.33727472e-01 1.20240144e+01], Loss = 0.3315\n",
      "Iteration 7731: Weights = [5.50000000e+01 3.33874991e+00 7.01977514e+00 2.31278858e-02\n",
      " 2.33720762e-01 1.20242273e+01], Loss = 0.3315\n",
      "Iteration 7732: Weights = [5.50000000e+01 3.33865407e+00 7.01957363e+00 2.31272219e-02\n",
      " 2.33714053e-01 1.20244402e+01], Loss = 0.3315\n",
      "Iteration 7733: Weights = [5.50000000e+01 3.33855823e+00 7.01937213e+00 2.31265580e-02\n",
      " 2.33707344e-01 1.20246531e+01], Loss = 0.3315\n",
      "Iteration 7734: Weights = [5.50000000e+01 3.33846239e+00 7.01917063e+00 2.31258941e-02\n",
      " 2.33700635e-01 1.20248660e+01], Loss = 0.3315\n",
      "Iteration 7735: Weights = [5.50000000e+01 3.33836655e+00 7.01896913e+00 2.31252302e-02\n",
      " 2.33693926e-01 1.20250789e+01], Loss = 0.3314\n",
      "Iteration 7736: Weights = [5.50000000e+01 3.33827072e+00 7.01876764e+00 2.31245664e-02\n",
      " 2.33687218e-01 1.20252917e+01], Loss = 0.3314\n",
      "Iteration 7737: Weights = [5.50000000e+01 3.33817489e+00 7.01856616e+00 2.31239026e-02\n",
      " 2.33680509e-01 1.20255046e+01], Loss = 0.3314\n",
      "Iteration 7738: Weights = [5.50000000e+01 3.33807907e+00 7.01836468e+00 2.31232388e-02\n",
      " 2.33673801e-01 1.20257175e+01], Loss = 0.3314\n",
      "Iteration 7739: Weights = [5.50000000e+01 3.33798324e+00 7.01816321e+00 2.31225750e-02\n",
      " 2.33667093e-01 1.20259303e+01], Loss = 0.3314\n",
      "Iteration 7740: Weights = [5.50000000e+01 3.33788742e+00 7.01796175e+00 2.31219112e-02\n",
      " 2.33660386e-01 1.20261432e+01], Loss = 0.3314\n",
      "Iteration 7741: Weights = [5.50000000e+01 3.33779160e+00 7.01776029e+00 2.31212475e-02\n",
      " 2.33653678e-01 1.20263560e+01], Loss = 0.3313\n",
      "Iteration 7742: Weights = [5.50000000e+01 3.33769579e+00 7.01755883e+00 2.31205838e-02\n",
      " 2.33646971e-01 1.20265688e+01], Loss = 0.3313\n",
      "Iteration 7743: Weights = [5.50000000e+01 3.33759997e+00 7.01735738e+00 2.31199201e-02\n",
      " 2.33640264e-01 1.20267817e+01], Loss = 0.3313\n",
      "Iteration 7744: Weights = [5.50000000e+01 3.33750416e+00 7.01715594e+00 2.31192564e-02\n",
      " 2.33633557e-01 1.20269945e+01], Loss = 0.3313\n",
      "Iteration 7745: Weights = [5.50000000e+01 3.33740836e+00 7.01695451e+00 2.31185927e-02\n",
      " 2.33626850e-01 1.20272073e+01], Loss = 0.3313\n",
      "Iteration 7746: Weights = [5.50000000e+01 3.33731255e+00 7.01675307e+00 2.31179291e-02\n",
      " 2.33620143e-01 1.20274201e+01], Loss = 0.3312\n",
      "Iteration 7747: Weights = [5.50000000e+01 3.33721675e+00 7.01655165e+00 2.31172654e-02\n",
      " 2.33613437e-01 1.20276329e+01], Loss = 0.3312\n",
      "Iteration 7748: Weights = [5.50000000e+01 3.33712095e+00 7.01635023e+00 2.31166018e-02\n",
      " 2.33606731e-01 1.20278457e+01], Loss = 0.3312\n",
      "Iteration 7749: Weights = [5.50000000e+01 3.33702515e+00 7.01614882e+00 2.31159382e-02\n",
      " 2.33600025e-01 1.20280585e+01], Loss = 0.3312\n",
      "Iteration 7750: Weights = [5.50000000e+01 3.33692936e+00 7.01594741e+00 2.31152746e-02\n",
      " 2.33593319e-01 1.20282713e+01], Loss = 0.3312\n",
      "Iteration 7751: Weights = [5.50000000e+01 3.33683357e+00 7.01574601e+00 2.31146111e-02\n",
      " 2.33586614e-01 1.20284841e+01], Loss = 0.3311\n",
      "Iteration 7752: Weights = [5.50000000e+01 3.33673778e+00 7.01554461e+00 2.31139476e-02\n",
      " 2.33579908e-01 1.20286968e+01], Loss = 0.3311\n",
      "Iteration 7753: Weights = [5.50000000e+01 3.33664200e+00 7.01534322e+00 2.31132840e-02\n",
      " 2.33573203e-01 1.20289096e+01], Loss = 0.3311\n",
      "Iteration 7754: Weights = [5.50000000e+01 3.33654621e+00 7.01514184e+00 2.31126205e-02\n",
      " 2.33566498e-01 1.20291223e+01], Loss = 0.3311\n",
      "Iteration 7755: Weights = [5.50000000e+01 3.33645043e+00 7.01494046e+00 2.31119571e-02\n",
      " 2.33559793e-01 1.20293351e+01], Loss = 0.3311\n",
      "Iteration 7756: Weights = [5.50000000e+01 3.33635466e+00 7.01473908e+00 2.31112936e-02\n",
      " 2.33553088e-01 1.20295478e+01], Loss = 0.3310\n",
      "Iteration 7757: Weights = [5.50000000e+01 3.33625888e+00 7.01453772e+00 2.31106302e-02\n",
      " 2.33546384e-01 1.20297606e+01], Loss = 0.3310\n",
      "Iteration 7758: Weights = [5.50000000e+01 3.33616311e+00 7.01433636e+00 2.31099667e-02\n",
      " 2.33539680e-01 1.20299733e+01], Loss = 0.3310\n",
      "Iteration 7759: Weights = [5.50000000e+01 3.33606734e+00 7.01413500e+00 2.31093033e-02\n",
      " 2.33532976e-01 1.20301861e+01], Loss = 0.3310\n",
      "Iteration 7760: Weights = [5.50000000e+01 3.33597158e+00 7.01393365e+00 2.31086400e-02\n",
      " 2.33526272e-01 1.20303988e+01], Loss = 0.3310\n",
      "Iteration 7761: Weights = [5.50000000e+01 3.33587581e+00 7.01373231e+00 2.31079766e-02\n",
      " 2.33519568e-01 1.20306115e+01], Loss = 0.3310\n",
      "Iteration 7762: Weights = [5.50000000e+01 3.33578005e+00 7.01353097e+00 2.31073133e-02\n",
      " 2.33512865e-01 1.20308242e+01], Loss = 0.3309\n",
      "Iteration 7763: Weights = [5.50000000e+01 3.33568429e+00 7.01332963e+00 2.31066499e-02\n",
      " 2.33506161e-01 1.20310369e+01], Loss = 0.3309\n",
      "Iteration 7764: Weights = [5.50000000e+01 3.33558854e+00 7.01312831e+00 2.31059866e-02\n",
      " 2.33499458e-01 1.20312496e+01], Loss = 0.3309\n",
      "Iteration 7765: Weights = [5.50000000e+01 3.33549279e+00 7.01292699e+00 2.31053233e-02\n",
      " 2.33492755e-01 1.20314623e+01], Loss = 0.3309\n",
      "Iteration 7766: Weights = [5.50000000e+01 3.33539704e+00 7.01272567e+00 2.31046601e-02\n",
      " 2.33486053e-01 1.20316750e+01], Loss = 0.3309\n",
      "Iteration 7767: Weights = [5.50000000e+01 3.33530129e+00 7.01252436e+00 2.31039968e-02\n",
      " 2.33479350e-01 1.20318877e+01], Loss = 0.3308\n",
      "Iteration 7768: Weights = [5.50000000e+01 3.33520554e+00 7.01232306e+00 2.31033336e-02\n",
      " 2.33472648e-01 1.20321003e+01], Loss = 0.3308\n",
      "Iteration 7769: Weights = [5.50000000e+01 3.33510980e+00 7.01212176e+00 2.31026704e-02\n",
      " 2.33465946e-01 1.20323130e+01], Loss = 0.3308\n",
      "Iteration 7770: Weights = [5.50000000e+01 3.33501406e+00 7.01192047e+00 2.31020072e-02\n",
      " 2.33459244e-01 1.20325257e+01], Loss = 0.3308\n",
      "Iteration 7771: Weights = [5.50000000e+01 3.33491833e+00 7.01171918e+00 2.31013440e-02\n",
      " 2.33452542e-01 1.20327383e+01], Loss = 0.3308\n",
      "Iteration 7772: Weights = [5.50000000e+01 3.33482260e+00 7.01151790e+00 2.31006809e-02\n",
      " 2.33445840e-01 1.20329510e+01], Loss = 0.3307\n",
      "Iteration 7773: Weights = [5.50000000e+01 3.33472687e+00 7.01131663e+00 2.31000177e-02\n",
      " 2.33439139e-01 1.20331636e+01], Loss = 0.3307\n",
      "Iteration 7774: Weights = [5.50000000e+01 3.33463114e+00 7.01111536e+00 2.30993546e-02\n",
      " 2.33432438e-01 1.20333763e+01], Loss = 0.3307\n",
      "Iteration 7775: Weights = [5.50000000e+01 3.33453541e+00 7.01091409e+00 2.30986915e-02\n",
      " 2.33425737e-01 1.20335889e+01], Loss = 0.3307\n",
      "Iteration 7776: Weights = [5.50000000e+01 3.33443969e+00 7.01071284e+00 2.30980284e-02\n",
      " 2.33419036e-01 1.20338015e+01], Loss = 0.3307\n",
      "Iteration 7777: Weights = [5.50000000e+01 3.33434397e+00 7.01051158e+00 2.30973654e-02\n",
      " 2.33412335e-01 1.20340141e+01], Loss = 0.3306\n",
      "Iteration 7778: Weights = [5.50000000e+01 3.33424825e+00 7.01031034e+00 2.30967023e-02\n",
      " 2.33405635e-01 1.20342267e+01], Loss = 0.3306\n",
      "Iteration 7779: Weights = [5.50000000e+01 3.33415254e+00 7.01010910e+00 2.30960393e-02\n",
      " 2.33398935e-01 1.20344394e+01], Loss = 0.3306\n",
      "Iteration 7780: Weights = [5.50000000e+01 3.33405683e+00 7.00990786e+00 2.30953763e-02\n",
      " 2.33392235e-01 1.20346520e+01], Loss = 0.3306\n",
      "Iteration 7781: Weights = [5.50000000e+01 3.33396112e+00 7.00970664e+00 2.30947133e-02\n",
      " 2.33385535e-01 1.20348645e+01], Loss = 0.3306\n",
      "Iteration 7782: Weights = [5.50000000e+01 3.33386541e+00 7.00950541e+00 2.30940504e-02\n",
      " 2.33378835e-01 1.20350771e+01], Loss = 0.3306\n",
      "Iteration 7783: Weights = [5.50000000e+01 3.33376971e+00 7.00930420e+00 2.30933874e-02\n",
      " 2.33372136e-01 1.20352897e+01], Loss = 0.3305\n",
      "Iteration 7784: Weights = [5.50000000e+01 3.33367401e+00 7.00910298e+00 2.30927245e-02\n",
      " 2.33365437e-01 1.20355023e+01], Loss = 0.3305\n",
      "Iteration 7785: Weights = [5.50000000e+01 3.33357831e+00 7.00890178e+00 2.30920616e-02\n",
      " 2.33358738e-01 1.20357149e+01], Loss = 0.3305\n",
      "Iteration 7786: Weights = [5.50000000e+01 3.33348262e+00 7.00870058e+00 2.30913987e-02\n",
      " 2.33352039e-01 1.20359274e+01], Loss = 0.3305\n",
      "Iteration 7787: Weights = [5.50000000e+01 3.33338693e+00 7.00849939e+00 2.30907358e-02\n",
      " 2.33345340e-01 1.20361400e+01], Loss = 0.3305\n",
      "Iteration 7788: Weights = [5.50000000e+01 3.33329124e+00 7.00829820e+00 2.30900730e-02\n",
      " 2.33338642e-01 1.20363525e+01], Loss = 0.3304\n",
      "Iteration 7789: Weights = [5.50000000e+01 3.33319555e+00 7.00809702e+00 2.30894101e-02\n",
      " 2.33331943e-01 1.20365651e+01], Loss = 0.3304\n",
      "Iteration 7790: Weights = [5.50000000e+01 3.33309987e+00 7.00789584e+00 2.30887473e-02\n",
      " 2.33325245e-01 1.20367776e+01], Loss = 0.3304\n",
      "Iteration 7791: Weights = [5.50000000e+01 3.33300419e+00 7.00769467e+00 2.30880845e-02\n",
      " 2.33318547e-01 1.20369902e+01], Loss = 0.3304\n",
      "Iteration 7792: Weights = [5.50000000e+01 3.33290851e+00 7.00749350e+00 2.30874218e-02\n",
      " 2.33311850e-01 1.20372027e+01], Loss = 0.3304\n",
      "Iteration 7793: Weights = [5.50000000e+01 3.33281283e+00 7.00729234e+00 2.30867590e-02\n",
      " 2.33305152e-01 1.20374152e+01], Loss = 0.3303\n",
      "Iteration 7794: Weights = [5.50000000e+01 3.33271716e+00 7.00709119e+00 2.30860963e-02\n",
      " 2.33298455e-01 1.20376277e+01], Loss = 0.3303\n",
      "Iteration 7795: Weights = [5.50000000e+01 3.33262149e+00 7.00689004e+00 2.30854336e-02\n",
      " 2.33291758e-01 1.20378402e+01], Loss = 0.3303\n",
      "Iteration 7796: Weights = [5.50000000e+01 3.33252582e+00 7.00668890e+00 2.30847709e-02\n",
      " 2.33285061e-01 1.20380527e+01], Loss = 0.3303\n",
      "Iteration 7797: Weights = [5.50000000e+01 3.33243016e+00 7.00648776e+00 2.30841082e-02\n",
      " 2.33278364e-01 1.20382652e+01], Loss = 0.3303\n",
      "Iteration 7798: Weights = [5.50000000e+01 3.33233450e+00 7.00628663e+00 2.30834455e-02\n",
      " 2.33271667e-01 1.20384777e+01], Loss = 0.3302\n",
      "Iteration 7799: Weights = [5.50000000e+01 3.33223884e+00 7.00608551e+00 2.30827829e-02\n",
      " 2.33264971e-01 1.20386902e+01], Loss = 0.3302\n",
      "Iteration 7800: Weights = [5.50000000e+01 3.33214318e+00 7.00588439e+00 2.30821203e-02\n",
      " 2.33258275e-01 1.20389027e+01], Loss = 0.3302\n",
      "Iteration 7801: Weights = [5.50000000e+01 3.33204753e+00 7.00568328e+00 2.30814577e-02\n",
      " 2.33251579e-01 1.20391152e+01], Loss = 0.3302\n",
      "Iteration 7802: Weights = [5.50000000e+01 3.33195188e+00 7.00548217e+00 2.30807951e-02\n",
      " 2.33244883e-01 1.20393276e+01], Loss = 0.3302\n",
      "Iteration 7803: Weights = [5.50000000e+01 3.33185623e+00 7.00528107e+00 2.30801325e-02\n",
      " 2.33238187e-01 1.20395401e+01], Loss = 0.3302\n",
      "Iteration 7804: Weights = [5.50000000e+01 3.33176058e+00 7.00507997e+00 2.30794700e-02\n",
      " 2.33231492e-01 1.20397525e+01], Loss = 0.3301\n",
      "Iteration 7805: Weights = [5.50000000e+01 3.33166494e+00 7.00487888e+00 2.30788074e-02\n",
      " 2.33224797e-01 1.20399650e+01], Loss = 0.3301\n",
      "Iteration 7806: Weights = [5.50000000e+01 3.33156930e+00 7.00467780e+00 2.30781449e-02\n",
      " 2.33218102e-01 1.20401774e+01], Loss = 0.3301\n",
      "Iteration 7807: Weights = [5.50000000e+01 3.33147366e+00 7.00447672e+00 2.30774824e-02\n",
      " 2.33211407e-01 1.20403899e+01], Loss = 0.3301\n",
      "Iteration 7808: Weights = [5.50000000e+01 3.33137803e+00 7.00427565e+00 2.30768200e-02\n",
      " 2.33204712e-01 1.20406023e+01], Loss = 0.3301\n",
      "Iteration 7809: Weights = [5.50000000e+01 3.33128240e+00 7.00407458e+00 2.30761575e-02\n",
      " 2.33198018e-01 1.20408147e+01], Loss = 0.3300\n",
      "Iteration 7810: Weights = [5.50000000e+01 3.33118677e+00 7.00387352e+00 2.30754951e-02\n",
      " 2.33191324e-01 1.20410271e+01], Loss = 0.3300\n",
      "Iteration 7811: Weights = [5.50000000e+01 3.33109114e+00 7.00367246e+00 2.30748327e-02\n",
      " 2.33184629e-01 1.20412396e+01], Loss = 0.3300\n",
      "Iteration 7812: Weights = [5.50000000e+01 3.33099552e+00 7.00347141e+00 2.30741703e-02\n",
      " 2.33177936e-01 1.20414520e+01], Loss = 0.3300\n",
      "Iteration 7813: Weights = [5.50000000e+01 3.33089990e+00 7.00327037e+00 2.30735079e-02\n",
      " 2.33171242e-01 1.20416644e+01], Loss = 0.3300\n",
      "Iteration 7814: Weights = [5.50000000e+01 3.33080428e+00 7.00306933e+00 2.30728456e-02\n",
      " 2.33164548e-01 1.20418768e+01], Loss = 0.3299\n",
      "Iteration 7815: Weights = [5.50000000e+01 3.33070867e+00 7.00286830e+00 2.30721832e-02\n",
      " 2.33157855e-01 1.20420891e+01], Loss = 0.3299\n",
      "Iteration 7816: Weights = [5.50000000e+01 3.33061305e+00 7.00266727e+00 2.30715209e-02\n",
      " 2.33151162e-01 1.20423015e+01], Loss = 0.3299\n",
      "Iteration 7817: Weights = [5.50000000e+01 3.33051744e+00 7.00246625e+00 2.30708586e-02\n",
      " 2.33144469e-01 1.20425139e+01], Loss = 0.3299\n",
      "Iteration 7818: Weights = [5.50000000e+01 3.33042184e+00 7.00226524e+00 2.30701963e-02\n",
      " 2.33137776e-01 1.20427263e+01], Loss = 0.3299\n",
      "Iteration 7819: Weights = [5.50000000e+01 3.33032623e+00 7.00206423e+00 2.30695341e-02\n",
      " 2.33131084e-01 1.20429386e+01], Loss = 0.3299\n",
      "Iteration 7820: Weights = [5.50000000e+01 3.33023063e+00 7.00186323e+00 2.30688718e-02\n",
      " 2.33124392e-01 1.20431510e+01], Loss = 0.3298\n",
      "Iteration 7821: Weights = [5.50000000e+01 3.33013503e+00 7.00166223e+00 2.30682096e-02\n",
      " 2.33117699e-01 1.20433633e+01], Loss = 0.3298\n",
      "Iteration 7822: Weights = [5.50000000e+01 3.33003944e+00 7.00146124e+00 2.30675474e-02\n",
      " 2.33111007e-01 1.20435757e+01], Loss = 0.3298\n",
      "Iteration 7823: Weights = [5.50000000e+01 3.32994384e+00 7.00126025e+00 2.30668852e-02\n",
      " 2.33104316e-01 1.20437880e+01], Loss = 0.3298\n",
      "Iteration 7824: Weights = [5.50000000e+01 3.32984825e+00 7.00105927e+00 2.30662230e-02\n",
      " 2.33097624e-01 1.20440004e+01], Loss = 0.3298\n",
      "Iteration 7825: Weights = [5.50000000e+01 3.32975267e+00 7.00085829e+00 2.30655609e-02\n",
      " 2.33090933e-01 1.20442127e+01], Loss = 0.3297\n",
      "Iteration 7826: Weights = [5.50000000e+01 3.32965708e+00 7.00065733e+00 2.30648988e-02\n",
      " 2.33084242e-01 1.20444250e+01], Loss = 0.3297\n",
      "Iteration 7827: Weights = [5.50000000e+01 3.32956150e+00 7.00045636e+00 2.30642367e-02\n",
      " 2.33077551e-01 1.20446373e+01], Loss = 0.3297\n",
      "Iteration 7828: Weights = [5.50000000e+01 3.32946592e+00 7.00025541e+00 2.30635746e-02\n",
      " 2.33070860e-01 1.20448496e+01], Loss = 0.3297\n",
      "Iteration 7829: Weights = [5.50000000e+01 3.32937034e+00 7.00005445e+00 2.30629125e-02\n",
      " 2.33064169e-01 1.20450619e+01], Loss = 0.3297\n",
      "Iteration 7830: Weights = [5.50000000e+01 3.32927477e+00 6.99985351e+00 2.30622505e-02\n",
      " 2.33057479e-01 1.20452742e+01], Loss = 0.3296\n",
      "Iteration 7831: Weights = [5.50000000e+01 3.32917920e+00 6.99965257e+00 2.30615884e-02\n",
      " 2.33050789e-01 1.20454865e+01], Loss = 0.3296\n",
      "Iteration 7832: Weights = [5.50000000e+01 3.32908363e+00 6.99945163e+00 2.30609264e-02\n",
      " 2.33044099e-01 1.20456988e+01], Loss = 0.3296\n",
      "Iteration 7833: Weights = [5.50000000e+01 3.32898806e+00 6.99925071e+00 2.30602644e-02\n",
      " 2.33037409e-01 1.20459111e+01], Loss = 0.3296\n",
      "Iteration 7834: Weights = [5.50000000e+01 3.32889250e+00 6.99904978e+00 2.30596024e-02\n",
      " 2.33030719e-01 1.20461233e+01], Loss = 0.3296\n",
      "Iteration 7835: Weights = [5.50000000e+01 3.32879694e+00 6.99884887e+00 2.30589405e-02\n",
      " 2.33024030e-01 1.20463356e+01], Loss = 0.3295\n",
      "Iteration 7836: Weights = [5.50000000e+01 3.32870138e+00 6.99864796e+00 2.30582785e-02\n",
      " 2.33017340e-01 1.20465479e+01], Loss = 0.3295\n",
      "Iteration 7837: Weights = [5.50000000e+01 3.32860583e+00 6.99844705e+00 2.30576166e-02\n",
      " 2.33010651e-01 1.20467601e+01], Loss = 0.3295\n",
      "Iteration 7838: Weights = [5.50000000e+01 3.32851028e+00 6.99824615e+00 2.30569547e-02\n",
      " 2.33003962e-01 1.20469724e+01], Loss = 0.3295\n",
      "Iteration 7839: Weights = [5.50000000e+01 3.32841473e+00 6.99804526e+00 2.30562929e-02\n",
      " 2.32997274e-01 1.20471846e+01], Loss = 0.3295\n",
      "Iteration 7840: Weights = [5.50000000e+01 3.32831918e+00 6.99784437e+00 2.30556310e-02\n",
      " 2.32990585e-01 1.20473968e+01], Loss = 0.3295\n",
      "Iteration 7841: Weights = [5.50000000e+01 3.32822364e+00 6.99764349e+00 2.30549691e-02\n",
      " 2.32983897e-01 1.20476091e+01], Loss = 0.3294\n",
      "Iteration 7842: Weights = [5.50000000e+01 3.32812810e+00 6.99744261e+00 2.30543073e-02\n",
      " 2.32977209e-01 1.20478213e+01], Loss = 0.3294\n",
      "Iteration 7843: Weights = [5.50000000e+01 3.32803256e+00 6.99724174e+00 2.30536455e-02\n",
      " 2.32970521e-01 1.20480335e+01], Loss = 0.3294\n",
      "Iteration 7844: Weights = [5.50000000e+01 3.32793702e+00 6.99704087e+00 2.30529837e-02\n",
      " 2.32963833e-01 1.20482457e+01], Loss = 0.3294\n",
      "Iteration 7845: Weights = [5.50000000e+01 3.32784149e+00 6.99684001e+00 2.30523220e-02\n",
      " 2.32957146e-01 1.20484579e+01], Loss = 0.3294\n",
      "Iteration 7846: Weights = [5.50000000e+01 3.32774596e+00 6.99663916e+00 2.30516602e-02\n",
      " 2.32950458e-01 1.20486701e+01], Loss = 0.3293\n",
      "Iteration 7847: Weights = [5.50000000e+01 3.32765043e+00 6.99643831e+00 2.30509985e-02\n",
      " 2.32943771e-01 1.20488823e+01], Loss = 0.3293\n",
      "Iteration 7848: Weights = [5.50000000e+01 3.32755491e+00 6.99623747e+00 2.30503368e-02\n",
      " 2.32937084e-01 1.20490945e+01], Loss = 0.3293\n",
      "Iteration 7849: Weights = [5.50000000e+01 3.32745939e+00 6.99603664e+00 2.30496751e-02\n",
      " 2.32930397e-01 1.20493067e+01], Loss = 0.3293\n",
      "Iteration 7850: Weights = [5.50000000e+01 3.32736387e+00 6.99583581e+00 2.30490134e-02\n",
      " 2.32923711e-01 1.20495189e+01], Loss = 0.3293\n",
      "Iteration 7851: Weights = [5.50000000e+01 3.32726835e+00 6.99563498e+00 2.30483518e-02\n",
      " 2.32917025e-01 1.20497310e+01], Loss = 0.3292\n",
      "Iteration 7852: Weights = [5.50000000e+01 3.32717284e+00 6.99543416e+00 2.30476901e-02\n",
      " 2.32910338e-01 1.20499432e+01], Loss = 0.3292\n",
      "Iteration 7853: Weights = [5.50000000e+01 3.32707733e+00 6.99523335e+00 2.30470285e-02\n",
      " 2.32903652e-01 1.20501553e+01], Loss = 0.3292\n",
      "Iteration 7854: Weights = [5.50000000e+01 3.32698182e+00 6.99503254e+00 2.30463669e-02\n",
      " 2.32896967e-01 1.20503675e+01], Loss = 0.3292\n",
      "Iteration 7855: Weights = [5.50000000e+01 3.32688631e+00 6.99483174e+00 2.30457054e-02\n",
      " 2.32890281e-01 1.20505796e+01], Loss = 0.3292\n",
      "Iteration 7856: Weights = [5.50000000e+01 3.32679081e+00 6.99463094e+00 2.30450438e-02\n",
      " 2.32883595e-01 1.20507918e+01], Loss = 0.3292\n",
      "Iteration 7857: Weights = [5.50000000e+01 3.32669531e+00 6.99443015e+00 2.30443823e-02\n",
      " 2.32876910e-01 1.20510039e+01], Loss = 0.3291\n",
      "Iteration 7858: Weights = [5.50000000e+01 3.32659981e+00 6.99422937e+00 2.30437207e-02\n",
      " 2.32870225e-01 1.20512160e+01], Loss = 0.3291\n",
      "Iteration 7859: Weights = [5.50000000e+01 3.32650432e+00 6.99402859e+00 2.30430592e-02\n",
      " 2.32863540e-01 1.20514282e+01], Loss = 0.3291\n",
      "Iteration 7860: Weights = [5.50000000e+01 3.32640883e+00 6.99382782e+00 2.30423978e-02\n",
      " 2.32856856e-01 1.20516403e+01], Loss = 0.3291\n",
      "Iteration 7861: Weights = [5.50000000e+01 3.32631334e+00 6.99362705e+00 2.30417363e-02\n",
      " 2.32850171e-01 1.20518524e+01], Loss = 0.3291\n",
      "Iteration 7862: Weights = [5.50000000e+01 3.32621785e+00 6.99342629e+00 2.30410749e-02\n",
      " 2.32843487e-01 1.20520645e+01], Loss = 0.3290\n",
      "Iteration 7863: Weights = [5.50000000e+01 3.32612237e+00 6.99322553e+00 2.30404134e-02\n",
      " 2.32836803e-01 1.20522766e+01], Loss = 0.3290\n",
      "Iteration 7864: Weights = [5.50000000e+01 3.32602689e+00 6.99302478e+00 2.30397520e-02\n",
      " 2.32830119e-01 1.20524887e+01], Loss = 0.3290\n",
      "Iteration 7865: Weights = [5.50000000e+01 3.32593141e+00 6.99282404e+00 2.30390906e-02\n",
      " 2.32823435e-01 1.20527007e+01], Loss = 0.3290\n",
      "Iteration 7866: Weights = [5.50000000e+01 3.32583593e+00 6.99262330e+00 2.30384293e-02\n",
      " 2.32816752e-01 1.20529128e+01], Loss = 0.3290\n",
      "Iteration 7867: Weights = [5.50000000e+01 3.32574046e+00 6.99242257e+00 2.30377679e-02\n",
      " 2.32810069e-01 1.20531249e+01], Loss = 0.3289\n",
      "Iteration 7868: Weights = [5.50000000e+01 3.32564499e+00 6.99222184e+00 2.30371066e-02\n",
      " 2.32803385e-01 1.20533370e+01], Loss = 0.3289\n",
      "Iteration 7869: Weights = [5.50000000e+01 3.32554953e+00 6.99202112e+00 2.30364453e-02\n",
      " 2.32796702e-01 1.20535490e+01], Loss = 0.3289\n",
      "Iteration 7870: Weights = [5.50000000e+01 3.32545406e+00 6.99182041e+00 2.30357840e-02\n",
      " 2.32790020e-01 1.20537611e+01], Loss = 0.3289\n",
      "Iteration 7871: Weights = [5.50000000e+01 3.32535860e+00 6.99161970e+00 2.30351227e-02\n",
      " 2.32783337e-01 1.20539731e+01], Loss = 0.3289\n",
      "Iteration 7872: Weights = [5.50000000e+01 3.32526314e+00 6.99141899e+00 2.30344615e-02\n",
      " 2.32776655e-01 1.20541852e+01], Loss = 0.3288\n",
      "Iteration 7873: Weights = [5.50000000e+01 3.32516769e+00 6.99121830e+00 2.30338002e-02\n",
      " 2.32769973e-01 1.20543972e+01], Loss = 0.3288\n",
      "Iteration 7874: Weights = [5.50000000e+01 3.32507223e+00 6.99101760e+00 2.30331390e-02\n",
      " 2.32763291e-01 1.20546092e+01], Loss = 0.3288\n",
      "Iteration 7875: Weights = [5.50000000e+01 3.32497678e+00 6.99081692e+00 2.30324778e-02\n",
      " 2.32756609e-01 1.20548212e+01], Loss = 0.3288\n",
      "Iteration 7876: Weights = [5.50000000e+01 3.32488133e+00 6.99061624e+00 2.30318166e-02\n",
      " 2.32749927e-01 1.20550332e+01], Loss = 0.3288\n",
      "Iteration 7877: Weights = [5.50000000e+01 3.32478589e+00 6.99041556e+00 2.30311555e-02\n",
      " 2.32743246e-01 1.20552453e+01], Loss = 0.3288\n",
      "Iteration 7878: Weights = [5.50000000e+01 3.32469045e+00 6.99021489e+00 2.30304943e-02\n",
      " 2.32736565e-01 1.20554573e+01], Loss = 0.3287\n",
      "Iteration 7879: Weights = [5.50000000e+01 3.32459501e+00 6.99001423e+00 2.30298332e-02\n",
      " 2.32729884e-01 1.20556693e+01], Loss = 0.3287\n",
      "Iteration 7880: Weights = [5.50000000e+01 3.32449957e+00 6.98981357e+00 2.30291721e-02\n",
      " 2.32723203e-01 1.20558813e+01], Loss = 0.3287\n",
      "Iteration 7881: Weights = [5.50000000e+01 3.32440414e+00 6.98961292e+00 2.30285110e-02\n",
      " 2.32716522e-01 1.20560932e+01], Loss = 0.3287\n",
      "Iteration 7882: Weights = [5.50000000e+01 3.32430870e+00 6.98941228e+00 2.30278500e-02\n",
      " 2.32709842e-01 1.20563052e+01], Loss = 0.3287\n",
      "Iteration 7883: Weights = [5.50000000e+01 3.32421328e+00 6.98921164e+00 2.30271889e-02\n",
      " 2.32703162e-01 1.20565172e+01], Loss = 0.3286\n",
      "Iteration 7884: Weights = [5.50000000e+01 3.32411785e+00 6.98901100e+00 2.30265279e-02\n",
      " 2.32696482e-01 1.20567292e+01], Loss = 0.3286\n",
      "Iteration 7885: Weights = [5.50000000e+01 3.32402243e+00 6.98881037e+00 2.30258669e-02\n",
      " 2.32689802e-01 1.20569411e+01], Loss = 0.3286\n",
      "Iteration 7886: Weights = [5.50000000e+01 3.32392701e+00 6.98860975e+00 2.30252059e-02\n",
      " 2.32683122e-01 1.20571531e+01], Loss = 0.3286\n",
      "Iteration 7887: Weights = [5.50000000e+01 3.32383159e+00 6.98840913e+00 2.30245449e-02\n",
      " 2.32676443e-01 1.20573650e+01], Loss = 0.3286\n",
      "Iteration 7888: Weights = [5.50000000e+01 3.32373617e+00 6.98820852e+00 2.30238840e-02\n",
      " 2.32669763e-01 1.20575770e+01], Loss = 0.3285\n",
      "Iteration 7889: Weights = [5.50000000e+01 3.32364076e+00 6.98800791e+00 2.30232231e-02\n",
      " 2.32663084e-01 1.20577889e+01], Loss = 0.3285\n",
      "Iteration 7890: Weights = [5.50000000e+01 3.32354535e+00 6.98780732e+00 2.30225621e-02\n",
      " 2.32656405e-01 1.20580008e+01], Loss = 0.3285\n",
      "Iteration 7891: Weights = [5.50000000e+01 3.32344994e+00 6.98760672e+00 2.30219013e-02\n",
      " 2.32649727e-01 1.20582128e+01], Loss = 0.3285\n",
      "Iteration 7892: Weights = [5.50000000e+01 3.32335454e+00 6.98740613e+00 2.30212404e-02\n",
      " 2.32643048e-01 1.20584247e+01], Loss = 0.3285\n",
      "Iteration 7893: Weights = [5.50000000e+01 3.32325914e+00 6.98720555e+00 2.30205795e-02\n",
      " 2.32636370e-01 1.20586366e+01], Loss = 0.3285\n",
      "Iteration 7894: Weights = [5.50000000e+01 3.32316374e+00 6.98700497e+00 2.30199187e-02\n",
      " 2.32629692e-01 1.20588485e+01], Loss = 0.3284\n",
      "Iteration 7895: Weights = [5.50000000e+01 3.32306835e+00 6.98680440e+00 2.30192579e-02\n",
      " 2.32623014e-01 1.20590604e+01], Loss = 0.3284\n",
      "Iteration 7896: Weights = [5.50000000e+01 3.32297295e+00 6.98660384e+00 2.30185971e-02\n",
      " 2.32616336e-01 1.20592723e+01], Loss = 0.3284\n",
      "Iteration 7897: Weights = [5.50000000e+01 3.32287756e+00 6.98640328e+00 2.30179363e-02\n",
      " 2.32609658e-01 1.20594842e+01], Loss = 0.3284\n",
      "Iteration 7898: Weights = [5.50000000e+01 3.32278217e+00 6.98620272e+00 2.30172755e-02\n",
      " 2.32602981e-01 1.20596961e+01], Loss = 0.3284\n",
      "Iteration 7899: Weights = [5.50000000e+01 3.32268679e+00 6.98600217e+00 2.30166148e-02\n",
      " 2.32596304e-01 1.20599079e+01], Loss = 0.3283\n",
      "Iteration 7900: Weights = [5.50000000e+01 3.32259141e+00 6.98580163e+00 2.30159541e-02\n",
      " 2.32589627e-01 1.20601198e+01], Loss = 0.3283\n",
      "Iteration 7901: Weights = [5.50000000e+01 3.32249603e+00 6.98560110e+00 2.30152934e-02\n",
      " 2.32582950e-01 1.20603317e+01], Loss = 0.3283\n",
      "Iteration 7902: Weights = [5.50000000e+01 3.32240065e+00 6.98540057e+00 2.30146327e-02\n",
      " 2.32576274e-01 1.20605435e+01], Loss = 0.3283\n",
      "Iteration 7903: Weights = [5.50000000e+01 3.32230528e+00 6.98520004e+00 2.30139720e-02\n",
      " 2.32569597e-01 1.20607554e+01], Loss = 0.3283\n",
      "Iteration 7904: Weights = [5.50000000e+01 3.32220991e+00 6.98499952e+00 2.30133114e-02\n",
      " 2.32562921e-01 1.20609672e+01], Loss = 0.3282\n",
      "Iteration 7905: Weights = [5.50000000e+01 3.32211454e+00 6.98479901e+00 2.30126507e-02\n",
      " 2.32556245e-01 1.20611791e+01], Loss = 0.3282\n",
      "Iteration 7906: Weights = [5.50000000e+01 3.32201917e+00 6.98459850e+00 2.30119901e-02\n",
      " 2.32549569e-01 1.20613909e+01], Loss = 0.3282\n",
      "Iteration 7907: Weights = [5.50000000e+01 3.32192381e+00 6.98439800e+00 2.30113296e-02\n",
      " 2.32542893e-01 1.20616027e+01], Loss = 0.3282\n",
      "Iteration 7908: Weights = [5.50000000e+01 3.32182845e+00 6.98419750e+00 2.30106690e-02\n",
      " 2.32536218e-01 1.20618145e+01], Loss = 0.3282\n",
      "Iteration 7909: Weights = [5.50000000e+01 3.32173309e+00 6.98399701e+00 2.30100084e-02\n",
      " 2.32529543e-01 1.20620264e+01], Loss = 0.3282\n",
      "Iteration 7910: Weights = [5.50000000e+01 3.32163774e+00 6.98379653e+00 2.30093479e-02\n",
      " 2.32522868e-01 1.20622382e+01], Loss = 0.3281\n",
      "Iteration 7911: Weights = [5.50000000e+01 3.32154239e+00 6.98359605e+00 2.30086874e-02\n",
      " 2.32516193e-01 1.20624500e+01], Loss = 0.3281\n",
      "Iteration 7912: Weights = [5.50000000e+01 3.32144704e+00 6.98339557e+00 2.30080269e-02\n",
      " 2.32509518e-01 1.20626618e+01], Loss = 0.3281\n",
      "Iteration 7913: Weights = [5.50000000e+01 3.32135169e+00 6.98319511e+00 2.30073664e-02\n",
      " 2.32502844e-01 1.20628736e+01], Loss = 0.3281\n",
      "Iteration 7914: Weights = [5.50000000e+01 3.32125635e+00 6.98299464e+00 2.30067060e-02\n",
      " 2.32496169e-01 1.20630853e+01], Loss = 0.3281\n",
      "Iteration 7915: Weights = [5.50000000e+01 3.32116101e+00 6.98279419e+00 2.30060455e-02\n",
      " 2.32489495e-01 1.20632971e+01], Loss = 0.3280\n",
      "Iteration 7916: Weights = [5.50000000e+01 3.32106567e+00 6.98259374e+00 2.30053851e-02\n",
      " 2.32482821e-01 1.20635089e+01], Loss = 0.3280\n",
      "Iteration 7917: Weights = [5.50000000e+01 3.32097033e+00 6.98239329e+00 2.30047247e-02\n",
      " 2.32476148e-01 1.20637207e+01], Loss = 0.3280\n",
      "Iteration 7918: Weights = [5.50000000e+01 3.32087500e+00 6.98219285e+00 2.30040643e-02\n",
      " 2.32469474e-01 1.20639324e+01], Loss = 0.3280\n",
      "Iteration 7919: Weights = [5.50000000e+01 3.32077967e+00 6.98199242e+00 2.30034040e-02\n",
      " 2.32462801e-01 1.20641442e+01], Loss = 0.3280\n",
      "Iteration 7920: Weights = [5.50000000e+01 3.32068434e+00 6.98179199e+00 2.30027436e-02\n",
      " 2.32456128e-01 1.20643559e+01], Loss = 0.3279\n",
      "Iteration 7921: Weights = [5.50000000e+01 3.32058902e+00 6.98159157e+00 2.30020833e-02\n",
      " 2.32449455e-01 1.20645677e+01], Loss = 0.3279\n",
      "Iteration 7922: Weights = [5.50000000e+01 3.32049369e+00 6.98139116e+00 2.30014230e-02\n",
      " 2.32442782e-01 1.20647794e+01], Loss = 0.3279\n",
      "Iteration 7923: Weights = [5.50000000e+01 3.32039838e+00 6.98119075e+00 2.30007627e-02\n",
      " 2.32436109e-01 1.20649911e+01], Loss = 0.3279\n",
      "Iteration 7924: Weights = [5.50000000e+01 3.32030306e+00 6.98099034e+00 2.30001024e-02\n",
      " 2.32429437e-01 1.20652029e+01], Loss = 0.3279\n",
      "Iteration 7925: Weights = [5.50000000e+01 3.32020775e+00 6.98078994e+00 2.29994422e-02\n",
      " 2.32422765e-01 1.20654146e+01], Loss = 0.3278\n",
      "Iteration 7926: Weights = [5.50000000e+01 3.32011243e+00 6.98058955e+00 2.29987820e-02\n",
      " 2.32416093e-01 1.20656263e+01], Loss = 0.3278\n",
      "Iteration 7927: Weights = [5.50000000e+01 3.32001713e+00 6.98038917e+00 2.29981217e-02\n",
      " 2.32409421e-01 1.20658380e+01], Loss = 0.3278\n",
      "Iteration 7928: Weights = [5.50000000e+01 3.31992182e+00 6.98018878e+00 2.29974616e-02\n",
      " 2.32402749e-01 1.20660497e+01], Loss = 0.3278\n",
      "Iteration 7929: Weights = [5.50000000e+01 3.31982652e+00 6.97998841e+00 2.29968014e-02\n",
      " 2.32396078e-01 1.20662614e+01], Loss = 0.3278\n",
      "Iteration 7930: Weights = [5.50000000e+01 3.31973122e+00 6.97978804e+00 2.29961412e-02\n",
      " 2.32389407e-01 1.20664731e+01], Loss = 0.3278\n",
      "Iteration 7931: Weights = [5.50000000e+01 3.31963592e+00 6.97958767e+00 2.29954811e-02\n",
      " 2.32382736e-01 1.20666848e+01], Loss = 0.3277\n",
      "Iteration 7932: Weights = [5.50000000e+01 3.31954063e+00 6.97938732e+00 2.29948210e-02\n",
      " 2.32376065e-01 1.20668964e+01], Loss = 0.3277\n",
      "Iteration 7933: Weights = [5.50000000e+01 3.31944533e+00 6.97918696e+00 2.29941609e-02\n",
      " 2.32369394e-01 1.20671081e+01], Loss = 0.3277\n",
      "Iteration 7934: Weights = [5.50000000e+01 3.31935005e+00 6.97898662e+00 2.29935008e-02\n",
      " 2.32362724e-01 1.20673198e+01], Loss = 0.3277\n",
      "Iteration 7935: Weights = [5.50000000e+01 3.31925476e+00 6.97878628e+00 2.29928407e-02\n",
      " 2.32356053e-01 1.20675314e+01], Loss = 0.3277\n",
      "Iteration 7936: Weights = [5.50000000e+01 3.31915948e+00 6.97858594e+00 2.29921807e-02\n",
      " 2.32349383e-01 1.20677431e+01], Loss = 0.3276\n",
      "Iteration 7937: Weights = [5.50000000e+01 3.31906420e+00 6.97838561e+00 2.29915207e-02\n",
      " 2.32342713e-01 1.20679547e+01], Loss = 0.3276\n",
      "Iteration 7938: Weights = [5.50000000e+01 3.31896892e+00 6.97818529e+00 2.29908607e-02\n",
      " 2.32336044e-01 1.20681663e+01], Loss = 0.3276\n",
      "Iteration 7939: Weights = [5.50000000e+01 3.31887364e+00 6.97798497e+00 2.29902007e-02\n",
      " 2.32329374e-01 1.20683780e+01], Loss = 0.3276\n",
      "Iteration 7940: Weights = [5.50000000e+01 3.31877837e+00 6.97778466e+00 2.29895407e-02\n",
      " 2.32322705e-01 1.20685896e+01], Loss = 0.3276\n",
      "Iteration 7941: Weights = [5.50000000e+01 3.31868310e+00 6.97758435e+00 2.29888808e-02\n",
      " 2.32316036e-01 1.20688012e+01], Loss = 0.3275\n",
      "Iteration 7942: Weights = [5.50000000e+01 3.31858783e+00 6.97738405e+00 2.29882209e-02\n",
      " 2.32309367e-01 1.20690128e+01], Loss = 0.3275\n",
      "Iteration 7943: Weights = [5.50000000e+01 3.31849257e+00 6.97718376e+00 2.29875610e-02\n",
      " 2.32302698e-01 1.20692245e+01], Loss = 0.3275\n",
      "Iteration 7944: Weights = [5.50000000e+01 3.31839731e+00 6.97698347e+00 2.29869011e-02\n",
      " 2.32296029e-01 1.20694361e+01], Loss = 0.3275\n",
      "Iteration 7945: Weights = [5.50000000e+01 3.31830205e+00 6.97678318e+00 2.29862412e-02\n",
      " 2.32289361e-01 1.20696477e+01], Loss = 0.3275\n",
      "Iteration 7946: Weights = [5.50000000e+01 3.31820679e+00 6.97658291e+00 2.29855814e-02\n",
      " 2.32282693e-01 1.20698592e+01], Loss = 0.3275\n",
      "Iteration 7947: Weights = [5.50000000e+01 3.31811154e+00 6.97638263e+00 2.29849215e-02\n",
      " 2.32276025e-01 1.20700708e+01], Loss = 0.3274\n",
      "Iteration 7948: Weights = [5.50000000e+01 3.31801629e+00 6.97618237e+00 2.29842617e-02\n",
      " 2.32269357e-01 1.20702824e+01], Loss = 0.3274\n",
      "Iteration 7949: Weights = [5.50000000e+01 3.31792104e+00 6.97598211e+00 2.29836019e-02\n",
      " 2.32262690e-01 1.20704940e+01], Loss = 0.3274\n",
      "Iteration 7950: Weights = [5.50000000e+01 3.31782579e+00 6.97578185e+00 2.29829421e-02\n",
      " 2.32256022e-01 1.20707055e+01], Loss = 0.3274\n",
      "Iteration 7951: Weights = [5.50000000e+01 3.31773055e+00 6.97558160e+00 2.29822824e-02\n",
      " 2.32249355e-01 1.20709171e+01], Loss = 0.3274\n",
      "Iteration 7952: Weights = [5.50000000e+01 3.31763531e+00 6.97538136e+00 2.29816227e-02\n",
      " 2.32242688e-01 1.20711287e+01], Loss = 0.3273\n",
      "Iteration 7953: Weights = [5.50000000e+01 3.31754007e+00 6.97518112e+00 2.29809629e-02\n",
      " 2.32236021e-01 1.20713402e+01], Loss = 0.3273\n",
      "Iteration 7954: Weights = [5.50000000e+01 3.31744484e+00 6.97498089e+00 2.29803032e-02\n",
      " 2.32229354e-01 1.20715517e+01], Loss = 0.3273\n",
      "Iteration 7955: Weights = [5.50000000e+01 3.31734961e+00 6.97478066e+00 2.29796436e-02\n",
      " 2.32222688e-01 1.20717633e+01], Loss = 0.3273\n",
      "Iteration 7956: Weights = [5.50000000e+01 3.31725438e+00 6.97458044e+00 2.29789839e-02\n",
      " 2.32216022e-01 1.20719748e+01], Loss = 0.3273\n",
      "Iteration 7957: Weights = [5.50000000e+01 3.31715915e+00 6.97438023e+00 2.29783243e-02\n",
      " 2.32209356e-01 1.20721863e+01], Loss = 0.3272\n",
      "Iteration 7958: Weights = [5.50000000e+01 3.31706393e+00 6.97418002e+00 2.29776646e-02\n",
      " 2.32202690e-01 1.20723978e+01], Loss = 0.3272\n",
      "Iteration 7959: Weights = [5.50000000e+01 3.31696871e+00 6.97397982e+00 2.29770050e-02\n",
      " 2.32196024e-01 1.20726094e+01], Loss = 0.3272\n",
      "Iteration 7960: Weights = [5.50000000e+01 3.31687349e+00 6.97377962e+00 2.29763454e-02\n",
      " 2.32189359e-01 1.20728209e+01], Loss = 0.3272\n",
      "Iteration 7961: Weights = [5.50000000e+01 3.31677828e+00 6.97357943e+00 2.29756859e-02\n",
      " 2.32182693e-01 1.20730324e+01], Loss = 0.3272\n",
      "Iteration 7962: Weights = [5.50000000e+01 3.31668306e+00 6.97337924e+00 2.29750263e-02\n",
      " 2.32176028e-01 1.20732439e+01], Loss = 0.3272\n",
      "Iteration 7963: Weights = [5.50000000e+01 3.31658785e+00 6.97317906e+00 2.29743668e-02\n",
      " 2.32169363e-01 1.20734553e+01], Loss = 0.3271\n",
      "Iteration 7964: Weights = [5.50000000e+01 3.31649265e+00 6.97297889e+00 2.29737073e-02\n",
      " 2.32162699e-01 1.20736668e+01], Loss = 0.3271\n",
      "Iteration 7965: Weights = [5.50000000e+01 3.31639744e+00 6.97277872e+00 2.29730478e-02\n",
      " 2.32156034e-01 1.20738783e+01], Loss = 0.3271\n",
      "Iteration 7966: Weights = [5.50000000e+01 3.31630224e+00 6.97257856e+00 2.29723883e-02\n",
      " 2.32149370e-01 1.20740898e+01], Loss = 0.3271\n",
      "Iteration 7967: Weights = [5.50000000e+01 3.31620704e+00 6.97237840e+00 2.29717289e-02\n",
      " 2.32142706e-01 1.20743012e+01], Loss = 0.3271\n",
      "Iteration 7968: Weights = [5.50000000e+01 3.31611185e+00 6.97217825e+00 2.29710694e-02\n",
      " 2.32136042e-01 1.20745127e+01], Loss = 0.3270\n",
      "Iteration 7969: Weights = [5.50000000e+01 3.31601665e+00 6.97197811e+00 2.29704100e-02\n",
      " 2.32129378e-01 1.20747241e+01], Loss = 0.3270\n",
      "Iteration 7970: Weights = [5.50000000e+01 3.31592146e+00 6.97177797e+00 2.29697506e-02\n",
      " 2.32122714e-01 1.20749356e+01], Loss = 0.3270\n",
      "Iteration 7971: Weights = [5.50000000e+01 3.31582627e+00 6.97157783e+00 2.29690913e-02\n",
      " 2.32116051e-01 1.20751470e+01], Loss = 0.3270\n",
      "Iteration 7972: Weights = [5.50000000e+01 3.31573109e+00 6.97137770e+00 2.29684319e-02\n",
      " 2.32109388e-01 1.20753585e+01], Loss = 0.3270\n",
      "Iteration 7973: Weights = [5.50000000e+01 3.31563591e+00 6.97117758e+00 2.29677726e-02\n",
      " 2.32102725e-01 1.20755699e+01], Loss = 0.3269\n",
      "Iteration 7974: Weights = [5.50000000e+01 3.31554073e+00 6.97097746e+00 2.29671132e-02\n",
      " 2.32096062e-01 1.20757813e+01], Loss = 0.3269\n",
      "Iteration 7975: Weights = [5.50000000e+01 3.31544555e+00 6.97077735e+00 2.29664539e-02\n",
      " 2.32089399e-01 1.20759927e+01], Loss = 0.3269\n",
      "Iteration 7976: Weights = [5.50000000e+01 3.31535038e+00 6.97057725e+00 2.29657947e-02\n",
      " 2.32082737e-01 1.20762041e+01], Loss = 0.3269\n",
      "Iteration 7977: Weights = [5.50000000e+01 3.31525520e+00 6.97037715e+00 2.29651354e-02\n",
      " 2.32076075e-01 1.20764155e+01], Loss = 0.3269\n",
      "Iteration 7978: Weights = [5.50000000e+01 3.31516004e+00 6.97017705e+00 2.29644761e-02\n",
      " 2.32069412e-01 1.20766269e+01], Loss = 0.3269\n",
      "Iteration 7979: Weights = [5.50000000e+01 3.31506487e+00 6.96997697e+00 2.29638169e-02\n",
      " 2.32062751e-01 1.20768383e+01], Loss = 0.3268\n",
      "Iteration 7980: Weights = [5.50000000e+01 3.31496971e+00 6.96977688e+00 2.29631577e-02\n",
      " 2.32056089e-01 1.20770497e+01], Loss = 0.3268\n",
      "Iteration 7981: Weights = [5.50000000e+01 3.31487455e+00 6.96957681e+00 2.29624985e-02\n",
      " 2.32049427e-01 1.20772611e+01], Loss = 0.3268\n",
      "Iteration 7982: Weights = [5.50000000e+01 3.31477939e+00 6.96937674e+00 2.29618394e-02\n",
      " 2.32042766e-01 1.20774724e+01], Loss = 0.3268\n",
      "Iteration 7983: Weights = [5.50000000e+01 3.31468423e+00 6.96917667e+00 2.29611802e-02\n",
      " 2.32036105e-01 1.20776838e+01], Loss = 0.3268\n",
      "Iteration 7984: Weights = [5.50000000e+01 3.31458908e+00 6.96897661e+00 2.29605211e-02\n",
      " 2.32029444e-01 1.20778952e+01], Loss = 0.3267\n",
      "Iteration 7985: Weights = [5.50000000e+01 3.31449393e+00 6.96877656e+00 2.29598620e-02\n",
      " 2.32022783e-01 1.20781065e+01], Loss = 0.3267\n",
      "Iteration 7986: Weights = [5.50000000e+01 3.31439878e+00 6.96857651e+00 2.29592029e-02\n",
      " 2.32016123e-01 1.20783179e+01], Loss = 0.3267\n",
      "Iteration 7987: Weights = [5.50000000e+01 3.31430364e+00 6.96837647e+00 2.29585438e-02\n",
      " 2.32009463e-01 1.20785292e+01], Loss = 0.3267\n",
      "Iteration 7988: Weights = [5.50000000e+01 3.31420850e+00 6.96817643e+00 2.29578847e-02\n",
      " 2.32002803e-01 1.20787405e+01], Loss = 0.3267\n",
      "Iteration 7989: Weights = [5.50000000e+01 3.31411336e+00 6.96797640e+00 2.29572257e-02\n",
      " 2.31996143e-01 1.20789519e+01], Loss = 0.3266\n",
      "Iteration 7990: Weights = [5.50000000e+01 3.31401822e+00 6.96777638e+00 2.29565667e-02\n",
      " 2.31989483e-01 1.20791632e+01], Loss = 0.3266\n",
      "Iteration 7991: Weights = [5.50000000e+01 3.31392309e+00 6.96757636e+00 2.29559077e-02\n",
      " 2.31982823e-01 1.20793745e+01], Loss = 0.3266\n",
      "Iteration 7992: Weights = [5.50000000e+01 3.31382796e+00 6.96737634e+00 2.29552487e-02\n",
      " 2.31976164e-01 1.20795858e+01], Loss = 0.3266\n",
      "Iteration 7993: Weights = [5.50000000e+01 3.31373283e+00 6.96717634e+00 2.29545898e-02\n",
      " 2.31969505e-01 1.20797971e+01], Loss = 0.3266\n",
      "Iteration 7994: Weights = [5.50000000e+01 3.31363771e+00 6.96697633e+00 2.29539308e-02\n",
      " 2.31962846e-01 1.20800084e+01], Loss = 0.3266\n",
      "Iteration 7995: Weights = [5.50000000e+01 3.31354259e+00 6.96677634e+00 2.29532719e-02\n",
      " 2.31956187e-01 1.20802197e+01], Loss = 0.3265\n",
      "Iteration 7996: Weights = [5.50000000e+01 3.31344747e+00 6.96657635e+00 2.29526130e-02\n",
      " 2.31949528e-01 1.20804310e+01], Loss = 0.3265\n",
      "Iteration 7997: Weights = [5.50000000e+01 3.31335235e+00 6.96637636e+00 2.29519541e-02\n",
      " 2.31942870e-01 1.20806423e+01], Loss = 0.3265\n",
      "Iteration 7998: Weights = [5.50000000e+01 3.31325723e+00 6.96617638e+00 2.29512952e-02\n",
      " 2.31936212e-01 1.20808536e+01], Loss = 0.3265\n",
      "Iteration 7999: Weights = [5.50000000e+01 3.31316212e+00 6.96597641e+00 2.29506364e-02\n",
      " 2.31929554e-01 1.20810648e+01], Loss = 0.3265\n",
      "Iteration 8000: Weights = [5.50000000e+01 3.31306701e+00 6.96577644e+00 2.29499776e-02\n",
      " 2.31922896e-01 1.20812761e+01], Loss = 0.3264\n",
      "Iteration 8001: Weights = [5.50000000e+01 3.31297191e+00 6.96557648e+00 2.29493188e-02\n",
      " 2.31916238e-01 1.20814874e+01], Loss = 0.3264\n",
      "Iteration 8002: Weights = [5.50000000e+01 3.31287681e+00 6.96537653e+00 2.29486600e-02\n",
      " 2.31909581e-01 1.20816986e+01], Loss = 0.3264\n",
      "Iteration 8003: Weights = [5.50000000e+01 3.31278170e+00 6.96517658e+00 2.29480012e-02\n",
      " 2.31902923e-01 1.20819098e+01], Loss = 0.3264\n",
      "Iteration 8004: Weights = [5.50000000e+01 3.31268661e+00 6.96497663e+00 2.29473424e-02\n",
      " 2.31896266e-01 1.20821211e+01], Loss = 0.3264\n",
      "Iteration 8005: Weights = [5.50000000e+01 3.31259151e+00 6.96477669e+00 2.29466837e-02\n",
      " 2.31889609e-01 1.20823323e+01], Loss = 0.3263\n",
      "Iteration 8006: Weights = [5.50000000e+01 3.31249642e+00 6.96457676e+00 2.29460250e-02\n",
      " 2.31882953e-01 1.20825435e+01], Loss = 0.3263\n",
      "Iteration 8007: Weights = [5.50000000e+01 3.31240133e+00 6.96437683e+00 2.29453663e-02\n",
      " 2.31876296e-01 1.20827548e+01], Loss = 0.3263\n",
      "Iteration 8008: Weights = [5.50000000e+01 3.31230624e+00 6.96417691e+00 2.29447076e-02\n",
      " 2.31869640e-01 1.20829660e+01], Loss = 0.3263\n",
      "Iteration 8009: Weights = [5.50000000e+01 3.31221116e+00 6.96397699e+00 2.29440490e-02\n",
      " 2.31862984e-01 1.20831772e+01], Loss = 0.3263\n",
      "Iteration 8010: Weights = [5.50000000e+01 3.31211608e+00 6.96377708e+00 2.29433903e-02\n",
      " 2.31856328e-01 1.20833884e+01], Loss = 0.3263\n",
      "Iteration 8011: Weights = [5.50000000e+01 3.31202100e+00 6.96357718e+00 2.29427317e-02\n",
      " 2.31849672e-01 1.20835996e+01], Loss = 0.3262\n",
      "Iteration 8012: Weights = [5.50000000e+01 3.31192592e+00 6.96337728e+00 2.29420731e-02\n",
      " 2.31843017e-01 1.20838108e+01], Loss = 0.3262\n",
      "Iteration 8013: Weights = [5.50000000e+01 3.31183085e+00 6.96317739e+00 2.29414145e-02\n",
      " 2.31836361e-01 1.20840220e+01], Loss = 0.3262\n",
      "Iteration 8014: Weights = [5.50000000e+01 3.31173578e+00 6.96297750e+00 2.29407560e-02\n",
      " 2.31829706e-01 1.20842331e+01], Loss = 0.3262\n",
      "Iteration 8015: Weights = [5.50000000e+01 3.31164071e+00 6.96277762e+00 2.29400974e-02\n",
      " 2.31823051e-01 1.20844443e+01], Loss = 0.3262\n",
      "Iteration 8016: Weights = [5.50000000e+01 3.31154565e+00 6.96257774e+00 2.29394389e-02\n",
      " 2.31816396e-01 1.20846555e+01], Loss = 0.3261\n",
      "Iteration 8017: Weights = [5.50000000e+01 3.31145059e+00 6.96237787e+00 2.29387804e-02\n",
      " 2.31809742e-01 1.20848666e+01], Loss = 0.3261\n",
      "Iteration 8018: Weights = [5.50000000e+01 3.31135553e+00 6.96217801e+00 2.29381219e-02\n",
      " 2.31803087e-01 1.20850778e+01], Loss = 0.3261\n",
      "Iteration 8019: Weights = [5.50000000e+01 3.31126047e+00 6.96197815e+00 2.29374634e-02\n",
      " 2.31796433e-01 1.20852889e+01], Loss = 0.3261\n",
      "Iteration 8020: Weights = [5.50000000e+01 3.31116541e+00 6.96177830e+00 2.29368050e-02\n",
      " 2.31789779e-01 1.20855001e+01], Loss = 0.3261\n",
      "Iteration 8021: Weights = [5.50000000e+01 3.31107036e+00 6.96157845e+00 2.29361465e-02\n",
      " 2.31783125e-01 1.20857112e+01], Loss = 0.3260\n",
      "Iteration 8022: Weights = [5.50000000e+01 3.31097531e+00 6.96137861e+00 2.29354881e-02\n",
      " 2.31776472e-01 1.20859223e+01], Loss = 0.3260\n",
      "Iteration 8023: Weights = [5.50000000e+01 3.31088027e+00 6.96117878e+00 2.29348297e-02\n",
      " 2.31769818e-01 1.20861335e+01], Loss = 0.3260\n",
      "Iteration 8024: Weights = [5.50000000e+01 3.31078523e+00 6.96097895e+00 2.29341714e-02\n",
      " 2.31763165e-01 1.20863446e+01], Loss = 0.3260\n",
      "Iteration 8025: Weights = [5.50000000e+01 3.31069019e+00 6.96077912e+00 2.29335130e-02\n",
      " 2.31756512e-01 1.20865557e+01], Loss = 0.3260\n",
      "Iteration 8026: Weights = [5.50000000e+01 3.31059515e+00 6.96057930e+00 2.29328547e-02\n",
      " 2.31749859e-01 1.20867668e+01], Loss = 0.3260\n",
      "Iteration 8027: Weights = [5.50000000e+01 3.31050011e+00 6.96037949e+00 2.29321964e-02\n",
      " 2.31743206e-01 1.20869779e+01], Loss = 0.3259\n",
      "Iteration 8028: Weights = [5.50000000e+01 3.31040508e+00 6.96017968e+00 2.29315381e-02\n",
      " 2.31736554e-01 1.20871890e+01], Loss = 0.3259\n",
      "Iteration 8029: Weights = [5.50000000e+01 3.31031005e+00 6.95997988e+00 2.29308798e-02\n",
      " 2.31729902e-01 1.20874001e+01], Loss = 0.3259\n",
      "Iteration 8030: Weights = [5.50000000e+01 3.31021502e+00 6.95978009e+00 2.29302215e-02\n",
      " 2.31723249e-01 1.20876111e+01], Loss = 0.3259\n",
      "Iteration 8031: Weights = [5.50000000e+01 3.31012000e+00 6.95958030e+00 2.29295633e-02\n",
      " 2.31716597e-01 1.20878222e+01], Loss = 0.3259\n",
      "Iteration 8032: Weights = [5.50000000e+01 3.31002498e+00 6.95938051e+00 2.29289050e-02\n",
      " 2.31709946e-01 1.20880333e+01], Loss = 0.3258\n",
      "Iteration 8033: Weights = [5.50000000e+01 3.30992996e+00 6.95918074e+00 2.29282468e-02\n",
      " 2.31703294e-01 1.20882444e+01], Loss = 0.3258\n",
      "Iteration 8034: Weights = [5.50000000e+01 3.30983494e+00 6.95898096e+00 2.29275887e-02\n",
      " 2.31696643e-01 1.20884554e+01], Loss = 0.3258\n",
      "Iteration 8035: Weights = [5.50000000e+01 3.30973993e+00 6.95878120e+00 2.29269305e-02\n",
      " 2.31689992e-01 1.20886665e+01], Loss = 0.3258\n",
      "Iteration 8036: Weights = [5.50000000e+01 3.30964492e+00 6.95858144e+00 2.29262723e-02\n",
      " 2.31683341e-01 1.20888775e+01], Loss = 0.3258\n",
      "Iteration 8037: Weights = [5.50000000e+01 3.30954991e+00 6.95838168e+00 2.29256142e-02\n",
      " 2.31676690e-01 1.20890885e+01], Loss = 0.3257\n",
      "Iteration 8038: Weights = [5.50000000e+01 3.30945491e+00 6.95818193e+00 2.29249561e-02\n",
      " 2.31670039e-01 1.20892996e+01], Loss = 0.3257\n",
      "Iteration 8039: Weights = [5.50000000e+01 3.30935991e+00 6.95798219e+00 2.29242980e-02\n",
      " 2.31663389e-01 1.20895106e+01], Loss = 0.3257\n",
      "Iteration 8040: Weights = [5.50000000e+01 3.30926491e+00 6.95778245e+00 2.29236399e-02\n",
      " 2.31656739e-01 1.20897216e+01], Loss = 0.3257\n",
      "Iteration 8041: Weights = [5.50000000e+01 3.30916991e+00 6.95758272e+00 2.29229819e-02\n",
      " 2.31650089e-01 1.20899326e+01], Loss = 0.3257\n",
      "Iteration 8042: Weights = [5.50000000e+01 3.30907492e+00 6.95738299e+00 2.29223239e-02\n",
      " 2.31643439e-01 1.20901436e+01], Loss = 0.3257\n",
      "Iteration 8043: Weights = [5.50000000e+01 3.30897992e+00 6.95718327e+00 2.29216658e-02\n",
      " 2.31636789e-01 1.20903546e+01], Loss = 0.3256\n",
      "Iteration 8044: Weights = [5.50000000e+01 3.30888494e+00 6.95698356e+00 2.29210078e-02\n",
      " 2.31630140e-01 1.20905656e+01], Loss = 0.3256\n",
      "Iteration 8045: Weights = [5.50000000e+01 3.30878995e+00 6.95678385e+00 2.29203499e-02\n",
      " 2.31623491e-01 1.20907766e+01], Loss = 0.3256\n",
      "Iteration 8046: Weights = [5.50000000e+01 3.30869497e+00 6.95658414e+00 2.29196919e-02\n",
      " 2.31616842e-01 1.20909876e+01], Loss = 0.3256\n",
      "Iteration 8047: Weights = [5.50000000e+01 3.30859999e+00 6.95638444e+00 2.29190340e-02\n",
      " 2.31610193e-01 1.20911986e+01], Loss = 0.3256\n",
      "Iteration 8048: Weights = [5.50000000e+01 3.30850501e+00 6.95618475e+00 2.29183760e-02\n",
      " 2.31603544e-01 1.20914096e+01], Loss = 0.3255\n",
      "Iteration 8049: Weights = [5.50000000e+01 3.30841003e+00 6.95598507e+00 2.29177181e-02\n",
      " 2.31596896e-01 1.20916205e+01], Loss = 0.3255\n",
      "Iteration 8050: Weights = [5.50000000e+01 3.30831506e+00 6.95578539e+00 2.29170603e-02\n",
      " 2.31590247e-01 1.20918315e+01], Loss = 0.3255\n",
      "Iteration 8051: Weights = [5.50000000e+01 3.30822009e+00 6.95558571e+00 2.29164024e-02\n",
      " 2.31583599e-01 1.20920424e+01], Loss = 0.3255\n",
      "Iteration 8052: Weights = [5.50000000e+01 3.30812512e+00 6.95538604e+00 2.29157446e-02\n",
      " 2.31576951e-01 1.20922534e+01], Loss = 0.3255\n",
      "Iteration 8053: Weights = [5.50000000e+01 3.30803016e+00 6.95518638e+00 2.29150867e-02\n",
      " 2.31570304e-01 1.20924643e+01], Loss = 0.3254\n",
      "Iteration 8054: Weights = [5.50000000e+01 3.30793520e+00 6.95498672e+00 2.29144289e-02\n",
      " 2.31563656e-01 1.20926753e+01], Loss = 0.3254\n",
      "Iteration 8055: Weights = [5.50000000e+01 3.30784024e+00 6.95478707e+00 2.29137711e-02\n",
      " 2.31557009e-01 1.20928862e+01], Loss = 0.3254\n",
      "Iteration 8056: Weights = [5.50000000e+01 3.30774528e+00 6.95458742e+00 2.29131134e-02\n",
      " 2.31550362e-01 1.20930971e+01], Loss = 0.3254\n",
      "Iteration 8057: Weights = [5.50000000e+01 3.30765033e+00 6.95438778e+00 2.29124556e-02\n",
      " 2.31543715e-01 1.20933080e+01], Loss = 0.3254\n",
      "Iteration 8058: Weights = [5.50000000e+01 3.30755538e+00 6.95418815e+00 2.29117979e-02\n",
      " 2.31537068e-01 1.20935189e+01], Loss = 0.3254\n",
      "Iteration 8059: Weights = [5.50000000e+01 3.30746043e+00 6.95398852e+00 2.29111402e-02\n",
      " 2.31530421e-01 1.20937299e+01], Loss = 0.3253\n",
      "Iteration 8060: Weights = [5.50000000e+01 3.30736549e+00 6.95378889e+00 2.29104825e-02\n",
      " 2.31523775e-01 1.20939407e+01], Loss = 0.3253\n",
      "Iteration 8061: Weights = [5.50000000e+01 3.30727055e+00 6.95358928e+00 2.29098248e-02\n",
      " 2.31517129e-01 1.20941516e+01], Loss = 0.3253\n",
      "Iteration 8062: Weights = [5.50000000e+01 3.30717561e+00 6.95338966e+00 2.29091671e-02\n",
      " 2.31510483e-01 1.20943625e+01], Loss = 0.3253\n",
      "Iteration 8063: Weights = [5.50000000e+01 3.30708067e+00 6.95319006e+00 2.29085095e-02\n",
      " 2.31503837e-01 1.20945734e+01], Loss = 0.3253\n",
      "Iteration 8064: Weights = [5.50000000e+01 3.30698574e+00 6.95299046e+00 2.29078519e-02\n",
      " 2.31497191e-01 1.20947843e+01], Loss = 0.3252\n",
      "Iteration 8065: Weights = [5.50000000e+01 3.30689080e+00 6.95279086e+00 2.29071943e-02\n",
      " 2.31490546e-01 1.20949952e+01], Loss = 0.3252\n",
      "Iteration 8066: Weights = [5.50000000e+01 3.30679588e+00 6.95259127e+00 2.29065367e-02\n",
      " 2.31483901e-01 1.20952060e+01], Loss = 0.3252\n",
      "Iteration 8067: Weights = [5.50000000e+01 3.30670095e+00 6.95239169e+00 2.29058791e-02\n",
      " 2.31477256e-01 1.20954169e+01], Loss = 0.3252\n",
      "Iteration 8068: Weights = [5.50000000e+01 3.30660603e+00 6.95219211e+00 2.29052216e-02\n",
      " 2.31470611e-01 1.20956277e+01], Loss = 0.3252\n",
      "Iteration 8069: Weights = [5.50000000e+01 3.30651111e+00 6.95199254e+00 2.29045641e-02\n",
      " 2.31463966e-01 1.20958386e+01], Loss = 0.3252\n",
      "Iteration 8070: Weights = [5.50000000e+01 3.30641619e+00 6.95179298e+00 2.29039066e-02\n",
      " 2.31457322e-01 1.20960494e+01], Loss = 0.3251\n",
      "Iteration 8071: Weights = [5.50000000e+01 3.30632127e+00 6.95159342e+00 2.29032491e-02\n",
      " 2.31450677e-01 1.20962602e+01], Loss = 0.3251\n",
      "Iteration 8072: Weights = [5.50000000e+01 3.30622636e+00 6.95139386e+00 2.29025916e-02\n",
      " 2.31444033e-01 1.20964711e+01], Loss = 0.3251\n",
      "Iteration 8073: Weights = [5.50000000e+01 3.30613145e+00 6.95119431e+00 2.29019342e-02\n",
      " 2.31437389e-01 1.20966819e+01], Loss = 0.3251\n",
      "Iteration 8074: Weights = [5.50000000e+01 3.30603655e+00 6.95099477e+00 2.29012767e-02\n",
      " 2.31430746e-01 1.20968927e+01], Loss = 0.3251\n",
      "Iteration 8075: Weights = [5.50000000e+01 3.30594164e+00 6.95079523e+00 2.29006193e-02\n",
      " 2.31424102e-01 1.20971035e+01], Loss = 0.3250\n",
      "Iteration 8076: Weights = [5.50000000e+01 3.30584674e+00 6.95059570e+00 2.28999619e-02\n",
      " 2.31417459e-01 1.20973143e+01], Loss = 0.3250\n",
      "Iteration 8077: Weights = [5.50000000e+01 3.30575184e+00 6.95039617e+00 2.28993046e-02\n",
      " 2.31410816e-01 1.20975251e+01], Loss = 0.3250\n",
      "Iteration 8078: Weights = [5.50000000e+01 3.30565694e+00 6.95019665e+00 2.28986472e-02\n",
      " 2.31404173e-01 1.20977359e+01], Loss = 0.3250\n",
      "Iteration 8079: Weights = [5.50000000e+01 3.30556205e+00 6.94999714e+00 2.28979899e-02\n",
      " 2.31397530e-01 1.20979467e+01], Loss = 0.3250\n",
      "Iteration 8080: Weights = [5.50000000e+01 3.30546716e+00 6.94979763e+00 2.28973325e-02\n",
      " 2.31390887e-01 1.20981575e+01], Loss = 0.3249\n",
      "Iteration 8081: Weights = [5.50000000e+01 3.30537227e+00 6.94959813e+00 2.28966752e-02\n",
      " 2.31384245e-01 1.20983682e+01], Loss = 0.3249\n",
      "Iteration 8082: Weights = [5.50000000e+01 3.30527739e+00 6.94939863e+00 2.28960180e-02\n",
      " 2.31377603e-01 1.20985790e+01], Loss = 0.3249\n",
      "Iteration 8083: Weights = [5.50000000e+01 3.30518251e+00 6.94919914e+00 2.28953607e-02\n",
      " 2.31370961e-01 1.20987898e+01], Loss = 0.3249\n",
      "Iteration 8084: Weights = [5.50000000e+01 3.30508763e+00 6.94899965e+00 2.28947035e-02\n",
      " 2.31364319e-01 1.20990005e+01], Loss = 0.3249\n",
      "Iteration 8085: Weights = [5.50000000e+01 3.30499275e+00 6.94880017e+00 2.28940462e-02\n",
      " 2.31357677e-01 1.20992113e+01], Loss = 0.3249\n",
      "Iteration 8086: Weights = [5.50000000e+01 3.30489788e+00 6.94860070e+00 2.28933890e-02\n",
      " 2.31351036e-01 1.20994220e+01], Loss = 0.3248\n",
      "Iteration 8087: Weights = [5.50000000e+01 3.30480300e+00 6.94840123e+00 2.28927319e-02\n",
      " 2.31344395e-01 1.20996327e+01], Loss = 0.3248\n",
      "Iteration 8088: Weights = [5.50000000e+01 3.30470814e+00 6.94820177e+00 2.28920747e-02\n",
      " 2.31337754e-01 1.20998435e+01], Loss = 0.3248\n",
      "Iteration 8089: Weights = [5.50000000e+01 3.30461327e+00 6.94800231e+00 2.28914175e-02\n",
      " 2.31331113e-01 1.21000542e+01], Loss = 0.3248\n",
      "Iteration 8090: Weights = [5.50000000e+01 3.30451841e+00 6.94780286e+00 2.28907604e-02\n",
      " 2.31324472e-01 1.21002649e+01], Loss = 0.3248\n",
      "Iteration 8091: Weights = [5.50000000e+01 3.30442355e+00 6.94760341e+00 2.28901033e-02\n",
      " 2.31317832e-01 1.21004756e+01], Loss = 0.3247\n",
      "Iteration 8092: Weights = [5.50000000e+01 3.30432869e+00 6.94740397e+00 2.28894462e-02\n",
      " 2.31311191e-01 1.21006863e+01], Loss = 0.3247\n",
      "Iteration 8093: Weights = [5.50000000e+01 3.30423383e+00 6.94720454e+00 2.28887891e-02\n",
      " 2.31304551e-01 1.21008970e+01], Loss = 0.3247\n",
      "Iteration 8094: Weights = [5.50000000e+01 3.30413898e+00 6.94700511e+00 2.28881321e-02\n",
      " 2.31297911e-01 1.21011077e+01], Loss = 0.3247\n",
      "Iteration 8095: Weights = [5.50000000e+01 3.30404413e+00 6.94680569e+00 2.28874751e-02\n",
      " 2.31291272e-01 1.21013184e+01], Loss = 0.3247\n",
      "Iteration 8096: Weights = [5.50000000e+01 3.30394928e+00 6.94660627e+00 2.28868180e-02\n",
      " 2.31284632e-01 1.21015291e+01], Loss = 0.3246\n",
      "Iteration 8097: Weights = [5.50000000e+01 3.30385444e+00 6.94640686e+00 2.28861610e-02\n",
      " 2.31277993e-01 1.21017398e+01], Loss = 0.3246\n",
      "Iteration 8098: Weights = [5.50000000e+01 3.30375960e+00 6.94620745e+00 2.28855041e-02\n",
      " 2.31271354e-01 1.21019504e+01], Loss = 0.3246\n",
      "Iteration 8099: Weights = [5.50000000e+01 3.30366476e+00 6.94600805e+00 2.28848471e-02\n",
      " 2.31264715e-01 1.21021611e+01], Loss = 0.3246\n",
      "Iteration 8100: Weights = [5.50000000e+01 3.30356992e+00 6.94580866e+00 2.28841902e-02\n",
      " 2.31258076e-01 1.21023717e+01], Loss = 0.3246\n",
      "Iteration 8101: Weights = [5.50000000e+01 3.30347509e+00 6.94560927e+00 2.28835333e-02\n",
      " 2.31251437e-01 1.21025824e+01], Loss = 0.3246\n",
      "Iteration 8102: Weights = [5.50000000e+01 3.30338026e+00 6.94540989e+00 2.28828764e-02\n",
      " 2.31244799e-01 1.21027930e+01], Loss = 0.3245\n",
      "Iteration 8103: Weights = [5.50000000e+01 3.30328543e+00 6.94521051e+00 2.28822195e-02\n",
      " 2.31238161e-01 1.21030037e+01], Loss = 0.3245\n",
      "Iteration 8104: Weights = [5.50000000e+01 3.30319061e+00 6.94501114e+00 2.28815626e-02\n",
      " 2.31231523e-01 1.21032143e+01], Loss = 0.3245\n",
      "Iteration 8105: Weights = [5.50000000e+01 3.30309578e+00 6.94481177e+00 2.28809058e-02\n",
      " 2.31224885e-01 1.21034249e+01], Loss = 0.3245\n",
      "Iteration 8106: Weights = [5.50000000e+01 3.30300096e+00 6.94461241e+00 2.28802489e-02\n",
      " 2.31218247e-01 1.21036356e+01], Loss = 0.3245\n",
      "Iteration 8107: Weights = [5.50000000e+01 3.30290615e+00 6.94441306e+00 2.28795921e-02\n",
      " 2.31211610e-01 1.21038462e+01], Loss = 0.3244\n",
      "Iteration 8108: Weights = [5.50000000e+01 3.30281133e+00 6.94421371e+00 2.28789353e-02\n",
      " 2.31204973e-01 1.21040568e+01], Loss = 0.3244\n",
      "Iteration 8109: Weights = [5.50000000e+01 3.30271652e+00 6.94401437e+00 2.28782786e-02\n",
      " 2.31198336e-01 1.21042674e+01], Loss = 0.3244\n",
      "Iteration 8110: Weights = [5.50000000e+01 3.30262171e+00 6.94381503e+00 2.28776218e-02\n",
      " 2.31191699e-01 1.21044780e+01], Loss = 0.3244\n",
      "Iteration 8111: Weights = [5.50000000e+01 3.30252691e+00 6.94361570e+00 2.28769651e-02\n",
      " 2.31185062e-01 1.21046886e+01], Loss = 0.3244\n",
      "Iteration 8112: Weights = [5.50000000e+01 3.30243210e+00 6.94341637e+00 2.28763084e-02\n",
      " 2.31178426e-01 1.21048992e+01], Loss = 0.3243\n",
      "Iteration 8113: Weights = [5.50000000e+01 3.30233730e+00 6.94321705e+00 2.28756517e-02\n",
      " 2.31171789e-01 1.21051097e+01], Loss = 0.3243\n",
      "Iteration 8114: Weights = [5.50000000e+01 3.30224251e+00 6.94301774e+00 2.28749950e-02\n",
      " 2.31165153e-01 1.21053203e+01], Loss = 0.3243\n",
      "Iteration 8115: Weights = [5.50000000e+01 3.30214771e+00 6.94281843e+00 2.28743383e-02\n",
      " 2.31158517e-01 1.21055309e+01], Loss = 0.3243\n",
      "Iteration 8116: Weights = [5.50000000e+01 3.30205292e+00 6.94261913e+00 2.28736817e-02\n",
      " 2.31151882e-01 1.21057414e+01], Loss = 0.3243\n",
      "Iteration 8117: Weights = [5.50000000e+01 3.30195813e+00 6.94241983e+00 2.28730251e-02\n",
      " 2.31145246e-01 1.21059520e+01], Loss = 0.3243\n",
      "Iteration 8118: Weights = [5.50000000e+01 3.30186334e+00 6.94222054e+00 2.28723685e-02\n",
      " 2.31138611e-01 1.21061625e+01], Loss = 0.3242\n",
      "Iteration 8119: Weights = [5.50000000e+01 3.30176856e+00 6.94202125e+00 2.28717119e-02\n",
      " 2.31131976e-01 1.21063731e+01], Loss = 0.3242\n",
      "Iteration 8120: Weights = [5.50000000e+01 3.30167377e+00 6.94182197e+00 2.28710553e-02\n",
      " 2.31125341e-01 1.21065836e+01], Loss = 0.3242\n",
      "Iteration 8121: Weights = [5.50000000e+01 3.30157900e+00 6.94162270e+00 2.28703988e-02\n",
      " 2.31118706e-01 1.21067941e+01], Loss = 0.3242\n",
      "Iteration 8122: Weights = [5.50000000e+01 3.30148422e+00 6.94142343e+00 2.28697423e-02\n",
      " 2.31112071e-01 1.21070047e+01], Loss = 0.3242\n",
      "Iteration 8123: Weights = [5.50000000e+01 3.30138945e+00 6.94122417e+00 2.28690858e-02\n",
      " 2.31105437e-01 1.21072152e+01], Loss = 0.3241\n",
      "Iteration 8124: Weights = [5.50000000e+01 3.30129468e+00 6.94102491e+00 2.28684293e-02\n",
      " 2.31098803e-01 1.21074257e+01], Loss = 0.3241\n",
      "Iteration 8125: Weights = [5.50000000e+01 3.30119991e+00 6.94082566e+00 2.28677728e-02\n",
      " 2.31092169e-01 1.21076362e+01], Loss = 0.3241\n",
      "Iteration 8126: Weights = [5.50000000e+01 3.30110514e+00 6.94062642e+00 2.28671164e-02\n",
      " 2.31085535e-01 1.21078467e+01], Loss = 0.3241\n",
      "Iteration 8127: Weights = [5.50000000e+01 3.30101038e+00 6.94042718e+00 2.28664599e-02\n",
      " 2.31078901e-01 1.21080572e+01], Loss = 0.3241\n",
      "Iteration 8128: Weights = [5.50000000e+01 3.30091562e+00 6.94022794e+00 2.28658035e-02\n",
      " 2.31072268e-01 1.21082677e+01], Loss = 0.3241\n",
      "Iteration 8129: Weights = [5.50000000e+01 3.30082086e+00 6.94002871e+00 2.28651471e-02\n",
      " 2.31065635e-01 1.21084782e+01], Loss = 0.3240\n",
      "Iteration 8130: Weights = [5.50000000e+01 3.30072611e+00 6.93982949e+00 2.28644908e-02\n",
      " 2.31059002e-01 1.21086886e+01], Loss = 0.3240\n",
      "Iteration 8131: Weights = [5.50000000e+01 3.30063136e+00 6.93963027e+00 2.28638344e-02\n",
      " 2.31052369e-01 1.21088991e+01], Loss = 0.3240\n",
      "Iteration 8132: Weights = [5.50000000e+01 3.30053661e+00 6.93943106e+00 2.28631781e-02\n",
      " 2.31045736e-01 1.21091096e+01], Loss = 0.3240\n",
      "Iteration 8133: Weights = [5.50000000e+01 3.30044186e+00 6.93923186e+00 2.28625217e-02\n",
      " 2.31039104e-01 1.21093200e+01], Loss = 0.3240\n",
      "Iteration 8134: Weights = [5.50000000e+01 3.30034712e+00 6.93903266e+00 2.28618654e-02\n",
      " 2.31032472e-01 1.21095305e+01], Loss = 0.3239\n",
      "Iteration 8135: Weights = [5.50000000e+01 3.30025238e+00 6.93883346e+00 2.28612092e-02\n",
      " 2.31025839e-01 1.21097409e+01], Loss = 0.3239\n",
      "Iteration 8136: Weights = [5.50000000e+01 3.30015764e+00 6.93863428e+00 2.28605529e-02\n",
      " 2.31019208e-01 1.21099514e+01], Loss = 0.3239\n",
      "Iteration 8137: Weights = [5.50000000e+01 3.30006290e+00 6.93843509e+00 2.28598967e-02\n",
      " 2.31012576e-01 1.21101618e+01], Loss = 0.3239\n",
      "Iteration 8138: Weights = [5.50000000e+01 3.29996817e+00 6.93823592e+00 2.28592404e-02\n",
      " 2.31005944e-01 1.21103722e+01], Loss = 0.3239\n",
      "Iteration 8139: Weights = [5.50000000e+01 3.29987344e+00 6.93803674e+00 2.28585842e-02\n",
      " 2.30999313e-01 1.21105826e+01], Loss = 0.3238\n",
      "Iteration 8140: Weights = [5.50000000e+01 3.29977871e+00 6.93783758e+00 2.28579281e-02\n",
      " 2.30992682e-01 1.21107931e+01], Loss = 0.3238\n",
      "Iteration 8141: Weights = [5.50000000e+01 3.29968399e+00 6.93763842e+00 2.28572719e-02\n",
      " 2.30986051e-01 1.21110035e+01], Loss = 0.3238\n",
      "Iteration 8142: Weights = [5.50000000e+01 3.29958927e+00 6.93743927e+00 2.28566157e-02\n",
      " 2.30979420e-01 1.21112139e+01], Loss = 0.3238\n",
      "Iteration 8143: Weights = [5.50000000e+01 3.29949455e+00 6.93724012e+00 2.28559596e-02\n",
      " 2.30972790e-01 1.21114243e+01], Loss = 0.3238\n",
      "Iteration 8144: Weights = [5.50000000e+01 3.29939983e+00 6.93704097e+00 2.28553035e-02\n",
      " 2.30966159e-01 1.21116347e+01], Loss = 0.3238\n",
      "Iteration 8145: Weights = [5.50000000e+01 3.29930512e+00 6.93684184e+00 2.28546474e-02\n",
      " 2.30959529e-01 1.21118450e+01], Loss = 0.3237\n",
      "Iteration 8146: Weights = [5.50000000e+01 3.29921041e+00 6.93664271e+00 2.28539913e-02\n",
      " 2.30952899e-01 1.21120554e+01], Loss = 0.3237\n",
      "Iteration 8147: Weights = [5.50000000e+01 3.29911570e+00 6.93644358e+00 2.28533353e-02\n",
      " 2.30946269e-01 1.21122658e+01], Loss = 0.3237\n",
      "Iteration 8148: Weights = [5.50000000e+01 3.29902099e+00 6.93624446e+00 2.28526792e-02\n",
      " 2.30939640e-01 1.21124762e+01], Loss = 0.3237\n",
      "Iteration 8149: Weights = [5.50000000e+01 3.29892629e+00 6.93604535e+00 2.28520232e-02\n",
      " 2.30933010e-01 1.21126865e+01], Loss = 0.3237\n",
      "Iteration 8150: Weights = [5.50000000e+01 3.29883159e+00 6.93584624e+00 2.28513672e-02\n",
      " 2.30926381e-01 1.21128969e+01], Loss = 0.3236\n",
      "Iteration 8151: Weights = [5.50000000e+01 3.29873689e+00 6.93564714e+00 2.28507113e-02\n",
      " 2.30919752e-01 1.21131072e+01], Loss = 0.3236\n",
      "Iteration 8152: Weights = [5.50000000e+01 3.29864220e+00 6.93544804e+00 2.28500553e-02\n",
      " 2.30913123e-01 1.21133176e+01], Loss = 0.3236\n",
      "Iteration 8153: Weights = [5.50000000e+01 3.29854751e+00 6.93524895e+00 2.28493994e-02\n",
      " 2.30906494e-01 1.21135279e+01], Loss = 0.3236\n",
      "Iteration 8154: Weights = [5.50000000e+01 3.29845282e+00 6.93504986e+00 2.28487434e-02\n",
      " 2.30899866e-01 1.21137382e+01], Loss = 0.3236\n",
      "Iteration 8155: Weights = [5.50000000e+01 3.29835813e+00 6.93485078e+00 2.28480875e-02\n",
      " 2.30893238e-01 1.21139486e+01], Loss = 0.3235\n",
      "Iteration 8156: Weights = [5.50000000e+01 3.29826345e+00 6.93465171e+00 2.28474316e-02\n",
      " 2.30886610e-01 1.21141589e+01], Loss = 0.3235\n",
      "Iteration 8157: Weights = [5.50000000e+01 3.29816877e+00 6.93445264e+00 2.28467758e-02\n",
      " 2.30879982e-01 1.21143692e+01], Loss = 0.3235\n",
      "Iteration 8158: Weights = [5.50000000e+01 3.29807409e+00 6.93425358e+00 2.28461199e-02\n",
      " 2.30873354e-01 1.21145795e+01], Loss = 0.3235\n",
      "Iteration 8159: Weights = [5.50000000e+01 3.29797941e+00 6.93405452e+00 2.28454641e-02\n",
      " 2.30866726e-01 1.21147898e+01], Loss = 0.3235\n",
      "Iteration 8160: Weights = [5.50000000e+01 3.29788474e+00 6.93385547e+00 2.28448083e-02\n",
      " 2.30860099e-01 1.21150001e+01], Loss = 0.3235\n",
      "Iteration 8161: Weights = [5.50000000e+01 3.29779007e+00 6.93365643e+00 2.28441525e-02\n",
      " 2.30853472e-01 1.21152104e+01], Loss = 0.3234\n",
      "Iteration 8162: Weights = [5.50000000e+01 3.29769540e+00 6.93345739e+00 2.28434967e-02\n",
      " 2.30846845e-01 1.21154207e+01], Loss = 0.3234\n",
      "Iteration 8163: Weights = [5.50000000e+01 3.29760074e+00 6.93325835e+00 2.28428410e-02\n",
      " 2.30840218e-01 1.21156309e+01], Loss = 0.3234\n",
      "Iteration 8164: Weights = [5.50000000e+01 3.29750608e+00 6.93305932e+00 2.28421852e-02\n",
      " 2.30833592e-01 1.21158412e+01], Loss = 0.3234\n",
      "Iteration 8165: Weights = [5.50000000e+01 3.29741142e+00 6.93286030e+00 2.28415295e-02\n",
      " 2.30826965e-01 1.21160515e+01], Loss = 0.3234\n",
      "Iteration 8166: Weights = [5.50000000e+01 3.29731676e+00 6.93266128e+00 2.28408738e-02\n",
      " 2.30820339e-01 1.21162617e+01], Loss = 0.3233\n",
      "Iteration 8167: Weights = [5.50000000e+01 3.29722211e+00 6.93246227e+00 2.28402182e-02\n",
      " 2.30813713e-01 1.21164720e+01], Loss = 0.3233\n",
      "Iteration 8168: Weights = [5.50000000e+01 3.29712746e+00 6.93226327e+00 2.28395625e-02\n",
      " 2.30807087e-01 1.21166822e+01], Loss = 0.3233\n",
      "Iteration 8169: Weights = [5.50000000e+01 3.29703281e+00 6.93206427e+00 2.28389069e-02\n",
      " 2.30800462e-01 1.21168925e+01], Loss = 0.3233\n",
      "Iteration 8170: Weights = [5.50000000e+01 3.29693816e+00 6.93186527e+00 2.28382512e-02\n",
      " 2.30793836e-01 1.21171027e+01], Loss = 0.3233\n",
      "Iteration 8171: Weights = [5.50000000e+01 3.29684352e+00 6.93166629e+00 2.28375956e-02\n",
      " 2.30787211e-01 1.21173129e+01], Loss = 0.3233\n",
      "Iteration 8172: Weights = [5.50000000e+01 3.29674888e+00 6.93146730e+00 2.28369401e-02\n",
      " 2.30780586e-01 1.21175232e+01], Loss = 0.3232\n",
      "Iteration 8173: Weights = [5.50000000e+01 3.29665424e+00 6.93126833e+00 2.28362845e-02\n",
      " 2.30773961e-01 1.21177334e+01], Loss = 0.3232\n",
      "Iteration 8174: Weights = [5.50000000e+01 3.29655961e+00 6.93106936e+00 2.28356289e-02\n",
      " 2.30767336e-01 1.21179436e+01], Loss = 0.3232\n",
      "Iteration 8175: Weights = [5.50000000e+01 3.29646498e+00 6.93087039e+00 2.28349734e-02\n",
      " 2.30760712e-01 1.21181538e+01], Loss = 0.3232\n",
      "Iteration 8176: Weights = [5.50000000e+01 3.29637035e+00 6.93067143e+00 2.28343179e-02\n",
      " 2.30754088e-01 1.21183640e+01], Loss = 0.3232\n",
      "Iteration 8177: Weights = [5.50000000e+01 3.29627572e+00 6.93047248e+00 2.28336624e-02\n",
      " 2.30747464e-01 1.21185742e+01], Loss = 0.3231\n",
      "Iteration 8178: Weights = [5.50000000e+01 3.29618110e+00 6.93027353e+00 2.28330070e-02\n",
      " 2.30740840e-01 1.21187844e+01], Loss = 0.3231\n",
      "Iteration 8179: Weights = [5.50000000e+01 3.29608647e+00 6.93007459e+00 2.28323515e-02\n",
      " 2.30734216e-01 1.21189945e+01], Loss = 0.3231\n",
      "Iteration 8180: Weights = [5.50000000e+01 3.29599186e+00 6.92987565e+00 2.28316961e-02\n",
      " 2.30727592e-01 1.21192047e+01], Loss = 0.3231\n",
      "Iteration 8181: Weights = [5.50000000e+01 3.29589724e+00 6.92967672e+00 2.28310407e-02\n",
      " 2.30720969e-01 1.21194149e+01], Loss = 0.3231\n",
      "Iteration 8182: Weights = [5.50000000e+01 3.29580263e+00 6.92947779e+00 2.28303853e-02\n",
      " 2.30714346e-01 1.21196250e+01], Loss = 0.3230\n",
      "Iteration 8183: Weights = [5.50000000e+01 3.29570802e+00 6.92927887e+00 2.28297299e-02\n",
      " 2.30707723e-01 1.21198352e+01], Loss = 0.3230\n",
      "Iteration 8184: Weights = [5.50000000e+01 3.29561341e+00 6.92907996e+00 2.28290745e-02\n",
      " 2.30701100e-01 1.21200453e+01], Loss = 0.3230\n",
      "Iteration 8185: Weights = [5.50000000e+01 3.29551880e+00 6.92888105e+00 2.28284192e-02\n",
      " 2.30694478e-01 1.21202555e+01], Loss = 0.3230\n",
      "Iteration 8186: Weights = [5.50000000e+01 3.29542420e+00 6.92868215e+00 2.28277639e-02\n",
      " 2.30687855e-01 1.21204656e+01], Loss = 0.3230\n",
      "Iteration 8187: Weights = [5.50000000e+01 3.29532960e+00 6.92848325e+00 2.28271086e-02\n",
      " 2.30681233e-01 1.21206758e+01], Loss = 0.3230\n",
      "Iteration 8188: Weights = [5.50000000e+01 3.29523501e+00 6.92828436e+00 2.28264533e-02\n",
      " 2.30674611e-01 1.21208859e+01], Loss = 0.3229\n",
      "Iteration 8189: Weights = [5.50000000e+01 3.29514041e+00 6.92808547e+00 2.28257980e-02\n",
      " 2.30667989e-01 1.21210960e+01], Loss = 0.3229\n",
      "Iteration 8190: Weights = [5.50000000e+01 3.29504582e+00 6.92788659e+00 2.28251428e-02\n",
      " 2.30661368e-01 1.21213061e+01], Loss = 0.3229\n",
      "Iteration 8191: Weights = [5.50000000e+01 3.29495123e+00 6.92768772e+00 2.28244876e-02\n",
      " 2.30654746e-01 1.21215162e+01], Loss = 0.3229\n",
      "Iteration 8192: Weights = [5.50000000e+01 3.29485665e+00 6.92748885e+00 2.28238323e-02\n",
      " 2.30648125e-01 1.21217263e+01], Loss = 0.3229\n",
      "Iteration 8193: Weights = [5.50000000e+01 3.29476206e+00 6.92728999e+00 2.28231772e-02\n",
      " 2.30641504e-01 1.21219364e+01], Loss = 0.3228\n",
      "Iteration 8194: Weights = [5.50000000e+01 3.29466748e+00 6.92709113e+00 2.28225220e-02\n",
      " 2.30634883e-01 1.21221465e+01], Loss = 0.3228\n",
      "Iteration 8195: Weights = [5.50000000e+01 3.29457290e+00 6.92689228e+00 2.28218668e-02\n",
      " 2.30628262e-01 1.21223566e+01], Loss = 0.3228\n",
      "Iteration 8196: Weights = [5.50000000e+01 3.29447833e+00 6.92669344e+00 2.28212117e-02\n",
      " 2.30621642e-01 1.21225667e+01], Loss = 0.3228\n",
      "Iteration 8197: Weights = [5.50000000e+01 3.29438376e+00 6.92649460e+00 2.28205566e-02\n",
      " 2.30615022e-01 1.21227767e+01], Loss = 0.3228\n",
      "Iteration 8198: Weights = [5.50000000e+01 3.29428919e+00 6.92629576e+00 2.28199015e-02\n",
      " 2.30608401e-01 1.21229868e+01], Loss = 0.3228\n",
      "Iteration 8199: Weights = [5.50000000e+01 3.29419462e+00 6.92609693e+00 2.28192464e-02\n",
      " 2.30601781e-01 1.21231969e+01], Loss = 0.3227\n",
      "Iteration 8200: Weights = [5.50000000e+01 3.29410006e+00 6.92589811e+00 2.28185914e-02\n",
      " 2.30595162e-01 1.21234069e+01], Loss = 0.3227\n",
      "Iteration 8201: Weights = [5.50000000e+01 3.29400549e+00 6.92569929e+00 2.28179363e-02\n",
      " 2.30588542e-01 1.21236170e+01], Loss = 0.3227\n",
      "Iteration 8202: Weights = [5.50000000e+01 3.29391094e+00 6.92550048e+00 2.28172813e-02\n",
      " 2.30581923e-01 1.21238270e+01], Loss = 0.3227\n",
      "Iteration 8203: Weights = [5.50000000e+01 3.29381638e+00 6.92530168e+00 2.28166263e-02\n",
      " 2.30575304e-01 1.21240370e+01], Loss = 0.3227\n",
      "Iteration 8204: Weights = [5.50000000e+01 3.29372183e+00 6.92510288e+00 2.28159713e-02\n",
      " 2.30568685e-01 1.21242471e+01], Loss = 0.3226\n",
      "Iteration 8205: Weights = [5.50000000e+01 3.29362728e+00 6.92490408e+00 2.28153164e-02\n",
      " 2.30562066e-01 1.21244571e+01], Loss = 0.3226\n",
      "Iteration 8206: Weights = [5.50000000e+01 3.29353273e+00 6.92470529e+00 2.28146614e-02\n",
      " 2.30555447e-01 1.21246671e+01], Loss = 0.3226\n",
      "Iteration 8207: Weights = [5.50000000e+01 3.29343818e+00 6.92450651e+00 2.28140065e-02\n",
      " 2.30548829e-01 1.21248771e+01], Loss = 0.3226\n",
      "Iteration 8208: Weights = [5.50000000e+01 3.29334364e+00 6.92430773e+00 2.28133516e-02\n",
      " 2.30542211e-01 1.21250871e+01], Loss = 0.3226\n",
      "Iteration 8209: Weights = [5.50000000e+01 3.29324910e+00 6.92410896e+00 2.28126967e-02\n",
      " 2.30535593e-01 1.21252971e+01], Loss = 0.3225\n",
      "Iteration 8210: Weights = [5.50000000e+01 3.29315456e+00 6.92391020e+00 2.28120418e-02\n",
      " 2.30528975e-01 1.21255071e+01], Loss = 0.3225\n",
      "Iteration 8211: Weights = [5.50000000e+01 3.29306003e+00 6.92371144e+00 2.28113870e-02\n",
      " 2.30522357e-01 1.21257171e+01], Loss = 0.3225\n",
      "Iteration 8212: Weights = [5.50000000e+01 3.29296550e+00 6.92351268e+00 2.28107322e-02\n",
      " 2.30515740e-01 1.21259271e+01], Loss = 0.3225\n",
      "Iteration 8213: Weights = [5.50000000e+01 3.29287097e+00 6.92331393e+00 2.28100773e-02\n",
      " 2.30509123e-01 1.21261371e+01], Loss = 0.3225\n",
      "Iteration 8214: Weights = [5.50000000e+01 3.29277644e+00 6.92311519e+00 2.28094226e-02\n",
      " 2.30502506e-01 1.21263470e+01], Loss = 0.3225\n",
      "Iteration 8215: Weights = [5.50000000e+01 3.29268192e+00 6.92291645e+00 2.28087678e-02\n",
      " 2.30495889e-01 1.21265570e+01], Loss = 0.3224\n",
      "Iteration 8216: Weights = [5.50000000e+01 3.29258740e+00 6.92271772e+00 2.28081130e-02\n",
      " 2.30489272e-01 1.21267669e+01], Loss = 0.3224\n",
      "Iteration 8217: Weights = [5.50000000e+01 3.29249288e+00 6.92251900e+00 2.28074583e-02\n",
      " 2.30482655e-01 1.21269769e+01], Loss = 0.3224\n",
      "Iteration 8218: Weights = [5.50000000e+01 3.29239837e+00 6.92232028e+00 2.28068036e-02\n",
      " 2.30476039e-01 1.21271868e+01], Loss = 0.3224\n",
      "Iteration 8219: Weights = [5.50000000e+01 3.29230385e+00 6.92212156e+00 2.28061489e-02\n",
      " 2.30469423e-01 1.21273968e+01], Loss = 0.3224\n",
      "Iteration 8220: Weights = [5.50000000e+01 3.29220934e+00 6.92192286e+00 2.28054942e-02\n",
      " 2.30462807e-01 1.21276067e+01], Loss = 0.3223\n",
      "Iteration 8221: Weights = [5.50000000e+01 3.29211484e+00 6.92172415e+00 2.28048395e-02\n",
      " 2.30456191e-01 1.21278166e+01], Loss = 0.3223\n",
      "Iteration 8222: Weights = [5.50000000e+01 3.29202033e+00 6.92152546e+00 2.28041849e-02\n",
      " 2.30449576e-01 1.21280266e+01], Loss = 0.3223\n",
      "Iteration 8223: Weights = [5.50000000e+01 3.29192583e+00 6.92132676e+00 2.28035303e-02\n",
      " 2.30442960e-01 1.21282365e+01], Loss = 0.3223\n",
      "Iteration 8224: Weights = [5.50000000e+01 3.29183133e+00 6.92112808e+00 2.28028757e-02\n",
      " 2.30436345e-01 1.21284464e+01], Loss = 0.3223\n",
      "Iteration 8225: Weights = [5.50000000e+01 3.29173683e+00 6.92092940e+00 2.28022211e-02\n",
      " 2.30429730e-01 1.21286563e+01], Loss = 0.3223\n",
      "Iteration 8226: Weights = [5.50000000e+01 3.29164234e+00 6.92073072e+00 2.28015665e-02\n",
      " 2.30423116e-01 1.21288662e+01], Loss = 0.3222\n",
      "Iteration 8227: Weights = [5.50000000e+01 3.29154785e+00 6.92053205e+00 2.28009120e-02\n",
      " 2.30416501e-01 1.21290761e+01], Loss = 0.3222\n",
      "Iteration 8228: Weights = [5.50000000e+01 3.29145336e+00 6.92033339e+00 2.28002574e-02\n",
      " 2.30409887e-01 1.21292860e+01], Loss = 0.3222\n",
      "Iteration 8229: Weights = [5.50000000e+01 3.29135888e+00 6.92013473e+00 2.27996029e-02\n",
      " 2.30403272e-01 1.21294958e+01], Loss = 0.3222\n",
      "Iteration 8230: Weights = [5.50000000e+01 3.29126439e+00 6.91993608e+00 2.27989484e-02\n",
      " 2.30396658e-01 1.21297057e+01], Loss = 0.3222\n",
      "Iteration 8231: Weights = [5.50000000e+01 3.29116991e+00 6.91973744e+00 2.27982939e-02\n",
      " 2.30390044e-01 1.21299156e+01], Loss = 0.3221\n",
      "Iteration 8232: Weights = [5.50000000e+01 3.29107544e+00 6.91953880e+00 2.27976395e-02\n",
      " 2.30383431e-01 1.21301254e+01], Loss = 0.3221\n",
      "Iteration 8233: Weights = [5.50000000e+01 3.29098096e+00 6.91934016e+00 2.27969851e-02\n",
      " 2.30376817e-01 1.21303353e+01], Loss = 0.3221\n",
      "Iteration 8234: Weights = [5.50000000e+01 3.29088649e+00 6.91914153e+00 2.27963306e-02\n",
      " 2.30370204e-01 1.21305451e+01], Loss = 0.3221\n",
      "Iteration 8235: Weights = [5.50000000e+01 3.29079202e+00 6.91894291e+00 2.27956762e-02\n",
      " 2.30363591e-01 1.21307550e+01], Loss = 0.3221\n",
      "Iteration 8236: Weights = [5.50000000e+01 3.29069755e+00 6.91874429e+00 2.27950219e-02\n",
      " 2.30356978e-01 1.21309648e+01], Loss = 0.3220\n",
      "Iteration 8237: Weights = [5.50000000e+01 3.29060309e+00 6.91854568e+00 2.27943675e-02\n",
      " 2.30350365e-01 1.21311746e+01], Loss = 0.3220\n",
      "Iteration 8238: Weights = [5.50000000e+01 3.29050863e+00 6.91834708e+00 2.27937132e-02\n",
      " 2.30343753e-01 1.21313845e+01], Loss = 0.3220\n",
      "Iteration 8239: Weights = [5.50000000e+01 3.29041417e+00 6.91814848e+00 2.27930588e-02\n",
      " 2.30337141e-01 1.21315943e+01], Loss = 0.3220\n",
      "Iteration 8240: Weights = [5.50000000e+01 3.29031971e+00 6.91794988e+00 2.27924045e-02\n",
      " 2.30330528e-01 1.21318041e+01], Loss = 0.3220\n",
      "Iteration 8241: Weights = [5.50000000e+01 3.29022526e+00 6.91775129e+00 2.27917502e-02\n",
      " 2.30323917e-01 1.21320139e+01], Loss = 0.3220\n",
      "Iteration 8242: Weights = [5.50000000e+01 3.29013081e+00 6.91755271e+00 2.27910960e-02\n",
      " 2.30317305e-01 1.21322237e+01], Loss = 0.3219\n",
      "Iteration 8243: Weights = [5.50000000e+01 3.29003636e+00 6.91735413e+00 2.27904417e-02\n",
      " 2.30310693e-01 1.21324335e+01], Loss = 0.3219\n",
      "Iteration 8244: Weights = [5.50000000e+01 3.28994192e+00 6.91715556e+00 2.27897875e-02\n",
      " 2.30304082e-01 1.21326433e+01], Loss = 0.3219\n",
      "Iteration 8245: Weights = [5.50000000e+01 3.28984748e+00 6.91695699e+00 2.27891333e-02\n",
      " 2.30297471e-01 1.21328531e+01], Loss = 0.3219\n",
      "Iteration 8246: Weights = [5.50000000e+01 3.28975304e+00 6.91675843e+00 2.27884791e-02\n",
      " 2.30290860e-01 1.21330628e+01], Loss = 0.3219\n",
      "Iteration 8247: Weights = [5.50000000e+01 3.28965860e+00 6.91655988e+00 2.27878249e-02\n",
      " 2.30284249e-01 1.21332726e+01], Loss = 0.3218\n",
      "Iteration 8248: Weights = [5.50000000e+01 3.28956417e+00 6.91636133e+00 2.27871708e-02\n",
      " 2.30277638e-01 1.21334824e+01], Loss = 0.3218\n",
      "Iteration 8249: Weights = [5.50000000e+01 3.28946974e+00 6.91616279e+00 2.27865166e-02\n",
      " 2.30271028e-01 1.21336921e+01], Loss = 0.3218\n",
      "Iteration 8250: Weights = [5.50000000e+01 3.28937531e+00 6.91596425e+00 2.27858625e-02\n",
      " 2.30264418e-01 1.21339019e+01], Loss = 0.3218\n",
      "Iteration 8251: Weights = [5.50000000e+01 3.28928088e+00 6.91576572e+00 2.27852084e-02\n",
      " 2.30257808e-01 1.21341116e+01], Loss = 0.3218\n",
      "Iteration 8252: Weights = [5.50000000e+01 3.28918646e+00 6.91556719e+00 2.27845543e-02\n",
      " 2.30251198e-01 1.21343214e+01], Loss = 0.3218\n",
      "Iteration 8253: Weights = [5.50000000e+01 3.28909204e+00 6.91536867e+00 2.27839003e-02\n",
      " 2.30244588e-01 1.21345311e+01], Loss = 0.3217\n",
      "Iteration 8254: Weights = [5.50000000e+01 3.28899762e+00 6.91517016e+00 2.27832462e-02\n",
      " 2.30237979e-01 1.21347408e+01], Loss = 0.3217\n",
      "Iteration 8255: Weights = [5.50000000e+01 3.28890321e+00 6.91497165e+00 2.27825922e-02\n",
      " 2.30231369e-01 1.21349505e+01], Loss = 0.3217\n",
      "Iteration 8256: Weights = [5.50000000e+01 3.28880879e+00 6.91477314e+00 2.27819382e-02\n",
      " 2.30224760e-01 1.21351603e+01], Loss = 0.3217\n",
      "Iteration 8257: Weights = [5.50000000e+01 3.28871438e+00 6.91457465e+00 2.27812842e-02\n",
      " 2.30218151e-01 1.21353700e+01], Loss = 0.3217\n",
      "Iteration 8258: Weights = [5.50000000e+01 3.28861998e+00 6.91437616e+00 2.27806303e-02\n",
      " 2.30211543e-01 1.21355797e+01], Loss = 0.3216\n",
      "Iteration 8259: Weights = [5.50000000e+01 3.28852557e+00 6.91417767e+00 2.27799763e-02\n",
      " 2.30204934e-01 1.21357894e+01], Loss = 0.3216\n",
      "Iteration 8260: Weights = [5.50000000e+01 3.28843117e+00 6.91397919e+00 2.27793224e-02\n",
      " 2.30198326e-01 1.21359991e+01], Loss = 0.3216\n",
      "Iteration 8261: Weights = [5.50000000e+01 3.28833677e+00 6.91378071e+00 2.27786685e-02\n",
      " 2.30191718e-01 1.21362088e+01], Loss = 0.3216\n",
      "Iteration 8262: Weights = [5.50000000e+01 3.28824238e+00 6.91358224e+00 2.27780146e-02\n",
      " 2.30185110e-01 1.21364184e+01], Loss = 0.3216\n",
      "Iteration 8263: Weights = [5.50000000e+01 3.28814798e+00 6.91338378e+00 2.27773607e-02\n",
      " 2.30178502e-01 1.21366281e+01], Loss = 0.3215\n",
      "Iteration 8264: Weights = [5.50000000e+01 3.28805359e+00 6.91318532e+00 2.27767069e-02\n",
      " 2.30171894e-01 1.21368378e+01], Loss = 0.3215\n",
      "Iteration 8265: Weights = [5.50000000e+01 3.28795920e+00 6.91298687e+00 2.27760530e-02\n",
      " 2.30165287e-01 1.21370474e+01], Loss = 0.3215\n",
      "Iteration 8266: Weights = [5.50000000e+01 3.28786482e+00 6.91278842e+00 2.27753992e-02\n",
      " 2.30158680e-01 1.21372571e+01], Loss = 0.3215\n",
      "Iteration 8267: Weights = [5.50000000e+01 3.28777044e+00 6.91258998e+00 2.27747454e-02\n",
      " 2.30152073e-01 1.21374667e+01], Loss = 0.3215\n",
      "Iteration 8268: Weights = [5.50000000e+01 3.28767606e+00 6.91239155e+00 2.27740916e-02\n",
      " 2.30145466e-01 1.21376764e+01], Loss = 0.3215\n",
      "Iteration 8269: Weights = [5.50000000e+01 3.28758168e+00 6.91219312e+00 2.27734379e-02\n",
      " 2.30138859e-01 1.21378860e+01], Loss = 0.3214\n",
      "Iteration 8270: Weights = [5.50000000e+01 3.28748731e+00 6.91199470e+00 2.27727841e-02\n",
      " 2.30132253e-01 1.21380957e+01], Loss = 0.3214\n",
      "Iteration 8271: Weights = [5.50000000e+01 3.28739293e+00 6.91179628e+00 2.27721304e-02\n",
      " 2.30125647e-01 1.21383053e+01], Loss = 0.3214\n",
      "Iteration 8272: Weights = [5.50000000e+01 3.28729857e+00 6.91159787e+00 2.27714767e-02\n",
      " 2.30119041e-01 1.21385149e+01], Loss = 0.3214\n",
      "Iteration 8273: Weights = [5.50000000e+01 3.28720420e+00 6.91139946e+00 2.27708230e-02\n",
      " 2.30112435e-01 1.21387245e+01], Loss = 0.3214\n",
      "Iteration 8274: Weights = [5.50000000e+01 3.28710984e+00 6.91120106e+00 2.27701693e-02\n",
      " 2.30105829e-01 1.21389341e+01], Loss = 0.3213\n",
      "Iteration 8275: Weights = [5.50000000e+01 3.28701547e+00 6.91100266e+00 2.27695157e-02\n",
      " 2.30099224e-01 1.21391437e+01], Loss = 0.3213\n",
      "Iteration 8276: Weights = [5.50000000e+01 3.28692112e+00 6.91080427e+00 2.27688621e-02\n",
      " 2.30092618e-01 1.21393533e+01], Loss = 0.3213\n",
      "Iteration 8277: Weights = [5.50000000e+01 3.28682676e+00 6.91060589e+00 2.27682085e-02\n",
      " 2.30086013e-01 1.21395629e+01], Loss = 0.3213\n",
      "Iteration 8278: Weights = [5.50000000e+01 3.28673241e+00 6.91040751e+00 2.27675549e-02\n",
      " 2.30079408e-01 1.21397725e+01], Loss = 0.3213\n",
      "Iteration 8279: Weights = [5.50000000e+01 3.28663806e+00 6.91020914e+00 2.27669013e-02\n",
      " 2.30072803e-01 1.21399821e+01], Loss = 0.3213\n",
      "Iteration 8280: Weights = [5.50000000e+01 3.28654371e+00 6.91001077e+00 2.27662477e-02\n",
      " 2.30066199e-01 1.21401916e+01], Loss = 0.3212\n",
      "Iteration 8281: Weights = [5.50000000e+01 3.28644937e+00 6.90981241e+00 2.27655942e-02\n",
      " 2.30059595e-01 1.21404012e+01], Loss = 0.3212\n",
      "Iteration 8282: Weights = [5.50000000e+01 3.28635503e+00 6.90961406e+00 2.27649407e-02\n",
      " 2.30052990e-01 1.21406108e+01], Loss = 0.3212\n",
      "Iteration 8283: Weights = [5.50000000e+01 3.28626069e+00 6.90941571e+00 2.27642872e-02\n",
      " 2.30046386e-01 1.21408203e+01], Loss = 0.3212\n",
      "Iteration 8284: Weights = [5.50000000e+01 3.28616635e+00 6.90921736e+00 2.27636337e-02\n",
      " 2.30039783e-01 1.21410299e+01], Loss = 0.3212\n",
      "Iteration 8285: Weights = [5.50000000e+01 3.28607202e+00 6.90901903e+00 2.27629803e-02\n",
      " 2.30033179e-01 1.21412394e+01], Loss = 0.3211\n",
      "Iteration 8286: Weights = [5.50000000e+01 3.28597768e+00 6.90882069e+00 2.27623268e-02\n",
      " 2.30026576e-01 1.21414489e+01], Loss = 0.3211\n",
      "Iteration 8287: Weights = [5.50000000e+01 3.28588336e+00 6.90862237e+00 2.27616734e-02\n",
      " 2.30019972e-01 1.21416585e+01], Loss = 0.3211\n",
      "Iteration 8288: Weights = [5.50000000e+01 3.28578903e+00 6.90842405e+00 2.27610200e-02\n",
      " 2.30013369e-01 1.21418680e+01], Loss = 0.3211\n",
      "Iteration 8289: Weights = [5.50000000e+01 3.28569471e+00 6.90822573e+00 2.27603666e-02\n",
      " 2.30006767e-01 1.21420775e+01], Loss = 0.3211\n",
      "Iteration 8290: Weights = [5.50000000e+01 3.28560039e+00 6.90802742e+00 2.27597132e-02\n",
      " 2.30000164e-01 1.21422870e+01], Loss = 0.3211\n",
      "Iteration 8291: Weights = [5.50000000e+01 3.28550607e+00 6.90782912e+00 2.27590599e-02\n",
      " 2.29993561e-01 1.21424965e+01], Loss = 0.3210\n",
      "Iteration 8292: Weights = [5.50000000e+01 3.28541176e+00 6.90763082e+00 2.27584066e-02\n",
      " 2.29986959e-01 1.21427060e+01], Loss = 0.3210\n",
      "Iteration 8293: Weights = [5.50000000e+01 3.28531744e+00 6.90743253e+00 2.27577533e-02\n",
      " 2.29980357e-01 1.21429155e+01], Loss = 0.3210\n",
      "Iteration 8294: Weights = [5.50000000e+01 3.28522313e+00 6.90723424e+00 2.27571000e-02\n",
      " 2.29973755e-01 1.21431250e+01], Loss = 0.3210\n",
      "Iteration 8295: Weights = [5.50000000e+01 3.28512883e+00 6.90703596e+00 2.27564467e-02\n",
      " 2.29967154e-01 1.21433345e+01], Loss = 0.3210\n",
      "Iteration 8296: Weights = [5.50000000e+01 3.28503452e+00 6.90683768e+00 2.27557934e-02\n",
      " 2.29960552e-01 1.21435440e+01], Loss = 0.3209\n",
      "Iteration 8297: Weights = [5.50000000e+01 3.28494022e+00 6.90663941e+00 2.27551402e-02\n",
      " 2.29953951e-01 1.21437534e+01], Loss = 0.3209\n",
      "Iteration 8298: Weights = [5.50000000e+01 3.28484592e+00 6.90644115e+00 2.27544870e-02\n",
      " 2.29947350e-01 1.21439629e+01], Loss = 0.3209\n",
      "Iteration 8299: Weights = [5.50000000e+01 3.28475163e+00 6.90624289e+00 2.27538338e-02\n",
      " 2.29940749e-01 1.21441723e+01], Loss = 0.3209\n",
      "Iteration 8300: Weights = [5.50000000e+01 3.28465734e+00 6.90604464e+00 2.27531806e-02\n",
      " 2.29934148e-01 1.21443818e+01], Loss = 0.3209\n",
      "Iteration 8301: Weights = [5.50000000e+01 3.28456304e+00 6.90584639e+00 2.27525274e-02\n",
      " 2.29927547e-01 1.21445912e+01], Loss = 0.3208\n",
      "Iteration 8302: Weights = [5.50000000e+01 3.28446876e+00 6.90564815e+00 2.27518743e-02\n",
      " 2.29920947e-01 1.21448007e+01], Loss = 0.3208\n",
      "Iteration 8303: Weights = [5.50000000e+01 3.28437447e+00 6.90544991e+00 2.27512212e-02\n",
      " 2.29914347e-01 1.21450101e+01], Loss = 0.3208\n",
      "Iteration 8304: Weights = [5.50000000e+01 3.28428019e+00 6.90525168e+00 2.27505681e-02\n",
      " 2.29907747e-01 1.21452195e+01], Loss = 0.3208\n",
      "Iteration 8305: Weights = [5.50000000e+01 3.28418591e+00 6.90505346e+00 2.27499150e-02\n",
      " 2.29901147e-01 1.21454290e+01], Loss = 0.3208\n",
      "Iteration 8306: Weights = [5.50000000e+01 3.28409163e+00 6.90485524e+00 2.27492619e-02\n",
      " 2.29894547e-01 1.21456384e+01], Loss = 0.3208\n",
      "Iteration 8307: Weights = [5.50000000e+01 3.28399736e+00 6.90465703e+00 2.27486089e-02\n",
      " 2.29887948e-01 1.21458478e+01], Loss = 0.3207\n",
      "Iteration 8308: Weights = [5.50000000e+01 3.28390309e+00 6.90445882e+00 2.27479559e-02\n",
      " 2.29881349e-01 1.21460572e+01], Loss = 0.3207\n",
      "Iteration 8309: Weights = [5.50000000e+01 3.28380882e+00 6.90426062e+00 2.27473028e-02\n",
      " 2.29874750e-01 1.21462666e+01], Loss = 0.3207\n",
      "Iteration 8310: Weights = [5.50000000e+01 3.28371455e+00 6.90406242e+00 2.27466499e-02\n",
      " 2.29868151e-01 1.21464760e+01], Loss = 0.3207\n",
      "Iteration 8311: Weights = [5.50000000e+01 3.28362029e+00 6.90386423e+00 2.27459969e-02\n",
      " 2.29861552e-01 1.21466854e+01], Loss = 0.3207\n",
      "Iteration 8312: Weights = [5.50000000e+01 3.28352603e+00 6.90366605e+00 2.27453439e-02\n",
      " 2.29854954e-01 1.21468947e+01], Loss = 0.3206\n",
      "Iteration 8313: Weights = [5.50000000e+01 3.28343177e+00 6.90346787e+00 2.27446910e-02\n",
      " 2.29848355e-01 1.21471041e+01], Loss = 0.3206\n",
      "Iteration 8314: Weights = [5.50000000e+01 3.28333752e+00 6.90326970e+00 2.27440381e-02\n",
      " 2.29841757e-01 1.21473135e+01], Loss = 0.3206\n",
      "Iteration 8315: Weights = [5.50000000e+01 3.28324326e+00 6.90307153e+00 2.27433852e-02\n",
      " 2.29835159e-01 1.21475228e+01], Loss = 0.3206\n",
      "Iteration 8316: Weights = [5.50000000e+01 3.28314901e+00 6.90287337e+00 2.27427323e-02\n",
      " 2.29828562e-01 1.21477322e+01], Loss = 0.3206\n",
      "Iteration 8317: Weights = [5.50000000e+01 3.28305477e+00 6.90267521e+00 2.27420794e-02\n",
      " 2.29821964e-01 1.21479415e+01], Loss = 0.3206\n",
      "Iteration 8318: Weights = [5.50000000e+01 3.28296052e+00 6.90247706e+00 2.27414266e-02\n",
      " 2.29815367e-01 1.21481509e+01], Loss = 0.3205\n",
      "Iteration 8319: Weights = [5.50000000e+01 3.28286628e+00 6.90227892e+00 2.27407738e-02\n",
      " 2.29808770e-01 1.21483602e+01], Loss = 0.3205\n",
      "Iteration 8320: Weights = [5.50000000e+01 3.28277204e+00 6.90208078e+00 2.27401210e-02\n",
      " 2.29802173e-01 1.21485695e+01], Loss = 0.3205\n",
      "Iteration 8321: Weights = [5.50000000e+01 3.28267781e+00 6.90188264e+00 2.27394682e-02\n",
      " 2.29795576e-01 1.21487789e+01], Loss = 0.3205\n",
      "Iteration 8322: Weights = [5.50000000e+01 3.28258357e+00 6.90168452e+00 2.27388154e-02\n",
      " 2.29788979e-01 1.21489882e+01], Loss = 0.3205\n",
      "Iteration 8323: Weights = [5.50000000e+01 3.28248934e+00 6.90148640e+00 2.27381627e-02\n",
      " 2.29782383e-01 1.21491975e+01], Loss = 0.3204\n",
      "Iteration 8324: Weights = [5.50000000e+01 3.28239511e+00 6.90128828e+00 2.27375099e-02\n",
      " 2.29775787e-01 1.21494068e+01], Loss = 0.3204\n",
      "Iteration 8325: Weights = [5.50000000e+01 3.28230089e+00 6.90109017e+00 2.27368572e-02\n",
      " 2.29769191e-01 1.21496161e+01], Loss = 0.3204\n",
      "Iteration 8326: Weights = [5.50000000e+01 3.28220666e+00 6.90089206e+00 2.27362045e-02\n",
      " 2.29762595e-01 1.21498254e+01], Loss = 0.3204\n",
      "Iteration 8327: Weights = [5.50000000e+01 3.28211244e+00 6.90069396e+00 2.27355519e-02\n",
      " 2.29755999e-01 1.21500347e+01], Loss = 0.3204\n",
      "Iteration 8328: Weights = [5.50000000e+01 3.28201823e+00 6.90049587e+00 2.27348992e-02\n",
      " 2.29749404e-01 1.21502440e+01], Loss = 0.3204\n",
      "Iteration 8329: Weights = [5.50000000e+01 3.28192401e+00 6.90029778e+00 2.27342466e-02\n",
      " 2.29742809e-01 1.21504533e+01], Loss = 0.3203\n",
      "Iteration 8330: Weights = [5.50000000e+01 3.28182980e+00 6.90009970e+00 2.27335940e-02\n",
      " 2.29736213e-01 1.21506625e+01], Loss = 0.3203\n",
      "Iteration 8331: Weights = [5.50000000e+01 3.28173559e+00 6.89990162e+00 2.27329414e-02\n",
      " 2.29729619e-01 1.21508718e+01], Loss = 0.3203\n",
      "Iteration 8332: Weights = [5.50000000e+01 3.28164138e+00 6.89970355e+00 2.27322888e-02\n",
      " 2.29723024e-01 1.21510810e+01], Loss = 0.3203\n",
      "Iteration 8333: Weights = [5.50000000e+01 3.28154718e+00 6.89950549e+00 2.27316362e-02\n",
      " 2.29716429e-01 1.21512903e+01], Loss = 0.3203\n",
      "Iteration 8334: Weights = [5.50000000e+01 3.28145298e+00 6.89930743e+00 2.27309837e-02\n",
      " 2.29709835e-01 1.21514995e+01], Loss = 0.3202\n",
      "Iteration 8335: Weights = [5.50000000e+01 3.28135878e+00 6.89910938e+00 2.27303312e-02\n",
      " 2.29703241e-01 1.21517088e+01], Loss = 0.3202\n",
      "Iteration 8336: Weights = [5.50000000e+01 3.28126459e+00 6.89891133e+00 2.27296787e-02\n",
      " 2.29696647e-01 1.21519180e+01], Loss = 0.3202\n",
      "Iteration 8337: Weights = [5.50000000e+01 3.28117039e+00 6.89871329e+00 2.27290262e-02\n",
      " 2.29690053e-01 1.21521272e+01], Loss = 0.3202\n",
      "Iteration 8338: Weights = [5.50000000e+01 3.28107620e+00 6.89851525e+00 2.27283737e-02\n",
      " 2.29683460e-01 1.21523365e+01], Loss = 0.3202\n",
      "Iteration 8339: Weights = [5.50000000e+01 3.28098202e+00 6.89831722e+00 2.27277213e-02\n",
      " 2.29676866e-01 1.21525457e+01], Loss = 0.3201\n",
      "Iteration 8340: Weights = [5.50000000e+01 3.28088783e+00 6.89811919e+00 2.27270688e-02\n",
      " 2.29670273e-01 1.21527549e+01], Loss = 0.3201\n",
      "Iteration 8341: Weights = [5.50000000e+01 3.28079365e+00 6.89792117e+00 2.27264164e-02\n",
      " 2.29663680e-01 1.21529641e+01], Loss = 0.3201\n",
      "Iteration 8342: Weights = [5.50000000e+01 3.28069947e+00 6.89772316e+00 2.27257640e-02\n",
      " 2.29657087e-01 1.21531733e+01], Loss = 0.3201\n",
      "Iteration 8343: Weights = [5.50000000e+01 3.28060529e+00 6.89752515e+00 2.27251117e-02\n",
      " 2.29650495e-01 1.21533825e+01], Loss = 0.3201\n",
      "Iteration 8344: Weights = [5.50000000e+01 3.28051112e+00 6.89732715e+00 2.27244593e-02\n",
      " 2.29643902e-01 1.21535917e+01], Loss = 0.3201\n",
      "Iteration 8345: Weights = [5.50000000e+01 3.28041695e+00 6.89712915e+00 2.27238070e-02\n",
      " 2.29637310e-01 1.21538009e+01], Loss = 0.3200\n",
      "Iteration 8346: Weights = [5.50000000e+01 3.28032278e+00 6.89693116e+00 2.27231547e-02\n",
      " 2.29630718e-01 1.21540100e+01], Loss = 0.3200\n",
      "Iteration 8347: Weights = [5.50000000e+01 3.28022861e+00 6.89673318e+00 2.27225024e-02\n",
      " 2.29624126e-01 1.21542192e+01], Loss = 0.3200\n",
      "Iteration 8348: Weights = [5.50000000e+01 3.28013445e+00 6.89653520e+00 2.27218501e-02\n",
      " 2.29617535e-01 1.21544284e+01], Loss = 0.3200\n",
      "Iteration 8349: Weights = [5.50000000e+01 3.28004029e+00 6.89633722e+00 2.27211978e-02\n",
      " 2.29610943e-01 1.21546375e+01], Loss = 0.3200\n",
      "Iteration 8350: Weights = [5.50000000e+01 3.27994613e+00 6.89613925e+00 2.27205456e-02\n",
      " 2.29604352e-01 1.21548467e+01], Loss = 0.3199\n",
      "Iteration 8351: Weights = [5.50000000e+01 3.27985197e+00 6.89594129e+00 2.27198933e-02\n",
      " 2.29597761e-01 1.21550558e+01], Loss = 0.3199\n",
      "Iteration 8352: Weights = [5.50000000e+01 3.27975782e+00 6.89574333e+00 2.27192411e-02\n",
      " 2.29591170e-01 1.21552650e+01], Loss = 0.3199\n",
      "Iteration 8353: Weights = [5.50000000e+01 3.27966367e+00 6.89554538e+00 2.27185890e-02\n",
      " 2.29584579e-01 1.21554741e+01], Loss = 0.3199\n",
      "Iteration 8354: Weights = [5.50000000e+01 3.27956953e+00 6.89534744e+00 2.27179368e-02\n",
      " 2.29577989e-01 1.21556832e+01], Loss = 0.3199\n",
      "Iteration 8355: Weights = [5.50000000e+01 3.27947538e+00 6.89514950e+00 2.27172846e-02\n",
      " 2.29571398e-01 1.21558923e+01], Loss = 0.3199\n",
      "Iteration 8356: Weights = [5.50000000e+01 3.27938124e+00 6.89495156e+00 2.27166325e-02\n",
      " 2.29564808e-01 1.21561014e+01], Loss = 0.3198\n",
      "Iteration 8357: Weights = [5.50000000e+01 3.27928710e+00 6.89475363e+00 2.27159804e-02\n",
      " 2.29558218e-01 1.21563106e+01], Loss = 0.3198\n",
      "Iteration 8358: Weights = [5.50000000e+01 3.27919296e+00 6.89455571e+00 2.27153283e-02\n",
      " 2.29551628e-01 1.21565197e+01], Loss = 0.3198\n",
      "Iteration 8359: Weights = [5.50000000e+01 3.27909883e+00 6.89435779e+00 2.27146762e-02\n",
      " 2.29545039e-01 1.21567288e+01], Loss = 0.3198\n",
      "Iteration 8360: Weights = [5.50000000e+01 3.27900470e+00 6.89415988e+00 2.27140242e-02\n",
      " 2.29538449e-01 1.21569378e+01], Loss = 0.3198\n",
      "Iteration 8361: Weights = [5.50000000e+01 3.27891057e+00 6.89396198e+00 2.27133721e-02\n",
      " 2.29531860e-01 1.21571469e+01], Loss = 0.3197\n",
      "Iteration 8362: Weights = [5.50000000e+01 3.27881645e+00 6.89376408e+00 2.27127201e-02\n",
      " 2.29525271e-01 1.21573560e+01], Loss = 0.3197\n",
      "Iteration 8363: Weights = [5.50000000e+01 3.27872232e+00 6.89356618e+00 2.27120681e-02\n",
      " 2.29518682e-01 1.21575651e+01], Loss = 0.3197\n",
      "Iteration 8364: Weights = [5.50000000e+01 3.27862820e+00 6.89336829e+00 2.27114162e-02\n",
      " 2.29512094e-01 1.21577741e+01], Loss = 0.3197\n",
      "Iteration 8365: Weights = [5.50000000e+01 3.27853409e+00 6.89317041e+00 2.27107642e-02\n",
      " 2.29505505e-01 1.21579832e+01], Loss = 0.3197\n",
      "Iteration 8366: Weights = [5.50000000e+01 3.27843997e+00 6.89297253e+00 2.27101123e-02\n",
      " 2.29498917e-01 1.21581923e+01], Loss = 0.3197\n",
      "Iteration 8367: Weights = [5.50000000e+01 3.27834586e+00 6.89277466e+00 2.27094603e-02\n",
      " 2.29492329e-01 1.21584013e+01], Loss = 0.3196\n",
      "Iteration 8368: Weights = [5.50000000e+01 3.27825175e+00 6.89257679e+00 2.27088084e-02\n",
      " 2.29485741e-01 1.21586104e+01], Loss = 0.3196\n",
      "Iteration 8369: Weights = [5.50000000e+01 3.27815764e+00 6.89237893e+00 2.27081565e-02\n",
      " 2.29479153e-01 1.21588194e+01], Loss = 0.3196\n",
      "Iteration 8370: Weights = [5.50000000e+01 3.27806354e+00 6.89218108e+00 2.27075047e-02\n",
      " 2.29472566e-01 1.21590284e+01], Loss = 0.3196\n",
      "Iteration 8371: Weights = [5.50000000e+01 3.27796944e+00 6.89198323e+00 2.27068528e-02\n",
      " 2.29465979e-01 1.21592374e+01], Loss = 0.3196\n",
      "Iteration 8372: Weights = [5.50000000e+01 3.27787534e+00 6.89178539e+00 2.27062010e-02\n",
      " 2.29459391e-01 1.21594465e+01], Loss = 0.3195\n",
      "Iteration 8373: Weights = [5.50000000e+01 3.27778125e+00 6.89158755e+00 2.27055492e-02\n",
      " 2.29452805e-01 1.21596555e+01], Loss = 0.3195\n",
      "Iteration 8374: Weights = [5.50000000e+01 3.27768715e+00 6.89138972e+00 2.27048974e-02\n",
      " 2.29446218e-01 1.21598645e+01], Loss = 0.3195\n",
      "Iteration 8375: Weights = [5.50000000e+01 3.27759306e+00 6.89119189e+00 2.27042456e-02\n",
      " 2.29439631e-01 1.21600735e+01], Loss = 0.3195\n",
      "Iteration 8376: Weights = [5.50000000e+01 3.27749897e+00 6.89099407e+00 2.27035939e-02\n",
      " 2.29433045e-01 1.21602825e+01], Loss = 0.3195\n",
      "Iteration 8377: Weights = [5.50000000e+01 3.27740489e+00 6.89079625e+00 2.27029421e-02\n",
      " 2.29426459e-01 1.21604915e+01], Loss = 0.3195\n",
      "Iteration 8378: Weights = [5.50000000e+01 3.27731081e+00 6.89059845e+00 2.27022904e-02\n",
      " 2.29419873e-01 1.21607004e+01], Loss = 0.3194\n",
      "Iteration 8379: Weights = [5.50000000e+01 3.27721673e+00 6.89040064e+00 2.27016387e-02\n",
      " 2.29413287e-01 1.21609094e+01], Loss = 0.3194\n",
      "Iteration 8380: Weights = [5.50000000e+01 3.27712265e+00 6.89020284e+00 2.27009870e-02\n",
      " 2.29406701e-01 1.21611184e+01], Loss = 0.3194\n",
      "Iteration 8381: Weights = [5.50000000e+01 3.27702858e+00 6.89000505e+00 2.27003354e-02\n",
      " 2.29400116e-01 1.21613274e+01], Loss = 0.3194\n",
      "Iteration 8382: Weights = [5.50000000e+01 3.27693451e+00 6.88980726e+00 2.26996837e-02\n",
      " 2.29393531e-01 1.21615363e+01], Loss = 0.3194\n",
      "Iteration 8383: Weights = [5.50000000e+01 3.27684044e+00 6.88960948e+00 2.26990321e-02\n",
      " 2.29386946e-01 1.21617453e+01], Loss = 0.3193\n",
      "Iteration 8384: Weights = [5.50000000e+01 3.27674637e+00 6.88941171e+00 2.26983805e-02\n",
      " 2.29380361e-01 1.21619542e+01], Loss = 0.3193\n",
      "Iteration 8385: Weights = [5.50000000e+01 3.27665231e+00 6.88921394e+00 2.26977289e-02\n",
      " 2.29373776e-01 1.21621632e+01], Loss = 0.3193\n",
      "Iteration 8386: Weights = [5.50000000e+01 3.27655825e+00 6.88901618e+00 2.26970773e-02\n",
      " 2.29367192e-01 1.21623721e+01], Loss = 0.3193\n",
      "Iteration 8387: Weights = [5.50000000e+01 3.27646419e+00 6.88881842e+00 2.26964258e-02\n",
      " 2.29360607e-01 1.21625810e+01], Loss = 0.3193\n",
      "Iteration 8388: Weights = [5.50000000e+01 3.27637013e+00 6.88862066e+00 2.26957743e-02\n",
      " 2.29354023e-01 1.21627899e+01], Loss = 0.3192\n",
      "Iteration 8389: Weights = [5.50000000e+01 3.27627608e+00 6.88842292e+00 2.26951227e-02\n",
      " 2.29347439e-01 1.21629989e+01], Loss = 0.3192\n",
      "Iteration 8390: Weights = [5.50000000e+01 3.27618203e+00 6.88822518e+00 2.26944713e-02\n",
      " 2.29340856e-01 1.21632078e+01], Loss = 0.3192\n",
      "Iteration 8391: Weights = [5.50000000e+01 3.27608798e+00 6.88802744e+00 2.26938198e-02\n",
      " 2.29334272e-01 1.21634167e+01], Loss = 0.3192\n",
      "Iteration 8392: Weights = [5.50000000e+01 3.27599394e+00 6.88782971e+00 2.26931683e-02\n",
      " 2.29327689e-01 1.21636256e+01], Loss = 0.3192\n",
      "Iteration 8393: Weights = [5.50000000e+01 3.27589990e+00 6.88763199e+00 2.26925169e-02\n",
      " 2.29321106e-01 1.21638345e+01], Loss = 0.3192\n",
      "Iteration 8394: Weights = [5.50000000e+01 3.27580586e+00 6.88743427e+00 2.26918655e-02\n",
      " 2.29314523e-01 1.21640434e+01], Loss = 0.3191\n",
      "Iteration 8395: Weights = [5.50000000e+01 3.27571182e+00 6.88723656e+00 2.26912141e-02\n",
      " 2.29307940e-01 1.21642522e+01], Loss = 0.3191\n",
      "Iteration 8396: Weights = [5.50000000e+01 3.27561779e+00 6.88703885e+00 2.26905627e-02\n",
      " 2.29301357e-01 1.21644611e+01], Loss = 0.3191\n",
      "Iteration 8397: Weights = [5.50000000e+01 3.27552376e+00 6.88684115e+00 2.26899113e-02\n",
      " 2.29294775e-01 1.21646700e+01], Loss = 0.3191\n",
      "Iteration 8398: Weights = [5.50000000e+01 3.27542973e+00 6.88664345e+00 2.26892600e-02\n",
      " 2.29288193e-01 1.21648788e+01], Loss = 0.3191\n",
      "Iteration 8399: Weights = [5.50000000e+01 3.27533570e+00 6.88644576e+00 2.26886087e-02\n",
      " 2.29281611e-01 1.21650877e+01], Loss = 0.3190\n",
      "Iteration 8400: Weights = [5.50000000e+01 3.27524168e+00 6.88624808e+00 2.26879573e-02\n",
      " 2.29275029e-01 1.21652965e+01], Loss = 0.3190\n",
      "Iteration 8401: Weights = [5.50000000e+01 3.27514766e+00 6.88605040e+00 2.26873061e-02\n",
      " 2.29268447e-01 1.21655054e+01], Loss = 0.3190\n",
      "Iteration 8402: Weights = [5.50000000e+01 3.27505364e+00 6.88585272e+00 2.26866548e-02\n",
      " 2.29261866e-01 1.21657142e+01], Loss = 0.3190\n",
      "Iteration 8403: Weights = [5.50000000e+01 3.27495963e+00 6.88565506e+00 2.26860035e-02\n",
      " 2.29255284e-01 1.21659231e+01], Loss = 0.3190\n",
      "Iteration 8404: Weights = [5.50000000e+01 3.27486562e+00 6.88545740e+00 2.26853523e-02\n",
      " 2.29248703e-01 1.21661319e+01], Loss = 0.3190\n",
      "Iteration 8405: Weights = [5.50000000e+01 3.27477161e+00 6.88525974e+00 2.26847011e-02\n",
      " 2.29242123e-01 1.21663407e+01], Loss = 0.3189\n",
      "Iteration 8406: Weights = [5.50000000e+01 3.27467760e+00 6.88506209e+00 2.26840499e-02\n",
      " 2.29235542e-01 1.21665495e+01], Loss = 0.3189\n",
      "Iteration 8407: Weights = [5.50000000e+01 3.27458360e+00 6.88486444e+00 2.26833987e-02\n",
      " 2.29228961e-01 1.21667583e+01], Loss = 0.3189\n",
      "Iteration 8408: Weights = [5.50000000e+01 3.27448960e+00 6.88466681e+00 2.26827476e-02\n",
      " 2.29222381e-01 1.21669671e+01], Loss = 0.3189\n",
      "Iteration 8409: Weights = [5.50000000e+01 3.27439560e+00 6.88446917e+00 2.26820964e-02\n",
      " 2.29215801e-01 1.21671759e+01], Loss = 0.3189\n",
      "Iteration 8410: Weights = [5.50000000e+01 3.27430160e+00 6.88427154e+00 2.26814453e-02\n",
      " 2.29209221e-01 1.21673847e+01], Loss = 0.3188\n",
      "Iteration 8411: Weights = [5.50000000e+01 3.27420761e+00 6.88407392e+00 2.26807942e-02\n",
      " 2.29202641e-01 1.21675935e+01], Loss = 0.3188\n",
      "Iteration 8412: Weights = [5.50000000e+01 3.27411362e+00 6.88387631e+00 2.26801431e-02\n",
      " 2.29196062e-01 1.21678023e+01], Loss = 0.3188\n",
      "Iteration 8413: Weights = [5.50000000e+01 3.27401963e+00 6.88367870e+00 2.26794921e-02\n",
      " 2.29189482e-01 1.21680111e+01], Loss = 0.3188\n",
      "Iteration 8414: Weights = [5.50000000e+01 3.27392565e+00 6.88348109e+00 2.26788410e-02\n",
      " 2.29182903e-01 1.21682198e+01], Loss = 0.3188\n",
      "Iteration 8415: Weights = [5.50000000e+01 3.27383166e+00 6.88328349e+00 2.26781900e-02\n",
      " 2.29176324e-01 1.21684286e+01], Loss = 0.3188\n",
      "Iteration 8416: Weights = [5.50000000e+01 3.27373768e+00 6.88308590e+00 2.26775390e-02\n",
      " 2.29169745e-01 1.21686373e+01], Loss = 0.3187\n",
      "Iteration 8417: Weights = [5.50000000e+01 3.27364371e+00 6.88288831e+00 2.26768880e-02\n",
      " 2.29163167e-01 1.21688461e+01], Loss = 0.3187\n",
      "Iteration 8418: Weights = [5.50000000e+01 3.27354973e+00 6.88269073e+00 2.26762370e-02\n",
      " 2.29156588e-01 1.21690548e+01], Loss = 0.3187\n",
      "Iteration 8419: Weights = [5.50000000e+01 3.27345576e+00 6.88249315e+00 2.26755861e-02\n",
      " 2.29150010e-01 1.21692636e+01], Loss = 0.3187\n",
      "Iteration 8420: Weights = [5.50000000e+01 3.27336179e+00 6.88229558e+00 2.26749351e-02\n",
      " 2.29143432e-01 1.21694723e+01], Loss = 0.3187\n",
      "Iteration 8421: Weights = [5.50000000e+01 3.27326783e+00 6.88209801e+00 2.26742842e-02\n",
      " 2.29136854e-01 1.21696810e+01], Loss = 0.3186\n",
      "Iteration 8422: Weights = [5.50000000e+01 3.27317386e+00 6.88190045e+00 2.26736333e-02\n",
      " 2.29130276e-01 1.21698897e+01], Loss = 0.3186\n",
      "Iteration 8423: Weights = [5.50000000e+01 3.27307990e+00 6.88170290e+00 2.26729825e-02\n",
      " 2.29123699e-01 1.21700984e+01], Loss = 0.3186\n",
      "Iteration 8424: Weights = [5.50000000e+01 3.27298594e+00 6.88150535e+00 2.26723316e-02\n",
      " 2.29117122e-01 1.21703072e+01], Loss = 0.3186\n",
      "Iteration 8425: Weights = [5.50000000e+01 3.27289199e+00 6.88130781e+00 2.26716808e-02\n",
      " 2.29110545e-01 1.21705159e+01], Loss = 0.3186\n",
      "Iteration 8426: Weights = [5.50000000e+01 3.27279804e+00 6.88111027e+00 2.26710299e-02\n",
      " 2.29103968e-01 1.21707246e+01], Loss = 0.3186\n",
      "Iteration 8427: Weights = [5.50000000e+01 3.27270409e+00 6.88091274e+00 2.26703791e-02\n",
      " 2.29097391e-01 1.21709332e+01], Loss = 0.3185\n",
      "Iteration 8428: Weights = [5.50000000e+01 3.27261014e+00 6.88071522e+00 2.26697284e-02\n",
      " 2.29090814e-01 1.21711419e+01], Loss = 0.3185\n",
      "Iteration 8429: Weights = [5.50000000e+01 3.27251619e+00 6.88051770e+00 2.26690776e-02\n",
      " 2.29084238e-01 1.21713506e+01], Loss = 0.3185\n",
      "Iteration 8430: Weights = [5.50000000e+01 3.27242225e+00 6.88032018e+00 2.26684269e-02\n",
      " 2.29077662e-01 1.21715593e+01], Loss = 0.3185\n",
      "Iteration 8431: Weights = [5.50000000e+01 3.27232831e+00 6.88012267e+00 2.26677761e-02\n",
      " 2.29071086e-01 1.21717679e+01], Loss = 0.3185\n",
      "Iteration 8432: Weights = [5.50000000e+01 3.27223438e+00 6.87992517e+00 2.26671254e-02\n",
      " 2.29064510e-01 1.21719766e+01], Loss = 0.3184\n",
      "Iteration 8433: Weights = [5.50000000e+01 3.27214044e+00 6.87972767e+00 2.26664747e-02\n",
      " 2.29057934e-01 1.21721852e+01], Loss = 0.3184\n",
      "Iteration 8434: Weights = [5.50000000e+01 3.27204651e+00 6.87953018e+00 2.26658241e-02\n",
      " 2.29051359e-01 1.21723939e+01], Loss = 0.3184\n",
      "Iteration 8435: Weights = [5.50000000e+01 3.27195258e+00 6.87933269e+00 2.26651734e-02\n",
      " 2.29044784e-01 1.21726025e+01], Loss = 0.3184\n",
      "Iteration 8436: Weights = [5.50000000e+01 3.27185866e+00 6.87913521e+00 2.26645228e-02\n",
      " 2.29038209e-01 1.21728112e+01], Loss = 0.3184\n",
      "Iteration 8437: Weights = [5.50000000e+01 3.27176474e+00 6.87893774e+00 2.26638722e-02\n",
      " 2.29031634e-01 1.21730198e+01], Loss = 0.3184\n",
      "Iteration 8438: Weights = [5.50000000e+01 3.27167082e+00 6.87874027e+00 2.26632216e-02\n",
      " 2.29025059e-01 1.21732284e+01], Loss = 0.3183\n",
      "Iteration 8439: Weights = [5.50000000e+01 3.27157690e+00 6.87854281e+00 2.26625710e-02\n",
      " 2.29018485e-01 1.21734370e+01], Loss = 0.3183\n",
      "Iteration 8440: Weights = [5.50000000e+01 3.27148298e+00 6.87834535e+00 2.26619204e-02\n",
      " 2.29011911e-01 1.21736456e+01], Loss = 0.3183\n",
      "Iteration 8441: Weights = [5.50000000e+01 3.27138907e+00 6.87814790e+00 2.26612699e-02\n",
      " 2.29005336e-01 1.21738543e+01], Loss = 0.3183\n",
      "Iteration 8442: Weights = [5.50000000e+01 3.27129516e+00 6.87795045e+00 2.26606194e-02\n",
      " 2.28998763e-01 1.21740629e+01], Loss = 0.3183\n",
      "Iteration 8443: Weights = [5.50000000e+01 3.27120125e+00 6.87775301e+00 2.26599689e-02\n",
      " 2.28992189e-01 1.21742714e+01], Loss = 0.3182\n",
      "Iteration 8444: Weights = [5.50000000e+01 3.27110735e+00 6.87755558e+00 2.26593184e-02\n",
      " 2.28985615e-01 1.21744800e+01], Loss = 0.3182\n",
      "Iteration 8445: Weights = [5.50000000e+01 3.27101345e+00 6.87735815e+00 2.26586679e-02\n",
      " 2.28979042e-01 1.21746886e+01], Loss = 0.3182\n",
      "Iteration 8446: Weights = [5.50000000e+01 3.27091955e+00 6.87716072e+00 2.26580175e-02\n",
      " 2.28972469e-01 1.21748972e+01], Loss = 0.3182\n",
      "Iteration 8447: Weights = [5.50000000e+01 3.27082565e+00 6.87696331e+00 2.26573670e-02\n",
      " 2.28965896e-01 1.21751058e+01], Loss = 0.3182\n",
      "Iteration 8448: Weights = [5.50000000e+01 3.27073176e+00 6.87676589e+00 2.26567166e-02\n",
      " 2.28959323e-01 1.21753143e+01], Loss = 0.3182\n",
      "Iteration 8449: Weights = [5.50000000e+01 3.27063787e+00 6.87656849e+00 2.26560662e-02\n",
      " 2.28952751e-01 1.21755229e+01], Loss = 0.3181\n",
      "Iteration 8450: Weights = [5.50000000e+01 3.27054398e+00 6.87637109e+00 2.26554159e-02\n",
      " 2.28946178e-01 1.21757314e+01], Loss = 0.3181\n",
      "Iteration 8451: Weights = [5.50000000e+01 3.27045010e+00 6.87617369e+00 2.26547655e-02\n",
      " 2.28939606e-01 1.21759400e+01], Loss = 0.3181\n",
      "Iteration 8452: Weights = [5.50000000e+01 3.27035621e+00 6.87597630e+00 2.26541152e-02\n",
      " 2.28933034e-01 1.21761485e+01], Loss = 0.3181\n",
      "Iteration 8453: Weights = [5.50000000e+01 3.27026233e+00 6.87577892e+00 2.26534649e-02\n",
      " 2.28926462e-01 1.21763570e+01], Loss = 0.3181\n",
      "Iteration 8454: Weights = [5.50000000e+01 3.27016846e+00 6.87558154e+00 2.26528146e-02\n",
      " 2.28919891e-01 1.21765656e+01], Loss = 0.3180\n",
      "Iteration 8455: Weights = [5.50000000e+01 3.27007458e+00 6.87538417e+00 2.26521643e-02\n",
      " 2.28913319e-01 1.21767741e+01], Loss = 0.3180\n",
      "Iteration 8456: Weights = [5.50000000e+01 3.26998071e+00 6.87518680e+00 2.26515140e-02\n",
      " 2.28906748e-01 1.21769826e+01], Loss = 0.3180\n",
      "Iteration 8457: Weights = [5.50000000e+01 3.26988684e+00 6.87498944e+00 2.26508638e-02\n",
      " 2.28900177e-01 1.21771911e+01], Loss = 0.3180\n",
      "Iteration 8458: Weights = [5.50000000e+01 3.26979298e+00 6.87479208e+00 2.26502136e-02\n",
      " 2.28893606e-01 1.21773996e+01], Loss = 0.3180\n",
      "Iteration 8459: Weights = [5.50000000e+01 3.26969911e+00 6.87459473e+00 2.26495634e-02\n",
      " 2.28887035e-01 1.21776081e+01], Loss = 0.3180\n",
      "Iteration 8460: Weights = [5.50000000e+01 3.26960525e+00 6.87439739e+00 2.26489132e-02\n",
      " 2.28880465e-01 1.21778166e+01], Loss = 0.3179\n",
      "Iteration 8461: Weights = [5.50000000e+01 3.26951139e+00 6.87420005e+00 2.26482630e-02\n",
      " 2.28873894e-01 1.21780251e+01], Loss = 0.3179\n",
      "Iteration 8462: Weights = [5.50000000e+01 3.26941754e+00 6.87400272e+00 2.26476129e-02\n",
      " 2.28867324e-01 1.21782336e+01], Loss = 0.3179\n",
      "Iteration 8463: Weights = [5.50000000e+01 3.26932368e+00 6.87380539e+00 2.26469627e-02\n",
      " 2.28860754e-01 1.21784420e+01], Loss = 0.3179\n",
      "Iteration 8464: Weights = [5.50000000e+01 3.26922983e+00 6.87360807e+00 2.26463126e-02\n",
      " 2.28854185e-01 1.21786505e+01], Loss = 0.3179\n",
      "Iteration 8465: Weights = [5.50000000e+01 3.26913599e+00 6.87341075e+00 2.26456625e-02\n",
      " 2.28847615e-01 1.21788590e+01], Loss = 0.3178\n",
      "Iteration 8466: Weights = [5.50000000e+01 3.26904214e+00 6.87321344e+00 2.26450125e-02\n",
      " 2.28841046e-01 1.21790674e+01], Loss = 0.3178\n",
      "Iteration 8467: Weights = [5.50000000e+01 3.26894830e+00 6.87301614e+00 2.26443624e-02\n",
      " 2.28834476e-01 1.21792759e+01], Loss = 0.3178\n",
      "Iteration 8468: Weights = [5.50000000e+01 3.26885446e+00 6.87281884e+00 2.26437124e-02\n",
      " 2.28827907e-01 1.21794843e+01], Loss = 0.3178\n",
      "Iteration 8469: Weights = [5.50000000e+01 3.26876062e+00 6.87262155e+00 2.26430623e-02\n",
      " 2.28821339e-01 1.21796928e+01], Loss = 0.3178\n",
      "Iteration 8470: Weights = [5.50000000e+01 3.26866679e+00 6.87242426e+00 2.26424123e-02\n",
      " 2.28814770e-01 1.21799012e+01], Loss = 0.3178\n",
      "Iteration 8471: Weights = [5.50000000e+01 3.26857296e+00 6.87222698e+00 2.26417624e-02\n",
      " 2.28808202e-01 1.21801096e+01], Loss = 0.3177\n",
      "Iteration 8472: Weights = [5.50000000e+01 3.26847913e+00 6.87202970e+00 2.26411124e-02\n",
      " 2.28801633e-01 1.21803180e+01], Loss = 0.3177\n",
      "Iteration 8473: Weights = [5.50000000e+01 3.26838530e+00 6.87183243e+00 2.26404625e-02\n",
      " 2.28795065e-01 1.21805264e+01], Loss = 0.3177\n",
      "Iteration 8474: Weights = [5.50000000e+01 3.26829148e+00 6.87163516e+00 2.26398125e-02\n",
      " 2.28788497e-01 1.21807349e+01], Loss = 0.3177\n",
      "Iteration 8475: Weights = [5.50000000e+01 3.26819766e+00 6.87143791e+00 2.26391626e-02\n",
      " 2.28781930e-01 1.21809433e+01], Loss = 0.3177\n",
      "Iteration 8476: Weights = [5.50000000e+01 3.26810384e+00 6.87124065e+00 2.26385127e-02\n",
      " 2.28775362e-01 1.21811516e+01], Loss = 0.3176\n",
      "Iteration 8477: Weights = [5.50000000e+01 3.26801003e+00 6.87104340e+00 2.26378629e-02\n",
      " 2.28768795e-01 1.21813600e+01], Loss = 0.3176\n",
      "Iteration 8478: Weights = [5.50000000e+01 3.26791621e+00 6.87084616e+00 2.26372130e-02\n",
      " 2.28762228e-01 1.21815684e+01], Loss = 0.3176\n",
      "Iteration 8479: Weights = [5.50000000e+01 3.26782240e+00 6.87064892e+00 2.26365632e-02\n",
      " 2.28755661e-01 1.21817768e+01], Loss = 0.3176\n",
      "Iteration 8480: Weights = [5.50000000e+01 3.26772860e+00 6.87045169e+00 2.26359134e-02\n",
      " 2.28749094e-01 1.21819852e+01], Loss = 0.3176\n",
      "Iteration 8481: Weights = [5.50000000e+01 3.26763479e+00 6.87025447e+00 2.26352636e-02\n",
      " 2.28742528e-01 1.21821935e+01], Loss = 0.3175\n",
      "Iteration 8482: Weights = [5.50000000e+01 3.26754099e+00 6.87005725e+00 2.26346138e-02\n",
      " 2.28735961e-01 1.21824019e+01], Loss = 0.3175\n",
      "Iteration 8483: Weights = [5.50000000e+01 3.26744719e+00 6.86986003e+00 2.26339641e-02\n",
      " 2.28729395e-01 1.21826102e+01], Loss = 0.3175\n",
      "Iteration 8484: Weights = [5.50000000e+01 3.26735339e+00 6.86966283e+00 2.26333143e-02\n",
      " 2.28722829e-01 1.21828186e+01], Loss = 0.3175\n",
      "Iteration 8485: Weights = [5.50000000e+01 3.26725960e+00 6.86946562e+00 2.26326646e-02\n",
      " 2.28716263e-01 1.21830269e+01], Loss = 0.3175\n",
      "Iteration 8486: Weights = [5.50000000e+01 3.26716581e+00 6.86926843e+00 2.26320149e-02\n",
      " 2.28709698e-01 1.21832353e+01], Loss = 0.3175\n",
      "Iteration 8487: Weights = [5.50000000e+01 3.26707202e+00 6.86907124e+00 2.26313652e-02\n",
      " 2.28703132e-01 1.21834436e+01], Loss = 0.3174\n",
      "Iteration 8488: Weights = [5.50000000e+01 3.26697824e+00 6.86887405e+00 2.26307156e-02\n",
      " 2.28696567e-01 1.21836519e+01], Loss = 0.3174\n",
      "Iteration 8489: Weights = [5.50000000e+01 3.26688445e+00 6.86867687e+00 2.26300659e-02\n",
      " 2.28690002e-01 1.21838602e+01], Loss = 0.3174\n",
      "Iteration 8490: Weights = [5.50000000e+01 3.26679067e+00 6.86847970e+00 2.26294163e-02\n",
      " 2.28683437e-01 1.21840686e+01], Loss = 0.3174\n",
      "Iteration 8491: Weights = [5.50000000e+01 3.26669690e+00 6.86828253e+00 2.26287667e-02\n",
      " 2.28676873e-01 1.21842769e+01], Loss = 0.3174\n",
      "Iteration 8492: Weights = [5.50000000e+01 3.26660312e+00 6.86808536e+00 2.26281171e-02\n",
      " 2.28670308e-01 1.21844852e+01], Loss = 0.3173\n",
      "Iteration 8493: Weights = [5.50000000e+01 3.26650935e+00 6.86788821e+00 2.26274675e-02\n",
      " 2.28663744e-01 1.21846935e+01], Loss = 0.3173\n",
      "Iteration 8494: Weights = [5.50000000e+01 3.26641558e+00 6.86769105e+00 2.26268180e-02\n",
      " 2.28657180e-01 1.21849017e+01], Loss = 0.3173\n",
      "Iteration 8495: Weights = [5.50000000e+01 3.26632181e+00 6.86749391e+00 2.26261684e-02\n",
      " 2.28650616e-01 1.21851100e+01], Loss = 0.3173\n",
      "Iteration 8496: Weights = [5.50000000e+01 3.26622805e+00 6.86729677e+00 2.26255189e-02\n",
      " 2.28644052e-01 1.21853183e+01], Loss = 0.3173\n",
      "Iteration 8497: Weights = [5.50000000e+01 3.26613429e+00 6.86709963e+00 2.26248694e-02\n",
      " 2.28637489e-01 1.21855266e+01], Loss = 0.3173\n",
      "Iteration 8498: Weights = [5.50000000e+01 3.26604053e+00 6.86690250e+00 2.26242200e-02\n",
      " 2.28630925e-01 1.21857348e+01], Loss = 0.3172\n",
      "Iteration 8499: Weights = [5.50000000e+01 3.26594677e+00 6.86670538e+00 2.26235705e-02\n",
      " 2.28624362e-01 1.21859431e+01], Loss = 0.3172\n",
      "Iteration 8500: Weights = [5.50000000e+01 3.26585302e+00 6.86650826e+00 2.26229211e-02\n",
      " 2.28617799e-01 1.21861513e+01], Loss = 0.3172\n",
      "Iteration 8501: Weights = [5.50000000e+01 3.26575927e+00 6.86631115e+00 2.26222716e-02\n",
      " 2.28611236e-01 1.21863596e+01], Loss = 0.3172\n",
      "Iteration 8502: Weights = [5.50000000e+01 3.26566552e+00 6.86611404e+00 2.26216222e-02\n",
      " 2.28604674e-01 1.21865678e+01], Loss = 0.3172\n",
      "Iteration 8503: Weights = [5.50000000e+01 3.26557178e+00 6.86591694e+00 2.26209728e-02\n",
      " 2.28598111e-01 1.21867761e+01], Loss = 0.3171\n",
      "Iteration 8504: Weights = [5.50000000e+01 3.26547803e+00 6.86571985e+00 2.26203235e-02\n",
      " 2.28591549e-01 1.21869843e+01], Loss = 0.3171\n",
      "Iteration 8505: Weights = [5.50000000e+01 3.26538429e+00 6.86552276e+00 2.26196741e-02\n",
      " 2.28584987e-01 1.21871925e+01], Loss = 0.3171\n",
      "Iteration 8506: Weights = [5.50000000e+01 3.26529056e+00 6.86532568e+00 2.26190248e-02\n",
      " 2.28578425e-01 1.21874007e+01], Loss = 0.3171\n",
      "Iteration 8507: Weights = [5.50000000e+01 3.26519682e+00 6.86512860e+00 2.26183755e-02\n",
      " 2.28571864e-01 1.21876089e+01], Loss = 0.3171\n",
      "Iteration 8508: Weights = [5.50000000e+01 3.26510309e+00 6.86493152e+00 2.26177262e-02\n",
      " 2.28565302e-01 1.21878171e+01], Loss = 0.3171\n",
      "Iteration 8509: Weights = [5.50000000e+01 3.26500936e+00 6.86473446e+00 2.26170769e-02\n",
      " 2.28558741e-01 1.21880253e+01], Loss = 0.3170\n",
      "Iteration 8510: Weights = [5.50000000e+01 3.26491563e+00 6.86453740e+00 2.26164277e-02\n",
      " 2.28552180e-01 1.21882335e+01], Loss = 0.3170\n",
      "Iteration 8511: Weights = [5.50000000e+01 3.26482191e+00 6.86434034e+00 2.26157785e-02\n",
      " 2.28545619e-01 1.21884417e+01], Loss = 0.3170\n",
      "Iteration 8512: Weights = [5.50000000e+01 3.26472819e+00 6.86414329e+00 2.26151292e-02\n",
      " 2.28539058e-01 1.21886499e+01], Loss = 0.3170\n",
      "Iteration 8513: Weights = [5.50000000e+01 3.26463447e+00 6.86394625e+00 2.26144800e-02\n",
      " 2.28532498e-01 1.21888581e+01], Loss = 0.3170\n",
      "Iteration 8514: Weights = [5.50000000e+01 3.26454076e+00 6.86374921e+00 2.26138309e-02\n",
      " 2.28525938e-01 1.21890662e+01], Loss = 0.3169\n",
      "Iteration 8515: Weights = [5.50000000e+01 3.26444704e+00 6.86355218e+00 2.26131817e-02\n",
      " 2.28519377e-01 1.21892744e+01], Loss = 0.3169\n",
      "Iteration 8516: Weights = [5.50000000e+01 3.26435333e+00 6.86335515e+00 2.26125326e-02\n",
      " 2.28512817e-01 1.21894826e+01], Loss = 0.3169\n",
      "Iteration 8517: Weights = [5.50000000e+01 3.26425963e+00 6.86315813e+00 2.26118834e-02\n",
      " 2.28506258e-01 1.21896907e+01], Loss = 0.3169\n",
      "Iteration 8518: Weights = [5.50000000e+01 3.26416592e+00 6.86296111e+00 2.26112343e-02\n",
      " 2.28499698e-01 1.21898989e+01], Loss = 0.3169\n",
      "Iteration 8519: Weights = [5.50000000e+01 3.26407222e+00 6.86276410e+00 2.26105853e-02\n",
      " 2.28493139e-01 1.21901070e+01], Loss = 0.3169\n",
      "Iteration 8520: Weights = [5.50000000e+01 3.26397852e+00 6.86256710e+00 2.26099362e-02\n",
      " 2.28486580e-01 1.21903151e+01], Loss = 0.3168\n",
      "Iteration 8521: Weights = [5.50000000e+01 3.26388482e+00 6.86237010e+00 2.26092871e-02\n",
      " 2.28480021e-01 1.21905232e+01], Loss = 0.3168\n",
      "Iteration 8522: Weights = [5.50000000e+01 3.26379113e+00 6.86217310e+00 2.26086381e-02\n",
      " 2.28473462e-01 1.21907314e+01], Loss = 0.3168\n",
      "Iteration 8523: Weights = [5.50000000e+01 3.26369744e+00 6.86197612e+00 2.26079891e-02\n",
      " 2.28466903e-01 1.21909395e+01], Loss = 0.3168\n",
      "Iteration 8524: Weights = [5.50000000e+01 3.26360375e+00 6.86177913e+00 2.26073401e-02\n",
      " 2.28460345e-01 1.21911476e+01], Loss = 0.3168\n",
      "Iteration 8525: Weights = [5.50000000e+01 3.26351006e+00 6.86158216e+00 2.26066911e-02\n",
      " 2.28453786e-01 1.21913557e+01], Loss = 0.3167\n",
      "Iteration 8526: Weights = [5.50000000e+01 3.26341638e+00 6.86138519e+00 2.26060422e-02\n",
      " 2.28447228e-01 1.21915638e+01], Loss = 0.3167\n",
      "Iteration 8527: Weights = [5.50000000e+01 3.26332270e+00 6.86118822e+00 2.26053932e-02\n",
      " 2.28440670e-01 1.21917719e+01], Loss = 0.3167\n",
      "Iteration 8528: Weights = [5.50000000e+01 3.26322902e+00 6.86099126e+00 2.26047443e-02\n",
      " 2.28434113e-01 1.21919800e+01], Loss = 0.3167\n",
      "Iteration 8529: Weights = [5.50000000e+01 3.26313534e+00 6.86079431e+00 2.26040954e-02\n",
      " 2.28427555e-01 1.21921880e+01], Loss = 0.3167\n",
      "Iteration 8530: Weights = [5.50000000e+01 3.26304167e+00 6.86059736e+00 2.26034465e-02\n",
      " 2.28420998e-01 1.21923961e+01], Loss = 0.3167\n",
      "Iteration 8531: Weights = [5.50000000e+01 3.26294800e+00 6.86040042e+00 2.26027977e-02\n",
      " 2.28414441e-01 1.21926042e+01], Loss = 0.3166\n",
      "Iteration 8532: Weights = [5.50000000e+01 3.26285434e+00 6.86020348e+00 2.26021488e-02\n",
      " 2.28407884e-01 1.21928122e+01], Loss = 0.3166\n",
      "Iteration 8533: Weights = [5.50000000e+01 3.26276067e+00 6.86000655e+00 2.26015000e-02\n",
      " 2.28401327e-01 1.21930203e+01], Loss = 0.3166\n",
      "Iteration 8534: Weights = [5.50000000e+01 3.26266701e+00 6.85980962e+00 2.26008512e-02\n",
      " 2.28394771e-01 1.21932283e+01], Loss = 0.3166\n",
      "Iteration 8535: Weights = [5.50000000e+01 3.26257335e+00 6.85961270e+00 2.26002024e-02\n",
      " 2.28388214e-01 1.21934364e+01], Loss = 0.3166\n",
      "Iteration 8536: Weights = [5.50000000e+01 3.26247969e+00 6.85941579e+00 2.25995537e-02\n",
      " 2.28381658e-01 1.21936444e+01], Loss = 0.3165\n",
      "Iteration 8537: Weights = [5.50000000e+01 3.26238604e+00 6.85921888e+00 2.25989049e-02\n",
      " 2.28375102e-01 1.21938525e+01], Loss = 0.3165\n",
      "Iteration 8538: Weights = [5.50000000e+01 3.26229239e+00 6.85902198e+00 2.25982562e-02\n",
      " 2.28368546e-01 1.21940605e+01], Loss = 0.3165\n",
      "Iteration 8539: Weights = [5.50000000e+01 3.26219874e+00 6.85882508e+00 2.25976075e-02\n",
      " 2.28361991e-01 1.21942685e+01], Loss = 0.3165\n",
      "Iteration 8540: Weights = [5.50000000e+01 3.26210509e+00 6.85862819e+00 2.25969588e-02\n",
      " 2.28355435e-01 1.21944765e+01], Loss = 0.3165\n",
      "Iteration 8541: Weights = [5.50000000e+01 3.26201145e+00 6.85843130e+00 2.25963101e-02\n",
      " 2.28348880e-01 1.21946845e+01], Loss = 0.3165\n",
      "Iteration 8542: Weights = [5.50000000e+01 3.26191781e+00 6.85823442e+00 2.25956614e-02\n",
      " 2.28342325e-01 1.21948925e+01], Loss = 0.3164\n",
      "Iteration 8543: Weights = [5.50000000e+01 3.26182417e+00 6.85803755e+00 2.25950128e-02\n",
      " 2.28335770e-01 1.21951005e+01], Loss = 0.3164\n",
      "Iteration 8544: Weights = [5.50000000e+01 3.26173054e+00 6.85784068e+00 2.25943642e-02\n",
      " 2.28329215e-01 1.21953085e+01], Loss = 0.3164\n",
      "Iteration 8545: Weights = [5.50000000e+01 3.26163691e+00 6.85764382e+00 2.25937156e-02\n",
      " 2.28322661e-01 1.21955165e+01], Loss = 0.3164\n",
      "Iteration 8546: Weights = [5.50000000e+01 3.26154328e+00 6.85744696e+00 2.25930670e-02\n",
      " 2.28316107e-01 1.21957245e+01], Loss = 0.3164\n",
      "Iteration 8547: Weights = [5.50000000e+01 3.26144965e+00 6.85725011e+00 2.25924184e-02\n",
      " 2.28309552e-01 1.21959324e+01], Loss = 0.3163\n",
      "Iteration 8548: Weights = [5.50000000e+01 3.26135603e+00 6.85705326e+00 2.25917699e-02\n",
      " 2.28302999e-01 1.21961404e+01], Loss = 0.3163\n",
      "Iteration 8549: Weights = [5.50000000e+01 3.26126240e+00 6.85685642e+00 2.25911214e-02\n",
      " 2.28296445e-01 1.21963484e+01], Loss = 0.3163\n",
      "Iteration 8550: Weights = [5.50000000e+01 3.26116879e+00 6.85665959e+00 2.25904729e-02\n",
      " 2.28289891e-01 1.21965563e+01], Loss = 0.3163\n",
      "Iteration 8551: Weights = [5.50000000e+01 3.26107517e+00 6.85646276e+00 2.25898244e-02\n",
      " 2.28283338e-01 1.21967643e+01], Loss = 0.3163\n",
      "Iteration 8552: Weights = [5.50000000e+01 3.26098156e+00 6.85626593e+00 2.25891759e-02\n",
      " 2.28276785e-01 1.21969722e+01], Loss = 0.3163\n",
      "Iteration 8553: Weights = [5.50000000e+01 3.26088795e+00 6.85606911e+00 2.25885274e-02\n",
      " 2.28270232e-01 1.21971801e+01], Loss = 0.3162\n",
      "Iteration 8554: Weights = [5.50000000e+01 3.26079434e+00 6.85587230e+00 2.25878790e-02\n",
      " 2.28263679e-01 1.21973881e+01], Loss = 0.3162\n",
      "Iteration 8555: Weights = [5.50000000e+01 3.26070073e+00 6.85567550e+00 2.25872306e-02\n",
      " 2.28257126e-01 1.21975960e+01], Loss = 0.3162\n",
      "Iteration 8556: Weights = [5.50000000e+01 3.26060713e+00 6.85547869e+00 2.25865822e-02\n",
      " 2.28250574e-01 1.21978039e+01], Loss = 0.3162\n",
      "Iteration 8557: Weights = [5.50000000e+01 3.26051353e+00 6.85528190e+00 2.25859338e-02\n",
      " 2.28244022e-01 1.21980118e+01], Loss = 0.3162\n",
      "Iteration 8558: Weights = [5.50000000e+01 3.26041993e+00 6.85508511e+00 2.25852855e-02\n",
      " 2.28237470e-01 1.21982197e+01], Loss = 0.3161\n",
      "Iteration 8559: Weights = [5.50000000e+01 3.26032634e+00 6.85488832e+00 2.25846371e-02\n",
      " 2.28230918e-01 1.21984276e+01], Loss = 0.3161\n",
      "Iteration 8560: Weights = [5.50000000e+01 3.26023275e+00 6.85469155e+00 2.25839888e-02\n",
      " 2.28224366e-01 1.21986355e+01], Loss = 0.3161\n",
      "Iteration 8561: Weights = [5.50000000e+01 3.26013916e+00 6.85449477e+00 2.25833405e-02\n",
      " 2.28217815e-01 1.21988434e+01], Loss = 0.3161\n",
      "Iteration 8562: Weights = [5.50000000e+01 3.26004557e+00 6.85429801e+00 2.25826922e-02\n",
      " 2.28211263e-01 1.21990513e+01], Loss = 0.3161\n",
      "Iteration 8563: Weights = [5.50000000e+01 3.25995199e+00 6.85410124e+00 2.25820439e-02\n",
      " 2.28204712e-01 1.21992592e+01], Loss = 0.3161\n",
      "Iteration 8564: Weights = [5.50000000e+01 3.25985840e+00 6.85390449e+00 2.25813957e-02\n",
      " 2.28198161e-01 1.21994670e+01], Loss = 0.3160\n",
      "Iteration 8565: Weights = [5.50000000e+01 3.25976483e+00 6.85370774e+00 2.25807475e-02\n",
      " 2.28191611e-01 1.21996749e+01], Loss = 0.3160\n",
      "Iteration 8566: Weights = [5.50000000e+01 3.25967125e+00 6.85351099e+00 2.25800993e-02\n",
      " 2.28185060e-01 1.21998827e+01], Loss = 0.3160\n",
      "Iteration 8567: Weights = [5.50000000e+01 3.25957768e+00 6.85331425e+00 2.25794511e-02\n",
      " 2.28178510e-01 1.22000906e+01], Loss = 0.3160\n",
      "Iteration 8568: Weights = [5.50000000e+01 3.25948411e+00 6.85311752e+00 2.25788029e-02\n",
      " 2.28171960e-01 1.22002984e+01], Loss = 0.3160\n",
      "Iteration 8569: Weights = [5.50000000e+01 3.25939054e+00 6.85292079e+00 2.25781547e-02\n",
      " 2.28165410e-01 1.22005063e+01], Loss = 0.3159\n",
      "Iteration 8570: Weights = [5.50000000e+01 3.25929697e+00 6.85272407e+00 2.25775066e-02\n",
      " 2.28158860e-01 1.22007141e+01], Loss = 0.3159\n",
      "Iteration 8571: Weights = [5.50000000e+01 3.25920341e+00 6.85252736e+00 2.25768585e-02\n",
      " 2.28152310e-01 1.22009219e+01], Loss = 0.3159\n",
      "Iteration 8572: Weights = [5.50000000e+01 3.25910985e+00 6.85233064e+00 2.25762104e-02\n",
      " 2.28145761e-01 1.22011298e+01], Loss = 0.3159\n",
      "Iteration 8573: Weights = [5.50000000e+01 3.25901629e+00 6.85213394e+00 2.25755623e-02\n",
      " 2.28139212e-01 1.22013376e+01], Loss = 0.3159\n",
      "Iteration 8574: Weights = [5.50000000e+01 3.25892274e+00 6.85193724e+00 2.25749143e-02\n",
      " 2.28132663e-01 1.22015454e+01], Loss = 0.3159\n",
      "Iteration 8575: Weights = [5.50000000e+01 3.25882919e+00 6.85174055e+00 2.25742662e-02\n",
      " 2.28126114e-01 1.22017532e+01], Loss = 0.3158\n",
      "Iteration 8576: Weights = [5.50000000e+01 3.25873564e+00 6.85154386e+00 2.25736182e-02\n",
      " 2.28119565e-01 1.22019610e+01], Loss = 0.3158\n",
      "Iteration 8577: Weights = [5.50000000e+01 3.25864209e+00 6.85134718e+00 2.25729702e-02\n",
      " 2.28113017e-01 1.22021688e+01], Loss = 0.3158\n",
      "Iteration 8578: Weights = [5.50000000e+01 3.25854855e+00 6.85115050e+00 2.25723222e-02\n",
      " 2.28106468e-01 1.22023766e+01], Loss = 0.3158\n",
      "Iteration 8579: Weights = [5.50000000e+01 3.25845501e+00 6.85095383e+00 2.25716742e-02\n",
      " 2.28099920e-01 1.22025844e+01], Loss = 0.3158\n",
      "Iteration 8580: Weights = [5.50000000e+01 3.25836147e+00 6.85075716e+00 2.25710263e-02\n",
      " 2.28093372e-01 1.22027921e+01], Loss = 0.3157\n",
      "Iteration 8581: Weights = [5.50000000e+01 3.25826794e+00 6.85056050e+00 2.25703783e-02\n",
      " 2.28086825e-01 1.22029999e+01], Loss = 0.3157\n",
      "Iteration 8582: Weights = [5.50000000e+01 3.25817440e+00 6.85036385e+00 2.25697304e-02\n",
      " 2.28080277e-01 1.22032077e+01], Loss = 0.3157\n",
      "Iteration 8583: Weights = [5.50000000e+01 3.25808087e+00 6.85016720e+00 2.25690825e-02\n",
      " 2.28073730e-01 1.22034154e+01], Loss = 0.3157\n",
      "Iteration 8584: Weights = [5.50000000e+01 3.25798734e+00 6.84997056e+00 2.25684347e-02\n",
      " 2.28067182e-01 1.22036232e+01], Loss = 0.3157\n",
      "Iteration 8585: Weights = [5.50000000e+01 3.25789382e+00 6.84977392e+00 2.25677868e-02\n",
      " 2.28060636e-01 1.22038309e+01], Loss = 0.3157\n",
      "Iteration 8586: Weights = [5.50000000e+01 3.25780030e+00 6.84957729e+00 2.25671390e-02\n",
      " 2.28054089e-01 1.22040386e+01], Loss = 0.3156\n",
      "Iteration 8587: Weights = [5.50000000e+01 3.25770678e+00 6.84938066e+00 2.25664912e-02\n",
      " 2.28047542e-01 1.22042464e+01], Loss = 0.3156\n",
      "Iteration 8588: Weights = [5.50000000e+01 3.25761326e+00 6.84918404e+00 2.25658434e-02\n",
      " 2.28040996e-01 1.22044541e+01], Loss = 0.3156\n",
      "Iteration 8589: Weights = [5.50000000e+01 3.25751975e+00 6.84898743e+00 2.25651956e-02\n",
      " 2.28034450e-01 1.22046618e+01], Loss = 0.3156\n",
      "Iteration 8590: Weights = [5.50000000e+01 3.25742624e+00 6.84879082e+00 2.25645478e-02\n",
      " 2.28027904e-01 1.22048695e+01], Loss = 0.3156\n",
      "Iteration 8591: Weights = [5.50000000e+01 3.25733273e+00 6.84859421e+00 2.25639001e-02\n",
      " 2.28021358e-01 1.22050772e+01], Loss = 0.3156\n",
      "Iteration 8592: Weights = [5.50000000e+01 3.25723922e+00 6.84839761e+00 2.25632523e-02\n",
      " 2.28014812e-01 1.22052850e+01], Loss = 0.3155\n",
      "Iteration 8593: Weights = [5.50000000e+01 3.25714572e+00 6.84820102e+00 2.25626046e-02\n",
      " 2.28008267e-01 1.22054926e+01], Loss = 0.3155\n",
      "Iteration 8594: Weights = [5.50000000e+01 3.25705222e+00 6.84800444e+00 2.25619569e-02\n",
      " 2.28001721e-01 1.22057003e+01], Loss = 0.3155\n",
      "Iteration 8595: Weights = [5.50000000e+01 3.25695872e+00 6.84780785e+00 2.25613093e-02\n",
      " 2.27995176e-01 1.22059080e+01], Loss = 0.3155\n",
      "Iteration 8596: Weights = [5.50000000e+01 3.25686522e+00 6.84761128e+00 2.25606616e-02\n",
      " 2.27988631e-01 1.22061157e+01], Loss = 0.3155\n",
      "Iteration 8597: Weights = [5.50000000e+01 3.25677173e+00 6.84741471e+00 2.25600140e-02\n",
      " 2.27982087e-01 1.22063234e+01], Loss = 0.3154\n",
      "Iteration 8598: Weights = [5.50000000e+01 3.25667824e+00 6.84721815e+00 2.25593664e-02\n",
      " 2.27975542e-01 1.22065310e+01], Loss = 0.3154\n",
      "Iteration 8599: Weights = [5.50000000e+01 3.25658475e+00 6.84702159e+00 2.25587188e-02\n",
      " 2.27968998e-01 1.22067387e+01], Loss = 0.3154\n",
      "Iteration 8600: Weights = [5.50000000e+01 3.25649127e+00 6.84682503e+00 2.25580712e-02\n",
      " 2.27962454e-01 1.22069464e+01], Loss = 0.3154\n",
      "Iteration 8601: Weights = [5.50000000e+01 3.25639779e+00 6.84662849e+00 2.25574236e-02\n",
      " 2.27955910e-01 1.22071540e+01], Loss = 0.3154\n",
      "Iteration 8602: Weights = [5.50000000e+01 3.25630431e+00 6.84643195e+00 2.25567761e-02\n",
      " 2.27949366e-01 1.22073616e+01], Loss = 0.3154\n",
      "Iteration 8603: Weights = [5.50000000e+01 3.25621083e+00 6.84623541e+00 2.25561286e-02\n",
      " 2.27942822e-01 1.22075693e+01], Loss = 0.3153\n",
      "Iteration 8604: Weights = [5.50000000e+01 3.25611736e+00 6.84603888e+00 2.25554811e-02\n",
      " 2.27936279e-01 1.22077769e+01], Loss = 0.3153\n",
      "Iteration 8605: Weights = [5.50000000e+01 3.25602389e+00 6.84584236e+00 2.25548336e-02\n",
      " 2.27929736e-01 1.22079845e+01], Loss = 0.3153\n",
      "Iteration 8606: Weights = [5.50000000e+01 3.25593042e+00 6.84564584e+00 2.25541861e-02\n",
      " 2.27923193e-01 1.22081922e+01], Loss = 0.3153\n",
      "Iteration 8607: Weights = [5.50000000e+01 3.25583695e+00 6.84544932e+00 2.25535387e-02\n",
      " 2.27916650e-01 1.22083998e+01], Loss = 0.3153\n",
      "Iteration 8608: Weights = [5.50000000e+01 3.25574349e+00 6.84525282e+00 2.25528912e-02\n",
      " 2.27910107e-01 1.22086074e+01], Loss = 0.3152\n",
      "Iteration 8609: Weights = [5.50000000e+01 3.25565003e+00 6.84505631e+00 2.25522438e-02\n",
      " 2.27903565e-01 1.22088150e+01], Loss = 0.3152\n",
      "Iteration 8610: Weights = [5.50000000e+01 3.25555657e+00 6.84485982e+00 2.25515964e-02\n",
      " 2.27897022e-01 1.22090226e+01], Loss = 0.3152\n",
      "Iteration 8611: Weights = [5.50000000e+01 3.25546312e+00 6.84466333e+00 2.25509491e-02\n",
      " 2.27890480e-01 1.22092302e+01], Loss = 0.3152\n",
      "Iteration 8612: Weights = [5.50000000e+01 3.25536967e+00 6.84446684e+00 2.25503017e-02\n",
      " 2.27883938e-01 1.22094377e+01], Loss = 0.3152\n",
      "Iteration 8613: Weights = [5.50000000e+01 3.25527622e+00 6.84427036e+00 2.25496544e-02\n",
      " 2.27877397e-01 1.22096453e+01], Loss = 0.3152\n",
      "Iteration 8614: Weights = [5.50000000e+01 3.25518277e+00 6.84407389e+00 2.25490071e-02\n",
      " 2.27870855e-01 1.22098529e+01], Loss = 0.3151\n",
      "Iteration 8615: Weights = [5.50000000e+01 3.25508932e+00 6.84387742e+00 2.25483598e-02\n",
      " 2.27864314e-01 1.22100605e+01], Loss = 0.3151\n",
      "Iteration 8616: Weights = [5.50000000e+01 3.25499588e+00 6.84368096e+00 2.25477125e-02\n",
      " 2.27857773e-01 1.22102680e+01], Loss = 0.3151\n",
      "Iteration 8617: Weights = [5.50000000e+01 3.25490244e+00 6.84348450e+00 2.25470652e-02\n",
      " 2.27851232e-01 1.22104756e+01], Loss = 0.3151\n",
      "Iteration 8618: Weights = [5.50000000e+01 3.25480901e+00 6.84328805e+00 2.25464180e-02\n",
      " 2.27844691e-01 1.22106831e+01], Loss = 0.3151\n",
      "Iteration 8619: Weights = [5.50000000e+01 3.25471557e+00 6.84309161e+00 2.25457708e-02\n",
      " 2.27838150e-01 1.22108907e+01], Loss = 0.3150\n",
      "Iteration 8620: Weights = [5.50000000e+01 3.25462214e+00 6.84289517e+00 2.25451235e-02\n",
      " 2.27831610e-01 1.22110982e+01], Loss = 0.3150\n",
      "Iteration 8621: Weights = [5.50000000e+01 3.25452871e+00 6.84269873e+00 2.25444764e-02\n",
      " 2.27825070e-01 1.22113057e+01], Loss = 0.3150\n",
      "Iteration 8622: Weights = [5.50000000e+01 3.25443529e+00 6.84250230e+00 2.25438292e-02\n",
      " 2.27818530e-01 1.22115133e+01], Loss = 0.3150\n",
      "Iteration 8623: Weights = [5.50000000e+01 3.25434187e+00 6.84230588e+00 2.25431820e-02\n",
      " 2.27811990e-01 1.22117208e+01], Loss = 0.3150\n",
      "Iteration 8624: Weights = [5.50000000e+01 3.25424845e+00 6.84210946e+00 2.25425349e-02\n",
      " 2.27805450e-01 1.22119283e+01], Loss = 0.3150\n",
      "Iteration 8625: Weights = [5.50000000e+01 3.25415503e+00 6.84191305e+00 2.25418878e-02\n",
      " 2.27798911e-01 1.22121358e+01], Loss = 0.3149\n",
      "Iteration 8626: Weights = [5.50000000e+01 3.25406161e+00 6.84171664e+00 2.25412407e-02\n",
      " 2.27792372e-01 1.22123433e+01], Loss = 0.3149\n",
      "Iteration 8627: Weights = [5.50000000e+01 3.25396820e+00 6.84152024e+00 2.25405936e-02\n",
      " 2.27785833e-01 1.22125508e+01], Loss = 0.3149\n",
      "Iteration 8628: Weights = [5.50000000e+01 3.25387479e+00 6.84132385e+00 2.25399466e-02\n",
      " 2.27779294e-01 1.22127583e+01], Loss = 0.3149\n",
      "Iteration 8629: Weights = [5.50000000e+01 3.25378139e+00 6.84112746e+00 2.25392995e-02\n",
      " 2.27772755e-01 1.22129658e+01], Loss = 0.3149\n",
      "Iteration 8630: Weights = [5.50000000e+01 3.25368798e+00 6.84093108e+00 2.25386525e-02\n",
      " 2.27766216e-01 1.22131732e+01], Loss = 0.3148\n",
      "Iteration 8631: Weights = [5.50000000e+01 3.25359458e+00 6.84073470e+00 2.25380055e-02\n",
      " 2.27759678e-01 1.22133807e+01], Loss = 0.3148\n",
      "Iteration 8632: Weights = [5.50000000e+01 3.25350118e+00 6.84053833e+00 2.25373585e-02\n",
      " 2.27753140e-01 1.22135882e+01], Loss = 0.3148\n",
      "Iteration 8633: Weights = [5.50000000e+01 3.25340779e+00 6.84034196e+00 2.25367116e-02\n",
      " 2.27746602e-01 1.22137956e+01], Loss = 0.3148\n",
      "Iteration 8634: Weights = [5.50000000e+01 3.25331439e+00 6.84014560e+00 2.25360646e-02\n",
      " 2.27740064e-01 1.22140031e+01], Loss = 0.3148\n",
      "Iteration 8635: Weights = [5.50000000e+01 3.25322100e+00 6.83994924e+00 2.25354177e-02\n",
      " 2.27733527e-01 1.22142105e+01], Loss = 0.3148\n",
      "Iteration 8636: Weights = [5.50000000e+01 3.25312761e+00 6.83975289e+00 2.25347708e-02\n",
      " 2.27726989e-01 1.22144180e+01], Loss = 0.3147\n",
      "Iteration 8637: Weights = [5.50000000e+01 3.25303423e+00 6.83955655e+00 2.25341239e-02\n",
      " 2.27720452e-01 1.22146254e+01], Loss = 0.3147\n",
      "Iteration 8638: Weights = [5.50000000e+01 3.25294085e+00 6.83936021e+00 2.25334770e-02\n",
      " 2.27713915e-01 1.22148328e+01], Loss = 0.3147\n",
      "Iteration 8639: Weights = [5.50000000e+01 3.25284747e+00 6.83916388e+00 2.25328302e-02\n",
      " 2.27707378e-01 1.22150402e+01], Loss = 0.3147\n",
      "Iteration 8640: Weights = [5.50000000e+01 3.25275409e+00 6.83896755e+00 2.25321833e-02\n",
      " 2.27700842e-01 1.22152477e+01], Loss = 0.3147\n",
      "Iteration 8641: Weights = [5.50000000e+01 3.25266071e+00 6.83877123e+00 2.25315365e-02\n",
      " 2.27694305e-01 1.22154551e+01], Loss = 0.3146\n",
      "Iteration 8642: Weights = [5.50000000e+01 3.25256734e+00 6.83857491e+00 2.25308897e-02\n",
      " 2.27687769e-01 1.22156625e+01], Loss = 0.3146\n",
      "Iteration 8643: Weights = [5.50000000e+01 3.25247397e+00 6.83837860e+00 2.25302429e-02\n",
      " 2.27681233e-01 1.22158699e+01], Loss = 0.3146\n",
      "Iteration 8644: Weights = [5.50000000e+01 3.25238061e+00 6.83818230e+00 2.25295962e-02\n",
      " 2.27674697e-01 1.22160773e+01], Loss = 0.3146\n",
      "Iteration 8645: Weights = [5.50000000e+01 3.25228724e+00 6.83798600e+00 2.25289494e-02\n",
      " 2.27668161e-01 1.22162847e+01], Loss = 0.3146\n",
      "Iteration 8646: Weights = [5.50000000e+01 3.25219388e+00 6.83778971e+00 2.25283027e-02\n",
      " 2.27661626e-01 1.22164920e+01], Loss = 0.3146\n",
      "Iteration 8647: Weights = [5.50000000e+01 3.25210052e+00 6.83759342e+00 2.25276560e-02\n",
      " 2.27655090e-01 1.22166994e+01], Loss = 0.3145\n",
      "Iteration 8648: Weights = [5.50000000e+01 3.25200717e+00 6.83739714e+00 2.25270093e-02\n",
      " 2.27648555e-01 1.22169068e+01], Loss = 0.3145\n",
      "Iteration 8649: Weights = [5.50000000e+01 3.25191381e+00 6.83720086e+00 2.25263627e-02\n",
      " 2.27642020e-01 1.22171141e+01], Loss = 0.3145\n",
      "Iteration 8650: Weights = [5.50000000e+01 3.25182046e+00 6.83700459e+00 2.25257160e-02\n",
      " 2.27635486e-01 1.22173215e+01], Loss = 0.3145\n",
      "Iteration 8651: Weights = [5.50000000e+01 3.25172712e+00 6.83680832e+00 2.25250694e-02\n",
      " 2.27628951e-01 1.22175289e+01], Loss = 0.3145\n",
      "Iteration 8652: Weights = [5.50000000e+01 3.25163377e+00 6.83661206e+00 2.25244228e-02\n",
      " 2.27622417e-01 1.22177362e+01], Loss = 0.3144\n",
      "Iteration 8653: Weights = [5.50000000e+01 3.25154043e+00 6.83641581e+00 2.25237762e-02\n",
      " 2.27615882e-01 1.22179435e+01], Loss = 0.3144\n",
      "Iteration 8654: Weights = [5.50000000e+01 3.25144709e+00 6.83621956e+00 2.25231296e-02\n",
      " 2.27609348e-01 1.22181509e+01], Loss = 0.3144\n",
      "Iteration 8655: Weights = [5.50000000e+01 3.25135375e+00 6.83602332e+00 2.25224830e-02\n",
      " 2.27602815e-01 1.22183582e+01], Loss = 0.3144\n",
      "Iteration 8656: Weights = [5.50000000e+01 3.25126042e+00 6.83582708e+00 2.25218365e-02\n",
      " 2.27596281e-01 1.22185655e+01], Loss = 0.3144\n",
      "Iteration 8657: Weights = [5.50000000e+01 3.25116709e+00 6.83563085e+00 2.25211900e-02\n",
      " 2.27589747e-01 1.22187728e+01], Loss = 0.3144\n",
      "Iteration 8658: Weights = [5.50000000e+01 3.25107376e+00 6.83543463e+00 2.25205435e-02\n",
      " 2.27583214e-01 1.22189801e+01], Loss = 0.3143\n",
      "Iteration 8659: Weights = [5.50000000e+01 3.25098043e+00 6.83523841e+00 2.25198970e-02\n",
      " 2.27576681e-01 1.22191874e+01], Loss = 0.3143\n",
      "Iteration 8660: Weights = [5.50000000e+01 3.25088711e+00 6.83504219e+00 2.25192505e-02\n",
      " 2.27570148e-01 1.22193947e+01], Loss = 0.3143\n",
      "Iteration 8661: Weights = [5.50000000e+01 3.25079379e+00 6.83484598e+00 2.25186041e-02\n",
      " 2.27563616e-01 1.22196020e+01], Loss = 0.3143\n",
      "Iteration 8662: Weights = [5.50000000e+01 3.25070047e+00 6.83464978e+00 2.25179577e-02\n",
      " 2.27557083e-01 1.22198093e+01], Loss = 0.3143\n",
      "Iteration 8663: Weights = [5.50000000e+01 3.25060715e+00 6.83445358e+00 2.25173113e-02\n",
      " 2.27550551e-01 1.22200166e+01], Loss = 0.3142\n",
      "Iteration 8664: Weights = [5.50000000e+01 3.25051384e+00 6.83425739e+00 2.25166649e-02\n",
      " 2.27544019e-01 1.22202239e+01], Loss = 0.3142\n",
      "Iteration 8665: Weights = [5.50000000e+01 3.25042053e+00 6.83406120e+00 2.25160185e-02\n",
      " 2.27537487e-01 1.22204311e+01], Loss = 0.3142\n",
      "Iteration 8666: Weights = [5.50000000e+01 3.25032722e+00 6.83386502e+00 2.25153721e-02\n",
      " 2.27530955e-01 1.22206384e+01], Loss = 0.3142\n",
      "Iteration 8667: Weights = [5.50000000e+01 3.25023392e+00 6.83366885e+00 2.25147258e-02\n",
      " 2.27524423e-01 1.22208457e+01], Loss = 0.3142\n",
      "Iteration 8668: Weights = [5.50000000e+01 3.25014061e+00 6.83347268e+00 2.25140795e-02\n",
      " 2.27517892e-01 1.22210529e+01], Loss = 0.3142\n",
      "Iteration 8669: Weights = [5.50000000e+01 3.25004731e+00 6.83327651e+00 2.25134332e-02\n",
      " 2.27511361e-01 1.22212602e+01], Loss = 0.3141\n",
      "Iteration 8670: Weights = [5.50000000e+01 3.24995402e+00 6.83308036e+00 2.25127869e-02\n",
      " 2.27504830e-01 1.22214674e+01], Loss = 0.3141\n",
      "Iteration 8671: Weights = [5.50000000e+01 3.24986072e+00 6.83288420e+00 2.25121407e-02\n",
      " 2.27498299e-01 1.22216746e+01], Loss = 0.3141\n",
      "Iteration 8672: Weights = [5.50000000e+01 3.24976743e+00 6.83268806e+00 2.25114944e-02\n",
      " 2.27491768e-01 1.22218818e+01], Loss = 0.3141\n",
      "Iteration 8673: Weights = [5.50000000e+01 3.24967414e+00 6.83249192e+00 2.25108482e-02\n",
      " 2.27485238e-01 1.22220891e+01], Loss = 0.3141\n",
      "Iteration 8674: Weights = [5.50000000e+01 3.24958086e+00 6.83229578e+00 2.25102020e-02\n",
      " 2.27478708e-01 1.22222963e+01], Loss = 0.3141\n",
      "Iteration 8675: Weights = [5.50000000e+01 3.24948757e+00 6.83209965e+00 2.25095558e-02\n",
      " 2.27472177e-01 1.22225035e+01], Loss = 0.3140\n",
      "Iteration 8676: Weights = [5.50000000e+01 3.24939429e+00 6.83190353e+00 2.25089097e-02\n",
      " 2.27465648e-01 1.22227107e+01], Loss = 0.3140\n",
      "Iteration 8677: Weights = [5.50000000e+01 3.24930101e+00 6.83170741e+00 2.25082635e-02\n",
      " 2.27459118e-01 1.22229179e+01], Loss = 0.3140\n",
      "Iteration 8678: Weights = [5.50000000e+01 3.24920774e+00 6.83151129e+00 2.25076174e-02\n",
      " 2.27452588e-01 1.22231251e+01], Loss = 0.3140\n",
      "Iteration 8679: Weights = [5.50000000e+01 3.24911447e+00 6.83131519e+00 2.25069713e-02\n",
      " 2.27446059e-01 1.22233323e+01], Loss = 0.3140\n",
      "Iteration 8680: Weights = [5.50000000e+01 3.24902120e+00 6.83111908e+00 2.25063252e-02\n",
      " 2.27439530e-01 1.22235394e+01], Loss = 0.3139\n",
      "Iteration 8681: Weights = [5.50000000e+01 3.24892793e+00 6.83092299e+00 2.25056791e-02\n",
      " 2.27433001e-01 1.22237466e+01], Loss = 0.3139\n",
      "Iteration 8682: Weights = [5.50000000e+01 3.24883466e+00 6.83072690e+00 2.25050330e-02\n",
      " 2.27426472e-01 1.22239538e+01], Loss = 0.3139\n",
      "Iteration 8683: Weights = [5.50000000e+01 3.24874140e+00 6.83053081e+00 2.25043870e-02\n",
      " 2.27419944e-01 1.22241609e+01], Loss = 0.3139\n",
      "Iteration 8684: Weights = [5.50000000e+01 3.24864814e+00 6.83033473e+00 2.25037410e-02\n",
      " 2.27413415e-01 1.22243681e+01], Loss = 0.3139\n",
      "Iteration 8685: Weights = [5.50000000e+01 3.24855489e+00 6.83013866e+00 2.25030950e-02\n",
      " 2.27406887e-01 1.22245752e+01], Loss = 0.3139\n",
      "Iteration 8686: Weights = [5.50000000e+01 3.24846163e+00 6.82994259e+00 2.25024490e-02\n",
      " 2.27400359e-01 1.22247824e+01], Loss = 0.3138\n",
      "Iteration 8687: Weights = [5.50000000e+01 3.24836838e+00 6.82974653e+00 2.25018030e-02\n",
      " 2.27393831e-01 1.22249895e+01], Loss = 0.3138\n",
      "Iteration 8688: Weights = [5.50000000e+01 3.24827513e+00 6.82955047e+00 2.25011571e-02\n",
      " 2.27387304e-01 1.22251967e+01], Loss = 0.3138\n",
      "Iteration 8689: Weights = [5.50000000e+01 3.24818189e+00 6.82935442e+00 2.25005112e-02\n",
      " 2.27380776e-01 1.22254038e+01], Loss = 0.3138\n",
      "Iteration 8690: Weights = [5.50000000e+01 3.24808864e+00 6.82915838e+00 2.24998653e-02\n",
      " 2.27374249e-01 1.22256109e+01], Loss = 0.3138\n",
      "Iteration 8691: Weights = [5.50000000e+01 3.24799540e+00 6.82896234e+00 2.24992194e-02\n",
      " 2.27367722e-01 1.22258180e+01], Loss = 0.3137\n",
      "Iteration 8692: Weights = [5.50000000e+01 3.24790216e+00 6.82876630e+00 2.24985735e-02\n",
      " 2.27361195e-01 1.22260251e+01], Loss = 0.3137\n",
      "Iteration 8693: Weights = [5.50000000e+01 3.24780893e+00 6.82857027e+00 2.24979277e-02\n",
      " 2.27354668e-01 1.22262322e+01], Loss = 0.3137\n",
      "Iteration 8694: Weights = [5.50000000e+01 3.24771570e+00 6.82837425e+00 2.24972818e-02\n",
      " 2.27348142e-01 1.22264393e+01], Loss = 0.3137\n",
      "Iteration 8695: Weights = [5.50000000e+01 3.24762247e+00 6.82817823e+00 2.24966360e-02\n",
      " 2.27341615e-01 1.22266464e+01], Loss = 0.3137\n",
      "Iteration 8696: Weights = [5.50000000e+01 3.24752924e+00 6.82798222e+00 2.24959902e-02\n",
      " 2.27335089e-01 1.22268535e+01], Loss = 0.3137\n",
      "Iteration 8697: Weights = [5.50000000e+01 3.24743601e+00 6.82778621e+00 2.24953444e-02\n",
      " 2.27328563e-01 1.22270606e+01], Loss = 0.3136\n",
      "Iteration 8698: Weights = [5.50000000e+01 3.24734279e+00 6.82759021e+00 2.24946987e-02\n",
      " 2.27322037e-01 1.22272676e+01], Loss = 0.3136\n",
      "Iteration 8699: Weights = [5.50000000e+01 3.24724957e+00 6.82739422e+00 2.24940529e-02\n",
      " 2.27315512e-01 1.22274747e+01], Loss = 0.3136\n",
      "Iteration 8700: Weights = [5.50000000e+01 3.24715636e+00 6.82719823e+00 2.24934072e-02\n",
      " 2.27308987e-01 1.22276818e+01], Loss = 0.3136\n",
      "Iteration 8701: Weights = [5.50000000e+01 3.24706314e+00 6.82700225e+00 2.24927615e-02\n",
      " 2.27302461e-01 1.22278888e+01], Loss = 0.3136\n",
      "Iteration 8702: Weights = [5.50000000e+01 3.24696993e+00 6.82680627e+00 2.24921158e-02\n",
      " 2.27295936e-01 1.22280959e+01], Loss = 0.3135\n",
      "Iteration 8703: Weights = [5.50000000e+01 3.24687672e+00 6.82661030e+00 2.24914702e-02\n",
      " 2.27289411e-01 1.22283029e+01], Loss = 0.3135\n",
      "Iteration 8704: Weights = [5.50000000e+01 3.24678352e+00 6.82641433e+00 2.24908245e-02\n",
      " 2.27282887e-01 1.22285099e+01], Loss = 0.3135\n",
      "Iteration 8705: Weights = [5.50000000e+01 3.24669031e+00 6.82621837e+00 2.24901789e-02\n",
      " 2.27276362e-01 1.22287170e+01], Loss = 0.3135\n",
      "Iteration 8706: Weights = [5.50000000e+01 3.24659711e+00 6.82602241e+00 2.24895333e-02\n",
      " 2.27269838e-01 1.22289240e+01], Loss = 0.3135\n",
      "Iteration 8707: Weights = [5.50000000e+01 3.24650392e+00 6.82582646e+00 2.24888877e-02\n",
      " 2.27263314e-01 1.22291310e+01], Loss = 0.3135\n",
      "Iteration 8708: Weights = [5.50000000e+01 3.24641072e+00 6.82563052e+00 2.24882421e-02\n",
      " 2.27256790e-01 1.22293380e+01], Loss = 0.3134\n",
      "Iteration 8709: Weights = [5.50000000e+01 3.24631753e+00 6.82543458e+00 2.24875966e-02\n",
      " 2.27250266e-01 1.22295450e+01], Loss = 0.3134\n",
      "Iteration 8710: Weights = [5.50000000e+01 3.24622434e+00 6.82523865e+00 2.24869510e-02\n",
      " 2.27243743e-01 1.22297520e+01], Loss = 0.3134\n",
      "Iteration 8711: Weights = [5.50000000e+01 3.24613115e+00 6.82504272e+00 2.24863055e-02\n",
      " 2.27237220e-01 1.22299590e+01], Loss = 0.3134\n",
      "Iteration 8712: Weights = [5.50000000e+01 3.24603797e+00 6.82484680e+00 2.24856600e-02\n",
      " 2.27230696e-01 1.22301660e+01], Loss = 0.3134\n",
      "Iteration 8713: Weights = [5.50000000e+01 3.24594478e+00 6.82465088e+00 2.24850145e-02\n",
      " 2.27224173e-01 1.22303730e+01], Loss = 0.3133\n",
      "Iteration 8714: Weights = [5.50000000e+01 3.24585161e+00 6.82445497e+00 2.24843691e-02\n",
      " 2.27217651e-01 1.22305800e+01], Loss = 0.3133\n",
      "Iteration 8715: Weights = [5.50000000e+01 3.24575843e+00 6.82425907e+00 2.24837236e-02\n",
      " 2.27211128e-01 1.22307869e+01], Loss = 0.3133\n",
      "Iteration 8716: Weights = [5.50000000e+01 3.24566526e+00 6.82406317e+00 2.24830782e-02\n",
      " 2.27204606e-01 1.22309939e+01], Loss = 0.3133\n",
      "Iteration 8717: Weights = [5.50000000e+01 3.24557208e+00 6.82386727e+00 2.24824328e-02\n",
      " 2.27198084e-01 1.22312009e+01], Loss = 0.3133\n",
      "Iteration 8718: Weights = [5.50000000e+01 3.24547892e+00 6.82367138e+00 2.24817874e-02\n",
      " 2.27191562e-01 1.22314078e+01], Loss = 0.3133\n",
      "Iteration 8719: Weights = [5.50000000e+01 3.24538575e+00 6.82347550e+00 2.24811420e-02\n",
      " 2.27185040e-01 1.22316148e+01], Loss = 0.3132\n",
      "Iteration 8720: Weights = [5.50000000e+01 3.24529259e+00 6.82327963e+00 2.24804967e-02\n",
      " 2.27178518e-01 1.22318217e+01], Loss = 0.3132\n",
      "Iteration 8721: Weights = [5.50000000e+01 3.24519943e+00 6.82308375e+00 2.24798514e-02\n",
      " 2.27171997e-01 1.22320286e+01], Loss = 0.3132\n",
      "Iteration 8722: Weights = [5.50000000e+01 3.24510627e+00 6.82288789e+00 2.24792060e-02\n",
      " 2.27165475e-01 1.22322356e+01], Loss = 0.3132\n",
      "Iteration 8723: Weights = [5.50000000e+01 3.24501311e+00 6.82269203e+00 2.24785608e-02\n",
      " 2.27158954e-01 1.22324425e+01], Loss = 0.3132\n",
      "Iteration 8724: Weights = [5.50000000e+01 3.24491996e+00 6.82249617e+00 2.24779155e-02\n",
      " 2.27152433e-01 1.22326494e+01], Loss = 0.3132\n",
      "Iteration 8725: Weights = [5.50000000e+01 3.24482681e+00 6.82230033e+00 2.24772702e-02\n",
      " 2.27145913e-01 1.22328563e+01], Loss = 0.3131\n",
      "Iteration 8726: Weights = [5.50000000e+01 3.24473367e+00 6.82210448e+00 2.24766250e-02\n",
      " 2.27139392e-01 1.22330632e+01], Loss = 0.3131\n",
      "Iteration 8727: Weights = [5.50000000e+01 3.24464052e+00 6.82190865e+00 2.24759798e-02\n",
      " 2.27132872e-01 1.22332701e+01], Loss = 0.3131\n",
      "Iteration 8728: Weights = [5.50000000e+01 3.24454738e+00 6.82171281e+00 2.24753346e-02\n",
      " 2.27126352e-01 1.22334770e+01], Loss = 0.3131\n",
      "Iteration 8729: Weights = [5.50000000e+01 3.24445424e+00 6.82151699e+00 2.24746894e-02\n",
      " 2.27119832e-01 1.22336839e+01], Loss = 0.3131\n",
      "Iteration 8730: Weights = [5.50000000e+01 3.24436110e+00 6.82132117e+00 2.24740442e-02\n",
      " 2.27113312e-01 1.22338908e+01], Loss = 0.3130\n",
      "Iteration 8731: Weights = [5.50000000e+01 3.24426797e+00 6.82112535e+00 2.24733991e-02\n",
      " 2.27106792e-01 1.22340977e+01], Loss = 0.3130\n",
      "Iteration 8732: Weights = [5.50000000e+01 3.24417484e+00 6.82092954e+00 2.24727539e-02\n",
      " 2.27100273e-01 1.22343045e+01], Loss = 0.3130\n",
      "Iteration 8733: Weights = [5.50000000e+01 3.24408171e+00 6.82073374e+00 2.24721088e-02\n",
      " 2.27093754e-01 1.22345114e+01], Loss = 0.3130\n",
      "Iteration 8734: Weights = [5.50000000e+01 3.24398859e+00 6.82053794e+00 2.24714637e-02\n",
      " 2.27087235e-01 1.22347183e+01], Loss = 0.3130\n",
      "Iteration 8735: Weights = [5.50000000e+01 3.24389546e+00 6.82034215e+00 2.24708187e-02\n",
      " 2.27080716e-01 1.22349251e+01], Loss = 0.3130\n",
      "Iteration 8736: Weights = [5.50000000e+01 3.24380234e+00 6.82014636e+00 2.24701736e-02\n",
      " 2.27074197e-01 1.22351319e+01], Loss = 0.3129\n",
      "Iteration 8737: Weights = [5.50000000e+01 3.24370922e+00 6.81995058e+00 2.24695286e-02\n",
      " 2.27067679e-01 1.22353388e+01], Loss = 0.3129\n",
      "Iteration 8738: Weights = [5.50000000e+01 3.24361611e+00 6.81975480e+00 2.24688835e-02\n",
      " 2.27061160e-01 1.22355456e+01], Loss = 0.3129\n",
      "Iteration 8739: Weights = [5.50000000e+01 3.24352300e+00 6.81955903e+00 2.24682386e-02\n",
      " 2.27054642e-01 1.22357525e+01], Loss = 0.3129\n",
      "Iteration 8740: Weights = [5.50000000e+01 3.24342989e+00 6.81936327e+00 2.24675936e-02\n",
      " 2.27048124e-01 1.22359593e+01], Loss = 0.3129\n",
      "Iteration 8741: Weights = [5.50000000e+01 3.24333678e+00 6.81916751e+00 2.24669486e-02\n",
      " 2.27041607e-01 1.22361661e+01], Loss = 0.3128\n",
      "Iteration 8742: Weights = [5.50000000e+01 3.24324368e+00 6.81897176e+00 2.24663037e-02\n",
      " 2.27035089e-01 1.22363729e+01], Loss = 0.3128\n",
      "Iteration 8743: Weights = [5.50000000e+01 3.24315058e+00 6.81877601e+00 2.24656587e-02\n",
      " 2.27028572e-01 1.22365797e+01], Loss = 0.3128\n",
      "Iteration 8744: Weights = [5.50000000e+01 3.24305748e+00 6.81858027e+00 2.24650138e-02\n",
      " 2.27022055e-01 1.22367865e+01], Loss = 0.3128\n",
      "Iteration 8745: Weights = [5.50000000e+01 3.24296438e+00 6.81838453e+00 2.24643689e-02\n",
      " 2.27015538e-01 1.22369933e+01], Loss = 0.3128\n",
      "Iteration 8746: Weights = [5.50000000e+01 3.24287129e+00 6.81818880e+00 2.24637241e-02\n",
      " 2.27009021e-01 1.22372001e+01], Loss = 0.3128\n",
      "Iteration 8747: Weights = [5.50000000e+01 3.24277820e+00 6.81799308e+00 2.24630792e-02\n",
      " 2.27002504e-01 1.22374069e+01], Loss = 0.3127\n",
      "Iteration 8748: Weights = [5.50000000e+01 3.24268511e+00 6.81779736e+00 2.24624344e-02\n",
      " 2.26995988e-01 1.22376136e+01], Loss = 0.3127\n",
      "Iteration 8749: Weights = [5.50000000e+01 3.24259202e+00 6.81760164e+00 2.24617896e-02\n",
      " 2.26989472e-01 1.22378204e+01], Loss = 0.3127\n",
      "Iteration 8750: Weights = [5.50000000e+01 3.24249894e+00 6.81740594e+00 2.24611448e-02\n",
      " 2.26982956e-01 1.22380272e+01], Loss = 0.3127\n",
      "Iteration 8751: Weights = [5.50000000e+01 3.24240586e+00 6.81721023e+00 2.24605000e-02\n",
      " 2.26976440e-01 1.22382339e+01], Loss = 0.3127\n",
      "Iteration 8752: Weights = [5.50000000e+01 3.24231278e+00 6.81701454e+00 2.24598553e-02\n",
      " 2.26969924e-01 1.22384407e+01], Loss = 0.3126\n",
      "Iteration 8753: Weights = [5.50000000e+01 3.24221971e+00 6.81681884e+00 2.24592105e-02\n",
      " 2.26963409e-01 1.22386474e+01], Loss = 0.3126\n",
      "Iteration 8754: Weights = [5.50000000e+01 3.24212663e+00 6.81662316e+00 2.24585658e-02\n",
      " 2.26956894e-01 1.22388542e+01], Loss = 0.3126\n",
      "Iteration 8755: Weights = [5.50000000e+01 3.24203357e+00 6.81642748e+00 2.24579211e-02\n",
      " 2.26950378e-01 1.22390609e+01], Loss = 0.3126\n",
      "Iteration 8756: Weights = [5.50000000e+01 3.24194050e+00 6.81623180e+00 2.24572764e-02\n",
      " 2.26943864e-01 1.22392676e+01], Loss = 0.3126\n",
      "Iteration 8757: Weights = [5.50000000e+01 3.24184743e+00 6.81603614e+00 2.24566317e-02\n",
      " 2.26937349e-01 1.22394743e+01], Loss = 0.3126\n",
      "Iteration 8758: Weights = [5.50000000e+01 3.24175437e+00 6.81584047e+00 2.24559871e-02\n",
      " 2.26930834e-01 1.22396811e+01], Loss = 0.3125\n",
      "Iteration 8759: Weights = [5.50000000e+01 3.24166131e+00 6.81564481e+00 2.24553425e-02\n",
      " 2.26924320e-01 1.22398878e+01], Loss = 0.3125\n",
      "Iteration 8760: Weights = [5.50000000e+01 3.24156826e+00 6.81544916e+00 2.24546979e-02\n",
      " 2.26917806e-01 1.22400945e+01], Loss = 0.3125\n",
      "Iteration 8761: Weights = [5.50000000e+01 3.24147520e+00 6.81525352e+00 2.24540533e-02\n",
      " 2.26911292e-01 1.22403012e+01], Loss = 0.3125\n",
      "Iteration 8762: Weights = [5.50000000e+01 3.24138215e+00 6.81505788e+00 2.24534087e-02\n",
      " 2.26904778e-01 1.22405079e+01], Loss = 0.3125\n",
      "Iteration 8763: Weights = [5.50000000e+01 3.24128911e+00 6.81486224e+00 2.24527641e-02\n",
      " 2.26898264e-01 1.22407145e+01], Loss = 0.3124\n",
      "Iteration 8764: Weights = [5.50000000e+01 3.24119606e+00 6.81466661e+00 2.24521196e-02\n",
      " 2.26891751e-01 1.22409212e+01], Loss = 0.3124\n",
      "Iteration 8765: Weights = [5.50000000e+01 3.24110302e+00 6.81447099e+00 2.24514751e-02\n",
      " 2.26885238e-01 1.22411279e+01], Loss = 0.3124\n",
      "Iteration 8766: Weights = [5.50000000e+01 3.24100998e+00 6.81427537e+00 2.24508306e-02\n",
      " 2.26878725e-01 1.22413346e+01], Loss = 0.3124\n",
      "Iteration 8767: Weights = [5.50000000e+01 3.24091694e+00 6.81407976e+00 2.24501861e-02\n",
      " 2.26872212e-01 1.22415412e+01], Loss = 0.3124\n",
      "Iteration 8768: Weights = [5.50000000e+01 3.24082390e+00 6.81388415e+00 2.24495416e-02\n",
      " 2.26865699e-01 1.22417479e+01], Loss = 0.3124\n",
      "Iteration 8769: Weights = [5.50000000e+01 3.24073087e+00 6.81368855e+00 2.24488972e-02\n",
      " 2.26859187e-01 1.22419545e+01], Loss = 0.3123\n",
      "Iteration 8770: Weights = [5.50000000e+01 3.24063784e+00 6.81349295e+00 2.24482528e-02\n",
      " 2.26852674e-01 1.22421612e+01], Loss = 0.3123\n",
      "Iteration 8771: Weights = [5.50000000e+01 3.24054482e+00 6.81329736e+00 2.24476084e-02\n",
      " 2.26846162e-01 1.22423678e+01], Loss = 0.3123\n",
      "Iteration 8772: Weights = [5.50000000e+01 3.24045179e+00 6.81310178e+00 2.24469640e-02\n",
      " 2.26839650e-01 1.22425744e+01], Loss = 0.3123\n",
      "Iteration 8773: Weights = [5.50000000e+01 3.24035877e+00 6.81290620e+00 2.24463196e-02\n",
      " 2.26833139e-01 1.22427811e+01], Loss = 0.3123\n",
      "Iteration 8774: Weights = [5.50000000e+01 3.24026575e+00 6.81271062e+00 2.24456753e-02\n",
      " 2.26826627e-01 1.22429877e+01], Loss = 0.3123\n",
      "Iteration 8775: Weights = [5.50000000e+01 3.24017274e+00 6.81251506e+00 2.24450309e-02\n",
      " 2.26820116e-01 1.22431943e+01], Loss = 0.3122\n",
      "Iteration 8776: Weights = [5.50000000e+01 3.24007972e+00 6.81231949e+00 2.24443866e-02\n",
      " 2.26813605e-01 1.22434009e+01], Loss = 0.3122\n",
      "Iteration 8777: Weights = [5.50000000e+01 3.23998671e+00 6.81212394e+00 2.24437423e-02\n",
      " 2.26807094e-01 1.22436075e+01], Loss = 0.3122\n",
      "Iteration 8778: Weights = [5.50000000e+01 3.23989370e+00 6.81192839e+00 2.24430980e-02\n",
      " 2.26800583e-01 1.22438141e+01], Loss = 0.3122\n",
      "Iteration 8779: Weights = [5.50000000e+01 3.23980070e+00 6.81173284e+00 2.24424538e-02\n",
      " 2.26794072e-01 1.22440207e+01], Loss = 0.3122\n",
      "Iteration 8780: Weights = [5.50000000e+01 3.23970770e+00 6.81153730e+00 2.24418095e-02\n",
      " 2.26787562e-01 1.22442273e+01], Loss = 0.3121\n",
      "Iteration 8781: Weights = [5.50000000e+01 3.23961470e+00 6.81134177e+00 2.24411653e-02\n",
      " 2.26781052e-01 1.22444339e+01], Loss = 0.3121\n",
      "Iteration 8782: Weights = [5.50000000e+01 3.23952170e+00 6.81114624e+00 2.24405211e-02\n",
      " 2.26774542e-01 1.22446404e+01], Loss = 0.3121\n",
      "Iteration 8783: Weights = [5.50000000e+01 3.23942870e+00 6.81095072e+00 2.24398769e-02\n",
      " 2.26768032e-01 1.22448470e+01], Loss = 0.3121\n",
      "Iteration 8784: Weights = [5.50000000e+01 3.23933571e+00 6.81075520e+00 2.24392328e-02\n",
      " 2.26761522e-01 1.22450536e+01], Loss = 0.3121\n",
      "Iteration 8785: Weights = [5.50000000e+01 3.23924272e+00 6.81055969e+00 2.24385886e-02\n",
      " 2.26755013e-01 1.22452601e+01], Loss = 0.3121\n",
      "Iteration 8786: Weights = [5.50000000e+01 3.23914974e+00 6.81036418e+00 2.24379445e-02\n",
      " 2.26748503e-01 1.22454667e+01], Loss = 0.3120\n",
      "Iteration 8787: Weights = [5.50000000e+01 3.23905675e+00 6.81016868e+00 2.24373004e-02\n",
      " 2.26741994e-01 1.22456732e+01], Loss = 0.3120\n",
      "Iteration 8788: Weights = [5.50000000e+01 3.23896377e+00 6.80997319e+00 2.24366563e-02\n",
      " 2.26735485e-01 1.22458797e+01], Loss = 0.3120\n",
      "Iteration 8789: Weights = [5.50000000e+01 3.23887079e+00 6.80977770e+00 2.24360122e-02\n",
      " 2.26728976e-01 1.22460863e+01], Loss = 0.3120\n",
      "Iteration 8790: Weights = [5.50000000e+01 3.23877782e+00 6.80958221e+00 2.24353682e-02\n",
      " 2.26722468e-01 1.22462928e+01], Loss = 0.3120\n",
      "Iteration 8791: Weights = [5.50000000e+01 3.23868484e+00 6.80938674e+00 2.24347241e-02\n",
      " 2.26715960e-01 1.22464993e+01], Loss = 0.3119\n",
      "Iteration 8792: Weights = [5.50000000e+01 3.23859187e+00 6.80919126e+00 2.24340801e-02\n",
      " 2.26709451e-01 1.22467058e+01], Loss = 0.3119\n",
      "Iteration 8793: Weights = [5.50000000e+01 3.23849890e+00 6.80899580e+00 2.24334361e-02\n",
      " 2.26702943e-01 1.22469123e+01], Loss = 0.3119\n",
      "Iteration 8794: Weights = [5.50000000e+01 3.23840594e+00 6.80880033e+00 2.24327921e-02\n",
      " 2.26696436e-01 1.22471188e+01], Loss = 0.3119\n",
      "Iteration 8795: Weights = [5.50000000e+01 3.23831298e+00 6.80860488e+00 2.24321482e-02\n",
      " 2.26689928e-01 1.22473253e+01], Loss = 0.3119\n",
      "Iteration 8796: Weights = [5.50000000e+01 3.23822002e+00 6.80840943e+00 2.24315042e-02\n",
      " 2.26683421e-01 1.22475318e+01], Loss = 0.3119\n",
      "Iteration 8797: Weights = [5.50000000e+01 3.23812706e+00 6.80821399e+00 2.24308603e-02\n",
      " 2.26676913e-01 1.22477383e+01], Loss = 0.3118\n",
      "Iteration 8798: Weights = [5.50000000e+01 3.23803410e+00 6.80801855e+00 2.24302164e-02\n",
      " 2.26670406e-01 1.22479448e+01], Loss = 0.3118\n",
      "Iteration 8799: Weights = [5.50000000e+01 3.23794115e+00 6.80782311e+00 2.24295725e-02\n",
      " 2.26663899e-01 1.22481513e+01], Loss = 0.3118\n",
      "Iteration 8800: Weights = [5.50000000e+01 3.23784820e+00 6.80762769e+00 2.24289286e-02\n",
      " 2.26657393e-01 1.22483577e+01], Loss = 0.3118\n",
      "Iteration 8801: Weights = [5.50000000e+01 3.23775526e+00 6.80743226e+00 2.24282848e-02\n",
      " 2.26650886e-01 1.22485642e+01], Loss = 0.3118\n",
      "Iteration 8802: Weights = [5.50000000e+01 3.23766231e+00 6.80723685e+00 2.24276409e-02\n",
      " 2.26644380e-01 1.22487706e+01], Loss = 0.3118\n",
      "Iteration 8803: Weights = [5.50000000e+01 3.23756937e+00 6.80704144e+00 2.24269971e-02\n",
      " 2.26637874e-01 1.22489771e+01], Loss = 0.3117\n",
      "Iteration 8804: Weights = [5.50000000e+01 3.23747643e+00 6.80684603e+00 2.24263533e-02\n",
      " 2.26631368e-01 1.22491835e+01], Loss = 0.3117\n",
      "Iteration 8805: Weights = [5.50000000e+01 3.23738350e+00 6.80665063e+00 2.24257095e-02\n",
      " 2.26624862e-01 1.22493900e+01], Loss = 0.3117\n",
      "Iteration 8806: Weights = [5.50000000e+01 3.23729056e+00 6.80645524e+00 2.24250658e-02\n",
      " 2.26618356e-01 1.22495964e+01], Loss = 0.3117\n",
      "Iteration 8807: Weights = [5.50000000e+01 3.23719763e+00 6.80625985e+00 2.24244220e-02\n",
      " 2.26611851e-01 1.22498028e+01], Loss = 0.3117\n",
      "Iteration 8808: Weights = [5.50000000e+01 3.23710470e+00 6.80606447e+00 2.24237783e-02\n",
      " 2.26605346e-01 1.22500092e+01], Loss = 0.3116\n",
      "Iteration 8809: Weights = [5.50000000e+01 3.23701178e+00 6.80586909e+00 2.24231346e-02\n",
      " 2.26598841e-01 1.22502157e+01], Loss = 0.3116\n",
      "Iteration 8810: Weights = [5.50000000e+01 3.23691886e+00 6.80567372e+00 2.24224909e-02\n",
      " 2.26592336e-01 1.22504221e+01], Loss = 0.3116\n",
      "Iteration 8811: Weights = [5.50000000e+01 3.23682594e+00 6.80547835e+00 2.24218473e-02\n",
      " 2.26585831e-01 1.22506285e+01], Loss = 0.3116\n",
      "Iteration 8812: Weights = [5.50000000e+01 3.23673302e+00 6.80528299e+00 2.24212036e-02\n",
      " 2.26579327e-01 1.22508349e+01], Loss = 0.3116\n",
      "Iteration 8813: Weights = [5.50000000e+01 3.23664010e+00 6.80508764e+00 2.24205600e-02\n",
      " 2.26572823e-01 1.22510412e+01], Loss = 0.3116\n",
      "Iteration 8814: Weights = [5.50000000e+01 3.23654719e+00 6.80489229e+00 2.24199164e-02\n",
      " 2.26566319e-01 1.22512476e+01], Loss = 0.3115\n",
      "Iteration 8815: Weights = [5.50000000e+01 3.23645428e+00 6.80469695e+00 2.24192728e-02\n",
      " 2.26559815e-01 1.22514540e+01], Loss = 0.3115\n",
      "Iteration 8816: Weights = [5.50000000e+01 3.23636138e+00 6.80450161e+00 2.24186292e-02\n",
      " 2.26553311e-01 1.22516604e+01], Loss = 0.3115\n",
      "Iteration 8817: Weights = [5.50000000e+01 3.23626847e+00 6.80430628e+00 2.24179857e-02\n",
      " 2.26546808e-01 1.22518667e+01], Loss = 0.3115\n",
      "Iteration 8818: Weights = [5.50000000e+01 3.23617557e+00 6.80411095e+00 2.24173421e-02\n",
      " 2.26540304e-01 1.22520731e+01], Loss = 0.3115\n",
      "Iteration 8819: Weights = [5.50000000e+01 3.23608267e+00 6.80391563e+00 2.24166986e-02\n",
      " 2.26533801e-01 1.22522795e+01], Loss = 0.3114\n",
      "Iteration 8820: Weights = [5.50000000e+01 3.23598978e+00 6.80372031e+00 2.24160551e-02\n",
      " 2.26527298e-01 1.22524858e+01], Loss = 0.3114\n",
      "Iteration 8821: Weights = [5.50000000e+01 3.23589688e+00 6.80352500e+00 2.24154116e-02\n",
      " 2.26520795e-01 1.22526921e+01], Loss = 0.3114\n",
      "Iteration 8822: Weights = [5.50000000e+01 3.23580399e+00 6.80332970e+00 2.24147682e-02\n",
      " 2.26514293e-01 1.22528985e+01], Loss = 0.3114\n",
      "Iteration 8823: Weights = [5.50000000e+01 3.23571110e+00 6.80313440e+00 2.24141247e-02\n",
      " 2.26507790e-01 1.22531048e+01], Loss = 0.3114\n",
      "Iteration 8824: Weights = [5.50000000e+01 3.23561822e+00 6.80293911e+00 2.24134813e-02\n",
      " 2.26501288e-01 1.22533111e+01], Loss = 0.3114\n",
      "Iteration 8825: Weights = [5.50000000e+01 3.23552534e+00 6.80274382e+00 2.24128379e-02\n",
      " 2.26494786e-01 1.22535175e+01], Loss = 0.3113\n",
      "Iteration 8826: Weights = [5.50000000e+01 3.23543246e+00 6.80254854e+00 2.24121945e-02\n",
      " 2.26488284e-01 1.22537238e+01], Loss = 0.3113\n",
      "Iteration 8827: Weights = [5.50000000e+01 3.23533958e+00 6.80235326e+00 2.24115511e-02\n",
      " 2.26481783e-01 1.22539301e+01], Loss = 0.3113\n",
      "Iteration 8828: Weights = [5.50000000e+01 3.23524670e+00 6.80215799e+00 2.24109078e-02\n",
      " 2.26475281e-01 1.22541364e+01], Loss = 0.3113\n",
      "Iteration 8829: Weights = [5.50000000e+01 3.23515383e+00 6.80196273e+00 2.24102644e-02\n",
      " 2.26468780e-01 1.22543427e+01], Loss = 0.3113\n",
      "Iteration 8830: Weights = [5.50000000e+01 3.23506096e+00 6.80176747e+00 2.24096211e-02\n",
      " 2.26462279e-01 1.22545490e+01], Loss = 0.3113\n",
      "Iteration 8831: Weights = [5.50000000e+01 3.23496810e+00 6.80157222e+00 2.24089778e-02\n",
      " 2.26455778e-01 1.22547552e+01], Loss = 0.3112\n",
      "Iteration 8832: Weights = [5.50000000e+01 3.23487523e+00 6.80137697e+00 2.24083345e-02\n",
      " 2.26449277e-01 1.22549615e+01], Loss = 0.3112\n",
      "Iteration 8833: Weights = [5.50000000e+01 3.23478237e+00 6.80118173e+00 2.24076913e-02\n",
      " 2.26442777e-01 1.22551678e+01], Loss = 0.3112\n",
      "Iteration 8834: Weights = [5.50000000e+01 3.23468951e+00 6.80098649e+00 2.24070480e-02\n",
      " 2.26436276e-01 1.22553740e+01], Loss = 0.3112\n",
      "Iteration 8835: Weights = [5.50000000e+01 3.23459666e+00 6.80079126e+00 2.24064048e-02\n",
      " 2.26429776e-01 1.22555803e+01], Loss = 0.3112\n",
      "Iteration 8836: Weights = [5.50000000e+01 3.23450380e+00 6.80059603e+00 2.24057616e-02\n",
      " 2.26423276e-01 1.22557866e+01], Loss = 0.3111\n",
      "Iteration 8837: Weights = [5.50000000e+01 3.23441095e+00 6.80040081e+00 2.24051184e-02\n",
      " 2.26416777e-01 1.22559928e+01], Loss = 0.3111\n",
      "Iteration 8838: Weights = [5.50000000e+01 3.23431810e+00 6.80020560e+00 2.24044752e-02\n",
      " 2.26410277e-01 1.22561990e+01], Loss = 0.3111\n",
      "Iteration 8839: Weights = [5.50000000e+01 3.23422526e+00 6.80001039e+00 2.24038321e-02\n",
      " 2.26403778e-01 1.22564053e+01], Loss = 0.3111\n",
      "Iteration 8840: Weights = [5.50000000e+01 3.23413242e+00 6.79981519e+00 2.24031890e-02\n",
      " 2.26397278e-01 1.22566115e+01], Loss = 0.3111\n",
      "Iteration 8841: Weights = [5.50000000e+01 3.23403958e+00 6.79961999e+00 2.24025458e-02\n",
      " 2.26390779e-01 1.22568177e+01], Loss = 0.3111\n",
      "Iteration 8842: Weights = [5.50000000e+01 3.23394674e+00 6.79942480e+00 2.24019028e-02\n",
      " 2.26384281e-01 1.22570240e+01], Loss = 0.3110\n",
      "Iteration 8843: Weights = [5.50000000e+01 3.23385390e+00 6.79922961e+00 2.24012597e-02\n",
      " 2.26377782e-01 1.22572302e+01], Loss = 0.3110\n",
      "Iteration 8844: Weights = [5.50000000e+01 3.23376107e+00 6.79903443e+00 2.24006166e-02\n",
      " 2.26371283e-01 1.22574364e+01], Loss = 0.3110\n",
      "Iteration 8845: Weights = [5.50000000e+01 3.23366824e+00 6.79883925e+00 2.23999736e-02\n",
      " 2.26364785e-01 1.22576426e+01], Loss = 0.3110\n",
      "Iteration 8846: Weights = [5.50000000e+01 3.23357542e+00 6.79864408e+00 2.23993306e-02\n",
      " 2.26358287e-01 1.22578488e+01], Loss = 0.3110\n",
      "Iteration 8847: Weights = [5.50000000e+01 3.23348259e+00 6.79844892e+00 2.23986876e-02\n",
      " 2.26351789e-01 1.22580549e+01], Loss = 0.3109\n",
      "Iteration 8848: Weights = [5.50000000e+01 3.23338977e+00 6.79825376e+00 2.23980446e-02\n",
      " 2.26345291e-01 1.22582611e+01], Loss = 0.3109\n",
      "Iteration 8849: Weights = [5.50000000e+01 3.23329695e+00 6.79805861e+00 2.23974016e-02\n",
      " 2.26338794e-01 1.22584673e+01], Loss = 0.3109\n",
      "Iteration 8850: Weights = [5.50000000e+01 3.23320414e+00 6.79786346e+00 2.23967587e-02\n",
      " 2.26332296e-01 1.22586735e+01], Loss = 0.3109\n",
      "Iteration 8851: Weights = [5.50000000e+01 3.23311132e+00 6.79766832e+00 2.23961157e-02\n",
      " 2.26325799e-01 1.22588796e+01], Loss = 0.3109\n",
      "Iteration 8852: Weights = [5.50000000e+01 3.23301851e+00 6.79747318e+00 2.23954728e-02\n",
      " 2.26319302e-01 1.22590858e+01], Loss = 0.3109\n",
      "Iteration 8853: Weights = [5.50000000e+01 3.23292570e+00 6.79727805e+00 2.23948299e-02\n",
      " 2.26312806e-01 1.22592920e+01], Loss = 0.3108\n",
      "Iteration 8854: Weights = [5.50000000e+01 3.23283290e+00 6.79708293e+00 2.23941871e-02\n",
      " 2.26306309e-01 1.22594981e+01], Loss = 0.3108\n",
      "Iteration 8855: Weights = [5.50000000e+01 3.23274010e+00 6.79688781e+00 2.23935442e-02\n",
      " 2.26299813e-01 1.22597042e+01], Loss = 0.3108\n",
      "Iteration 8856: Weights = [5.50000000e+01 3.23264730e+00 6.79669270e+00 2.23929014e-02\n",
      " 2.26293316e-01 1.22599104e+01], Loss = 0.3108\n",
      "Iteration 8857: Weights = [5.50000000e+01 3.23255450e+00 6.79649759e+00 2.23922586e-02\n",
      " 2.26286820e-01 1.22601165e+01], Loss = 0.3108\n",
      "Iteration 8858: Weights = [5.50000000e+01 3.23246170e+00 6.79630249e+00 2.23916158e-02\n",
      " 2.26280324e-01 1.22603226e+01], Loss = 0.3108\n",
      "Iteration 8859: Weights = [5.50000000e+01 3.23236891e+00 6.79610739e+00 2.23909730e-02\n",
      " 2.26273829e-01 1.22605287e+01], Loss = 0.3107\n",
      "Iteration 8860: Weights = [5.50000000e+01 3.23227612e+00 6.79591230e+00 2.23903302e-02\n",
      " 2.26267333e-01 1.22607348e+01], Loss = 0.3107\n",
      "Iteration 8861: Weights = [5.50000000e+01 3.23218334e+00 6.79571721e+00 2.23896875e-02\n",
      " 2.26260838e-01 1.22609410e+01], Loss = 0.3107\n",
      "Iteration 8862: Weights = [5.50000000e+01 3.23209055e+00 6.79552213e+00 2.23890447e-02\n",
      " 2.26254343e-01 1.22611471e+01], Loss = 0.3107\n",
      "Iteration 8863: Weights = [5.50000000e+01 3.23199777e+00 6.79532706e+00 2.23884020e-02\n",
      " 2.26247848e-01 1.22613531e+01], Loss = 0.3107\n",
      "Iteration 8864: Weights = [5.50000000e+01 3.23190499e+00 6.79513199e+00 2.23877593e-02\n",
      " 2.26241353e-01 1.22615592e+01], Loss = 0.3106\n",
      "Iteration 8865: Weights = [5.50000000e+01 3.23181221e+00 6.79493693e+00 2.23871167e-02\n",
      " 2.26234859e-01 1.22617653e+01], Loss = 0.3106\n",
      "Iteration 8866: Weights = [5.50000000e+01 3.23171944e+00 6.79474187e+00 2.23864740e-02\n",
      " 2.26228364e-01 1.22619714e+01], Loss = 0.3106\n",
      "Iteration 8867: Weights = [5.50000000e+01 3.23162667e+00 6.79454682e+00 2.23858314e-02\n",
      " 2.26221870e-01 1.22621775e+01], Loss = 0.3106\n",
      "Iteration 8868: Weights = [5.50000000e+01 3.23153390e+00 6.79435177e+00 2.23851888e-02\n",
      " 2.26215376e-01 1.22623835e+01], Loss = 0.3106\n",
      "Iteration 8869: Weights = [5.50000000e+01 3.23144114e+00 6.79415673e+00 2.23845462e-02\n",
      " 2.26208882e-01 1.22625896e+01], Loss = 0.3106\n",
      "Iteration 8870: Weights = [5.50000000e+01 3.23134837e+00 6.79396169e+00 2.23839036e-02\n",
      " 2.26202389e-01 1.22627956e+01], Loss = 0.3105\n",
      "Iteration 8871: Weights = [5.50000000e+01 3.23125561e+00 6.79376666e+00 2.23832610e-02\n",
      " 2.26195895e-01 1.22630017e+01], Loss = 0.3105\n",
      "Iteration 8872: Weights = [5.50000000e+01 3.23116286e+00 6.79357164e+00 2.23826185e-02\n",
      " 2.26189402e-01 1.22632077e+01], Loss = 0.3105\n",
      "Iteration 8873: Weights = [5.50000000e+01 3.23107010e+00 6.79337662e+00 2.23819760e-02\n",
      " 2.26182909e-01 1.22634137e+01], Loss = 0.3105\n",
      "Iteration 8874: Weights = [5.50000000e+01 3.23097735e+00 6.79318161e+00 2.23813335e-02\n",
      " 2.26176416e-01 1.22636198e+01], Loss = 0.3105\n",
      "Iteration 8875: Weights = [5.50000000e+01 3.23088460e+00 6.79298660e+00 2.23806910e-02\n",
      " 2.26169923e-01 1.22638258e+01], Loss = 0.3104\n",
      "Iteration 8876: Weights = [5.50000000e+01 3.23079185e+00 6.79279160e+00 2.23800485e-02\n",
      " 2.26163431e-01 1.22640318e+01], Loss = 0.3104\n",
      "Iteration 8877: Weights = [5.50000000e+01 3.23069911e+00 6.79259661e+00 2.23794061e-02\n",
      " 2.26156938e-01 1.22642378e+01], Loss = 0.3104\n",
      "Iteration 8878: Weights = [5.50000000e+01 3.23060637e+00 6.79240161e+00 2.23787636e-02\n",
      " 2.26150446e-01 1.22644438e+01], Loss = 0.3104\n",
      "Iteration 8879: Weights = [5.50000000e+01 3.23051363e+00 6.79220663e+00 2.23781212e-02\n",
      " 2.26143954e-01 1.22646498e+01], Loss = 0.3104\n",
      "Iteration 8880: Weights = [5.50000000e+01 3.23042089e+00 6.79201165e+00 2.23774788e-02\n",
      " 2.26137463e-01 1.22648558e+01], Loss = 0.3104\n",
      "Iteration 8881: Weights = [5.50000000e+01 3.23032816e+00 6.79181668e+00 2.23768365e-02\n",
      " 2.26130971e-01 1.22650618e+01], Loss = 0.3103\n",
      "Iteration 8882: Weights = [5.50000000e+01 3.23023543e+00 6.79162171e+00 2.23761941e-02\n",
      " 2.26124480e-01 1.22652678e+01], Loss = 0.3103\n",
      "Iteration 8883: Weights = [5.50000000e+01 3.23014270e+00 6.79142675e+00 2.23755518e-02\n",
      " 2.26117988e-01 1.22654738e+01], Loss = 0.3103\n",
      "Iteration 8884: Weights = [5.50000000e+01 3.23004998e+00 6.79123179e+00 2.23749095e-02\n",
      " 2.26111497e-01 1.22656797e+01], Loss = 0.3103\n",
      "Iteration 8885: Weights = [5.50000000e+01 3.22995725e+00 6.79103684e+00 2.23742672e-02\n",
      " 2.26105007e-01 1.22658857e+01], Loss = 0.3103\n",
      "Iteration 8886: Weights = [5.50000000e+01 3.22986453e+00 6.79084189e+00 2.23736249e-02\n",
      " 2.26098516e-01 1.22660917e+01], Loss = 0.3103\n",
      "Iteration 8887: Weights = [5.50000000e+01 3.22977182e+00 6.79064695e+00 2.23729826e-02\n",
      " 2.26092026e-01 1.22662976e+01], Loss = 0.3102\n",
      "Iteration 8888: Weights = [5.50000000e+01 3.22967910e+00 6.79045202e+00 2.23723404e-02\n",
      " 2.26085535e-01 1.22665035e+01], Loss = 0.3102\n",
      "Iteration 8889: Weights = [5.50000000e+01 3.22958639e+00 6.79025709e+00 2.23716981e-02\n",
      " 2.26079045e-01 1.22667095e+01], Loss = 0.3102\n",
      "Iteration 8890: Weights = [5.50000000e+01 3.22949368e+00 6.79006217e+00 2.23710559e-02\n",
      " 2.26072555e-01 1.22669154e+01], Loss = 0.3102\n",
      "Iteration 8891: Weights = [5.50000000e+01 3.22940097e+00 6.78986725e+00 2.23704137e-02\n",
      " 2.26066066e-01 1.22671213e+01], Loss = 0.3102\n",
      "Iteration 8892: Weights = [5.50000000e+01 3.22930827e+00 6.78967234e+00 2.23697716e-02\n",
      " 2.26059576e-01 1.22673273e+01], Loss = 0.3101\n",
      "Iteration 8893: Weights = [5.50000000e+01 3.22921557e+00 6.78947743e+00 2.23691294e-02\n",
      " 2.26053087e-01 1.22675332e+01], Loss = 0.3101\n",
      "Iteration 8894: Weights = [5.50000000e+01 3.22912287e+00 6.78928253e+00 2.23684873e-02\n",
      " 2.26046598e-01 1.22677391e+01], Loss = 0.3101\n",
      "Iteration 8895: Weights = [5.50000000e+01 3.22903017e+00 6.78908763e+00 2.23678452e-02\n",
      " 2.26040109e-01 1.22679450e+01], Loss = 0.3101\n",
      "Iteration 8896: Weights = [5.50000000e+01 3.22893748e+00 6.78889274e+00 2.23672031e-02\n",
      " 2.26033620e-01 1.22681509e+01], Loss = 0.3101\n",
      "Iteration 8897: Weights = [5.50000000e+01 3.22884479e+00 6.78869786e+00 2.23665610e-02\n",
      " 2.26027131e-01 1.22683568e+01], Loss = 0.3101\n",
      "Iteration 8898: Weights = [5.50000000e+01 3.22875210e+00 6.78850298e+00 2.23659189e-02\n",
      " 2.26020643e-01 1.22685627e+01], Loss = 0.3100\n",
      "Iteration 8899: Weights = [5.50000000e+01 3.22865941e+00 6.78830811e+00 2.23652769e-02\n",
      " 2.26014155e-01 1.22687686e+01], Loss = 0.3100\n",
      "Iteration 8900: Weights = [5.50000000e+01 3.22856673e+00 6.78811324e+00 2.23646348e-02\n",
      " 2.26007667e-01 1.22689744e+01], Loss = 0.3100\n",
      "Iteration 8901: Weights = [5.50000000e+01 3.22847405e+00 6.78791838e+00 2.23639928e-02\n",
      " 2.26001179e-01 1.22691803e+01], Loss = 0.3100\n",
      "Iteration 8902: Weights = [5.50000000e+01 3.22838137e+00 6.78772352e+00 2.23633509e-02\n",
      " 2.25994691e-01 1.22693862e+01], Loss = 0.3100\n",
      "Iteration 8903: Weights = [5.50000000e+01 3.22828870e+00 6.78752867e+00 2.23627089e-02\n",
      " 2.25988204e-01 1.22695920e+01], Loss = 0.3099\n",
      "Iteration 8904: Weights = [5.50000000e+01 3.22819603e+00 6.78733383e+00 2.23620669e-02\n",
      " 2.25981716e-01 1.22697979e+01], Loss = 0.3099\n",
      "Iteration 8905: Weights = [5.50000000e+01 3.22810336e+00 6.78713899e+00 2.23614250e-02\n",
      " 2.25975229e-01 1.22700037e+01], Loss = 0.3099\n",
      "Iteration 8906: Weights = [5.50000000e+01 3.22801069e+00 6.78694416e+00 2.23607831e-02\n",
      " 2.25968742e-01 1.22702095e+01], Loss = 0.3099\n",
      "Iteration 8907: Weights = [5.50000000e+01 3.22791802e+00 6.78674933e+00 2.23601412e-02\n",
      " 2.25962256e-01 1.22704154e+01], Loss = 0.3099\n",
      "Iteration 8908: Weights = [5.50000000e+01 3.22782536e+00 6.78655451e+00 2.23594993e-02\n",
      " 2.25955769e-01 1.22706212e+01], Loss = 0.3099\n",
      "Iteration 8909: Weights = [5.50000000e+01 3.22773270e+00 6.78635969e+00 2.23588575e-02\n",
      " 2.25949283e-01 1.22708270e+01], Loss = 0.3098\n",
      "Iteration 8910: Weights = [5.50000000e+01 3.22764005e+00 6.78616488e+00 2.23582156e-02\n",
      " 2.25942797e-01 1.22710328e+01], Loss = 0.3098\n",
      "Iteration 8911: Weights = [5.50000000e+01 3.22754739e+00 6.78597007e+00 2.23575738e-02\n",
      " 2.25936311e-01 1.22712387e+01], Loss = 0.3098\n",
      "Iteration 8912: Weights = [5.50000000e+01 3.22745474e+00 6.78577527e+00 2.23569320e-02\n",
      " 2.25929825e-01 1.22714445e+01], Loss = 0.3098\n",
      "Iteration 8913: Weights = [5.50000000e+01 3.22736209e+00 6.78558048e+00 2.23562902e-02\n",
      " 2.25923339e-01 1.22716503e+01], Loss = 0.3098\n",
      "Iteration 8914: Weights = [5.50000000e+01 3.22726945e+00 6.78538569e+00 2.23556484e-02\n",
      " 2.25916854e-01 1.22718560e+01], Loss = 0.3098\n",
      "Iteration 8915: Weights = [5.50000000e+01 3.22717681e+00 6.78519090e+00 2.23550067e-02\n",
      " 2.25910368e-01 1.22720618e+01], Loss = 0.3097\n",
      "Iteration 8916: Weights = [5.50000000e+01 3.22708417e+00 6.78499613e+00 2.23543650e-02\n",
      " 2.25903883e-01 1.22722676e+01], Loss = 0.3097\n",
      "Iteration 8917: Weights = [5.50000000e+01 3.22699153e+00 6.78480135e+00 2.23537233e-02\n",
      " 2.25897399e-01 1.22724734e+01], Loss = 0.3097\n",
      "Iteration 8918: Weights = [5.50000000e+01 3.22689889e+00 6.78460659e+00 2.23530816e-02\n",
      " 2.25890914e-01 1.22726792e+01], Loss = 0.3097\n",
      "Iteration 8919: Weights = [5.50000000e+01 3.22680626e+00 6.78441183e+00 2.23524399e-02\n",
      " 2.25884429e-01 1.22728849e+01], Loss = 0.3097\n",
      "Iteration 8920: Weights = [5.50000000e+01 3.22671363e+00 6.78421707e+00 2.23517982e-02\n",
      " 2.25877945e-01 1.22730907e+01], Loss = 0.3096\n",
      "Iteration 8921: Weights = [5.50000000e+01 3.22662100e+00 6.78402232e+00 2.23511566e-02\n",
      " 2.25871461e-01 1.22732964e+01], Loss = 0.3096\n",
      "Iteration 8922: Weights = [5.50000000e+01 3.22652838e+00 6.78382758e+00 2.23505150e-02\n",
      " 2.25864977e-01 1.22735022e+01], Loss = 0.3096\n",
      "Iteration 8923: Weights = [5.50000000e+01 3.22643576e+00 6.78363284e+00 2.23498734e-02\n",
      " 2.25858493e-01 1.22737079e+01], Loss = 0.3096\n",
      "Iteration 8924: Weights = [5.50000000e+01 3.22634314e+00 6.78343811e+00 2.23492318e-02\n",
      " 2.25852010e-01 1.22739136e+01], Loss = 0.3096\n",
      "Iteration 8925: Weights = [5.50000000e+01 3.22625052e+00 6.78324338e+00 2.23485902e-02\n",
      " 2.25845526e-01 1.22741194e+01], Loss = 0.3096\n",
      "Iteration 8926: Weights = [5.50000000e+01 3.22615791e+00 6.78304866e+00 2.23479487e-02\n",
      " 2.25839043e-01 1.22743251e+01], Loss = 0.3095\n",
      "Iteration 8927: Weights = [5.50000000e+01 3.22606530e+00 6.78285394e+00 2.23473072e-02\n",
      " 2.25832560e-01 1.22745308e+01], Loss = 0.3095\n",
      "Iteration 8928: Weights = [5.50000000e+01 3.22597269e+00 6.78265923e+00 2.23466656e-02\n",
      " 2.25826077e-01 1.22747365e+01], Loss = 0.3095\n",
      "Iteration 8929: Weights = [5.50000000e+01 3.22588008e+00 6.78246452e+00 2.23460242e-02\n",
      " 2.25819595e-01 1.22749422e+01], Loss = 0.3095\n",
      "Iteration 8930: Weights = [5.50000000e+01 3.22578748e+00 6.78226982e+00 2.23453827e-02\n",
      " 2.25813112e-01 1.22751479e+01], Loss = 0.3095\n",
      "Iteration 8931: Weights = [5.50000000e+01 3.22569488e+00 6.78207513e+00 2.23447412e-02\n",
      " 2.25806630e-01 1.22753536e+01], Loss = 0.3095\n",
      "Iteration 8932: Weights = [5.50000000e+01 3.22560228e+00 6.78188044e+00 2.23440998e-02\n",
      " 2.25800148e-01 1.22755593e+01], Loss = 0.3094\n",
      "Iteration 8933: Weights = [5.50000000e+01 3.22550969e+00 6.78168576e+00 2.23434584e-02\n",
      " 2.25793666e-01 1.22757650e+01], Loss = 0.3094\n",
      "Iteration 8934: Weights = [5.50000000e+01 3.22541709e+00 6.78149108e+00 2.23428170e-02\n",
      " 2.25787184e-01 1.22759706e+01], Loss = 0.3094\n",
      "Iteration 8935: Weights = [5.50000000e+01 3.22532450e+00 6.78129641e+00 2.23421756e-02\n",
      " 2.25780703e-01 1.22761763e+01], Loss = 0.3094\n",
      "Iteration 8936: Weights = [5.50000000e+01 3.22523192e+00 6.78110174e+00 2.23415342e-02\n",
      " 2.25774221e-01 1.22763820e+01], Loss = 0.3094\n",
      "Iteration 8937: Weights = [5.50000000e+01 3.22513933e+00 6.78090708e+00 2.23408929e-02\n",
      " 2.25767740e-01 1.22765876e+01], Loss = 0.3093\n",
      "Iteration 8938: Weights = [5.50000000e+01 3.22504675e+00 6.78071243e+00 2.23402516e-02\n",
      " 2.25761259e-01 1.22767933e+01], Loss = 0.3093\n",
      "Iteration 8939: Weights = [5.50000000e+01 3.22495417e+00 6.78051778e+00 2.23396103e-02\n",
      " 2.25754779e-01 1.22769989e+01], Loss = 0.3093\n",
      "Iteration 8940: Weights = [5.50000000e+01 3.22486160e+00 6.78032314e+00 2.23389690e-02\n",
      " 2.25748298e-01 1.22772045e+01], Loss = 0.3093\n",
      "Iteration 8941: Weights = [5.50000000e+01 3.22476902e+00 6.78012850e+00 2.23383277e-02\n",
      " 2.25741818e-01 1.22774102e+01], Loss = 0.3093\n",
      "Iteration 8942: Weights = [5.50000000e+01 3.22467645e+00 6.77993387e+00 2.23376865e-02\n",
      " 2.25735337e-01 1.22776158e+01], Loss = 0.3093\n",
      "Iteration 8943: Weights = [5.50000000e+01 3.22458388e+00 6.77973924e+00 2.23370452e-02\n",
      " 2.25728857e-01 1.22778214e+01], Loss = 0.3092\n",
      "Iteration 8944: Weights = [5.50000000e+01 3.22449132e+00 6.77954462e+00 2.23364040e-02\n",
      " 2.25722378e-01 1.22780270e+01], Loss = 0.3092\n",
      "Iteration 8945: Weights = [5.50000000e+01 3.22439875e+00 6.77935000e+00 2.23357628e-02\n",
      " 2.25715898e-01 1.22782326e+01], Loss = 0.3092\n",
      "Iteration 8946: Weights = [5.50000000e+01 3.22430619e+00 6.77915539e+00 2.23351216e-02\n",
      " 2.25709418e-01 1.22784383e+01], Loss = 0.3092\n",
      "Iteration 8947: Weights = [5.50000000e+01 3.22421363e+00 6.77896079e+00 2.23344805e-02\n",
      " 2.25702939e-01 1.22786438e+01], Loss = 0.3092\n",
      "Iteration 8948: Weights = [5.50000000e+01 3.22412108e+00 6.77876619e+00 2.23338393e-02\n",
      " 2.25696460e-01 1.22788494e+01], Loss = 0.3091\n",
      "Iteration 8949: Weights = [5.50000000e+01 3.22402853e+00 6.77857160e+00 2.23331982e-02\n",
      " 2.25689981e-01 1.22790550e+01], Loss = 0.3091\n",
      "Iteration 8950: Weights = [5.50000000e+01 3.22393598e+00 6.77837701e+00 2.23325571e-02\n",
      " 2.25683502e-01 1.22792606e+01], Loss = 0.3091\n",
      "Iteration 8951: Weights = [5.50000000e+01 3.22384343e+00 6.77818243e+00 2.23319160e-02\n",
      " 2.25677024e-01 1.22794662e+01], Loss = 0.3091\n",
      "Iteration 8952: Weights = [5.50000000e+01 3.22375088e+00 6.77798785e+00 2.23312750e-02\n",
      " 2.25670545e-01 1.22796717e+01], Loss = 0.3091\n",
      "Iteration 8953: Weights = [5.50000000e+01 3.22365834e+00 6.77779328e+00 2.23306339e-02\n",
      " 2.25664067e-01 1.22798773e+01], Loss = 0.3091\n",
      "Iteration 8954: Weights = [5.50000000e+01 3.22356580e+00 6.77759871e+00 2.23299929e-02\n",
      " 2.25657589e-01 1.22800829e+01], Loss = 0.3090\n",
      "Iteration 8955: Weights = [5.50000000e+01 3.22347327e+00 6.77740415e+00 2.23293519e-02\n",
      " 2.25651112e-01 1.22802884e+01], Loss = 0.3090\n",
      "Iteration 8956: Weights = [5.50000000e+01 3.22338073e+00 6.77720960e+00 2.23287109e-02\n",
      " 2.25644634e-01 1.22804940e+01], Loss = 0.3090\n",
      "Iteration 8957: Weights = [5.50000000e+01 3.22328820e+00 6.77701505e+00 2.23280699e-02\n",
      " 2.25638156e-01 1.22806995e+01], Loss = 0.3090\n",
      "Iteration 8958: Weights = [5.50000000e+01 3.22319567e+00 6.77682051e+00 2.23274289e-02\n",
      " 2.25631679e-01 1.22809050e+01], Loss = 0.3090\n",
      "Iteration 8959: Weights = [5.50000000e+01 3.22310315e+00 6.77662597e+00 2.23267880e-02\n",
      " 2.25625202e-01 1.22811105e+01], Loss = 0.3090\n",
      "Iteration 8960: Weights = [5.50000000e+01 3.22301062e+00 6.77643144e+00 2.23261471e-02\n",
      " 2.25618725e-01 1.22813161e+01], Loss = 0.3089\n",
      "Iteration 8961: Weights = [5.50000000e+01 3.22291810e+00 6.77623691e+00 2.23255062e-02\n",
      " 2.25612249e-01 1.22815216e+01], Loss = 0.3089\n",
      "Iteration 8962: Weights = [5.50000000e+01 3.22282558e+00 6.77604239e+00 2.23248653e-02\n",
      " 2.25605772e-01 1.22817271e+01], Loss = 0.3089\n",
      "Iteration 8963: Weights = [5.50000000e+01 3.22273307e+00 6.77584787e+00 2.23242244e-02\n",
      " 2.25599296e-01 1.22819326e+01], Loss = 0.3089\n",
      "Iteration 8964: Weights = [5.50000000e+01 3.22264056e+00 6.77565337e+00 2.23235836e-02\n",
      " 2.25592820e-01 1.22821381e+01], Loss = 0.3089\n",
      "Iteration 8965: Weights = [5.50000000e+01 3.22254805e+00 6.77545886e+00 2.23229428e-02\n",
      " 2.25586344e-01 1.22823436e+01], Loss = 0.3088\n",
      "Iteration 8966: Weights = [5.50000000e+01 3.22245554e+00 6.77526436e+00 2.23223020e-02\n",
      " 2.25579868e-01 1.22825491e+01], Loss = 0.3088\n",
      "Iteration 8967: Weights = [5.50000000e+01 3.22236303e+00 6.77506987e+00 2.23216612e-02\n",
      " 2.25573392e-01 1.22827545e+01], Loss = 0.3088\n",
      "Iteration 8968: Weights = [5.50000000e+01 3.22227053e+00 6.77487538e+00 2.23210204e-02\n",
      " 2.25566917e-01 1.22829600e+01], Loss = 0.3088\n",
      "Iteration 8969: Weights = [5.50000000e+01 3.22217803e+00 6.77468090e+00 2.23203796e-02\n",
      " 2.25560442e-01 1.22831655e+01], Loss = 0.3088\n",
      "Iteration 8970: Weights = [5.50000000e+01 3.22208553e+00 6.77448643e+00 2.23197389e-02\n",
      " 2.25553967e-01 1.22833709e+01], Loss = 0.3088\n",
      "Iteration 8971: Weights = [5.50000000e+01 3.22199304e+00 6.77429195e+00 2.23190982e-02\n",
      " 2.25547492e-01 1.22835764e+01], Loss = 0.3087\n",
      "Iteration 8972: Weights = [5.50000000e+01 3.22190055e+00 6.77409749e+00 2.23184575e-02\n",
      " 2.25541017e-01 1.22837818e+01], Loss = 0.3087\n",
      "Iteration 8973: Weights = [5.50000000e+01 3.22180806e+00 6.77390303e+00 2.23178168e-02\n",
      " 2.25534543e-01 1.22839873e+01], Loss = 0.3087\n",
      "Iteration 8974: Weights = [5.50000000e+01 3.22171557e+00 6.77370858e+00 2.23171761e-02\n",
      " 2.25528069e-01 1.22841927e+01], Loss = 0.3087\n",
      "Iteration 8975: Weights = [5.50000000e+01 3.22162309e+00 6.77351413e+00 2.23165355e-02\n",
      " 2.25521595e-01 1.22843982e+01], Loss = 0.3087\n",
      "Iteration 8976: Weights = [5.50000000e+01 3.22153061e+00 6.77331969e+00 2.23158949e-02\n",
      " 2.25515121e-01 1.22846036e+01], Loss = 0.3087\n",
      "Iteration 8977: Weights = [5.50000000e+01 3.22143813e+00 6.77312525e+00 2.23152543e-02\n",
      " 2.25508647e-01 1.22848090e+01], Loss = 0.3086\n",
      "Iteration 8978: Weights = [5.50000000e+01 3.22134566e+00 6.77293082e+00 2.23146137e-02\n",
      " 2.25502174e-01 1.22850144e+01], Loss = 0.3086\n",
      "Iteration 8979: Weights = [5.50000000e+01 3.22125318e+00 6.77273639e+00 2.23139731e-02\n",
      " 2.25495700e-01 1.22852198e+01], Loss = 0.3086\n",
      "Iteration 8980: Weights = [5.50000000e+01 3.22116071e+00 6.77254197e+00 2.23133326e-02\n",
      " 2.25489227e-01 1.22854252e+01], Loss = 0.3086\n",
      "Iteration 8981: Weights = [5.50000000e+01 3.22106824e+00 6.77234756e+00 2.23126920e-02\n",
      " 2.25482754e-01 1.22856306e+01], Loss = 0.3086\n",
      "Iteration 8982: Weights = [5.50000000e+01 3.22097578e+00 6.77215315e+00 2.23120515e-02\n",
      " 2.25476281e-01 1.22858360e+01], Loss = 0.3085\n",
      "Iteration 8983: Weights = [5.50000000e+01 3.22088332e+00 6.77195874e+00 2.23114110e-02\n",
      " 2.25469809e-01 1.22860414e+01], Loss = 0.3085\n",
      "Iteration 8984: Weights = [5.50000000e+01 3.22079086e+00 6.77176435e+00 2.23107705e-02\n",
      " 2.25463336e-01 1.22862468e+01], Loss = 0.3085\n",
      "Iteration 8985: Weights = [5.50000000e+01 3.22069840e+00 6.77156995e+00 2.23101301e-02\n",
      " 2.25456864e-01 1.22864521e+01], Loss = 0.3085\n",
      "Iteration 8986: Weights = [5.50000000e+01 3.22060595e+00 6.77137557e+00 2.23094896e-02\n",
      " 2.25450392e-01 1.22866575e+01], Loss = 0.3085\n",
      "Iteration 8987: Weights = [5.50000000e+01 3.22051349e+00 6.77118119e+00 2.23088492e-02\n",
      " 2.25443920e-01 1.22868629e+01], Loss = 0.3085\n",
      "Iteration 8988: Weights = [5.50000000e+01 3.22042105e+00 6.77098681e+00 2.23082088e-02\n",
      " 2.25437449e-01 1.22870682e+01], Loss = 0.3084\n",
      "Iteration 8989: Weights = [5.50000000e+01 3.22032860e+00 6.77079244e+00 2.23075684e-02\n",
      " 2.25430977e-01 1.22872736e+01], Loss = 0.3084\n",
      "Iteration 8990: Weights = [5.50000000e+01 3.22023616e+00 6.77059808e+00 2.23069280e-02\n",
      " 2.25424506e-01 1.22874789e+01], Loss = 0.3084\n",
      "Iteration 8991: Weights = [5.50000000e+01 3.22014371e+00 6.77040372e+00 2.23062877e-02\n",
      " 2.25418035e-01 1.22876843e+01], Loss = 0.3084\n",
      "Iteration 8992: Weights = [5.50000000e+01 3.22005128e+00 6.77020936e+00 2.23056474e-02\n",
      " 2.25411564e-01 1.22878896e+01], Loss = 0.3084\n",
      "Iteration 8993: Weights = [5.50000000e+01 3.21995884e+00 6.77001502e+00 2.23050071e-02\n",
      " 2.25405093e-01 1.22880949e+01], Loss = 0.3084\n",
      "Iteration 8994: Weights = [5.50000000e+01 3.21986641e+00 6.76982067e+00 2.23043668e-02\n",
      " 2.25398622e-01 1.22883002e+01], Loss = 0.3083\n",
      "Iteration 8995: Weights = [5.50000000e+01 3.21977398e+00 6.76962634e+00 2.23037265e-02\n",
      " 2.25392152e-01 1.22885055e+01], Loss = 0.3083\n",
      "Iteration 8996: Weights = [5.50000000e+01 3.21968155e+00 6.76943201e+00 2.23030862e-02\n",
      " 2.25385682e-01 1.22887109e+01], Loss = 0.3083\n",
      "Iteration 8997: Weights = [5.50000000e+01 3.21958912e+00 6.76923768e+00 2.23024460e-02\n",
      " 2.25379212e-01 1.22889162e+01], Loss = 0.3083\n",
      "Iteration 8998: Weights = [5.50000000e+01 3.21949670e+00 6.76904336e+00 2.23018058e-02\n",
      " 2.25372742e-01 1.22891215e+01], Loss = 0.3083\n",
      "Iteration 8999: Weights = [5.50000000e+01 3.21940428e+00 6.76884905e+00 2.23011656e-02\n",
      " 2.25366272e-01 1.22893267e+01], Loss = 0.3082\n",
      "Iteration 9000: Weights = [5.50000000e+01 3.21931186e+00 6.76865474e+00 2.23005254e-02\n",
      " 2.25359803e-01 1.22895320e+01], Loss = 0.3082\n",
      "Iteration 9001: Weights = [5.50000000e+01 3.21921945e+00 6.76846043e+00 2.22998852e-02\n",
      " 2.25353334e-01 1.22897373e+01], Loss = 0.3082\n",
      "Iteration 9002: Weights = [5.50000000e+01 3.21912704e+00 6.76826614e+00 2.22992451e-02\n",
      " 2.25346865e-01 1.22899426e+01], Loss = 0.3082\n",
      "Iteration 9003: Weights = [5.50000000e+01 3.21903463e+00 6.76807185e+00 2.22986049e-02\n",
      " 2.25340396e-01 1.22901478e+01], Loss = 0.3082\n",
      "Iteration 9004: Weights = [5.50000000e+01 3.21894222e+00 6.76787756e+00 2.22979648e-02\n",
      " 2.25333927e-01 1.22903531e+01], Loss = 0.3082\n",
      "Iteration 9005: Weights = [5.50000000e+01 3.21884982e+00 6.76768328e+00 2.22973247e-02\n",
      " 2.25327459e-01 1.22905584e+01], Loss = 0.3081\n",
      "Iteration 9006: Weights = [5.50000000e+01 3.21875742e+00 6.76748900e+00 2.22966847e-02\n",
      " 2.25320990e-01 1.22907636e+01], Loss = 0.3081\n",
      "Iteration 9007: Weights = [5.50000000e+01 3.21866502e+00 6.76729473e+00 2.22960446e-02\n",
      " 2.25314522e-01 1.22909688e+01], Loss = 0.3081\n",
      "Iteration 9008: Weights = [5.50000000e+01 3.21857262e+00 6.76710047e+00 2.22954046e-02\n",
      " 2.25308054e-01 1.22911741e+01], Loss = 0.3081\n",
      "Iteration 9009: Weights = [5.50000000e+01 3.21848023e+00 6.76690621e+00 2.22947645e-02\n",
      " 2.25301587e-01 1.22913793e+01], Loss = 0.3081\n",
      "Iteration 9010: Weights = [5.50000000e+01 3.21838784e+00 6.76671196e+00 2.22941245e-02\n",
      " 2.25295119e-01 1.22915845e+01], Loss = 0.3081\n",
      "Iteration 9011: Weights = [5.50000000e+01 3.21829545e+00 6.76651771e+00 2.22934846e-02\n",
      " 2.25288652e-01 1.22917898e+01], Loss = 0.3080\n",
      "Iteration 9012: Weights = [5.50000000e+01 3.21820306e+00 6.76632347e+00 2.22928446e-02\n",
      " 2.25282184e-01 1.22919950e+01], Loss = 0.3080\n",
      "Iteration 9013: Weights = [5.50000000e+01 3.21811068e+00 6.76612923e+00 2.22922047e-02\n",
      " 2.25275717e-01 1.22922002e+01], Loss = 0.3080\n",
      "Iteration 9014: Weights = [5.50000000e+01 3.21801830e+00 6.76593500e+00 2.22915647e-02\n",
      " 2.25269250e-01 1.22924054e+01], Loss = 0.3080\n",
      "Iteration 9015: Weights = [5.50000000e+01 3.21792592e+00 6.76574078e+00 2.22909248e-02\n",
      " 2.25262784e-01 1.22926106e+01], Loss = 0.3080\n",
      "Iteration 9016: Weights = [5.50000000e+01 3.21783355e+00 6.76554656e+00 2.22902849e-02\n",
      " 2.25256317e-01 1.22928158e+01], Loss = 0.3079\n",
      "Iteration 9017: Weights = [5.50000000e+01 3.21774118e+00 6.76535234e+00 2.22896451e-02\n",
      " 2.25249851e-01 1.22930210e+01], Loss = 0.3079\n",
      "Iteration 9018: Weights = [5.50000000e+01 3.21764881e+00 6.76515814e+00 2.22890052e-02\n",
      " 2.25243385e-01 1.22932261e+01], Loss = 0.3079\n",
      "Iteration 9019: Weights = [5.50000000e+01 3.21755644e+00 6.76496393e+00 2.22883654e-02\n",
      " 2.25236919e-01 1.22934313e+01], Loss = 0.3079\n",
      "Iteration 9020: Weights = [5.50000000e+01 3.21746408e+00 6.76476974e+00 2.22877256e-02\n",
      " 2.25230453e-01 1.22936365e+01], Loss = 0.3079\n",
      "Iteration 9021: Weights = [5.50000000e+01 3.21737171e+00 6.76457554e+00 2.22870858e-02\n",
      " 2.25223988e-01 1.22938416e+01], Loss = 0.3079\n",
      "Iteration 9022: Weights = [5.50000000e+01 3.21727936e+00 6.76438136e+00 2.22864460e-02\n",
      " 2.25217522e-01 1.22940468e+01], Loss = 0.3078\n",
      "Iteration 9023: Weights = [5.50000000e+01 3.21718700e+00 6.76418718e+00 2.22858062e-02\n",
      " 2.25211057e-01 1.22942519e+01], Loss = 0.3078\n",
      "Iteration 9024: Weights = [5.50000000e+01 3.21709465e+00 6.76399300e+00 2.22851665e-02\n",
      " 2.25204592e-01 1.22944571e+01], Loss = 0.3078\n",
      "Iteration 9025: Weights = [5.50000000e+01 3.21700230e+00 6.76379883e+00 2.22845267e-02\n",
      " 2.25198128e-01 1.22946622e+01], Loss = 0.3078\n",
      "Iteration 9026: Weights = [5.50000000e+01 3.21690995e+00 6.76360467e+00 2.22838870e-02\n",
      " 2.25191663e-01 1.22948673e+01], Loss = 0.3078\n",
      "Iteration 9027: Weights = [5.50000000e+01 3.21681760e+00 6.76341051e+00 2.22832474e-02\n",
      " 2.25185199e-01 1.22950725e+01], Loss = 0.3077\n",
      "Iteration 9028: Weights = [5.50000000e+01 3.21672526e+00 6.76321636e+00 2.22826077e-02\n",
      " 2.25178734e-01 1.22952776e+01], Loss = 0.3077\n",
      "Iteration 9029: Weights = [5.50000000e+01 3.21663292e+00 6.76302221e+00 2.22819680e-02\n",
      " 2.25172270e-01 1.22954827e+01], Loss = 0.3077\n",
      "Iteration 9030: Weights = [5.50000000e+01 3.21654058e+00 6.76282807e+00 2.22813284e-02\n",
      " 2.25165806e-01 1.22956878e+01], Loss = 0.3077\n",
      "Iteration 9031: Weights = [5.50000000e+01 3.21644825e+00 6.76263393e+00 2.22806888e-02\n",
      " 2.25159343e-01 1.22958929e+01], Loss = 0.3077\n",
      "Iteration 9032: Weights = [5.50000000e+01 3.21635591e+00 6.76243980e+00 2.22800492e-02\n",
      " 2.25152879e-01 1.22960980e+01], Loss = 0.3077\n",
      "Iteration 9033: Weights = [5.50000000e+01 3.21626358e+00 6.76224568e+00 2.22794096e-02\n",
      " 2.25146416e-01 1.22963031e+01], Loss = 0.3076\n",
      "Iteration 9034: Weights = [5.50000000e+01 3.21617126e+00 6.76205156e+00 2.22787700e-02\n",
      " 2.25139953e-01 1.22965082e+01], Loss = 0.3076\n",
      "Iteration 9035: Weights = [5.50000000e+01 3.21607893e+00 6.76185745e+00 2.22781305e-02\n",
      " 2.25133490e-01 1.22967133e+01], Loss = 0.3076\n",
      "Iteration 9036: Weights = [5.50000000e+01 3.21598661e+00 6.76166334e+00 2.22774910e-02\n",
      " 2.25127027e-01 1.22969183e+01], Loss = 0.3076\n",
      "Iteration 9037: Weights = [5.50000000e+01 3.21589429e+00 6.76146924e+00 2.22768515e-02\n",
      " 2.25120565e-01 1.22971234e+01], Loss = 0.3076\n",
      "Iteration 9038: Weights = [5.50000000e+01 3.21580197e+00 6.76127514e+00 2.22762120e-02\n",
      " 2.25114102e-01 1.22973285e+01], Loss = 0.3076\n",
      "Iteration 9039: Weights = [5.50000000e+01 3.21570966e+00 6.76108105e+00 2.22755725e-02\n",
      " 2.25107640e-01 1.22975335e+01], Loss = 0.3075\n",
      "Iteration 9040: Weights = [5.50000000e+01 3.21561735e+00 6.76088696e+00 2.22749331e-02\n",
      " 2.25101178e-01 1.22977386e+01], Loss = 0.3075\n",
      "Iteration 9041: Weights = [5.50000000e+01 3.21552504e+00 6.76069288e+00 2.22742936e-02\n",
      " 2.25094716e-01 1.22979436e+01], Loss = 0.3075\n",
      "Iteration 9042: Weights = [5.50000000e+01 3.21543274e+00 6.76049881e+00 2.22736542e-02\n",
      " 2.25088254e-01 1.22981486e+01], Loss = 0.3075\n",
      "Iteration 9043: Weights = [5.50000000e+01 3.21534043e+00 6.76030474e+00 2.22730148e-02\n",
      " 2.25081793e-01 1.22983537e+01], Loss = 0.3075\n",
      "Iteration 9044: Weights = [5.50000000e+01 3.21524813e+00 6.76011068e+00 2.22723755e-02\n",
      " 2.25075332e-01 1.22985587e+01], Loss = 0.3074\n",
      "Iteration 9045: Weights = [5.50000000e+01 3.21515583e+00 6.75991662e+00 2.22717361e-02\n",
      " 2.25068871e-01 1.22987637e+01], Loss = 0.3074\n",
      "Iteration 9046: Weights = [5.50000000e+01 3.21506354e+00 6.75972257e+00 2.22710968e-02\n",
      " 2.25062410e-01 1.22989687e+01], Loss = 0.3074\n",
      "Iteration 9047: Weights = [5.50000000e+01 3.21497125e+00 6.75952852e+00 2.22704574e-02\n",
      " 2.25055949e-01 1.22991737e+01], Loss = 0.3074\n",
      "Iteration 9048: Weights = [5.50000000e+01 3.21487896e+00 6.75933448e+00 2.22698181e-02\n",
      " 2.25049489e-01 1.22993787e+01], Loss = 0.3074\n",
      "Iteration 9049: Weights = [5.50000000e+01 3.21478667e+00 6.75914044e+00 2.22691789e-02\n",
      " 2.25043028e-01 1.22995837e+01], Loss = 0.3074\n",
      "Iteration 9050: Weights = [5.50000000e+01 3.21469438e+00 6.75894641e+00 2.22685396e-02\n",
      " 2.25036568e-01 1.22997887e+01], Loss = 0.3073\n",
      "Iteration 9051: Weights = [5.50000000e+01 3.21460210e+00 6.75875239e+00 2.22679003e-02\n",
      " 2.25030108e-01 1.22999937e+01], Loss = 0.3073\n",
      "Iteration 9052: Weights = [5.50000000e+01 3.21450982e+00 6.75855837e+00 2.22672611e-02\n",
      " 2.25023648e-01 1.23001987e+01], Loss = 0.3073\n",
      "Iteration 9053: Weights = [5.50000000e+01 3.21441755e+00 6.75836436e+00 2.22666219e-02\n",
      " 2.25017189e-01 1.23004036e+01], Loss = 0.3073\n",
      "Iteration 9054: Weights = [5.50000000e+01 3.21432527e+00 6.75817035e+00 2.22659827e-02\n",
      " 2.25010729e-01 1.23006086e+01], Loss = 0.3073\n",
      "Iteration 9055: Weights = [5.50000000e+01 3.21423300e+00 6.75797635e+00 2.22653435e-02\n",
      " 2.25004270e-01 1.23008136e+01], Loss = 0.3073\n",
      "Iteration 9056: Weights = [5.50000000e+01 3.21414073e+00 6.75778235e+00 2.22647044e-02\n",
      " 2.24997811e-01 1.23010185e+01], Loss = 0.3072\n",
      "Iteration 9057: Weights = [5.50000000e+01 3.21404847e+00 6.75758836e+00 2.22640652e-02\n",
      " 2.24991352e-01 1.23012235e+01], Loss = 0.3072\n",
      "Iteration 9058: Weights = [5.50000000e+01 3.21395620e+00 6.75739437e+00 2.22634261e-02\n",
      " 2.24984893e-01 1.23014284e+01], Loss = 0.3072\n",
      "Iteration 9059: Weights = [5.50000000e+01 3.21386394e+00 6.75720039e+00 2.22627870e-02\n",
      " 2.24978435e-01 1.23016334e+01], Loss = 0.3072\n",
      "Iteration 9060: Weights = [5.50000000e+01 3.21377168e+00 6.75700642e+00 2.22621479e-02\n",
      " 2.24971977e-01 1.23018383e+01], Loss = 0.3072\n",
      "Iteration 9061: Weights = [5.50000000e+01 3.21367943e+00 6.75681245e+00 2.22615089e-02\n",
      " 2.24965519e-01 1.23020432e+01], Loss = 0.3071\n",
      "Iteration 9062: Weights = [5.50000000e+01 3.21358717e+00 6.75661849e+00 2.22608698e-02\n",
      " 2.24959061e-01 1.23022481e+01], Loss = 0.3071\n",
      "Iteration 9063: Weights = [5.50000000e+01 3.21349492e+00 6.75642453e+00 2.22602308e-02\n",
      " 2.24952603e-01 1.23024530e+01], Loss = 0.3071\n",
      "Iteration 9064: Weights = [5.50000000e+01 3.21340268e+00 6.75623058e+00 2.22595918e-02\n",
      " 2.24946145e-01 1.23026580e+01], Loss = 0.3071\n",
      "Iteration 9065: Weights = [5.50000000e+01 3.21331043e+00 6.75603663e+00 2.22589528e-02\n",
      " 2.24939688e-01 1.23028629e+01], Loss = 0.3071\n",
      "Iteration 9066: Weights = [5.50000000e+01 3.21321819e+00 6.75584269e+00 2.22583138e-02\n",
      " 2.24933231e-01 1.23030677e+01], Loss = 0.3071\n",
      "Iteration 9067: Weights = [5.50000000e+01 3.21312595e+00 6.75564876e+00 2.22576749e-02\n",
      " 2.24926774e-01 1.23032726e+01], Loss = 0.3070\n",
      "Iteration 9068: Weights = [5.50000000e+01 3.21303371e+00 6.75545483e+00 2.22570359e-02\n",
      " 2.24920317e-01 1.23034775e+01], Loss = 0.3070\n",
      "Iteration 9069: Weights = [5.50000000e+01 3.21294148e+00 6.75526090e+00 2.22563970e-02\n",
      " 2.24913860e-01 1.23036824e+01], Loss = 0.3070\n",
      "Iteration 9070: Weights = [5.50000000e+01 3.21284925e+00 6.75506698e+00 2.22557581e-02\n",
      " 2.24907404e-01 1.23038873e+01], Loss = 0.3070\n",
      "Iteration 9071: Weights = [5.50000000e+01 3.21275702e+00 6.75487307e+00 2.22551192e-02\n",
      " 2.24900948e-01 1.23040921e+01], Loss = 0.3070\n",
      "Iteration 9072: Weights = [5.50000000e+01 3.21266479e+00 6.75467916e+00 2.22544804e-02\n",
      " 2.24894492e-01 1.23042970e+01], Loss = 0.3070\n",
      "Iteration 9073: Weights = [5.50000000e+01 3.21257257e+00 6.75448526e+00 2.22538415e-02\n",
      " 2.24888036e-01 1.23045019e+01], Loss = 0.3069\n",
      "Iteration 9074: Weights = [5.50000000e+01 3.21248035e+00 6.75429136e+00 2.22532027e-02\n",
      " 2.24881580e-01 1.23047067e+01], Loss = 0.3069\n",
      "Iteration 9075: Weights = [5.50000000e+01 3.21238813e+00 6.75409747e+00 2.22525639e-02\n",
      " 2.24875124e-01 1.23049115e+01], Loss = 0.3069\n",
      "Iteration 9076: Weights = [5.50000000e+01 3.21229591e+00 6.75390359e+00 2.22519251e-02\n",
      " 2.24868669e-01 1.23051164e+01], Loss = 0.3069\n",
      "Iteration 9077: Weights = [5.50000000e+01 3.21220370e+00 6.75370971e+00 2.22512863e-02\n",
      " 2.24862214e-01 1.23053212e+01], Loss = 0.3069\n",
      "Iteration 9078: Weights = [5.50000000e+01 3.21211149e+00 6.75351583e+00 2.22506476e-02\n",
      " 2.24855759e-01 1.23055260e+01], Loss = 0.3068\n",
      "Iteration 9079: Weights = [5.50000000e+01 3.21201928e+00 6.75332197e+00 2.22500089e-02\n",
      " 2.24849304e-01 1.23057309e+01], Loss = 0.3068\n",
      "Iteration 9080: Weights = [5.50000000e+01 3.21192708e+00 6.75312810e+00 2.22493701e-02\n",
      " 2.24842850e-01 1.23059357e+01], Loss = 0.3068\n",
      "Iteration 9081: Weights = [5.50000000e+01 3.21183487e+00 6.75293425e+00 2.22487314e-02\n",
      " 2.24836395e-01 1.23061405e+01], Loss = 0.3068\n",
      "Iteration 9082: Weights = [5.50000000e+01 3.21174267e+00 6.75274039e+00 2.22480928e-02\n",
      " 2.24829941e-01 1.23063453e+01], Loss = 0.3068\n",
      "Iteration 9083: Weights = [5.50000000e+01 3.21165048e+00 6.75254655e+00 2.22474541e-02\n",
      " 2.24823487e-01 1.23065501e+01], Loss = 0.3068\n",
      "Iteration 9084: Weights = [5.50000000e+01 3.21155828e+00 6.75235271e+00 2.22468155e-02\n",
      " 2.24817033e-01 1.23067549e+01], Loss = 0.3067\n",
      "Iteration 9085: Weights = [5.50000000e+01 3.21146609e+00 6.75215887e+00 2.22461768e-02\n",
      " 2.24810579e-01 1.23069596e+01], Loss = 0.3067\n",
      "Iteration 9086: Weights = [5.50000000e+01 3.21137390e+00 6.75196504e+00 2.22455382e-02\n",
      " 2.24804126e-01 1.23071644e+01], Loss = 0.3067\n",
      "Iteration 9087: Weights = [5.50000000e+01 3.21128171e+00 6.75177122e+00 2.22448996e-02\n",
      " 2.24797673e-01 1.23073692e+01], Loss = 0.3067\n",
      "Iteration 9088: Weights = [5.50000000e+01 3.21118953e+00 6.75157740e+00 2.22442611e-02\n",
      " 2.24791220e-01 1.23075740e+01], Loss = 0.3067\n",
      "Iteration 9089: Weights = [5.50000000e+01 3.21109735e+00 6.75138359e+00 2.22436225e-02\n",
      " 2.24784767e-01 1.23077787e+01], Loss = 0.3067\n",
      "Iteration 9090: Weights = [5.50000000e+01 3.21100517e+00 6.75118978e+00 2.22429840e-02\n",
      " 2.24778314e-01 1.23079835e+01], Loss = 0.3066\n",
      "Iteration 9091: Weights = [5.50000000e+01 3.21091299e+00 6.75099598e+00 2.22423455e-02\n",
      " 2.24771861e-01 1.23081882e+01], Loss = 0.3066\n",
      "Iteration 9092: Weights = [5.50000000e+01 3.21082082e+00 6.75080218e+00 2.22417070e-02\n",
      " 2.24765409e-01 1.23083930e+01], Loss = 0.3066\n",
      "Iteration 9093: Weights = [5.50000000e+01 3.21072865e+00 6.75060839e+00 2.22410685e-02\n",
      " 2.24758957e-01 1.23085977e+01], Loss = 0.3066\n",
      "Iteration 9094: Weights = [5.50000000e+01 3.21063648e+00 6.75041461e+00 2.22404301e-02\n",
      " 2.24752505e-01 1.23088024e+01], Loss = 0.3066\n",
      "Iteration 9095: Weights = [5.50000000e+01 3.21054432e+00 6.75022083e+00 2.22397916e-02\n",
      " 2.24746053e-01 1.23090072e+01], Loss = 0.3066\n",
      "Iteration 9096: Weights = [5.50000000e+01 3.21045215e+00 6.75002705e+00 2.22391532e-02\n",
      " 2.24739601e-01 1.23092119e+01], Loss = 0.3065\n",
      "Iteration 9097: Weights = [5.50000000e+01 3.21035999e+00 6.74983328e+00 2.22385148e-02\n",
      " 2.24733150e-01 1.23094166e+01], Loss = 0.3065\n",
      "Iteration 9098: Weights = [5.50000000e+01 3.21026783e+00 6.74963952e+00 2.22378764e-02\n",
      " 2.24726699e-01 1.23096213e+01], Loss = 0.3065\n",
      "Iteration 9099: Weights = [5.50000000e+01 3.21017568e+00 6.74944576e+00 2.22372380e-02\n",
      " 2.24720248e-01 1.23098260e+01], Loss = 0.3065\n",
      "Iteration 9100: Weights = [5.50000000e+01 3.21008353e+00 6.74925201e+00 2.22365997e-02\n",
      " 2.24713797e-01 1.23100307e+01], Loss = 0.3065\n",
      "Iteration 9101: Weights = [5.50000000e+01 3.20999138e+00 6.74905827e+00 2.22359614e-02\n",
      " 2.24707346e-01 1.23102354e+01], Loss = 0.3064\n",
      "Iteration 9102: Weights = [5.50000000e+01 3.20989923e+00 6.74886453e+00 2.22353230e-02\n",
      " 2.24700895e-01 1.23104401e+01], Loss = 0.3064\n",
      "Iteration 9103: Weights = [5.50000000e+01 3.20980709e+00 6.74867079e+00 2.22346847e-02\n",
      " 2.24694445e-01 1.23106447e+01], Loss = 0.3064\n",
      "Iteration 9104: Weights = [5.50000000e+01 3.20971494e+00 6.74847706e+00 2.22340465e-02\n",
      " 2.24687995e-01 1.23108494e+01], Loss = 0.3064\n",
      "Iteration 9105: Weights = [5.50000000e+01 3.20962281e+00 6.74828334e+00 2.22334082e-02\n",
      " 2.24681545e-01 1.23110541e+01], Loss = 0.3064\n",
      "Iteration 9106: Weights = [5.50000000e+01 3.20953067e+00 6.74808962e+00 2.22327700e-02\n",
      " 2.24675095e-01 1.23112587e+01], Loss = 0.3064\n",
      "Iteration 9107: Weights = [5.50000000e+01 3.20943854e+00 6.74789591e+00 2.22321318e-02\n",
      " 2.24668646e-01 1.23114634e+01], Loss = 0.3063\n",
      "Iteration 9108: Weights = [5.50000000e+01 3.20934640e+00 6.74770220e+00 2.22314935e-02\n",
      " 2.24662196e-01 1.23116680e+01], Loss = 0.3063\n",
      "Iteration 9109: Weights = [5.50000000e+01 3.20925428e+00 6.74750850e+00 2.22308554e-02\n",
      " 2.24655747e-01 1.23118727e+01], Loss = 0.3063\n",
      "Iteration 9110: Weights = [5.50000000e+01 3.20916215e+00 6.74731480e+00 2.22302172e-02\n",
      " 2.24649298e-01 1.23120773e+01], Loss = 0.3063\n",
      "Iteration 9111: Weights = [5.50000000e+01 3.20907003e+00 6.74712111e+00 2.22295791e-02\n",
      " 2.24642849e-01 1.23122820e+01], Loss = 0.3063\n",
      "Iteration 9112: Weights = [5.50000000e+01 3.20897791e+00 6.74692743e+00 2.22289409e-02\n",
      " 2.24636400e-01 1.23124866e+01], Loss = 0.3063\n",
      "Iteration 9113: Weights = [5.50000000e+01 3.20888579e+00 6.74673375e+00 2.22283028e-02\n",
      " 2.24629952e-01 1.23126912e+01], Loss = 0.3062\n",
      "Iteration 9114: Weights = [5.50000000e+01 3.20879367e+00 6.74654007e+00 2.22276647e-02\n",
      " 2.24623504e-01 1.23128958e+01], Loss = 0.3062\n",
      "Iteration 9115: Weights = [5.50000000e+01 3.20870156e+00 6.74634640e+00 2.22270266e-02\n",
      " 2.24617056e-01 1.23131004e+01], Loss = 0.3062\n",
      "Iteration 9116: Weights = [5.50000000e+01 3.20860945e+00 6.74615274e+00 2.22263886e-02\n",
      " 2.24610608e-01 1.23133050e+01], Loss = 0.3062\n",
      "Iteration 9117: Weights = [5.50000000e+01 3.20851734e+00 6.74595908e+00 2.22257506e-02\n",
      " 2.24604160e-01 1.23135096e+01], Loss = 0.3062\n",
      "Iteration 9118: Weights = [5.50000000e+01 3.20842524e+00 6.74576543e+00 2.22251125e-02\n",
      " 2.24597712e-01 1.23137142e+01], Loss = 0.3061\n",
      "Iteration 9119: Weights = [5.50000000e+01 3.20833314e+00 6.74557179e+00 2.22244745e-02\n",
      " 2.24591265e-01 1.23139188e+01], Loss = 0.3061\n",
      "Iteration 9120: Weights = [5.50000000e+01 3.20824104e+00 6.74537815e+00 2.22238365e-02\n",
      " 2.24584818e-01 1.23141234e+01], Loss = 0.3061\n",
      "Iteration 9121: Weights = [5.50000000e+01 3.20814894e+00 6.74518451e+00 2.22231986e-02\n",
      " 2.24578371e-01 1.23143279e+01], Loss = 0.3061\n",
      "Iteration 9122: Weights = [5.50000000e+01 3.20805685e+00 6.74499088e+00 2.22225606e-02\n",
      " 2.24571924e-01 1.23145325e+01], Loss = 0.3061\n",
      "Iteration 9123: Weights = [5.50000000e+01 3.20796475e+00 6.74479726e+00 2.22219227e-02\n",
      " 2.24565477e-01 1.23147371e+01], Loss = 0.3061\n",
      "Iteration 9124: Weights = [5.50000000e+01 3.20787267e+00 6.74460364e+00 2.22212848e-02\n",
      " 2.24559031e-01 1.23149416e+01], Loss = 0.3060\n",
      "Iteration 9125: Weights = [5.50000000e+01 3.20778058e+00 6.74441003e+00 2.22206469e-02\n",
      " 2.24552585e-01 1.23151462e+01], Loss = 0.3060\n",
      "Iteration 9126: Weights = [5.50000000e+01 3.20768850e+00 6.74421642e+00 2.22200090e-02\n",
      " 2.24546139e-01 1.23153507e+01], Loss = 0.3060\n",
      "Iteration 9127: Weights = [5.50000000e+01 3.20759641e+00 6.74402282e+00 2.22193712e-02\n",
      " 2.24539693e-01 1.23155553e+01], Loss = 0.3060\n",
      "Iteration 9128: Weights = [5.50000000e+01 3.20750434e+00 6.74382922e+00 2.22187333e-02\n",
      " 2.24533247e-01 1.23157598e+01], Loss = 0.3060\n",
      "Iteration 9129: Weights = [5.50000000e+01 3.20741226e+00 6.74363563e+00 2.22180955e-02\n",
      " 2.24526801e-01 1.23159643e+01], Loss = 0.3060\n",
      "Iteration 9130: Weights = [5.50000000e+01 3.20732019e+00 6.74344205e+00 2.22174577e-02\n",
      " 2.24520356e-01 1.23161688e+01], Loss = 0.3059\n",
      "Iteration 9131: Weights = [5.50000000e+01 3.20722812e+00 6.74324847e+00 2.22168199e-02\n",
      " 2.24513911e-01 1.23163733e+01], Loss = 0.3059\n",
      "Iteration 9132: Weights = [5.50000000e+01 3.20713605e+00 6.74305489e+00 2.22161822e-02\n",
      " 2.24507466e-01 1.23165779e+01], Loss = 0.3059\n",
      "Iteration 9133: Weights = [5.50000000e+01 3.20704398e+00 6.74286133e+00 2.22155444e-02\n",
      " 2.24501021e-01 1.23167824e+01], Loss = 0.3059\n",
      "Iteration 9134: Weights = [5.50000000e+01 3.20695192e+00 6.74266776e+00 2.22149067e-02\n",
      " 2.24494577e-01 1.23169868e+01], Loss = 0.3059\n",
      "Iteration 9135: Weights = [5.50000000e+01 3.20685986e+00 6.74247421e+00 2.22142690e-02\n",
      " 2.24488132e-01 1.23171913e+01], Loss = 0.3058\n",
      "Iteration 9136: Weights = [5.50000000e+01 3.20676781e+00 6.74228065e+00 2.22136313e-02\n",
      " 2.24481688e-01 1.23173958e+01], Loss = 0.3058\n",
      "Iteration 9137: Weights = [5.50000000e+01 3.20667575e+00 6.74208711e+00 2.22129936e-02\n",
      " 2.24475244e-01 1.23176003e+01], Loss = 0.3058\n",
      "Iteration 9138: Weights = [5.50000000e+01 3.20658370e+00 6.74189357e+00 2.22123560e-02\n",
      " 2.24468800e-01 1.23178048e+01], Loss = 0.3058\n",
      "Iteration 9139: Weights = [5.50000000e+01 3.20649165e+00 6.74170003e+00 2.22117184e-02\n",
      " 2.24462356e-01 1.23180092e+01], Loss = 0.3058\n",
      "Iteration 9140: Weights = [5.50000000e+01 3.20639960e+00 6.74150650e+00 2.22110807e-02\n",
      " 2.24455913e-01 1.23182137e+01], Loss = 0.3058\n",
      "Iteration 9141: Weights = [5.50000000e+01 3.20630756e+00 6.74131298e+00 2.22104431e-02\n",
      " 2.24449470e-01 1.23184182e+01], Loss = 0.3057\n",
      "Iteration 9142: Weights = [5.50000000e+01 3.20621552e+00 6.74111946e+00 2.22098056e-02\n",
      " 2.24443026e-01 1.23186226e+01], Loss = 0.3057\n",
      "Iteration 9143: Weights = [5.50000000e+01 3.20612348e+00 6.74092595e+00 2.22091680e-02\n",
      " 2.24436584e-01 1.23188270e+01], Loss = 0.3057\n",
      "Iteration 9144: Weights = [5.50000000e+01 3.20603144e+00 6.74073244e+00 2.22085305e-02\n",
      " 2.24430141e-01 1.23190315e+01], Loss = 0.3057\n",
      "Iteration 9145: Weights = [5.50000000e+01 3.20593941e+00 6.74053894e+00 2.22078929e-02\n",
      " 2.24423698e-01 1.23192359e+01], Loss = 0.3057\n",
      "Iteration 9146: Weights = [5.50000000e+01 3.20584738e+00 6.74034544e+00 2.22072554e-02\n",
      " 2.24417256e-01 1.23194403e+01], Loss = 0.3057\n",
      "Iteration 9147: Weights = [5.50000000e+01 3.20575535e+00 6.74015195e+00 2.22066179e-02\n",
      " 2.24410814e-01 1.23196448e+01], Loss = 0.3056\n",
      "Iteration 9148: Weights = [5.50000000e+01 3.20566333e+00 6.73995847e+00 2.22059805e-02\n",
      " 2.24404372e-01 1.23198492e+01], Loss = 0.3056\n",
      "Iteration 9149: Weights = [5.50000000e+01 3.20557130e+00 6.73976499e+00 2.22053430e-02\n",
      " 2.24397930e-01 1.23200536e+01], Loss = 0.3056\n",
      "Iteration 9150: Weights = [5.50000000e+01 3.20547928e+00 6.73957152e+00 2.22047056e-02\n",
      " 2.24391488e-01 1.23202580e+01], Loss = 0.3056\n",
      "Iteration 9151: Weights = [5.50000000e+01 3.20538727e+00 6.73937805e+00 2.22040682e-02\n",
      " 2.24385047e-01 1.23204624e+01], Loss = 0.3056\n",
      "Iteration 9152: Weights = [5.50000000e+01 3.20529525e+00 6.73918459e+00 2.22034308e-02\n",
      " 2.24378605e-01 1.23206668e+01], Loss = 0.3055\n",
      "Iteration 9153: Weights = [5.50000000e+01 3.20520324e+00 6.73899113e+00 2.22027934e-02\n",
      " 2.24372164e-01 1.23208712e+01], Loss = 0.3055\n",
      "Iteration 9154: Weights = [5.50000000e+01 3.20511123e+00 6.73879768e+00 2.22021560e-02\n",
      " 2.24365723e-01 1.23210755e+01], Loss = 0.3055\n",
      "Iteration 9155: Weights = [5.50000000e+01 3.20501922e+00 6.73860423e+00 2.22015187e-02\n",
      " 2.24359283e-01 1.23212799e+01], Loss = 0.3055\n",
      "Iteration 9156: Weights = [5.50000000e+01 3.20492722e+00 6.73841079e+00 2.22008814e-02\n",
      " 2.24352842e-01 1.23214843e+01], Loss = 0.3055\n",
      "Iteration 9157: Weights = [5.50000000e+01 3.20483522e+00 6.73821736e+00 2.22002441e-02\n",
      " 2.24346402e-01 1.23216886e+01], Loss = 0.3055\n",
      "Iteration 9158: Weights = [5.50000000e+01 3.20474322e+00 6.73802393e+00 2.21996068e-02\n",
      " 2.24339962e-01 1.23218930e+01], Loss = 0.3054\n",
      "Iteration 9159: Weights = [5.50000000e+01 3.20465122e+00 6.73783050e+00 2.21989695e-02\n",
      " 2.24333522e-01 1.23220973e+01], Loss = 0.3054\n",
      "Iteration 9160: Weights = [5.50000000e+01 3.20455923e+00 6.73763708e+00 2.21983323e-02\n",
      " 2.24327082e-01 1.23223017e+01], Loss = 0.3054\n",
      "Iteration 9161: Weights = [5.50000000e+01 3.20446724e+00 6.73744367e+00 2.21976950e-02\n",
      " 2.24320642e-01 1.23225060e+01], Loss = 0.3054\n",
      "Iteration 9162: Weights = [5.50000000e+01 3.20437525e+00 6.73725026e+00 2.21970578e-02\n",
      " 2.24314203e-01 1.23227104e+01], Loss = 0.3054\n",
      "Iteration 9163: Weights = [5.50000000e+01 3.20428326e+00 6.73705686e+00 2.21964206e-02\n",
      " 2.24307764e-01 1.23229147e+01], Loss = 0.3054\n",
      "Iteration 9164: Weights = [5.50000000e+01 3.20419128e+00 6.73686347e+00 2.21957834e-02\n",
      " 2.24301325e-01 1.23231190e+01], Loss = 0.3053\n",
      "Iteration 9165: Weights = [5.50000000e+01 3.20409930e+00 6.73667008e+00 2.21951463e-02\n",
      " 2.24294886e-01 1.23233233e+01], Loss = 0.3053\n",
      "Iteration 9166: Weights = [5.50000000e+01 3.20400732e+00 6.73647669e+00 2.21945091e-02\n",
      " 2.24288447e-01 1.23235276e+01], Loss = 0.3053\n",
      "Iteration 9167: Weights = [5.50000000e+01 3.20391535e+00 6.73628331e+00 2.21938720e-02\n",
      " 2.24282009e-01 1.23237319e+01], Loss = 0.3053\n",
      "Iteration 9168: Weights = [5.50000000e+01 3.20382337e+00 6.73608994e+00 2.21932349e-02\n",
      " 2.24275570e-01 1.23239362e+01], Loss = 0.3053\n",
      "Iteration 9169: Weights = [5.50000000e+01 3.20373140e+00 6.73589657e+00 2.21925978e-02\n",
      " 2.24269132e-01 1.23241405e+01], Loss = 0.3053\n",
      "Iteration 9170: Weights = [5.50000000e+01 3.20363944e+00 6.73570321e+00 2.21919608e-02\n",
      " 2.24262694e-01 1.23243448e+01], Loss = 0.3052\n",
      "Iteration 9171: Weights = [5.50000000e+01 3.20354747e+00 6.73550985e+00 2.21913237e-02\n",
      " 2.24256257e-01 1.23245491e+01], Loss = 0.3052\n",
      "Iteration 9172: Weights = [5.50000000e+01 3.20345551e+00 6.73531650e+00 2.21906867e-02\n",
      " 2.24249819e-01 1.23247533e+01], Loss = 0.3052\n",
      "Iteration 9173: Weights = [5.50000000e+01 3.20336355e+00 6.73512315e+00 2.21900497e-02\n",
      " 2.24243382e-01 1.23249576e+01], Loss = 0.3052\n",
      "Iteration 9174: Weights = [5.50000000e+01 3.20327159e+00 6.73492981e+00 2.21894127e-02\n",
      " 2.24236944e-01 1.23251619e+01], Loss = 0.3052\n",
      "Iteration 9175: Weights = [5.50000000e+01 3.20317964e+00 6.73473648e+00 2.21887757e-02\n",
      " 2.24230507e-01 1.23253661e+01], Loss = 0.3051\n",
      "Iteration 9176: Weights = [5.50000000e+01 3.20308769e+00 6.73454315e+00 2.21881387e-02\n",
      " 2.24224071e-01 1.23255704e+01], Loss = 0.3051\n",
      "Iteration 9177: Weights = [5.50000000e+01 3.20299574e+00 6.73434982e+00 2.21875018e-02\n",
      " 2.24217634e-01 1.23257746e+01], Loss = 0.3051\n",
      "Iteration 9178: Weights = [5.50000000e+01 3.20290379e+00 6.73415651e+00 2.21868649e-02\n",
      " 2.24211197e-01 1.23259789e+01], Loss = 0.3051\n",
      "Iteration 9179: Weights = [5.50000000e+01 3.20281185e+00 6.73396319e+00 2.21862280e-02\n",
      " 2.24204761e-01 1.23261831e+01], Loss = 0.3051\n",
      "Iteration 9180: Weights = [5.50000000e+01 3.20271991e+00 6.73376989e+00 2.21855911e-02\n",
      " 2.24198325e-01 1.23263873e+01], Loss = 0.3051\n",
      "Iteration 9181: Weights = [5.50000000e+01 3.20262797e+00 6.73357658e+00 2.21849542e-02\n",
      " 2.24191889e-01 1.23265915e+01], Loss = 0.3050\n",
      "Iteration 9182: Weights = [5.50000000e+01 3.20253603e+00 6.73338329e+00 2.21843174e-02\n",
      " 2.24185453e-01 1.23267957e+01], Loss = 0.3050\n",
      "Iteration 9183: Weights = [5.50000000e+01 3.20244410e+00 6.73319000e+00 2.21836805e-02\n",
      " 2.24179018e-01 1.23270000e+01], Loss = 0.3050\n",
      "Iteration 9184: Weights = [5.50000000e+01 3.20235217e+00 6.73299671e+00 2.21830437e-02\n",
      " 2.24172583e-01 1.23272042e+01], Loss = 0.3050\n",
      "Iteration 9185: Weights = [5.50000000e+01 3.20226024e+00 6.73280343e+00 2.21824069e-02\n",
      " 2.24166147e-01 1.23274084e+01], Loss = 0.3050\n",
      "Iteration 9186: Weights = [5.50000000e+01 3.20216832e+00 6.73261016e+00 2.21817702e-02\n",
      " 2.24159712e-01 1.23276125e+01], Loss = 0.3050\n",
      "Iteration 9187: Weights = [5.50000000e+01 3.20207640e+00 6.73241689e+00 2.21811334e-02\n",
      " 2.24153278e-01 1.23278167e+01], Loss = 0.3049\n",
      "Iteration 9188: Weights = [5.50000000e+01 3.20198448e+00 6.73222363e+00 2.21804967e-02\n",
      " 2.24146843e-01 1.23280209e+01], Loss = 0.3049\n",
      "Iteration 9189: Weights = [5.50000000e+01 3.20189256e+00 6.73203037e+00 2.21798599e-02\n",
      " 2.24140409e-01 1.23282251e+01], Loss = 0.3049\n",
      "Iteration 9190: Weights = [5.50000000e+01 3.20180064e+00 6.73183712e+00 2.21792232e-02\n",
      " 2.24133974e-01 1.23284293e+01], Loss = 0.3049\n",
      "Iteration 9191: Weights = [5.50000000e+01 3.20170873e+00 6.73164387e+00 2.21785866e-02\n",
      " 2.24127540e-01 1.23286334e+01], Loss = 0.3049\n",
      "Iteration 9192: Weights = [5.50000000e+01 3.20161682e+00 6.73145063e+00 2.21779499e-02\n",
      " 2.24121106e-01 1.23288376e+01], Loss = 0.3048\n",
      "Iteration 9193: Weights = [5.50000000e+01 3.20152492e+00 6.73125740e+00 2.21773132e-02\n",
      " 2.24114673e-01 1.23290417e+01], Loss = 0.3048\n",
      "Iteration 9194: Weights = [5.50000000e+01 3.20143301e+00 6.73106417e+00 2.21766766e-02\n",
      " 2.24108239e-01 1.23292459e+01], Loss = 0.3048\n",
      "Iteration 9195: Weights = [5.50000000e+01 3.20134111e+00 6.73087094e+00 2.21760400e-02\n",
      " 2.24101806e-01 1.23294500e+01], Loss = 0.3048\n",
      "Iteration 9196: Weights = [5.50000000e+01 3.20124921e+00 6.73067772e+00 2.21754034e-02\n",
      " 2.24095373e-01 1.23296541e+01], Loss = 0.3048\n",
      "Iteration 9197: Weights = [5.50000000e+01 3.20115732e+00 6.73048451e+00 2.21747668e-02\n",
      " 2.24088940e-01 1.23298583e+01], Loss = 0.3048\n",
      "Iteration 9198: Weights = [5.50000000e+01 3.20106542e+00 6.73029130e+00 2.21741303e-02\n",
      " 2.24082507e-01 1.23300624e+01], Loss = 0.3047\n",
      "Iteration 9199: Weights = [5.50000000e+01 3.20097353e+00 6.73009810e+00 2.21734937e-02\n",
      " 2.24076074e-01 1.23302665e+01], Loss = 0.3047\n",
      "Iteration 9200: Weights = [5.50000000e+01 3.20088164e+00 6.72990491e+00 2.21728572e-02\n",
      " 2.24069642e-01 1.23304706e+01], Loss = 0.3047\n",
      "Iteration 9201: Weights = [5.50000000e+01 3.20078976e+00 6.72971171e+00 2.21722207e-02\n",
      " 2.24063210e-01 1.23306747e+01], Loss = 0.3047\n",
      "Iteration 9202: Weights = [5.50000000e+01 3.20069788e+00 6.72951853e+00 2.21715842e-02\n",
      " 2.24056778e-01 1.23308788e+01], Loss = 0.3047\n",
      "Iteration 9203: Weights = [5.50000000e+01 3.20060600e+00 6.72932535e+00 2.21709478e-02\n",
      " 2.24050346e-01 1.23310829e+01], Loss = 0.3047\n",
      "Iteration 9204: Weights = [5.50000000e+01 3.20051412e+00 6.72913218e+00 2.21703113e-02\n",
      " 2.24043914e-01 1.23312870e+01], Loss = 0.3046\n",
      "Iteration 9205: Weights = [5.50000000e+01 3.20042224e+00 6.72893901e+00 2.21696749e-02\n",
      " 2.24037483e-01 1.23314911e+01], Loss = 0.3046\n",
      "Iteration 9206: Weights = [5.50000000e+01 3.20033037e+00 6.72874584e+00 2.21690385e-02\n",
      " 2.24031052e-01 1.23316951e+01], Loss = 0.3046\n",
      "Iteration 9207: Weights = [5.50000000e+01 3.20023850e+00 6.72855269e+00 2.21684021e-02\n",
      " 2.24024620e-01 1.23318992e+01], Loss = 0.3046\n",
      "Iteration 9208: Weights = [5.50000000e+01 3.20014663e+00 6.72835953e+00 2.21677657e-02\n",
      " 2.24018189e-01 1.23321033e+01], Loss = 0.3046\n",
      "Iteration 9209: Weights = [5.50000000e+01 3.20005477e+00 6.72816639e+00 2.21671294e-02\n",
      " 2.24011759e-01 1.23323073e+01], Loss = 0.3046\n",
      "Iteration 9210: Weights = [5.50000000e+01 3.19996291e+00 6.72797325e+00 2.21664930e-02\n",
      " 2.24005328e-01 1.23325114e+01], Loss = 0.3045\n",
      "Iteration 9211: Weights = [5.50000000e+01 3.19987105e+00 6.72778011e+00 2.21658567e-02\n",
      " 2.23998898e-01 1.23327154e+01], Loss = 0.3045\n",
      "Iteration 9212: Weights = [5.50000000e+01 3.19977919e+00 6.72758698e+00 2.21652204e-02\n",
      " 2.23992468e-01 1.23329195e+01], Loss = 0.3045\n",
      "Iteration 9213: Weights = [5.50000000e+01 3.19968734e+00 6.72739386e+00 2.21645841e-02\n",
      " 2.23986038e-01 1.23331235e+01], Loss = 0.3045\n",
      "Iteration 9214: Weights = [5.50000000e+01 3.19959549e+00 6.72720074e+00 2.21639479e-02\n",
      " 2.23979608e-01 1.23333275e+01], Loss = 0.3045\n",
      "Iteration 9215: Weights = [5.50000000e+01 3.19950364e+00 6.72700763e+00 2.21633116e-02\n",
      " 2.23973178e-01 1.23335315e+01], Loss = 0.3044\n",
      "Iteration 9216: Weights = [5.50000000e+01 3.19941179e+00 6.72681452e+00 2.21626754e-02\n",
      " 2.23966749e-01 1.23337355e+01], Loss = 0.3044\n",
      "Iteration 9217: Weights = [5.50000000e+01 3.19931995e+00 6.72662142e+00 2.21620392e-02\n",
      " 2.23960320e-01 1.23339396e+01], Loss = 0.3044\n",
      "Iteration 9218: Weights = [5.50000000e+01 3.19922811e+00 6.72642832e+00 2.21614030e-02\n",
      " 2.23953890e-01 1.23341436e+01], Loss = 0.3044\n",
      "Iteration 9219: Weights = [5.50000000e+01 3.19913627e+00 6.72623523e+00 2.21607668e-02\n",
      " 2.23947462e-01 1.23343476e+01], Loss = 0.3044\n",
      "Iteration 9220: Weights = [5.50000000e+01 3.19904444e+00 6.72604214e+00 2.21601307e-02\n",
      " 2.23941033e-01 1.23345515e+01], Loss = 0.3044\n",
      "Iteration 9221: Weights = [5.50000000e+01 3.19895260e+00 6.72584906e+00 2.21594945e-02\n",
      " 2.23934604e-01 1.23347555e+01], Loss = 0.3043\n",
      "Iteration 9222: Weights = [5.50000000e+01 3.19886077e+00 6.72565599e+00 2.21588584e-02\n",
      " 2.23928176e-01 1.23349595e+01], Loss = 0.3043\n",
      "Iteration 9223: Weights = [5.50000000e+01 3.19876894e+00 6.72546292e+00 2.21582223e-02\n",
      " 2.23921748e-01 1.23351635e+01], Loss = 0.3043\n",
      "Iteration 9224: Weights = [5.50000000e+01 3.19867712e+00 6.72526986e+00 2.21575863e-02\n",
      " 2.23915320e-01 1.23353675e+01], Loss = 0.3043\n",
      "Iteration 9225: Weights = [5.50000000e+01 3.19858530e+00 6.72507680e+00 2.21569502e-02\n",
      " 2.23908892e-01 1.23355714e+01], Loss = 0.3043\n",
      "Iteration 9226: Weights = [5.50000000e+01 3.19849348e+00 6.72488375e+00 2.21563141e-02\n",
      " 2.23902465e-01 1.23357754e+01], Loss = 0.3043\n",
      "Iteration 9227: Weights = [5.50000000e+01 3.19840166e+00 6.72469070e+00 2.21556781e-02\n",
      " 2.23896037e-01 1.23359793e+01], Loss = 0.3042\n",
      "Iteration 9228: Weights = [5.50000000e+01 3.19830985e+00 6.72449766e+00 2.21550421e-02\n",
      " 2.23889610e-01 1.23361833e+01], Loss = 0.3042\n",
      "Iteration 9229: Weights = [5.50000000e+01 3.19821804e+00 6.72430463e+00 2.21544061e-02\n",
      " 2.23883183e-01 1.23363872e+01], Loss = 0.3042\n",
      "Iteration 9230: Weights = [5.50000000e+01 3.19812623e+00 6.72411160e+00 2.21537701e-02\n",
      " 2.23876756e-01 1.23365911e+01], Loss = 0.3042\n",
      "Iteration 9231: Weights = [5.50000000e+01 3.19803442e+00 6.72391857e+00 2.21531342e-02\n",
      " 2.23870329e-01 1.23367951e+01], Loss = 0.3042\n",
      "Iteration 9232: Weights = [5.50000000e+01 3.19794262e+00 6.72372555e+00 2.21524983e-02\n",
      " 2.23863903e-01 1.23369990e+01], Loss = 0.3041\n",
      "Iteration 9233: Weights = [5.50000000e+01 3.19785081e+00 6.72353254e+00 2.21518623e-02\n",
      " 2.23857476e-01 1.23372029e+01], Loss = 0.3041\n",
      "Iteration 9234: Weights = [5.50000000e+01 3.19775902e+00 6.72333953e+00 2.21512264e-02\n",
      " 2.23851050e-01 1.23374068e+01], Loss = 0.3041\n",
      "Iteration 9235: Weights = [5.50000000e+01 3.19766722e+00 6.72314653e+00 2.21505906e-02\n",
      " 2.23844624e-01 1.23376107e+01], Loss = 0.3041\n",
      "Iteration 9236: Weights = [5.50000000e+01 3.19757543e+00 6.72295353e+00 2.21499547e-02\n",
      " 2.23838199e-01 1.23378146e+01], Loss = 0.3041\n",
      "Iteration 9237: Weights = [5.50000000e+01 3.19748364e+00 6.72276054e+00 2.21493189e-02\n",
      " 2.23831773e-01 1.23380185e+01], Loss = 0.3041\n",
      "Iteration 9238: Weights = [5.50000000e+01 3.19739185e+00 6.72256756e+00 2.21486830e-02\n",
      " 2.23825348e-01 1.23382224e+01], Loss = 0.3040\n",
      "Iteration 9239: Weights = [5.50000000e+01 3.19730006e+00 6.72237458e+00 2.21480472e-02\n",
      " 2.23818923e-01 1.23384263e+01], Loss = 0.3040\n",
      "Iteration 9240: Weights = [5.50000000e+01 3.19720828e+00 6.72218160e+00 2.21474114e-02\n",
      " 2.23812498e-01 1.23386302e+01], Loss = 0.3040\n",
      "Iteration 9241: Weights = [5.50000000e+01 3.19711650e+00 6.72198863e+00 2.21467757e-02\n",
      " 2.23806073e-01 1.23388340e+01], Loss = 0.3040\n",
      "Iteration 9242: Weights = [5.50000000e+01 3.19702472e+00 6.72179567e+00 2.21461399e-02\n",
      " 2.23799648e-01 1.23390379e+01], Loss = 0.3040\n",
      "Iteration 9243: Weights = [5.50000000e+01 3.19693295e+00 6.72160271e+00 2.21455042e-02\n",
      " 2.23793224e-01 1.23392417e+01], Loss = 0.3040\n",
      "Iteration 9244: Weights = [5.50000000e+01 3.19684118e+00 6.72140976e+00 2.21448685e-02\n",
      " 2.23786799e-01 1.23394456e+01], Loss = 0.3039\n",
      "Iteration 9245: Weights = [5.50000000e+01 3.19674941e+00 6.72121681e+00 2.21442328e-02\n",
      " 2.23780375e-01 1.23396494e+01], Loss = 0.3039\n",
      "Iteration 9246: Weights = [5.50000000e+01 3.19665764e+00 6.72102387e+00 2.21435971e-02\n",
      " 2.23773951e-01 1.23398533e+01], Loss = 0.3039\n",
      "Iteration 9247: Weights = [5.50000000e+01 3.19656588e+00 6.72083093e+00 2.21429614e-02\n",
      " 2.23767528e-01 1.23400571e+01], Loss = 0.3039\n",
      "Iteration 9248: Weights = [5.50000000e+01 3.19647411e+00 6.72063800e+00 2.21423258e-02\n",
      " 2.23761104e-01 1.23402609e+01], Loss = 0.3039\n",
      "Iteration 9249: Weights = [5.50000000e+01 3.19638236e+00 6.72044508e+00 2.21416902e-02\n",
      " 2.23754681e-01 1.23404648e+01], Loss = 0.3039\n",
      "Iteration 9250: Weights = [5.50000000e+01 3.19629060e+00 6.72025216e+00 2.21410546e-02\n",
      " 2.23748257e-01 1.23406686e+01], Loss = 0.3038\n",
      "Iteration 9251: Weights = [5.50000000e+01 3.19619885e+00 6.72005925e+00 2.21404190e-02\n",
      " 2.23741835e-01 1.23408724e+01], Loss = 0.3038\n",
      "Iteration 9252: Weights = [5.50000000e+01 3.19610709e+00 6.71986634e+00 2.21397834e-02\n",
      " 2.23735412e-01 1.23410762e+01], Loss = 0.3038\n",
      "Iteration 9253: Weights = [5.50000000e+01 3.19601535e+00 6.71967344e+00 2.21391478e-02\n",
      " 2.23728989e-01 1.23412800e+01], Loss = 0.3038\n",
      "Iteration 9254: Weights = [5.50000000e+01 3.19592360e+00 6.71948054e+00 2.21385123e-02\n",
      " 2.23722567e-01 1.23414838e+01], Loss = 0.3038\n",
      "Iteration 9255: Weights = [5.50000000e+01 3.19583186e+00 6.71928765e+00 2.21378768e-02\n",
      " 2.23716144e-01 1.23416876e+01], Loss = 0.3037\n",
      "Iteration 9256: Weights = [5.50000000e+01 3.19574012e+00 6.71909476e+00 2.21372413e-02\n",
      " 2.23709722e-01 1.23418913e+01], Loss = 0.3037\n",
      "Iteration 9257: Weights = [5.50000000e+01 3.19564838e+00 6.71890188e+00 2.21366058e-02\n",
      " 2.23703300e-01 1.23420951e+01], Loss = 0.3037\n",
      "Iteration 9258: Weights = [5.50000000e+01 3.19555664e+00 6.71870901e+00 2.21359704e-02\n",
      " 2.23696879e-01 1.23422989e+01], Loss = 0.3037\n",
      "Iteration 9259: Weights = [5.50000000e+01 3.19546491e+00 6.71851614e+00 2.21353349e-02\n",
      " 2.23690457e-01 1.23425027e+01], Loss = 0.3037\n",
      "Iteration 9260: Weights = [5.50000000e+01 3.19537318e+00 6.71832327e+00 2.21346995e-02\n",
      " 2.23684036e-01 1.23427064e+01], Loss = 0.3037\n",
      "Iteration 9261: Weights = [5.50000000e+01 3.19528145e+00 6.71813041e+00 2.21340641e-02\n",
      " 2.23677615e-01 1.23429102e+01], Loss = 0.3036\n",
      "Iteration 9262: Weights = [5.50000000e+01 3.19518973e+00 6.71793756e+00 2.21334287e-02\n",
      " 2.23671194e-01 1.23431139e+01], Loss = 0.3036\n",
      "Iteration 9263: Weights = [5.50000000e+01 3.19509801e+00 6.71774471e+00 2.21327933e-02\n",
      " 2.23664773e-01 1.23433177e+01], Loss = 0.3036\n",
      "Iteration 9264: Weights = [5.50000000e+01 3.19500629e+00 6.71755187e+00 2.21321580e-02\n",
      " 2.23658352e-01 1.23435214e+01], Loss = 0.3036\n",
      "Iteration 9265: Weights = [5.50000000e+01 3.19491457e+00 6.71735904e+00 2.21315227e-02\n",
      " 2.23651932e-01 1.23437251e+01], Loss = 0.3036\n",
      "Iteration 9266: Weights = [5.50000000e+01 3.19482286e+00 6.71716621e+00 2.21308873e-02\n",
      " 2.23645512e-01 1.23439288e+01], Loss = 0.3036\n",
      "Iteration 9267: Weights = [5.50000000e+01 3.19473114e+00 6.71697338e+00 2.21302520e-02\n",
      " 2.23639092e-01 1.23441326e+01], Loss = 0.3035\n",
      "Iteration 9268: Weights = [5.50000000e+01 3.19463943e+00 6.71678056e+00 2.21296168e-02\n",
      " 2.23632672e-01 1.23443363e+01], Loss = 0.3035\n",
      "Iteration 9269: Weights = [5.50000000e+01 3.19454773e+00 6.71658775e+00 2.21289815e-02\n",
      " 2.23626252e-01 1.23445400e+01], Loss = 0.3035\n",
      "Iteration 9270: Weights = [5.50000000e+01 3.19445603e+00 6.71639494e+00 2.21283463e-02\n",
      " 2.23619833e-01 1.23447437e+01], Loss = 0.3035\n",
      "Iteration 9271: Weights = [5.50000000e+01 3.19436432e+00 6.71620214e+00 2.21277110e-02\n",
      " 2.23613413e-01 1.23449474e+01], Loss = 0.3035\n",
      "Iteration 9272: Weights = [5.50000000e+01 3.19427263e+00 6.71600934e+00 2.21270758e-02\n",
      " 2.23606994e-01 1.23451510e+01], Loss = 0.3035\n",
      "Iteration 9273: Weights = [5.50000000e+01 3.19418093e+00 6.71581655e+00 2.21264407e-02\n",
      " 2.23600575e-01 1.23453547e+01], Loss = 0.3034\n",
      "Iteration 9274: Weights = [5.50000000e+01 3.19408924e+00 6.71562376e+00 2.21258055e-02\n",
      " 2.23594157e-01 1.23455584e+01], Loss = 0.3034\n",
      "Iteration 9275: Weights = [5.50000000e+01 3.19399755e+00 6.71543098e+00 2.21251703e-02\n",
      " 2.23587738e-01 1.23457621e+01], Loss = 0.3034\n",
      "Iteration 9276: Weights = [5.50000000e+01 3.19390586e+00 6.71523820e+00 2.21245352e-02\n",
      " 2.23581320e-01 1.23459657e+01], Loss = 0.3034\n",
      "Iteration 9277: Weights = [5.50000000e+01 3.19381417e+00 6.71504543e+00 2.21239001e-02\n",
      " 2.23574902e-01 1.23461694e+01], Loss = 0.3034\n",
      "Iteration 9278: Weights = [5.50000000e+01 3.19372249e+00 6.71485267e+00 2.21232650e-02\n",
      " 2.23568484e-01 1.23463730e+01], Loss = 0.3033\n",
      "Iteration 9279: Weights = [5.50000000e+01 3.19363081e+00 6.71465991e+00 2.21226299e-02\n",
      " 2.23562066e-01 1.23465767e+01], Loss = 0.3033\n",
      "Iteration 9280: Weights = [5.50000000e+01 3.19353913e+00 6.71446716e+00 2.21219949e-02\n",
      " 2.23555648e-01 1.23467803e+01], Loss = 0.3033\n",
      "Iteration 9281: Weights = [5.50000000e+01 3.19344746e+00 6.71427441e+00 2.21213598e-02\n",
      " 2.23549231e-01 1.23469840e+01], Loss = 0.3033\n",
      "Iteration 9282: Weights = [5.50000000e+01 3.19335579e+00 6.71408167e+00 2.21207248e-02\n",
      " 2.23542813e-01 1.23471876e+01], Loss = 0.3033\n",
      "Iteration 9283: Weights = [5.50000000e+01 3.19326412e+00 6.71388893e+00 2.21200898e-02\n",
      " 2.23536396e-01 1.23473912e+01], Loss = 0.3033\n",
      "Iteration 9284: Weights = [5.50000000e+01 3.19317245e+00 6.71369620e+00 2.21194548e-02\n",
      " 2.23529979e-01 1.23475948e+01], Loss = 0.3032\n",
      "Iteration 9285: Weights = [5.50000000e+01 3.19308079e+00 6.71350348e+00 2.21188198e-02\n",
      " 2.23523563e-01 1.23477985e+01], Loss = 0.3032\n",
      "Iteration 9286: Weights = [5.50000000e+01 3.19298912e+00 6.71331076e+00 2.21181849e-02\n",
      " 2.23517146e-01 1.23480021e+01], Loss = 0.3032\n",
      "Iteration 9287: Weights = [5.50000000e+01 3.19289747e+00 6.71311804e+00 2.21175500e-02\n",
      " 2.23510730e-01 1.23482057e+01], Loss = 0.3032\n",
      "Iteration 9288: Weights = [5.50000000e+01 3.19280581e+00 6.71292533e+00 2.21169150e-02\n",
      " 2.23504314e-01 1.23484093e+01], Loss = 0.3032\n",
      "Iteration 9289: Weights = [5.50000000e+01 3.19271416e+00 6.71273263e+00 2.21162801e-02\n",
      " 2.23497898e-01 1.23486128e+01], Loss = 0.3032\n",
      "Iteration 9290: Weights = [5.50000000e+01 3.19262250e+00 6.71253993e+00 2.21156453e-02\n",
      " 2.23491482e-01 1.23488164e+01], Loss = 0.3031\n",
      "Iteration 9291: Weights = [5.50000000e+01 3.19253086e+00 6.71234724e+00 2.21150104e-02\n",
      " 2.23485066e-01 1.23490200e+01], Loss = 0.3031\n",
      "Iteration 9292: Weights = [5.50000000e+01 3.19243921e+00 6.71215455e+00 2.21143756e-02\n",
      " 2.23478651e-01 1.23492236e+01], Loss = 0.3031\n",
      "Iteration 9293: Weights = [5.50000000e+01 3.19234757e+00 6.71196187e+00 2.21137407e-02\n",
      " 2.23472235e-01 1.23494271e+01], Loss = 0.3031\n",
      "Iteration 9294: Weights = [5.50000000e+01 3.19225593e+00 6.71176920e+00 2.21131059e-02\n",
      " 2.23465820e-01 1.23496307e+01], Loss = 0.3031\n",
      "Iteration 9295: Weights = [5.50000000e+01 3.19216429e+00 6.71157653e+00 2.21124712e-02\n",
      " 2.23459406e-01 1.23498342e+01], Loss = 0.3031\n",
      "Iteration 9296: Weights = [5.50000000e+01 3.19207265e+00 6.71138386e+00 2.21118364e-02\n",
      " 2.23452991e-01 1.23500378e+01], Loss = 0.3030\n",
      "Iteration 9297: Weights = [5.50000000e+01 3.19198102e+00 6.71119120e+00 2.21112016e-02\n",
      " 2.23446576e-01 1.23502413e+01], Loss = 0.3030\n",
      "Iteration 9298: Weights = [5.50000000e+01 3.19188939e+00 6.71099855e+00 2.21105669e-02\n",
      " 2.23440162e-01 1.23504449e+01], Loss = 0.3030\n",
      "Iteration 9299: Weights = [5.50000000e+01 3.19179776e+00 6.71080590e+00 2.21099322e-02\n",
      " 2.23433748e-01 1.23506484e+01], Loss = 0.3030\n",
      "Iteration 9300: Weights = [5.50000000e+01 3.19170614e+00 6.71061326e+00 2.21092975e-02\n",
      " 2.23427334e-01 1.23508519e+01], Loss = 0.3030\n",
      "Iteration 9301: Weights = [5.50000000e+01 3.19161452e+00 6.71042062e+00 2.21086628e-02\n",
      " 2.23420920e-01 1.23510554e+01], Loss = 0.3029\n",
      "Iteration 9302: Weights = [5.50000000e+01 3.19152290e+00 6.71022799e+00 2.21080282e-02\n",
      " 2.23414507e-01 1.23512590e+01], Loss = 0.3029\n",
      "Iteration 9303: Weights = [5.50000000e+01 3.19143128e+00 6.71003536e+00 2.21073935e-02\n",
      " 2.23408093e-01 1.23514625e+01], Loss = 0.3029\n",
      "Iteration 9304: Weights = [5.50000000e+01 3.19133967e+00 6.70984274e+00 2.21067589e-02\n",
      " 2.23401680e-01 1.23516660e+01], Loss = 0.3029\n",
      "Iteration 9305: Weights = [5.50000000e+01 3.19124805e+00 6.70965013e+00 2.21061243e-02\n",
      " 2.23395267e-01 1.23518695e+01], Loss = 0.3029\n",
      "Iteration 9306: Weights = [5.50000000e+01 3.19115645e+00 6.70945752e+00 2.21054897e-02\n",
      " 2.23388854e-01 1.23520729e+01], Loss = 0.3029\n",
      "Iteration 9307: Weights = [5.50000000e+01 3.19106484e+00 6.70926492e+00 2.21048551e-02\n",
      " 2.23382441e-01 1.23522764e+01], Loss = 0.3028\n",
      "Iteration 9308: Weights = [5.50000000e+01 3.19097324e+00 6.70907232e+00 2.21042206e-02\n",
      " 2.23376029e-01 1.23524799e+01], Loss = 0.3028\n",
      "Iteration 9309: Weights = [5.50000000e+01 3.19088163e+00 6.70887973e+00 2.21035861e-02\n",
      " 2.23369617e-01 1.23526834e+01], Loss = 0.3028\n",
      "Iteration 9310: Weights = [5.50000000e+01 3.19079004e+00 6.70868714e+00 2.21029516e-02\n",
      " 2.23363204e-01 1.23528868e+01], Loss = 0.3028\n",
      "Iteration 9311: Weights = [5.50000000e+01 3.19069844e+00 6.70849456e+00 2.21023171e-02\n",
      " 2.23356793e-01 1.23530903e+01], Loss = 0.3028\n",
      "Iteration 9312: Weights = [5.50000000e+01 3.19060685e+00 6.70830198e+00 2.21016826e-02\n",
      " 2.23350381e-01 1.23532937e+01], Loss = 0.3028\n",
      "Iteration 9313: Weights = [5.50000000e+01 3.19051526e+00 6.70810941e+00 2.21010481e-02\n",
      " 2.23343969e-01 1.23534972e+01], Loss = 0.3027\n",
      "Iteration 9314: Weights = [5.50000000e+01 3.19042367e+00 6.70791684e+00 2.21004137e-02\n",
      " 2.23337558e-01 1.23537006e+01], Loss = 0.3027\n",
      "Iteration 9315: Weights = [5.50000000e+01 3.19033208e+00 6.70772429e+00 2.20997793e-02\n",
      " 2.23331147e-01 1.23539041e+01], Loss = 0.3027\n",
      "Iteration 9316: Weights = [5.50000000e+01 3.19024050e+00 6.70753173e+00 2.20991449e-02\n",
      " 2.23324736e-01 1.23541075e+01], Loss = 0.3027\n",
      "Iteration 9317: Weights = [5.50000000e+01 3.19014892e+00 6.70733918e+00 2.20985105e-02\n",
      " 2.23318325e-01 1.23543109e+01], Loss = 0.3027\n",
      "Iteration 9318: Weights = [5.50000000e+01 3.19005734e+00 6.70714664e+00 2.20978761e-02\n",
      " 2.23311914e-01 1.23545143e+01], Loss = 0.3027\n",
      "Iteration 9319: Weights = [5.50000000e+01 3.18996577e+00 6.70695410e+00 2.20972418e-02\n",
      " 2.23305504e-01 1.23547178e+01], Loss = 0.3026\n",
      "Iteration 9320: Weights = [5.50000000e+01 3.18987420e+00 6.70676157e+00 2.20966074e-02\n",
      " 2.23299093e-01 1.23549212e+01], Loss = 0.3026\n",
      "Iteration 9321: Weights = [5.50000000e+01 3.18978263e+00 6.70656904e+00 2.20959731e-02\n",
      " 2.23292683e-01 1.23551246e+01], Loss = 0.3026\n",
      "Iteration 9322: Weights = [5.50000000e+01 3.18969106e+00 6.70637652e+00 2.20953388e-02\n",
      " 2.23286273e-01 1.23553280e+01], Loss = 0.3026\n",
      "Iteration 9323: Weights = [5.50000000e+01 3.18959950e+00 6.70618401e+00 2.20947046e-02\n",
      " 2.23279864e-01 1.23555314e+01], Loss = 0.3026\n",
      "Iteration 9324: Weights = [5.50000000e+01 3.18950793e+00 6.70599150e+00 2.20940703e-02\n",
      " 2.23273454e-01 1.23557347e+01], Loss = 0.3025\n",
      "Iteration 9325: Weights = [5.50000000e+01 3.18941637e+00 6.70579899e+00 2.20934361e-02\n",
      " 2.23267045e-01 1.23559381e+01], Loss = 0.3025\n",
      "Iteration 9326: Weights = [5.50000000e+01 3.18932482e+00 6.70560649e+00 2.20928018e-02\n",
      " 2.23260636e-01 1.23561415e+01], Loss = 0.3025\n",
      "Iteration 9327: Weights = [5.50000000e+01 3.18923326e+00 6.70541400e+00 2.20921676e-02\n",
      " 2.23254227e-01 1.23563449e+01], Loss = 0.3025\n",
      "Iteration 9328: Weights = [5.50000000e+01 3.18914171e+00 6.70522151e+00 2.20915334e-02\n",
      " 2.23247818e-01 1.23565482e+01], Loss = 0.3025\n",
      "Iteration 9329: Weights = [5.50000000e+01 3.18905017e+00 6.70502903e+00 2.20908993e-02\n",
      " 2.23241409e-01 1.23567516e+01], Loss = 0.3025\n",
      "Iteration 9330: Weights = [5.50000000e+01 3.18895862e+00 6.70483656e+00 2.20902651e-02\n",
      " 2.23235001e-01 1.23569549e+01], Loss = 0.3024\n",
      "Iteration 9331: Weights = [5.50000000e+01 3.18886708e+00 6.70464408e+00 2.20896310e-02\n",
      " 2.23228593e-01 1.23571583e+01], Loss = 0.3024\n",
      "Iteration 9332: Weights = [5.50000000e+01 3.18877554e+00 6.70445162e+00 2.20889969e-02\n",
      " 2.23222184e-01 1.23573616e+01], Loss = 0.3024\n",
      "Iteration 9333: Weights = [5.50000000e+01 3.18868400e+00 6.70425916e+00 2.20883628e-02\n",
      " 2.23215777e-01 1.23575649e+01], Loss = 0.3024\n",
      "Iteration 9334: Weights = [5.50000000e+01 3.18859246e+00 6.70406670e+00 2.20877287e-02\n",
      " 2.23209369e-01 1.23577683e+01], Loss = 0.3024\n",
      "Iteration 9335: Weights = [5.50000000e+01 3.18850093e+00 6.70387425e+00 2.20870947e-02\n",
      " 2.23202961e-01 1.23579716e+01], Loss = 0.3024\n",
      "Iteration 9336: Weights = [5.50000000e+01 3.18840940e+00 6.70368181e+00 2.20864606e-02\n",
      " 2.23196554e-01 1.23581749e+01], Loss = 0.3023\n",
      "Iteration 9337: Weights = [5.50000000e+01 3.18831787e+00 6.70348937e+00 2.20858266e-02\n",
      " 2.23190147e-01 1.23583782e+01], Loss = 0.3023\n",
      "Iteration 9338: Weights = [5.50000000e+01 3.18822635e+00 6.70329694e+00 2.20851926e-02\n",
      " 2.23183740e-01 1.23585815e+01], Loss = 0.3023\n",
      "Iteration 9339: Weights = [5.50000000e+01 3.18813482e+00 6.70310451e+00 2.20845586e-02\n",
      " 2.23177333e-01 1.23587848e+01], Loss = 0.3023\n",
      "Iteration 9340: Weights = [5.50000000e+01 3.18804331e+00 6.70291209e+00 2.20839247e-02\n",
      " 2.23170927e-01 1.23589881e+01], Loss = 0.3023\n",
      "Iteration 9341: Weights = [5.50000000e+01 3.18795179e+00 6.70271968e+00 2.20832907e-02\n",
      " 2.23164520e-01 1.23591914e+01], Loss = 0.3023\n",
      "Iteration 9342: Weights = [5.50000000e+01 3.18786027e+00 6.70252727e+00 2.20826568e-02\n",
      " 2.23158114e-01 1.23593946e+01], Loss = 0.3022\n",
      "Iteration 9343: Weights = [5.50000000e+01 3.18776876e+00 6.70233486e+00 2.20820229e-02\n",
      " 2.23151708e-01 1.23595979e+01], Loss = 0.3022\n",
      "Iteration 9344: Weights = [5.50000000e+01 3.18767725e+00 6.70214246e+00 2.20813890e-02\n",
      " 2.23145302e-01 1.23598012e+01], Loss = 0.3022\n",
      "Iteration 9345: Weights = [5.50000000e+01 3.18758575e+00 6.70195007e+00 2.20807551e-02\n",
      " 2.23138896e-01 1.23600044e+01], Loss = 0.3022\n",
      "Iteration 9346: Weights = [5.50000000e+01 3.18749424e+00 6.70175768e+00 2.20801212e-02\n",
      " 2.23132491e-01 1.23602077e+01], Loss = 0.3022\n",
      "Iteration 9347: Weights = [5.50000000e+01 3.18740274e+00 6.70156530e+00 2.20794874e-02\n",
      " 2.23126085e-01 1.23604109e+01], Loss = 0.3021\n",
      "Iteration 9348: Weights = [5.50000000e+01 3.18731124e+00 6.70137292e+00 2.20788536e-02\n",
      " 2.23119680e-01 1.23606142e+01], Loss = 0.3021\n",
      "Iteration 9349: Weights = [5.50000000e+01 3.18721975e+00 6.70118055e+00 2.20782198e-02\n",
      " 2.23113275e-01 1.23608174e+01], Loss = 0.3021\n",
      "Iteration 9350: Weights = [5.50000000e+01 3.18712825e+00 6.70098818e+00 2.20775860e-02\n",
      " 2.23106871e-01 1.23610207e+01], Loss = 0.3021\n",
      "Iteration 9351: Weights = [5.50000000e+01 3.18703676e+00 6.70079582e+00 2.20769522e-02\n",
      " 2.23100466e-01 1.23612239e+01], Loss = 0.3021\n",
      "Iteration 9352: Weights = [5.50000000e+01 3.18694528e+00 6.70060347e+00 2.20763185e-02\n",
      " 2.23094062e-01 1.23614271e+01], Loss = 0.3021\n",
      "Iteration 9353: Weights = [5.50000000e+01 3.18685379e+00 6.70041112e+00 2.20756847e-02\n",
      " 2.23087657e-01 1.23616303e+01], Loss = 0.3020\n",
      "Iteration 9354: Weights = [5.50000000e+01 3.18676231e+00 6.70021877e+00 2.20750510e-02\n",
      " 2.23081253e-01 1.23618335e+01], Loss = 0.3020\n",
      "Iteration 9355: Weights = [5.50000000e+01 3.18667083e+00 6.70002643e+00 2.20744173e-02\n",
      " 2.23074850e-01 1.23620367e+01], Loss = 0.3020\n",
      "Iteration 9356: Weights = [5.50000000e+01 3.18657935e+00 6.69983410e+00 2.20737837e-02\n",
      " 2.23068446e-01 1.23622399e+01], Loss = 0.3020\n",
      "Iteration 9357: Weights = [5.50000000e+01 3.18648787e+00 6.69964177e+00 2.20731500e-02\n",
      " 2.23062042e-01 1.23624431e+01], Loss = 0.3020\n",
      "Iteration 9358: Weights = [5.50000000e+01 3.18639640e+00 6.69944945e+00 2.20725164e-02\n",
      " 2.23055639e-01 1.23626463e+01], Loss = 0.3020\n",
      "Iteration 9359: Weights = [5.50000000e+01 3.18630493e+00 6.69925714e+00 2.20718828e-02\n",
      " 2.23049236e-01 1.23628495e+01], Loss = 0.3019\n",
      "Iteration 9360: Weights = [5.50000000e+01 3.18621347e+00 6.69906482e+00 2.20712492e-02\n",
      " 2.23042833e-01 1.23630527e+01], Loss = 0.3019\n",
      "Iteration 9361: Weights = [5.50000000e+01 3.18612200e+00 6.69887252e+00 2.20706156e-02\n",
      " 2.23036430e-01 1.23632558e+01], Loss = 0.3019\n",
      "Iteration 9362: Weights = [5.50000000e+01 3.18603054e+00 6.69868022e+00 2.20699820e-02\n",
      " 2.23030028e-01 1.23634590e+01], Loss = 0.3019\n",
      "Iteration 9363: Weights = [5.50000000e+01 3.18593908e+00 6.69848793e+00 2.20693485e-02\n",
      " 2.23023626e-01 1.23636621e+01], Loss = 0.3019\n",
      "Iteration 9364: Weights = [5.50000000e+01 3.18584762e+00 6.69829564e+00 2.20687149e-02\n",
      " 2.23017223e-01 1.23638653e+01], Loss = 0.3019\n",
      "Iteration 9365: Weights = [5.50000000e+01 3.18575617e+00 6.69810335e+00 2.20680814e-02\n",
      " 2.23010821e-01 1.23640684e+01], Loss = 0.3018\n",
      "Iteration 9366: Weights = [5.50000000e+01 3.18566472e+00 6.69791107e+00 2.20674479e-02\n",
      " 2.23004420e-01 1.23642716e+01], Loss = 0.3018\n",
      "Iteration 9367: Weights = [5.50000000e+01 3.18557327e+00 6.69771880e+00 2.20668144e-02\n",
      " 2.22998018e-01 1.23644747e+01], Loss = 0.3018\n",
      "Iteration 9368: Weights = [5.50000000e+01 3.18548182e+00 6.69752654e+00 2.20661810e-02\n",
      " 2.22991616e-01 1.23646778e+01], Loss = 0.3018\n",
      "Iteration 9369: Weights = [5.50000000e+01 3.18539038e+00 6.69733427e+00 2.20655475e-02\n",
      " 2.22985215e-01 1.23648810e+01], Loss = 0.3018\n",
      "Iteration 9370: Weights = [5.50000000e+01 3.18529894e+00 6.69714202e+00 2.20649141e-02\n",
      " 2.22978814e-01 1.23650841e+01], Loss = 0.3017\n",
      "Iteration 9371: Weights = [5.50000000e+01 3.18520750e+00 6.69694977e+00 2.20642807e-02\n",
      " 2.22972413e-01 1.23652872e+01], Loss = 0.3017\n",
      "Iteration 9372: Weights = [5.50000000e+01 3.18511607e+00 6.69675752e+00 2.20636473e-02\n",
      " 2.22966012e-01 1.23654903e+01], Loss = 0.3017\n",
      "Iteration 9373: Weights = [5.50000000e+01 3.18502463e+00 6.69656528e+00 2.20630140e-02\n",
      " 2.22959612e-01 1.23656934e+01], Loss = 0.3017\n",
      "Iteration 9374: Weights = [5.50000000e+01 3.18493320e+00 6.69637305e+00 2.20623806e-02\n",
      " 2.22953212e-01 1.23658965e+01], Loss = 0.3017\n",
      "Iteration 9375: Weights = [5.50000000e+01 3.18484177e+00 6.69618082e+00 2.20617473e-02\n",
      " 2.22946811e-01 1.23660996e+01], Loss = 0.3017\n",
      "Iteration 9376: Weights = [5.50000000e+01 3.18475035e+00 6.69598860e+00 2.20611140e-02\n",
      " 2.22940411e-01 1.23663026e+01], Loss = 0.3016\n",
      "Iteration 9377: Weights = [5.50000000e+01 3.18465893e+00 6.69579638e+00 2.20604807e-02\n",
      " 2.22934012e-01 1.23665057e+01], Loss = 0.3016\n",
      "Iteration 9378: Weights = [5.50000000e+01 3.18456751e+00 6.69560417e+00 2.20598474e-02\n",
      " 2.22927612e-01 1.23667088e+01], Loss = 0.3016\n",
      "Iteration 9379: Weights = [5.50000000e+01 3.18447609e+00 6.69541197e+00 2.20592142e-02\n",
      " 2.22921213e-01 1.23669118e+01], Loss = 0.3016\n",
      "Iteration 9380: Weights = [5.50000000e+01 3.18438468e+00 6.69521976e+00 2.20585809e-02\n",
      " 2.22914813e-01 1.23671149e+01], Loss = 0.3016\n",
      "Iteration 9381: Weights = [5.50000000e+01 3.18429326e+00 6.69502757e+00 2.20579477e-02\n",
      " 2.22908414e-01 1.23673180e+01], Loss = 0.3016\n",
      "Iteration 9382: Weights = [5.50000000e+01 3.18420185e+00 6.69483538e+00 2.20573145e-02\n",
      " 2.22902015e-01 1.23675210e+01], Loss = 0.3015\n",
      "Iteration 9383: Weights = [5.50000000e+01 3.18411045e+00 6.69464320e+00 2.20566813e-02\n",
      " 2.22895617e-01 1.23677240e+01], Loss = 0.3015\n",
      "Iteration 9384: Weights = [5.50000000e+01 3.18401904e+00 6.69445102e+00 2.20560482e-02\n",
      " 2.22889218e-01 1.23679271e+01], Loss = 0.3015\n",
      "Iteration 9385: Weights = [5.50000000e+01 3.18392764e+00 6.69425884e+00 2.20554150e-02\n",
      " 2.22882820e-01 1.23681301e+01], Loss = 0.3015\n",
      "Iteration 9386: Weights = [5.50000000e+01 3.18383624e+00 6.69406668e+00 2.20547819e-02\n",
      " 2.22876422e-01 1.23683331e+01], Loss = 0.3015\n",
      "Iteration 9387: Weights = [5.50000000e+01 3.18374485e+00 6.69387452e+00 2.20541488e-02\n",
      " 2.22870024e-01 1.23685361e+01], Loss = 0.3015\n",
      "Iteration 9388: Weights = [5.50000000e+01 3.18365345e+00 6.69368236e+00 2.20535157e-02\n",
      " 2.22863626e-01 1.23687391e+01], Loss = 0.3014\n",
      "Iteration 9389: Weights = [5.50000000e+01 3.18356206e+00 6.69349021e+00 2.20528826e-02\n",
      " 2.22857228e-01 1.23689421e+01], Loss = 0.3014\n",
      "Iteration 9390: Weights = [5.50000000e+01 3.18347067e+00 6.69329806e+00 2.20522495e-02\n",
      " 2.22850831e-01 1.23691451e+01], Loss = 0.3014\n",
      "Iteration 9391: Weights = [5.50000000e+01 3.18337929e+00 6.69310592e+00 2.20516165e-02\n",
      " 2.22844434e-01 1.23693481e+01], Loss = 0.3014\n",
      "Iteration 9392: Weights = [5.50000000e+01 3.18328791e+00 6.69291379e+00 2.20509835e-02\n",
      " 2.22838037e-01 1.23695511e+01], Loss = 0.3014\n",
      "Iteration 9393: Weights = [5.50000000e+01 3.18319652e+00 6.69272166e+00 2.20503505e-02\n",
      " 2.22831640e-01 1.23697541e+01], Loss = 0.3014\n",
      "Iteration 9394: Weights = [5.50000000e+01 3.18310515e+00 6.69252954e+00 2.20497175e-02\n",
      " 2.22825243e-01 1.23699571e+01], Loss = 0.3013\n",
      "Iteration 9395: Weights = [5.50000000e+01 3.18301377e+00 6.69233742e+00 2.20490845e-02\n",
      " 2.22818847e-01 1.23701601e+01], Loss = 0.3013\n",
      "Iteration 9396: Weights = [5.50000000e+01 3.18292240e+00 6.69214531e+00 2.20484516e-02\n",
      " 2.22812450e-01 1.23703630e+01], Loss = 0.3013\n",
      "Iteration 9397: Weights = [5.50000000e+01 3.18283103e+00 6.69195320e+00 2.20478186e-02\n",
      " 2.22806054e-01 1.23705660e+01], Loss = 0.3013\n",
      "Iteration 9398: Weights = [5.50000000e+01 3.18273966e+00 6.69176110e+00 2.20471857e-02\n",
      " 2.22799658e-01 1.23707689e+01], Loss = 0.3013\n",
      "Iteration 9399: Weights = [5.50000000e+01 3.18264830e+00 6.69156900e+00 2.20465528e-02\n",
      " 2.22793263e-01 1.23709719e+01], Loss = 0.3012\n",
      "Iteration 9400: Weights = [5.50000000e+01 3.18255694e+00 6.69137691e+00 2.20459200e-02\n",
      " 2.22786867e-01 1.23711748e+01], Loss = 0.3012\n",
      "Iteration 9401: Weights = [5.50000000e+01 3.18246558e+00 6.69118483e+00 2.20452871e-02\n",
      " 2.22780472e-01 1.23713777e+01], Loss = 0.3012\n",
      "Iteration 9402: Weights = [5.50000000e+01 3.18237422e+00 6.69099275e+00 2.20446543e-02\n",
      " 2.22774076e-01 1.23715807e+01], Loss = 0.3012\n",
      "Iteration 9403: Weights = [5.50000000e+01 3.18228286e+00 6.69080067e+00 2.20440215e-02\n",
      " 2.22767681e-01 1.23717836e+01], Loss = 0.3012\n",
      "Iteration 9404: Weights = [5.50000000e+01 3.18219151e+00 6.69060861e+00 2.20433886e-02\n",
      " 2.22761287e-01 1.23719865e+01], Loss = 0.3012\n",
      "Iteration 9405: Weights = [5.50000000e+01 3.18210016e+00 6.69041654e+00 2.20427559e-02\n",
      " 2.22754892e-01 1.23721894e+01], Loss = 0.3011\n",
      "Iteration 9406: Weights = [5.50000000e+01 3.18200882e+00 6.69022449e+00 2.20421231e-02\n",
      " 2.22748497e-01 1.23723923e+01], Loss = 0.3011\n",
      "Iteration 9407: Weights = [5.50000000e+01 3.18191747e+00 6.69003243e+00 2.20414904e-02\n",
      " 2.22742103e-01 1.23725952e+01], Loss = 0.3011\n",
      "Iteration 9408: Weights = [5.50000000e+01 3.18182613e+00 6.68984039e+00 2.20408576e-02\n",
      " 2.22735709e-01 1.23727981e+01], Loss = 0.3011\n",
      "Iteration 9409: Weights = [5.50000000e+01 3.18173479e+00 6.68964835e+00 2.20402249e-02\n",
      " 2.22729315e-01 1.23730010e+01], Loss = 0.3011\n",
      "Iteration 9410: Weights = [5.50000000e+01 3.18164346e+00 6.68945631e+00 2.20395922e-02\n",
      " 2.22722921e-01 1.23732039e+01], Loss = 0.3011\n",
      "Iteration 9411: Weights = [5.50000000e+01 3.18155213e+00 6.68926428e+00 2.20389595e-02\n",
      " 2.22716528e-01 1.23734068e+01], Loss = 0.3010\n",
      "Iteration 9412: Weights = [5.50000000e+01 3.18146079e+00 6.68907226e+00 2.20383269e-02\n",
      " 2.22710134e-01 1.23736096e+01], Loss = 0.3010\n",
      "Iteration 9413: Weights = [5.50000000e+01 3.18136947e+00 6.68888024e+00 2.20376942e-02\n",
      " 2.22703741e-01 1.23738125e+01], Loss = 0.3010\n",
      "Iteration 9414: Weights = [5.50000000e+01 3.18127814e+00 6.68868823e+00 2.20370616e-02\n",
      " 2.22697348e-01 1.23740154e+01], Loss = 0.3010\n",
      "Iteration 9415: Weights = [5.50000000e+01 3.18118682e+00 6.68849622e+00 2.20364290e-02\n",
      " 2.22690955e-01 1.23742182e+01], Loss = 0.3010\n",
      "Iteration 9416: Weights = [5.50000000e+01 3.18109550e+00 6.68830422e+00 2.20357964e-02\n",
      " 2.22684563e-01 1.23744211e+01], Loss = 0.3010\n",
      "Iteration 9417: Weights = [5.50000000e+01 3.18100418e+00 6.68811222e+00 2.20351639e-02\n",
      " 2.22678170e-01 1.23746239e+01], Loss = 0.3009\n",
      "Iteration 9418: Weights = [5.50000000e+01 3.18091287e+00 6.68792023e+00 2.20345313e-02\n",
      " 2.22671778e-01 1.23748267e+01], Loss = 0.3009\n",
      "Iteration 9419: Weights = [5.50000000e+01 3.18082155e+00 6.68772824e+00 2.20338988e-02\n",
      " 2.22665386e-01 1.23750296e+01], Loss = 0.3009\n",
      "Iteration 9420: Weights = [5.50000000e+01 3.18073024e+00 6.68753626e+00 2.20332663e-02\n",
      " 2.22658994e-01 1.23752324e+01], Loss = 0.3009\n",
      "Iteration 9421: Weights = [5.50000000e+01 3.18063894e+00 6.68734429e+00 2.20326338e-02\n",
      " 2.22652602e-01 1.23754352e+01], Loss = 0.3009\n",
      "Iteration 9422: Weights = [5.50000000e+01 3.18054763e+00 6.68715232e+00 2.20320013e-02\n",
      " 2.22646211e-01 1.23756380e+01], Loss = 0.3008\n",
      "Iteration 9423: Weights = [5.50000000e+01 3.18045633e+00 6.68696036e+00 2.20313689e-02\n",
      " 2.22639820e-01 1.23758408e+01], Loss = 0.3008\n",
      "Iteration 9424: Weights = [5.50000000e+01 3.18036503e+00 6.68676840e+00 2.20307364e-02\n",
      " 2.22633428e-01 1.23760436e+01], Loss = 0.3008\n",
      "Iteration 9425: Weights = [5.50000000e+01 3.18027374e+00 6.68657645e+00 2.20301040e-02\n",
      " 2.22627037e-01 1.23762464e+01], Loss = 0.3008\n",
      "Iteration 9426: Weights = [5.50000000e+01 3.18018244e+00 6.68638450e+00 2.20294716e-02\n",
      " 2.22620647e-01 1.23764492e+01], Loss = 0.3008\n",
      "Iteration 9427: Weights = [5.50000000e+01 3.18009115e+00 6.68619256e+00 2.20288392e-02\n",
      " 2.22614256e-01 1.23766520e+01], Loss = 0.3008\n",
      "Iteration 9428: Weights = [5.50000000e+01 3.17999986e+00 6.68600062e+00 2.20282068e-02\n",
      " 2.22607866e-01 1.23768548e+01], Loss = 0.3007\n",
      "Iteration 9429: Weights = [5.50000000e+01 3.17990858e+00 6.68580869e+00 2.20275745e-02\n",
      " 2.22601475e-01 1.23770575e+01], Loss = 0.3007\n",
      "Iteration 9430: Weights = [5.50000000e+01 3.17981729e+00 6.68561677e+00 2.20269422e-02\n",
      " 2.22595085e-01 1.23772603e+01], Loss = 0.3007\n",
      "Iteration 9431: Weights = [5.50000000e+01 3.17972601e+00 6.68542485e+00 2.20263098e-02\n",
      " 2.22588695e-01 1.23774631e+01], Loss = 0.3007\n",
      "Iteration 9432: Weights = [5.50000000e+01 3.17963473e+00 6.68523293e+00 2.20256776e-02\n",
      " 2.22582306e-01 1.23776658e+01], Loss = 0.3007\n",
      "Iteration 9433: Weights = [5.50000000e+01 3.17954346e+00 6.68504103e+00 2.20250453e-02\n",
      " 2.22575916e-01 1.23778686e+01], Loss = 0.3007\n",
      "Iteration 9434: Weights = [5.50000000e+01 3.17945218e+00 6.68484912e+00 2.20244130e-02\n",
      " 2.22569527e-01 1.23780713e+01], Loss = 0.3006\n",
      "Iteration 9435: Weights = [5.50000000e+01 3.17936091e+00 6.68465723e+00 2.20237808e-02\n",
      " 2.22563138e-01 1.23782741e+01], Loss = 0.3006\n",
      "Iteration 9436: Weights = [5.50000000e+01 3.17926965e+00 6.68446533e+00 2.20231486e-02\n",
      " 2.22556749e-01 1.23784768e+01], Loss = 0.3006\n",
      "Iteration 9437: Weights = [5.50000000e+01 3.17917838e+00 6.68427345e+00 2.20225164e-02\n",
      " 2.22550360e-01 1.23786795e+01], Loss = 0.3006\n",
      "Iteration 9438: Weights = [5.50000000e+01 3.17908712e+00 6.68408157e+00 2.20218842e-02\n",
      " 2.22543971e-01 1.23788822e+01], Loss = 0.3006\n",
      "Iteration 9439: Weights = [5.50000000e+01 3.17899586e+00 6.68388969e+00 2.20212520e-02\n",
      " 2.22537583e-01 1.23790849e+01], Loss = 0.3006\n",
      "Iteration 9440: Weights = [5.50000000e+01 3.17890460e+00 6.68369782e+00 2.20206199e-02\n",
      " 2.22531195e-01 1.23792876e+01], Loss = 0.3005\n",
      "Iteration 9441: Weights = [5.50000000e+01 3.17881335e+00 6.68350596e+00 2.20199877e-02\n",
      " 2.22524807e-01 1.23794904e+01], Loss = 0.3005\n",
      "Iteration 9442: Weights = [5.50000000e+01 3.17872209e+00 6.68331410e+00 2.20193556e-02\n",
      " 2.22518419e-01 1.23796930e+01], Loss = 0.3005\n",
      "Iteration 9443: Weights = [5.50000000e+01 3.17863085e+00 6.68312225e+00 2.20187235e-02\n",
      " 2.22512031e-01 1.23798957e+01], Loss = 0.3005\n",
      "Iteration 9444: Weights = [5.50000000e+01 3.17853960e+00 6.68293040e+00 2.20180914e-02\n",
      " 2.22505644e-01 1.23800984e+01], Loss = 0.3005\n",
      "Iteration 9445: Weights = [5.50000000e+01 3.17844835e+00 6.68273856e+00 2.20174594e-02\n",
      " 2.22499256e-01 1.23803011e+01], Loss = 0.3005\n",
      "Iteration 9446: Weights = [5.50000000e+01 3.17835711e+00 6.68254672e+00 2.20168273e-02\n",
      " 2.22492869e-01 1.23805038e+01], Loss = 0.3004\n",
      "Iteration 9447: Weights = [5.50000000e+01 3.17826587e+00 6.68235489e+00 2.20161953e-02\n",
      " 2.22486482e-01 1.23807064e+01], Loss = 0.3004\n",
      "Iteration 9448: Weights = [5.50000000e+01 3.17817464e+00 6.68216306e+00 2.20155633e-02\n",
      " 2.22480095e-01 1.23809091e+01], Loss = 0.3004\n",
      "Iteration 9449: Weights = [5.50000000e+01 3.17808340e+00 6.68197124e+00 2.20149313e-02\n",
      " 2.22473709e-01 1.23811118e+01], Loss = 0.3004\n",
      "Iteration 9450: Weights = [5.50000000e+01 3.17799217e+00 6.68177943e+00 2.20142994e-02\n",
      " 2.22467322e-01 1.23813144e+01], Loss = 0.3004\n",
      "Iteration 9451: Weights = [5.50000000e+01 3.17790094e+00 6.68158762e+00 2.20136674e-02\n",
      " 2.22460936e-01 1.23815170e+01], Loss = 0.3003\n",
      "Iteration 9452: Weights = [5.50000000e+01 3.17780972e+00 6.68139581e+00 2.20130355e-02\n",
      " 2.22454550e-01 1.23817197e+01], Loss = 0.3003\n",
      "Iteration 9453: Weights = [5.50000000e+01 3.17771850e+00 6.68120402e+00 2.20124036e-02\n",
      " 2.22448164e-01 1.23819223e+01], Loss = 0.3003\n",
      "Iteration 9454: Weights = [5.50000000e+01 3.17762728e+00 6.68101222e+00 2.20117717e-02\n",
      " 2.22441779e-01 1.23821249e+01], Loss = 0.3003\n",
      "Iteration 9455: Weights = [5.50000000e+01 3.17753606e+00 6.68082044e+00 2.20111398e-02\n",
      " 2.22435393e-01 1.23823276e+01], Loss = 0.3003\n",
      "Iteration 9456: Weights = [5.50000000e+01 3.17744484e+00 6.68062865e+00 2.20105079e-02\n",
      " 2.22429008e-01 1.23825302e+01], Loss = 0.3003\n",
      "Iteration 9457: Weights = [5.50000000e+01 3.17735363e+00 6.68043688e+00 2.20098761e-02\n",
      " 2.22422623e-01 1.23827328e+01], Loss = 0.3002\n",
      "Iteration 9458: Weights = [5.50000000e+01 3.17726242e+00 6.68024511e+00 2.20092443e-02\n",
      " 2.22416238e-01 1.23829354e+01], Loss = 0.3002\n",
      "Iteration 9459: Weights = [5.50000000e+01 3.17717121e+00 6.68005334e+00 2.20086125e-02\n",
      " 2.22409853e-01 1.23831380e+01], Loss = 0.3002\n",
      "Iteration 9460: Weights = [5.50000000e+01 3.17708001e+00 6.67986158e+00 2.20079807e-02\n",
      " 2.22403468e-01 1.23833406e+01], Loss = 0.3002\n",
      "Iteration 9461: Weights = [5.50000000e+01 3.17698880e+00 6.67966983e+00 2.20073489e-02\n",
      " 2.22397084e-01 1.23835432e+01], Loss = 0.3002\n",
      "Iteration 9462: Weights = [5.50000000e+01 3.17689761e+00 6.67947808e+00 2.20067172e-02\n",
      " 2.22390700e-01 1.23837457e+01], Loss = 0.3002\n",
      "Iteration 9463: Weights = [5.50000000e+01 3.17680641e+00 6.67928634e+00 2.20060854e-02\n",
      " 2.22384316e-01 1.23839483e+01], Loss = 0.3001\n",
      "Iteration 9464: Weights = [5.50000000e+01 3.17671521e+00 6.67909460e+00 2.20054537e-02\n",
      " 2.22377932e-01 1.23841509e+01], Loss = 0.3001\n",
      "Iteration 9465: Weights = [5.50000000e+01 3.17662402e+00 6.67890287e+00 2.20048220e-02\n",
      " 2.22371548e-01 1.23843534e+01], Loss = 0.3001\n",
      "Iteration 9466: Weights = [5.50000000e+01 3.17653283e+00 6.67871114e+00 2.20041904e-02\n",
      " 2.22365165e-01 1.23845560e+01], Loss = 0.3001\n",
      "Iteration 9467: Weights = [5.50000000e+01 3.17644165e+00 6.67851942e+00 2.20035587e-02\n",
      " 2.22358782e-01 1.23847585e+01], Loss = 0.3001\n",
      "Iteration 9468: Weights = [5.50000000e+01 3.17635046e+00 6.67832770e+00 2.20029271e-02\n",
      " 2.22352399e-01 1.23849611e+01], Loss = 0.3001\n",
      "Iteration 9469: Weights = [5.50000000e+01 3.17625928e+00 6.67813599e+00 2.20022954e-02\n",
      " 2.22346016e-01 1.23851636e+01], Loss = 0.3000\n",
      "Iteration 9470: Weights = [5.50000000e+01 3.17616810e+00 6.67794429e+00 2.20016638e-02\n",
      " 2.22339633e-01 1.23853662e+01], Loss = 0.3000\n",
      "Iteration 9471: Weights = [5.50000000e+01 3.17607693e+00 6.67775259e+00 2.20010322e-02\n",
      " 2.22333250e-01 1.23855687e+01], Loss = 0.3000\n",
      "Iteration 9472: Weights = [5.50000000e+01 3.17598575e+00 6.67756090e+00 2.20004007e-02\n",
      " 2.22326868e-01 1.23857712e+01], Loss = 0.3000\n",
      "Iteration 9473: Weights = [5.50000000e+01 3.17589458e+00 6.67736921e+00 2.19997691e-02\n",
      " 2.22320486e-01 1.23859737e+01], Loss = 0.3000\n",
      "Iteration 9474: Weights = [5.50000000e+01 3.17580341e+00 6.67717752e+00 2.19991376e-02\n",
      " 2.22314104e-01 1.23861762e+01], Loss = 0.3000\n",
      "Iteration 9475: Weights = [5.50000000e+01 3.17571225e+00 6.67698585e+00 2.19985061e-02\n",
      " 2.22307722e-01 1.23863787e+01], Loss = 0.2999\n",
      "Iteration 9476: Weights = [5.50000000e+01 3.17562109e+00 6.67679418e+00 2.19978746e-02\n",
      " 2.22301340e-01 1.23865812e+01], Loss = 0.2999\n",
      "Iteration 9477: Weights = [5.50000000e+01 3.17552992e+00 6.67660251e+00 2.19972431e-02\n",
      " 2.22294959e-01 1.23867837e+01], Loss = 0.2999\n",
      "Iteration 9478: Weights = [5.50000000e+01 3.17543877e+00 6.67641085e+00 2.19966116e-02\n",
      " 2.22288578e-01 1.23869862e+01], Loss = 0.2999\n",
      "Iteration 9479: Weights = [5.50000000e+01 3.17534761e+00 6.67621919e+00 2.19959802e-02\n",
      " 2.22282197e-01 1.23871887e+01], Loss = 0.2999\n",
      "Iteration 9480: Weights = [5.50000000e+01 3.17525646e+00 6.67602754e+00 2.19953488e-02\n",
      " 2.22275816e-01 1.23873912e+01], Loss = 0.2998\n",
      "Iteration 9481: Weights = [5.50000000e+01 3.17516531e+00 6.67583590e+00 2.19947174e-02\n",
      " 2.22269435e-01 1.23875936e+01], Loss = 0.2998\n",
      "Iteration 9482: Weights = [5.50000000e+01 3.17507416e+00 6.67564426e+00 2.19940860e-02\n",
      " 2.22263054e-01 1.23877961e+01], Loss = 0.2998\n",
      "Iteration 9483: Weights = [5.50000000e+01 3.17498302e+00 6.67545263e+00 2.19934546e-02\n",
      " 2.22256674e-01 1.23879986e+01], Loss = 0.2998\n",
      "Iteration 9484: Weights = [5.50000000e+01 3.17489188e+00 6.67526100e+00 2.19928233e-02\n",
      " 2.22250294e-01 1.23882010e+01], Loss = 0.2998\n",
      "Iteration 9485: Weights = [5.50000000e+01 3.17480074e+00 6.67506938e+00 2.19921919e-02\n",
      " 2.22243914e-01 1.23884035e+01], Loss = 0.2998\n",
      "Iteration 9486: Weights = [5.50000000e+01 3.17470960e+00 6.67487776e+00 2.19915606e-02\n",
      " 2.22237534e-01 1.23886059e+01], Loss = 0.2997\n",
      "Iteration 9487: Weights = [5.50000000e+01 3.17461847e+00 6.67468615e+00 2.19909293e-02\n",
      " 2.22231154e-01 1.23888083e+01], Loss = 0.2997\n",
      "Iteration 9488: Weights = [5.50000000e+01 3.17452733e+00 6.67449455e+00 2.19902980e-02\n",
      " 2.22224775e-01 1.23890108e+01], Loss = 0.2997\n",
      "Iteration 9489: Weights = [5.50000000e+01 3.17443620e+00 6.67430295e+00 2.19896668e-02\n",
      " 2.22218396e-01 1.23892132e+01], Loss = 0.2997\n",
      "Iteration 9490: Weights = [5.50000000e+01 3.17434508e+00 6.67411135e+00 2.19890355e-02\n",
      " 2.22212017e-01 1.23894156e+01], Loss = 0.2997\n",
      "Iteration 9491: Weights = [5.50000000e+01 3.17425395e+00 6.67391976e+00 2.19884043e-02\n",
      " 2.22205638e-01 1.23896180e+01], Loss = 0.2997\n",
      "Iteration 9492: Weights = [5.50000000e+01 3.17416283e+00 6.67372818e+00 2.19877731e-02\n",
      " 2.22199259e-01 1.23898204e+01], Loss = 0.2996\n",
      "Iteration 9493: Weights = [5.50000000e+01 3.17407171e+00 6.67353660e+00 2.19871419e-02\n",
      " 2.22192881e-01 1.23900228e+01], Loss = 0.2996\n",
      "Iteration 9494: Weights = [5.50000000e+01 3.17398060e+00 6.67334503e+00 2.19865107e-02\n",
      " 2.22186502e-01 1.23902252e+01], Loss = 0.2996\n",
      "Iteration 9495: Weights = [5.50000000e+01 3.17388949e+00 6.67315346e+00 2.19858796e-02\n",
      " 2.22180124e-01 1.23904276e+01], Loss = 0.2996\n",
      "Iteration 9496: Weights = [5.50000000e+01 3.17379838e+00 6.67296190e+00 2.19852485e-02\n",
      " 2.22173746e-01 1.23906300e+01], Loss = 0.2996\n",
      "Iteration 9497: Weights = [5.50000000e+01 3.17370727e+00 6.67277034e+00 2.19846173e-02\n",
      " 2.22167368e-01 1.23908324e+01], Loss = 0.2996\n",
      "Iteration 9498: Weights = [5.50000000e+01 3.17361616e+00 6.67257879e+00 2.19839863e-02\n",
      " 2.22160991e-01 1.23910347e+01], Loss = 0.2995\n",
      "Iteration 9499: Weights = [5.50000000e+01 3.17352506e+00 6.67238725e+00 2.19833552e-02\n",
      " 2.22154613e-01 1.23912371e+01], Loss = 0.2995\n",
      "Iteration 9500: Weights = [5.50000000e+01 3.17343396e+00 6.67219571e+00 2.19827241e-02\n",
      " 2.22148236e-01 1.23914394e+01], Loss = 0.2995\n",
      "Iteration 9501: Weights = [5.50000000e+01 3.17334286e+00 6.67200417e+00 2.19820931e-02\n",
      " 2.22141859e-01 1.23916418e+01], Loss = 0.2995\n",
      "Iteration 9502: Weights = [5.50000000e+01 3.17325177e+00 6.67181264e+00 2.19814620e-02\n",
      " 2.22135482e-01 1.23918441e+01], Loss = 0.2995\n",
      "Iteration 9503: Weights = [5.50000000e+01 3.17316067e+00 6.67162112e+00 2.19808310e-02\n",
      " 2.22129105e-01 1.23920465e+01], Loss = 0.2995\n",
      "Iteration 9504: Weights = [5.50000000e+01 3.17306958e+00 6.67142960e+00 2.19802000e-02\n",
      " 2.22122729e-01 1.23922488e+01], Loss = 0.2994\n",
      "Iteration 9505: Weights = [5.50000000e+01 3.17297850e+00 6.67123809e+00 2.19795691e-02\n",
      " 2.22116353e-01 1.23924512e+01], Loss = 0.2994\n",
      "Iteration 9506: Weights = [5.50000000e+01 3.17288741e+00 6.67104659e+00 2.19789381e-02\n",
      " 2.22109976e-01 1.23926535e+01], Loss = 0.2994\n",
      "Iteration 9507: Weights = [5.50000000e+01 3.17279633e+00 6.67085508e+00 2.19783072e-02\n",
      " 2.22103601e-01 1.23928558e+01], Loss = 0.2994\n",
      "Iteration 9508: Weights = [5.50000000e+01 3.17270525e+00 6.67066359e+00 2.19776763e-02\n",
      " 2.22097225e-01 1.23930581e+01], Loss = 0.2994\n",
      "Iteration 9509: Weights = [5.50000000e+01 3.17261417e+00 6.67047210e+00 2.19770454e-02\n",
      " 2.22090849e-01 1.23932604e+01], Loss = 0.2993\n",
      "Iteration 9510: Weights = [5.50000000e+01 3.17252310e+00 6.67028061e+00 2.19764145e-02\n",
      " 2.22084474e-01 1.23934627e+01], Loss = 0.2993\n",
      "Iteration 9511: Weights = [5.50000000e+01 3.17243203e+00 6.67008913e+00 2.19757836e-02\n",
      " 2.22078099e-01 1.23936650e+01], Loss = 0.2993\n",
      "Iteration 9512: Weights = [5.50000000e+01 3.17234096e+00 6.66989766e+00 2.19751528e-02\n",
      " 2.22071723e-01 1.23938673e+01], Loss = 0.2993\n",
      "Iteration 9513: Weights = [5.50000000e+01 3.17224989e+00 6.66970619e+00 2.19745220e-02\n",
      " 2.22065349e-01 1.23940696e+01], Loss = 0.2993\n",
      "Iteration 9514: Weights = [5.50000000e+01 3.17215883e+00 6.66951473e+00 2.19738912e-02\n",
      " 2.22058974e-01 1.23942719e+01], Loss = 0.2993\n",
      "Iteration 9515: Weights = [5.50000000e+01 3.17206777e+00 6.66932327e+00 2.19732604e-02\n",
      " 2.22052599e-01 1.23944741e+01], Loss = 0.2992\n",
      "Iteration 9516: Weights = [5.50000000e+01 3.17197671e+00 6.66913182e+00 2.19726296e-02\n",
      " 2.22046225e-01 1.23946764e+01], Loss = 0.2992\n",
      "Iteration 9517: Weights = [5.50000000e+01 3.17188566e+00 6.66894038e+00 2.19719988e-02\n",
      " 2.22039851e-01 1.23948787e+01], Loss = 0.2992\n",
      "Iteration 9518: Weights = [5.50000000e+01 3.17179460e+00 6.66874893e+00 2.19713681e-02\n",
      " 2.22033477e-01 1.23950809e+01], Loss = 0.2992\n",
      "Iteration 9519: Weights = [5.50000000e+01 3.17170355e+00 6.66855750e+00 2.19707374e-02\n",
      " 2.22027103e-01 1.23952832e+01], Loss = 0.2992\n",
      "Iteration 9520: Weights = [5.50000000e+01 3.17161250e+00 6.66836607e+00 2.19701067e-02\n",
      " 2.22020730e-01 1.23954854e+01], Loss = 0.2992\n",
      "Iteration 9521: Weights = [5.50000000e+01 3.17152146e+00 6.66817465e+00 2.19694760e-02\n",
      " 2.22014356e-01 1.23956876e+01], Loss = 0.2991\n",
      "Iteration 9522: Weights = [5.50000000e+01 3.17143042e+00 6.66798323e+00 2.19688454e-02\n",
      " 2.22007983e-01 1.23958899e+01], Loss = 0.2991\n",
      "Iteration 9523: Weights = [5.50000000e+01 3.17133938e+00 6.66779181e+00 2.19682147e-02\n",
      " 2.22001610e-01 1.23960921e+01], Loss = 0.2991\n",
      "Iteration 9524: Weights = [5.50000000e+01 3.17124834e+00 6.66760041e+00 2.19675841e-02\n",
      " 2.21995237e-01 1.23962943e+01], Loss = 0.2991\n",
      "Iteration 9525: Weights = [5.50000000e+01 3.17115730e+00 6.66740900e+00 2.19669535e-02\n",
      " 2.21988865e-01 1.23964965e+01], Loss = 0.2991\n",
      "Iteration 9526: Weights = [5.50000000e+01 3.17106627e+00 6.66721761e+00 2.19663229e-02\n",
      " 2.21982492e-01 1.23966987e+01], Loss = 0.2991\n",
      "Iteration 9527: Weights = [5.50000000e+01 3.17097524e+00 6.66702622e+00 2.19656923e-02\n",
      " 2.21976120e-01 1.23969009e+01], Loss = 0.2990\n",
      "Iteration 9528: Weights = [5.50000000e+01 3.17088421e+00 6.66683483e+00 2.19650618e-02\n",
      " 2.21969748e-01 1.23971031e+01], Loss = 0.2990\n",
      "Iteration 9529: Weights = [5.50000000e+01 3.17079319e+00 6.66664345e+00 2.19644312e-02\n",
      " 2.21963376e-01 1.23973053e+01], Loss = 0.2990\n",
      "Iteration 9530: Weights = [5.50000000e+01 3.17070217e+00 6.66645208e+00 2.19638007e-02\n",
      " 2.21957004e-01 1.23975075e+01], Loss = 0.2990\n",
      "Iteration 9531: Weights = [5.50000000e+01 3.17061115e+00 6.66626071e+00 2.19631702e-02\n",
      " 2.21950632e-01 1.23977097e+01], Loss = 0.2990\n",
      "Iteration 9532: Weights = [5.50000000e+01 3.17052013e+00 6.66606934e+00 2.19625397e-02\n",
      " 2.21944261e-01 1.23979119e+01], Loss = 0.2990\n",
      "Iteration 9533: Weights = [5.50000000e+01 3.17042912e+00 6.66587798e+00 2.19619093e-02\n",
      " 2.21937890e-01 1.23981140e+01], Loss = 0.2989\n",
      "Iteration 9534: Weights = [5.50000000e+01 3.17033811e+00 6.66568663e+00 2.19612788e-02\n",
      " 2.21931519e-01 1.23983162e+01], Loss = 0.2989\n",
      "Iteration 9535: Weights = [5.50000000e+01 3.17024710e+00 6.66549528e+00 2.19606484e-02\n",
      " 2.21925148e-01 1.23985183e+01], Loss = 0.2989\n",
      "Iteration 9536: Weights = [5.50000000e+01 3.17015609e+00 6.66530394e+00 2.19600180e-02\n",
      " 2.21918777e-01 1.23987205e+01], Loss = 0.2989\n",
      "Iteration 9537: Weights = [5.50000000e+01 3.17006509e+00 6.66511261e+00 2.19593876e-02\n",
      " 2.21912407e-01 1.23989226e+01], Loss = 0.2989\n",
      "Iteration 9538: Weights = [5.50000000e+01 3.16997409e+00 6.66492128e+00 2.19587572e-02\n",
      " 2.21906037e-01 1.23991248e+01], Loss = 0.2989\n",
      "Iteration 9539: Weights = [5.50000000e+01 3.16988309e+00 6.66472995e+00 2.19581269e-02\n",
      " 2.21899666e-01 1.23993269e+01], Loss = 0.2988\n",
      "Iteration 9540: Weights = [5.50000000e+01 3.16979209e+00 6.66453863e+00 2.19574965e-02\n",
      " 2.21893297e-01 1.23995290e+01], Loss = 0.2988\n",
      "Iteration 9541: Weights = [5.50000000e+01 3.16970110e+00 6.66434732e+00 2.19568662e-02\n",
      " 2.21886927e-01 1.23997311e+01], Loss = 0.2988\n",
      "Iteration 9542: Weights = [5.50000000e+01 3.16961011e+00 6.66415601e+00 2.19562359e-02\n",
      " 2.21880557e-01 1.23999333e+01], Loss = 0.2988\n",
      "Iteration 9543: Weights = [5.50000000e+01 3.16951912e+00 6.66396470e+00 2.19556056e-02\n",
      " 2.21874188e-01 1.24001354e+01], Loss = 0.2988\n",
      "Iteration 9544: Weights = [5.50000000e+01 3.16942814e+00 6.66377341e+00 2.19549754e-02\n",
      " 2.21867819e-01 1.24003375e+01], Loss = 0.2987\n",
      "Iteration 9545: Weights = [5.50000000e+01 3.16933716e+00 6.66358211e+00 2.19543451e-02\n",
      " 2.21861450e-01 1.24005396e+01], Loss = 0.2987\n",
      "Iteration 9546: Weights = [5.50000000e+01 3.16924618e+00 6.66339083e+00 2.19537149e-02\n",
      " 2.21855081e-01 1.24007417e+01], Loss = 0.2987\n",
      "Iteration 9547: Weights = [5.50000000e+01 3.16915520e+00 6.66319955e+00 2.19530847e-02\n",
      " 2.21848712e-01 1.24009438e+01], Loss = 0.2987\n",
      "Iteration 9548: Weights = [5.50000000e+01 3.16906422e+00 6.66300827e+00 2.19524545e-02\n",
      " 2.21842344e-01 1.24011458e+01], Loss = 0.2987\n",
      "Iteration 9549: Weights = [5.50000000e+01 3.16897325e+00 6.66281700e+00 2.19518243e-02\n",
      " 2.21835976e-01 1.24013479e+01], Loss = 0.2987\n",
      "Iteration 9550: Weights = [5.50000000e+01 3.16888228e+00 6.66262573e+00 2.19511941e-02\n",
      " 2.21829607e-01 1.24015500e+01], Loss = 0.2986\n",
      "Iteration 9551: Weights = [5.50000000e+01 3.16879131e+00 6.66243447e+00 2.19505640e-02\n",
      " 2.21823240e-01 1.24017520e+01], Loss = 0.2986\n",
      "Iteration 9552: Weights = [5.50000000e+01 3.16870035e+00 6.66224322e+00 2.19499339e-02\n",
      " 2.21816872e-01 1.24019541e+01], Loss = 0.2986\n",
      "Iteration 9553: Weights = [5.50000000e+01 3.16860939e+00 6.66205197e+00 2.19493038e-02\n",
      " 2.21810504e-01 1.24021561e+01], Loss = 0.2986\n",
      "Iteration 9554: Weights = [5.50000000e+01 3.16851843e+00 6.66186073e+00 2.19486737e-02\n",
      " 2.21804137e-01 1.24023582e+01], Loss = 0.2986\n",
      "Iteration 9555: Weights = [5.50000000e+01 3.16842747e+00 6.66166949e+00 2.19480436e-02\n",
      " 2.21797770e-01 1.24025602e+01], Loss = 0.2986\n",
      "Iteration 9556: Weights = [5.50000000e+01 3.16833652e+00 6.66147826e+00 2.19474136e-02\n",
      " 2.21791403e-01 1.24027623e+01], Loss = 0.2985\n",
      "Iteration 9557: Weights = [5.50000000e+01 3.16824557e+00 6.66128703e+00 2.19467836e-02\n",
      " 2.21785036e-01 1.24029643e+01], Loss = 0.2985\n",
      "Iteration 9558: Weights = [5.50000000e+01 3.16815462e+00 6.66109581e+00 2.19461536e-02\n",
      " 2.21778669e-01 1.24031663e+01], Loss = 0.2985\n",
      "Iteration 9559: Weights = [5.50000000e+01 3.16806367e+00 6.66090460e+00 2.19455236e-02\n",
      " 2.21772303e-01 1.24033683e+01], Loss = 0.2985\n",
      "Iteration 9560: Weights = [5.50000000e+01 3.16797273e+00 6.66071339e+00 2.19448936e-02\n",
      " 2.21765937e-01 1.24035703e+01], Loss = 0.2985\n",
      "Iteration 9561: Weights = [5.50000000e+01 3.16788179e+00 6.66052218e+00 2.19442636e-02\n",
      " 2.21759570e-01 1.24037723e+01], Loss = 0.2985\n",
      "Iteration 9562: Weights = [5.50000000e+01 3.16779085e+00 6.66033098e+00 2.19436337e-02\n",
      " 2.21753205e-01 1.24039743e+01], Loss = 0.2984\n",
      "Iteration 9563: Weights = [5.50000000e+01 3.16769992e+00 6.66013979e+00 2.19430038e-02\n",
      " 2.21746839e-01 1.24041763e+01], Loss = 0.2984\n",
      "Iteration 9564: Weights = [5.50000000e+01 3.16760898e+00 6.65994860e+00 2.19423739e-02\n",
      " 2.21740473e-01 1.24043783e+01], Loss = 0.2984\n",
      "Iteration 9565: Weights = [5.50000000e+01 3.16751805e+00 6.65975742e+00 2.19417440e-02\n",
      " 2.21734108e-01 1.24045803e+01], Loss = 0.2984\n",
      "Iteration 9566: Weights = [5.50000000e+01 3.16742712e+00 6.65956624e+00 2.19411141e-02\n",
      " 2.21727743e-01 1.24047823e+01], Loss = 0.2984\n",
      "Iteration 9567: Weights = [5.50000000e+01 3.16733620e+00 6.65937507e+00 2.19404843e-02\n",
      " 2.21721378e-01 1.24049842e+01], Loss = 0.2984\n",
      "Iteration 9568: Weights = [5.50000000e+01 3.16724528e+00 6.65918391e+00 2.19398544e-02\n",
      " 2.21715013e-01 1.24051862e+01], Loss = 0.2983\n",
      "Iteration 9569: Weights = [5.50000000e+01 3.16715436e+00 6.65899274e+00 2.19392246e-02\n",
      " 2.21708648e-01 1.24053882e+01], Loss = 0.2983\n",
      "Iteration 9570: Weights = [5.50000000e+01 3.16706344e+00 6.65880159e+00 2.19385948e-02\n",
      " 2.21702284e-01 1.24055901e+01], Loss = 0.2983\n",
      "Iteration 9571: Weights = [5.50000000e+01 3.16697252e+00 6.65861044e+00 2.19379651e-02\n",
      " 2.21695920e-01 1.24057921e+01], Loss = 0.2983\n",
      "Iteration 9572: Weights = [5.50000000e+01 3.16688161e+00 6.65841930e+00 2.19373353e-02\n",
      " 2.21689556e-01 1.24059940e+01], Loss = 0.2983\n",
      "Iteration 9573: Weights = [5.50000000e+01 3.16679070e+00 6.65822816e+00 2.19367056e-02\n",
      " 2.21683192e-01 1.24061959e+01], Loss = 0.2983\n",
      "Iteration 9574: Weights = [5.50000000e+01 3.16669980e+00 6.65803702e+00 2.19360758e-02\n",
      " 2.21676828e-01 1.24063979e+01], Loss = 0.2982\n",
      "Iteration 9575: Weights = [5.50000000e+01 3.16660889e+00 6.65784590e+00 2.19354461e-02\n",
      " 2.21670465e-01 1.24065998e+01], Loss = 0.2982\n",
      "Iteration 9576: Weights = [5.50000000e+01 3.16651799e+00 6.65765477e+00 2.19348164e-02\n",
      " 2.21664101e-01 1.24068017e+01], Loss = 0.2982\n",
      "Iteration 9577: Weights = [5.50000000e+01 3.16642709e+00 6.65746366e+00 2.19341868e-02\n",
      " 2.21657738e-01 1.24070036e+01], Loss = 0.2982\n",
      "Iteration 9578: Weights = [5.50000000e+01 3.16633620e+00 6.65727255e+00 2.19335571e-02\n",
      " 2.21651375e-01 1.24072055e+01], Loss = 0.2982\n",
      "Iteration 9579: Weights = [5.50000000e+01 3.16624530e+00 6.65708144e+00 2.19329275e-02\n",
      " 2.21645012e-01 1.24074074e+01], Loss = 0.2981\n",
      "Iteration 9580: Weights = [5.50000000e+01 3.16615441e+00 6.65689034e+00 2.19322979e-02\n",
      " 2.21638650e-01 1.24076093e+01], Loss = 0.2981\n",
      "Iteration 9581: Weights = [5.50000000e+01 3.16606352e+00 6.65669925e+00 2.19316683e-02\n",
      " 2.21632287e-01 1.24078112e+01], Loss = 0.2981\n",
      "Iteration 9582: Weights = [5.50000000e+01 3.16597264e+00 6.65650816e+00 2.19310387e-02\n",
      " 2.21625925e-01 1.24080131e+01], Loss = 0.2981\n",
      "Iteration 9583: Weights = [5.50000000e+01 3.16588175e+00 6.65631707e+00 2.19304092e-02\n",
      " 2.21619563e-01 1.24082150e+01], Loss = 0.2981\n",
      "Iteration 9584: Weights = [5.50000000e+01 3.16579087e+00 6.65612599e+00 2.19297796e-02\n",
      " 2.21613201e-01 1.24084168e+01], Loss = 0.2981\n",
      "Iteration 9585: Weights = [5.50000000e+01 3.16569999e+00 6.65593492e+00 2.19291501e-02\n",
      " 2.21606839e-01 1.24086187e+01], Loss = 0.2980\n",
      "Iteration 9586: Weights = [5.50000000e+01 3.16560912e+00 6.65574385e+00 2.19285206e-02\n",
      " 2.21600478e-01 1.24088206e+01], Loss = 0.2980\n",
      "Iteration 9587: Weights = [5.50000000e+01 3.16551824e+00 6.65555279e+00 2.19278911e-02\n",
      " 2.21594116e-01 1.24090224e+01], Loss = 0.2980\n",
      "Iteration 9588: Weights = [5.50000000e+01 3.16542737e+00 6.65536174e+00 2.19272616e-02\n",
      " 2.21587755e-01 1.24092243e+01], Loss = 0.2980\n",
      "Iteration 9589: Weights = [5.50000000e+01 3.16533651e+00 6.65517068e+00 2.19266322e-02\n",
      " 2.21581394e-01 1.24094261e+01], Loss = 0.2980\n",
      "Iteration 9590: Weights = [5.50000000e+01 3.16524564e+00 6.65497964e+00 2.19260027e-02\n",
      " 2.21575034e-01 1.24096279e+01], Loss = 0.2980\n",
      "Iteration 9591: Weights = [5.50000000e+01 3.16515478e+00 6.65478860e+00 2.19253733e-02\n",
      " 2.21568673e-01 1.24098298e+01], Loss = 0.2979\n",
      "Iteration 9592: Weights = [5.50000000e+01 3.16506392e+00 6.65459757e+00 2.19247439e-02\n",
      " 2.21562313e-01 1.24100316e+01], Loss = 0.2979\n",
      "Iteration 9593: Weights = [5.50000000e+01 3.16497306e+00 6.65440654e+00 2.19241146e-02\n",
      " 2.21555952e-01 1.24102334e+01], Loss = 0.2979\n",
      "Iteration 9594: Weights = [5.50000000e+01 3.16488221e+00 6.65421551e+00 2.19234852e-02\n",
      " 2.21549592e-01 1.24104352e+01], Loss = 0.2979\n",
      "Iteration 9595: Weights = [5.50000000e+01 3.16479135e+00 6.65402449e+00 2.19228559e-02\n",
      " 2.21543232e-01 1.24106370e+01], Loss = 0.2979\n",
      "Iteration 9596: Weights = [5.50000000e+01 3.16470051e+00 6.65383348e+00 2.19222265e-02\n",
      " 2.21536873e-01 1.24108388e+01], Loss = 0.2979\n",
      "Iteration 9597: Weights = [5.50000000e+01 3.16460966e+00 6.65364248e+00 2.19215972e-02\n",
      " 2.21530513e-01 1.24110406e+01], Loss = 0.2978\n",
      "Iteration 9598: Weights = [5.50000000e+01 3.16451881e+00 6.65345147e+00 2.19209679e-02\n",
      " 2.21524154e-01 1.24112424e+01], Loss = 0.2978\n",
      "Iteration 9599: Weights = [5.50000000e+01 3.16442797e+00 6.65326048e+00 2.19203387e-02\n",
      " 2.21517795e-01 1.24114442e+01], Loss = 0.2978\n",
      "Iteration 9600: Weights = [5.50000000e+01 3.16433713e+00 6.65306949e+00 2.19197094e-02\n",
      " 2.21511436e-01 1.24116460e+01], Loss = 0.2978\n",
      "Iteration 9601: Weights = [5.50000000e+01 3.16424630e+00 6.65287850e+00 2.19190802e-02\n",
      " 2.21505077e-01 1.24118478e+01], Loss = 0.2978\n",
      "Iteration 9602: Weights = [5.50000000e+01 3.16415546e+00 6.65268752e+00 2.19184510e-02\n",
      " 2.21498718e-01 1.24120495e+01], Loss = 0.2978\n",
      "Iteration 9603: Weights = [5.50000000e+01 3.16406463e+00 6.65249655e+00 2.19178218e-02\n",
      " 2.21492360e-01 1.24122513e+01], Loss = 0.2977\n",
      "Iteration 9604: Weights = [5.50000000e+01 3.16397380e+00 6.65230558e+00 2.19171926e-02\n",
      " 2.21486002e-01 1.24124531e+01], Loss = 0.2977\n",
      "Iteration 9605: Weights = [5.50000000e+01 3.16388298e+00 6.65211462e+00 2.19165634e-02\n",
      " 2.21479644e-01 1.24126548e+01], Loss = 0.2977\n",
      "Iteration 9606: Weights = [5.50000000e+01 3.16379215e+00 6.65192366e+00 2.19159343e-02\n",
      " 2.21473286e-01 1.24128565e+01], Loss = 0.2977\n",
      "Iteration 9607: Weights = [5.50000000e+01 3.16370133e+00 6.65173271e+00 2.19153052e-02\n",
      " 2.21466928e-01 1.24130583e+01], Loss = 0.2977\n",
      "Iteration 9608: Weights = [5.50000000e+01 3.16361052e+00 6.65154176e+00 2.19146760e-02\n",
      " 2.21460571e-01 1.24132600e+01], Loss = 0.2977\n",
      "Iteration 9609: Weights = [5.50000000e+01 3.16351970e+00 6.65135082e+00 2.19140470e-02\n",
      " 2.21454213e-01 1.24134617e+01], Loss = 0.2976\n",
      "Iteration 9610: Weights = [5.50000000e+01 3.16342889e+00 6.65115988e+00 2.19134179e-02\n",
      " 2.21447856e-01 1.24136635e+01], Loss = 0.2976\n",
      "Iteration 9611: Weights = [5.50000000e+01 3.16333808e+00 6.65096895e+00 2.19127888e-02\n",
      " 2.21441499e-01 1.24138652e+01], Loss = 0.2976\n",
      "Iteration 9612: Weights = [5.50000000e+01 3.16324727e+00 6.65077803e+00 2.19121598e-02\n",
      " 2.21435143e-01 1.24140669e+01], Loss = 0.2976\n",
      "Iteration 9613: Weights = [5.50000000e+01 3.16315646e+00 6.65058711e+00 2.19115308e-02\n",
      " 2.21428786e-01 1.24142686e+01], Loss = 0.2976\n",
      "Iteration 9614: Weights = [5.50000000e+01 3.16306566e+00 6.65039620e+00 2.19109018e-02\n",
      " 2.21422430e-01 1.24144703e+01], Loss = 0.2976\n",
      "Iteration 9615: Weights = [5.50000000e+01 3.16297486e+00 6.65020529e+00 2.19102728e-02\n",
      " 2.21416073e-01 1.24146720e+01], Loss = 0.2975\n",
      "Iteration 9616: Weights = [5.50000000e+01 3.16288406e+00 6.65001438e+00 2.19096438e-02\n",
      " 2.21409717e-01 1.24148737e+01], Loss = 0.2975\n",
      "Iteration 9617: Weights = [5.50000000e+01 3.16279327e+00 6.64982349e+00 2.19090149e-02\n",
      " 2.21403361e-01 1.24150753e+01], Loss = 0.2975\n",
      "Iteration 9618: Weights = [5.50000000e+01 3.16270248e+00 6.64963259e+00 2.19083860e-02\n",
      " 2.21397006e-01 1.24152770e+01], Loss = 0.2975\n",
      "Iteration 9619: Weights = [5.50000000e+01 3.16261169e+00 6.64944171e+00 2.19077571e-02\n",
      " 2.21390650e-01 1.24154787e+01], Loss = 0.2975\n",
      "Iteration 9620: Weights = [5.50000000e+01 3.16252090e+00 6.64925083e+00 2.19071282e-02\n",
      " 2.21384295e-01 1.24156803e+01], Loss = 0.2974\n",
      "Iteration 9621: Weights = [5.50000000e+01 3.16243012e+00 6.64905995e+00 2.19064993e-02\n",
      " 2.21377940e-01 1.24158820e+01], Loss = 0.2974\n",
      "Iteration 9622: Weights = [5.50000000e+01 3.16233933e+00 6.64886908e+00 2.19058704e-02\n",
      " 2.21371585e-01 1.24160837e+01], Loss = 0.2974\n",
      "Iteration 9623: Weights = [5.50000000e+01 3.16224855e+00 6.64867822e+00 2.19052416e-02\n",
      " 2.21365230e-01 1.24162853e+01], Loss = 0.2974\n",
      "Iteration 9624: Weights = [5.50000000e+01 3.16215778e+00 6.64848736e+00 2.19046128e-02\n",
      " 2.21358876e-01 1.24164869e+01], Loss = 0.2974\n",
      "Iteration 9625: Weights = [5.50000000e+01 3.16206700e+00 6.64829650e+00 2.19039840e-02\n",
      " 2.21352521e-01 1.24166886e+01], Loss = 0.2974\n",
      "Iteration 9626: Weights = [5.50000000e+01 3.16197623e+00 6.64810566e+00 2.19033552e-02\n",
      " 2.21346167e-01 1.24168902e+01], Loss = 0.2973\n",
      "Iteration 9627: Weights = [5.50000000e+01 3.16188546e+00 6.64791481e+00 2.19027264e-02\n",
      " 2.21339813e-01 1.24170918e+01], Loss = 0.2973\n",
      "Iteration 9628: Weights = [5.50000000e+01 3.16179470e+00 6.64772398e+00 2.19020977e-02\n",
      " 2.21333459e-01 1.24172934e+01], Loss = 0.2973\n",
      "Iteration 9629: Weights = [5.50000000e+01 3.16170394e+00 6.64753315e+00 2.19014690e-02\n",
      " 2.21327105e-01 1.24174951e+01], Loss = 0.2973\n",
      "Iteration 9630: Weights = [5.50000000e+01 3.16161317e+00 6.64734232e+00 2.19008402e-02\n",
      " 2.21320752e-01 1.24176967e+01], Loss = 0.2973\n",
      "Iteration 9631: Weights = [5.50000000e+01 3.16152242e+00 6.64715150e+00 2.19002116e-02\n",
      " 2.21314399e-01 1.24178983e+01], Loss = 0.2973\n",
      "Iteration 9632: Weights = [5.50000000e+01 3.16143166e+00 6.64696068e+00 2.18995829e-02\n",
      " 2.21308045e-01 1.24180998e+01], Loss = 0.2972\n",
      "Iteration 9633: Weights = [5.50000000e+01 3.16134091e+00 6.64676987e+00 2.18989542e-02\n",
      " 2.21301693e-01 1.24183014e+01], Loss = 0.2972\n",
      "Iteration 9634: Weights = [5.50000000e+01 3.16125016e+00 6.64657907e+00 2.18983256e-02\n",
      " 2.21295340e-01 1.24185030e+01], Loss = 0.2972\n",
      "Iteration 9635: Weights = [5.50000000e+01 3.16115941e+00 6.64638827e+00 2.18976970e-02\n",
      " 2.21288987e-01 1.24187046e+01], Loss = 0.2972\n",
      "Iteration 9636: Weights = [5.50000000e+01 3.16106866e+00 6.64619748e+00 2.18970684e-02\n",
      " 2.21282635e-01 1.24189062e+01], Loss = 0.2972\n",
      "Iteration 9637: Weights = [5.50000000e+01 3.16097792e+00 6.64600669e+00 2.18964398e-02\n",
      " 2.21276283e-01 1.24191077e+01], Loss = 0.2972\n",
      "Iteration 9638: Weights = [5.50000000e+01 3.16088718e+00 6.64581591e+00 2.18958112e-02\n",
      " 2.21269931e-01 1.24193093e+01], Loss = 0.2971\n",
      "Iteration 9639: Weights = [5.50000000e+01 3.16079644e+00 6.64562513e+00 2.18951827e-02\n",
      " 2.21263579e-01 1.24195108e+01], Loss = 0.2971\n",
      "Iteration 9640: Weights = [5.50000000e+01 3.16070571e+00 6.64543436e+00 2.18945541e-02\n",
      " 2.21257227e-01 1.24197124e+01], Loss = 0.2971\n",
      "Iteration 9641: Weights = [5.50000000e+01 3.16061498e+00 6.64524359e+00 2.18939256e-02\n",
      " 2.21250876e-01 1.24199139e+01], Loss = 0.2971\n",
      "Iteration 9642: Weights = [5.50000000e+01 3.16052425e+00 6.64505283e+00 2.18932971e-02\n",
      " 2.21244524e-01 1.24201155e+01], Loss = 0.2971\n",
      "Iteration 9643: Weights = [5.50000000e+01 3.16043352e+00 6.64486208e+00 2.18926687e-02\n",
      " 2.21238173e-01 1.24203170e+01], Loss = 0.2971\n",
      "Iteration 9644: Weights = [5.50000000e+01 3.16034280e+00 6.64467133e+00 2.18920402e-02\n",
      " 2.21231822e-01 1.24205185e+01], Loss = 0.2970\n",
      "Iteration 9645: Weights = [5.50000000e+01 3.16025207e+00 6.64448058e+00 2.18914118e-02\n",
      " 2.21225472e-01 1.24207200e+01], Loss = 0.2970\n",
      "Iteration 9646: Weights = [5.50000000e+01 3.16016135e+00 6.64428985e+00 2.18907833e-02\n",
      " 2.21219121e-01 1.24209215e+01], Loss = 0.2970\n",
      "Iteration 9647: Weights = [5.50000000e+01 3.16007064e+00 6.64409911e+00 2.18901549e-02\n",
      " 2.21212771e-01 1.24211231e+01], Loss = 0.2970\n",
      "Iteration 9648: Weights = [5.50000000e+01 3.15997992e+00 6.64390839e+00 2.18895265e-02\n",
      " 2.21206420e-01 1.24213246e+01], Loss = 0.2970\n",
      "Iteration 9649: Weights = [5.50000000e+01 3.15988921e+00 6.64371766e+00 2.18888982e-02\n",
      " 2.21200070e-01 1.24215260e+01], Loss = 0.2970\n",
      "Iteration 9650: Weights = [5.50000000e+01 3.15979850e+00 6.64352695e+00 2.18882698e-02\n",
      " 2.21193721e-01 1.24217275e+01], Loss = 0.2969\n",
      "Iteration 9651: Weights = [5.50000000e+01 3.15970780e+00 6.64333624e+00 2.18876415e-02\n",
      " 2.21187371e-01 1.24219290e+01], Loss = 0.2969\n",
      "Iteration 9652: Weights = [5.50000000e+01 3.15961709e+00 6.64314553e+00 2.18870132e-02\n",
      " 2.21181021e-01 1.24221305e+01], Loss = 0.2969\n",
      "Iteration 9653: Weights = [5.50000000e+01 3.15952639e+00 6.64295483e+00 2.18863849e-02\n",
      " 2.21174672e-01 1.24223320e+01], Loss = 0.2969\n",
      "Iteration 9654: Weights = [5.50000000e+01 3.15943570e+00 6.64276414e+00 2.18857566e-02\n",
      " 2.21168323e-01 1.24225334e+01], Loss = 0.2969\n",
      "Iteration 9655: Weights = [5.50000000e+01 3.15934500e+00 6.64257345e+00 2.18851284e-02\n",
      " 2.21161974e-01 1.24227349e+01], Loss = 0.2969\n",
      "Iteration 9656: Weights = [5.50000000e+01 3.15925431e+00 6.64238276e+00 2.18845001e-02\n",
      " 2.21155625e-01 1.24229363e+01], Loss = 0.2968\n",
      "Iteration 9657: Weights = [5.50000000e+01 3.15916362e+00 6.64219208e+00 2.18838719e-02\n",
      " 2.21149277e-01 1.24231378e+01], Loss = 0.2968\n",
      "Iteration 9658: Weights = [5.50000000e+01 3.15907293e+00 6.64200141e+00 2.18832437e-02\n",
      " 2.21142928e-01 1.24233392e+01], Loss = 0.2968\n",
      "Iteration 9659: Weights = [5.50000000e+01 3.15898224e+00 6.64181074e+00 2.18826155e-02\n",
      " 2.21136580e-01 1.24235407e+01], Loss = 0.2968\n",
      "Iteration 9660: Weights = [5.50000000e+01 3.15889156e+00 6.64162008e+00 2.18819873e-02\n",
      " 2.21130232e-01 1.24237421e+01], Loss = 0.2968\n",
      "Iteration 9661: Weights = [5.50000000e+01 3.15880088e+00 6.64142943e+00 2.18813592e-02\n",
      " 2.21123884e-01 1.24239435e+01], Loss = 0.2967\n",
      "Iteration 9662: Weights = [5.50000000e+01 3.15871020e+00 6.64123877e+00 2.18807310e-02\n",
      " 2.21117537e-01 1.24241450e+01], Loss = 0.2967\n",
      "Iteration 9663: Weights = [5.50000000e+01 3.15861953e+00 6.64104813e+00 2.18801029e-02\n",
      " 2.21111189e-01 1.24243464e+01], Loss = 0.2967\n",
      "Iteration 9664: Weights = [5.50000000e+01 3.15852886e+00 6.64085749e+00 2.18794748e-02\n",
      " 2.21104842e-01 1.24245478e+01], Loss = 0.2967\n",
      "Iteration 9665: Weights = [5.50000000e+01 3.15843819e+00 6.64066685e+00 2.18788468e-02\n",
      " 2.21098495e-01 1.24247492e+01], Loss = 0.2967\n",
      "Iteration 9666: Weights = [5.50000000e+01 3.15834752e+00 6.64047623e+00 2.18782187e-02\n",
      " 2.21092148e-01 1.24249506e+01], Loss = 0.2967\n",
      "Iteration 9667: Weights = [5.50000000e+01 3.15825685e+00 6.64028560e+00 2.18775906e-02\n",
      " 2.21085801e-01 1.24251520e+01], Loss = 0.2966\n",
      "Iteration 9668: Weights = [5.50000000e+01 3.15816619e+00 6.64009498e+00 2.18769626e-02\n",
      " 2.21079455e-01 1.24253534e+01], Loss = 0.2966\n",
      "Iteration 9669: Weights = [5.50000000e+01 3.15807553e+00 6.63990437e+00 2.18763346e-02\n",
      " 2.21073108e-01 1.24255547e+01], Loss = 0.2966\n",
      "Iteration 9670: Weights = [5.50000000e+01 3.15798488e+00 6.63971376e+00 2.18757066e-02\n",
      " 2.21066762e-01 1.24257561e+01], Loss = 0.2966\n",
      "Iteration 9671: Weights = [5.50000000e+01 3.15789422e+00 6.63952316e+00 2.18750787e-02\n",
      " 2.21060416e-01 1.24259575e+01], Loss = 0.2966\n",
      "Iteration 9672: Weights = [5.50000000e+01 3.15780357e+00 6.63933257e+00 2.18744507e-02\n",
      " 2.21054070e-01 1.24261588e+01], Loss = 0.2966\n",
      "Iteration 9673: Weights = [5.50000000e+01 3.15771292e+00 6.63914198e+00 2.18738228e-02\n",
      " 2.21047725e-01 1.24263602e+01], Loss = 0.2965\n",
      "Iteration 9674: Weights = [5.50000000e+01 3.15762228e+00 6.63895139e+00 2.18731949e-02\n",
      " 2.21041379e-01 1.24265615e+01], Loss = 0.2965\n",
      "Iteration 9675: Weights = [5.50000000e+01 3.15753163e+00 6.63876081e+00 2.18725670e-02\n",
      " 2.21035034e-01 1.24267629e+01], Loss = 0.2965\n",
      "Iteration 9676: Weights = [5.50000000e+01 3.15744099e+00 6.63857024e+00 2.18719391e-02\n",
      " 2.21028689e-01 1.24269642e+01], Loss = 0.2965\n",
      "Iteration 9677: Weights = [5.50000000e+01 3.15735035e+00 6.63837967e+00 2.18713112e-02\n",
      " 2.21022344e-01 1.24271656e+01], Loss = 0.2965\n",
      "Iteration 9678: Weights = [5.50000000e+01 3.15725972e+00 6.63818910e+00 2.18706834e-02\n",
      " 2.21015999e-01 1.24273669e+01], Loss = 0.2965\n",
      "Iteration 9679: Weights = [5.50000000e+01 3.15716908e+00 6.63799855e+00 2.18700555e-02\n",
      " 2.21009654e-01 1.24275682e+01], Loss = 0.2964\n",
      "Iteration 9680: Weights = [5.50000000e+01 3.15707845e+00 6.63780799e+00 2.18694277e-02\n",
      " 2.21003310e-01 1.24277695e+01], Loss = 0.2964\n",
      "Iteration 9681: Weights = [5.50000000e+01 3.15698782e+00 6.63761745e+00 2.18687999e-02\n",
      " 2.20996966e-01 1.24279708e+01], Loss = 0.2964\n",
      "Iteration 9682: Weights = [5.50000000e+01 3.15689720e+00 6.63742690e+00 2.18681722e-02\n",
      " 2.20990622e-01 1.24281721e+01], Loss = 0.2964\n",
      "Iteration 9683: Weights = [5.50000000e+01 3.15680658e+00 6.63723637e+00 2.18675444e-02\n",
      " 2.20984278e-01 1.24283734e+01], Loss = 0.2964\n",
      "Iteration 9684: Weights = [5.50000000e+01 3.15671596e+00 6.63704584e+00 2.18669167e-02\n",
      " 2.20977934e-01 1.24285747e+01], Loss = 0.2964\n",
      "Iteration 9685: Weights = [5.50000000e+01 3.15662534e+00 6.63685531e+00 2.18662890e-02\n",
      " 2.20971591e-01 1.24287760e+01], Loss = 0.2963\n",
      "Iteration 9686: Weights = [5.50000000e+01 3.15653472e+00 6.63666479e+00 2.18656613e-02\n",
      " 2.20965248e-01 1.24289773e+01], Loss = 0.2963\n",
      "Iteration 9687: Weights = [5.50000000e+01 3.15644411e+00 6.63647428e+00 2.18650336e-02\n",
      " 2.20958905e-01 1.24291786e+01], Loss = 0.2963\n",
      "Iteration 9688: Weights = [5.50000000e+01 3.15635350e+00 6.63628377e+00 2.18644059e-02\n",
      " 2.20952562e-01 1.24293798e+01], Loss = 0.2963\n",
      "Iteration 9689: Weights = [5.50000000e+01 3.15626289e+00 6.63609327e+00 2.18637783e-02\n",
      " 2.20946219e-01 1.24295811e+01], Loss = 0.2963\n",
      "Iteration 9690: Weights = [5.50000000e+01 3.15617229e+00 6.63590277e+00 2.18631506e-02\n",
      " 2.20939876e-01 1.24297824e+01], Loss = 0.2963\n",
      "Iteration 9691: Weights = [5.50000000e+01 3.15608169e+00 6.63571228e+00 2.18625230e-02\n",
      " 2.20933534e-01 1.24299836e+01], Loss = 0.2962\n",
      "Iteration 9692: Weights = [5.50000000e+01 3.15599109e+00 6.63552179e+00 2.18618954e-02\n",
      " 2.20927192e-01 1.24301849e+01], Loss = 0.2962\n",
      "Iteration 9693: Weights = [5.50000000e+01 3.15590049e+00 6.63533131e+00 2.18612679e-02\n",
      " 2.20920850e-01 1.24303861e+01], Loss = 0.2962\n",
      "Iteration 9694: Weights = [5.50000000e+01 3.15580990e+00 6.63514083e+00 2.18606403e-02\n",
      " 2.20914508e-01 1.24305873e+01], Loss = 0.2962\n",
      "Iteration 9695: Weights = [5.50000000e+01 3.15571930e+00 6.63495036e+00 2.18600128e-02\n",
      " 2.20908166e-01 1.24307886e+01], Loss = 0.2962\n",
      "Iteration 9696: Weights = [5.50000000e+01 3.15562872e+00 6.63475990e+00 2.18593852e-02\n",
      " 2.20901825e-01 1.24309898e+01], Loss = 0.2962\n",
      "Iteration 9697: Weights = [5.50000000e+01 3.15553813e+00 6.63456944e+00 2.18587577e-02\n",
      " 2.20895484e-01 1.24311910e+01], Loss = 0.2961\n",
      "Iteration 9698: Weights = [5.50000000e+01 3.15544754e+00 6.63437898e+00 2.18581303e-02\n",
      " 2.20889143e-01 1.24313922e+01], Loss = 0.2961\n",
      "Iteration 9699: Weights = [5.50000000e+01 3.15535696e+00 6.63418854e+00 2.18575028e-02\n",
      " 2.20882802e-01 1.24315934e+01], Loss = 0.2961\n",
      "Iteration 9700: Weights = [5.50000000e+01 3.15526638e+00 6.63399809e+00 2.18568753e-02\n",
      " 2.20876461e-01 1.24317946e+01], Loss = 0.2961\n",
      "Iteration 9701: Weights = [5.50000000e+01 3.15517581e+00 6.63380766e+00 2.18562479e-02\n",
      " 2.20870120e-01 1.24319958e+01], Loss = 0.2961\n",
      "Iteration 9702: Weights = [5.50000000e+01 3.15508524e+00 6.63361722e+00 2.18556205e-02\n",
      " 2.20863780e-01 1.24321970e+01], Loss = 0.2961\n",
      "Iteration 9703: Weights = [5.50000000e+01 3.15499466e+00 6.63342680e+00 2.18549931e-02\n",
      " 2.20857440e-01 1.24323982e+01], Loss = 0.2960\n",
      "Iteration 9704: Weights = [5.50000000e+01 3.15490410e+00 6.63323638e+00 2.18543657e-02\n",
      " 2.20851100e-01 1.24325994e+01], Loss = 0.2960\n",
      "Iteration 9705: Weights = [5.50000000e+01 3.15481353e+00 6.63304596e+00 2.18537384e-02\n",
      " 2.20844760e-01 1.24328005e+01], Loss = 0.2960\n",
      "Iteration 9706: Weights = [5.50000000e+01 3.15472297e+00 6.63285555e+00 2.18531110e-02\n",
      " 2.20838420e-01 1.24330017e+01], Loss = 0.2960\n",
      "Iteration 9707: Weights = [5.50000000e+01 3.15463241e+00 6.63266514e+00 2.18524837e-02\n",
      " 2.20832081e-01 1.24332029e+01], Loss = 0.2960\n",
      "Iteration 9708: Weights = [5.50000000e+01 3.15454185e+00 6.63247475e+00 2.18518564e-02\n",
      " 2.20825742e-01 1.24334040e+01], Loss = 0.2959\n",
      "Iteration 9709: Weights = [5.50000000e+01 3.15445129e+00 6.63228435e+00 2.18512291e-02\n",
      " 2.20819403e-01 1.24336052e+01], Loss = 0.2959\n",
      "Iteration 9710: Weights = [5.50000000e+01 3.15436074e+00 6.63209396e+00 2.18506019e-02\n",
      " 2.20813064e-01 1.24338063e+01], Loss = 0.2959\n",
      "Iteration 9711: Weights = [5.50000000e+01 3.15427019e+00 6.63190358e+00 2.18499746e-02\n",
      " 2.20806725e-01 1.24340074e+01], Loss = 0.2959\n",
      "Iteration 9712: Weights = [5.50000000e+01 3.15417964e+00 6.63171320e+00 2.18493474e-02\n",
      " 2.20800386e-01 1.24342086e+01], Loss = 0.2959\n",
      "Iteration 9713: Weights = [5.50000000e+01 3.15408910e+00 6.63152283e+00 2.18487202e-02\n",
      " 2.20794048e-01 1.24344097e+01], Loss = 0.2959\n",
      "Iteration 9714: Weights = [5.50000000e+01 3.15399856e+00 6.63133246e+00 2.18480930e-02\n",
      " 2.20787710e-01 1.24346108e+01], Loss = 0.2958\n",
      "Iteration 9715: Weights = [5.50000000e+01 3.15390802e+00 6.63114210e+00 2.18474658e-02\n",
      " 2.20781372e-01 1.24348119e+01], Loss = 0.2958\n",
      "Iteration 9716: Weights = [5.50000000e+01 3.15381748e+00 6.63095175e+00 2.18468386e-02\n",
      " 2.20775034e-01 1.24350130e+01], Loss = 0.2958\n",
      "Iteration 9717: Weights = [5.50000000e+01 3.15372695e+00 6.63076140e+00 2.18462115e-02\n",
      " 2.20768696e-01 1.24352141e+01], Loss = 0.2958\n",
      "Iteration 9718: Weights = [5.50000000e+01 3.15363641e+00 6.63057105e+00 2.18455844e-02\n",
      " 2.20762359e-01 1.24354152e+01], Loss = 0.2958\n",
      "Iteration 9719: Weights = [5.50000000e+01 3.15354588e+00 6.63038071e+00 2.18449572e-02\n",
      " 2.20756022e-01 1.24356163e+01], Loss = 0.2958\n",
      "Iteration 9720: Weights = [5.50000000e+01 3.15345536e+00 6.63019038e+00 2.18443302e-02\n",
      " 2.20749685e-01 1.24358174e+01], Loss = 0.2957\n",
      "Iteration 9721: Weights = [5.50000000e+01 3.15336483e+00 6.63000005e+00 2.18437031e-02\n",
      " 2.20743348e-01 1.24360185e+01], Loss = 0.2957\n",
      "Iteration 9722: Weights = [5.50000000e+01 3.15327431e+00 6.62980973e+00 2.18430760e-02\n",
      " 2.20737011e-01 1.24362196e+01], Loss = 0.2957\n",
      "Iteration 9723: Weights = [5.50000000e+01 3.15318379e+00 6.62961941e+00 2.18424490e-02\n",
      " 2.20730674e-01 1.24364206e+01], Loss = 0.2957\n",
      "Iteration 9724: Weights = [5.50000000e+01 3.15309328e+00 6.62942910e+00 2.18418220e-02\n",
      " 2.20724338e-01 1.24366217e+01], Loss = 0.2957\n",
      "Iteration 9725: Weights = [5.50000000e+01 3.15300276e+00 6.62923879e+00 2.18411950e-02\n",
      " 2.20718002e-01 1.24368227e+01], Loss = 0.2957\n",
      "Iteration 9726: Weights = [5.50000000e+01 3.15291225e+00 6.62904849e+00 2.18405680e-02\n",
      " 2.20711666e-01 1.24370238e+01], Loss = 0.2956\n",
      "Iteration 9727: Weights = [5.50000000e+01 3.15282174e+00 6.62885820e+00 2.18399410e-02\n",
      " 2.20705330e-01 1.24372248e+01], Loss = 0.2956\n",
      "Iteration 9728: Weights = [5.50000000e+01 3.15273124e+00 6.62866791e+00 2.18393141e-02\n",
      " 2.20698994e-01 1.24374259e+01], Loss = 0.2956\n",
      "Iteration 9729: Weights = [5.50000000e+01 3.15264073e+00 6.62847762e+00 2.18386872e-02\n",
      " 2.20692659e-01 1.24376269e+01], Loss = 0.2956\n",
      "Iteration 9730: Weights = [5.50000000e+01 3.15255023e+00 6.62828734e+00 2.18380603e-02\n",
      " 2.20686324e-01 1.24378279e+01], Loss = 0.2956\n",
      "Iteration 9731: Weights = [5.50000000e+01 3.15245974e+00 6.62809707e+00 2.18374334e-02\n",
      " 2.20679989e-01 1.24380290e+01], Loss = 0.2956\n",
      "Iteration 9732: Weights = [5.50000000e+01 3.15236924e+00 6.62790680e+00 2.18368065e-02\n",
      " 2.20673654e-01 1.24382300e+01], Loss = 0.2955\n",
      "Iteration 9733: Weights = [5.50000000e+01 3.15227875e+00 6.62771654e+00 2.18361797e-02\n",
      " 2.20667319e-01 1.24384310e+01], Loss = 0.2955\n",
      "Iteration 9734: Weights = [5.50000000e+01 3.15218826e+00 6.62752628e+00 2.18355528e-02\n",
      " 2.20660984e-01 1.24386320e+01], Loss = 0.2955\n",
      "Iteration 9735: Weights = [5.50000000e+01 3.15209777e+00 6.62733603e+00 2.18349260e-02\n",
      " 2.20654650e-01 1.24388330e+01], Loss = 0.2955\n",
      "Iteration 9736: Weights = [5.50000000e+01 3.15200728e+00 6.62714578e+00 2.18342992e-02\n",
      " 2.20648316e-01 1.24390340e+01], Loss = 0.2955\n",
      "Iteration 9737: Weights = [5.50000000e+01 3.15191680e+00 6.62695554e+00 2.18336724e-02\n",
      " 2.20641982e-01 1.24392350e+01], Loss = 0.2955\n",
      "Iteration 9738: Weights = [5.50000000e+01 3.15182632e+00 6.62676531e+00 2.18330457e-02\n",
      " 2.20635648e-01 1.24394359e+01], Loss = 0.2954\n",
      "Iteration 9739: Weights = [5.50000000e+01 3.15173584e+00 6.62657508e+00 2.18324189e-02\n",
      " 2.20629314e-01 1.24396369e+01], Loss = 0.2954\n",
      "Iteration 9740: Weights = [5.50000000e+01 3.15164537e+00 6.62638485e+00 2.18317922e-02\n",
      " 2.20622981e-01 1.24398379e+01], Loss = 0.2954\n",
      "Iteration 9741: Weights = [5.50000000e+01 3.15155490e+00 6.62619463e+00 2.18311655e-02\n",
      " 2.20616648e-01 1.24400388e+01], Loss = 0.2954\n",
      "Iteration 9742: Weights = [5.50000000e+01 3.15146443e+00 6.62600442e+00 2.18305388e-02\n",
      " 2.20610315e-01 1.24402398e+01], Loss = 0.2954\n",
      "Iteration 9743: Weights = [5.50000000e+01 3.15137396e+00 6.62581421e+00 2.18299121e-02\n",
      " 2.20603982e-01 1.24404408e+01], Loss = 0.2954\n",
      "Iteration 9744: Weights = [5.50000000e+01 3.15128350e+00 6.62562401e+00 2.18292854e-02\n",
      " 2.20597649e-01 1.24406417e+01], Loss = 0.2953\n",
      "Iteration 9745: Weights = [5.50000000e+01 3.15119304e+00 6.62543381e+00 2.18286588e-02\n",
      " 2.20591316e-01 1.24408426e+01], Loss = 0.2953\n",
      "Iteration 9746: Weights = [5.50000000e+01 3.15110258e+00 6.62524362e+00 2.18280322e-02\n",
      " 2.20584984e-01 1.24410436e+01], Loss = 0.2953\n",
      "Iteration 9747: Weights = [5.50000000e+01 3.15101212e+00 6.62505343e+00 2.18274056e-02\n",
      " 2.20578652e-01 1.24412445e+01], Loss = 0.2953\n",
      "Iteration 9748: Weights = [5.50000000e+01 3.15092167e+00 6.62486325e+00 2.18267790e-02\n",
      " 2.20572320e-01 1.24414454e+01], Loss = 0.2953\n",
      "Iteration 9749: Weights = [5.50000000e+01 3.15083121e+00 6.62467308e+00 2.18261524e-02\n",
      " 2.20565988e-01 1.24416463e+01], Loss = 0.2953\n",
      "Iteration 9750: Weights = [5.50000000e+01 3.15074077e+00 6.62448291e+00 2.18255259e-02\n",
      " 2.20559656e-01 1.24418473e+01], Loss = 0.2952\n",
      "Iteration 9751: Weights = [5.50000000e+01 3.15065032e+00 6.62429274e+00 2.18248994e-02\n",
      " 2.20553325e-01 1.24420482e+01], Loss = 0.2952\n",
      "Iteration 9752: Weights = [5.50000000e+01 3.15055988e+00 6.62410258e+00 2.18242728e-02\n",
      " 2.20546994e-01 1.24422491e+01], Loss = 0.2952\n",
      "Iteration 9753: Weights = [5.50000000e+01 3.15046944e+00 6.62391243e+00 2.18236463e-02\n",
      " 2.20540663e-01 1.24424500e+01], Loss = 0.2952\n",
      "Iteration 9754: Weights = [5.50000000e+01 3.15037900e+00 6.62372228e+00 2.18230199e-02\n",
      " 2.20534332e-01 1.24426508e+01], Loss = 0.2952\n",
      "Iteration 9755: Weights = [5.50000000e+01 3.15028856e+00 6.62353214e+00 2.18223934e-02\n",
      " 2.20528001e-01 1.24428517e+01], Loss = 0.2952\n",
      "Iteration 9756: Weights = [5.50000000e+01 3.15019813e+00 6.62334200e+00 2.18217670e-02\n",
      " 2.20521670e-01 1.24430526e+01], Loss = 0.2951\n",
      "Iteration 9757: Weights = [5.50000000e+01 3.15010770e+00 6.62315187e+00 2.18211406e-02\n",
      " 2.20515340e-01 1.24432535e+01], Loss = 0.2951\n",
      "Iteration 9758: Weights = [5.50000000e+01 3.15001727e+00 6.62296174e+00 2.18205141e-02\n",
      " 2.20509010e-01 1.24434543e+01], Loss = 0.2951\n",
      "Iteration 9759: Weights = [5.50000000e+01 3.14992684e+00 6.62277162e+00 2.18198878e-02\n",
      " 2.20502680e-01 1.24436552e+01], Loss = 0.2951\n",
      "Iteration 9760: Weights = [5.50000000e+01 3.14983642e+00 6.62258151e+00 2.18192614e-02\n",
      " 2.20496350e-01 1.24438561e+01], Loss = 0.2951\n",
      "Iteration 9761: Weights = [5.50000000e+01 3.14974600e+00 6.62239140e+00 2.18186350e-02\n",
      " 2.20490020e-01 1.24440569e+01], Loss = 0.2950\n",
      "Iteration 9762: Weights = [5.50000000e+01 3.14965558e+00 6.62220129e+00 2.18180087e-02\n",
      " 2.20483691e-01 1.24442577e+01], Loss = 0.2950\n",
      "Iteration 9763: Weights = [5.50000000e+01 3.14956517e+00 6.62201119e+00 2.18173824e-02\n",
      " 2.20477362e-01 1.24444586e+01], Loss = 0.2950\n",
      "Iteration 9764: Weights = [5.50000000e+01 3.14947476e+00 6.62182110e+00 2.18167561e-02\n",
      " 2.20471033e-01 1.24446594e+01], Loss = 0.2950\n",
      "Iteration 9765: Weights = [5.50000000e+01 3.14938435e+00 6.62163101e+00 2.18161298e-02\n",
      " 2.20464704e-01 1.24448602e+01], Loss = 0.2950\n",
      "Iteration 9766: Weights = [5.50000000e+01 3.14929394e+00 6.62144093e+00 2.18155036e-02\n",
      " 2.20458375e-01 1.24450611e+01], Loss = 0.2950\n",
      "Iteration 9767: Weights = [5.50000000e+01 3.14920353e+00 6.62125085e+00 2.18148773e-02\n",
      " 2.20452046e-01 1.24452619e+01], Loss = 0.2949\n",
      "Iteration 9768: Weights = [5.50000000e+01 3.14911313e+00 6.62106078e+00 2.18142511e-02\n",
      " 2.20445718e-01 1.24454627e+01], Loss = 0.2949\n",
      "Iteration 9769: Weights = [5.50000000e+01 3.14902273e+00 6.62087072e+00 2.18136249e-02\n",
      " 2.20439390e-01 1.24456635e+01], Loss = 0.2949\n",
      "Iteration 9770: Weights = [5.50000000e+01 3.14893234e+00 6.62068065e+00 2.18129987e-02\n",
      " 2.20433062e-01 1.24458643e+01], Loss = 0.2949\n",
      "Iteration 9771: Weights = [5.50000000e+01 3.14884194e+00 6.62049060e+00 2.18123725e-02\n",
      " 2.20426734e-01 1.24460651e+01], Loss = 0.2949\n",
      "Iteration 9772: Weights = [5.50000000e+01 3.14875155e+00 6.62030055e+00 2.18117464e-02\n",
      " 2.20420406e-01 1.24462659e+01], Loss = 0.2949\n",
      "Iteration 9773: Weights = [5.50000000e+01 3.14866116e+00 6.62011051e+00 2.18111202e-02\n",
      " 2.20414079e-01 1.24464666e+01], Loss = 0.2948\n",
      "Iteration 9774: Weights = [5.50000000e+01 3.14857078e+00 6.61992047e+00 2.18104941e-02\n",
      " 2.20407752e-01 1.24466674e+01], Loss = 0.2948\n",
      "Iteration 9775: Weights = [5.50000000e+01 3.14848039e+00 6.61973043e+00 2.18098680e-02\n",
      " 2.20401425e-01 1.24468682e+01], Loss = 0.2948\n",
      "Iteration 9776: Weights = [5.50000000e+01 3.14839001e+00 6.61954040e+00 2.18092419e-02\n",
      " 2.20395098e-01 1.24470689e+01], Loss = 0.2948\n",
      "Iteration 9777: Weights = [5.50000000e+01 3.14829963e+00 6.61935038e+00 2.18086159e-02\n",
      " 2.20388771e-01 1.24472697e+01], Loss = 0.2948\n",
      "Iteration 9778: Weights = [5.50000000e+01 3.14820926e+00 6.61916037e+00 2.18079898e-02\n",
      " 2.20382444e-01 1.24474704e+01], Loss = 0.2948\n",
      "Iteration 9779: Weights = [5.50000000e+01 3.14811888e+00 6.61897035e+00 2.18073638e-02\n",
      " 2.20376118e-01 1.24476712e+01], Loss = 0.2947\n",
      "Iteration 9780: Weights = [5.50000000e+01 3.14802851e+00 6.61878035e+00 2.18067378e-02\n",
      " 2.20369792e-01 1.24478719e+01], Loss = 0.2947\n",
      "Iteration 9781: Weights = [5.50000000e+01 3.14793814e+00 6.61859035e+00 2.18061118e-02\n",
      " 2.20363466e-01 1.24480727e+01], Loss = 0.2947\n",
      "Iteration 9782: Weights = [5.50000000e+01 3.14784778e+00 6.61840035e+00 2.18054858e-02\n",
      " 2.20357140e-01 1.24482734e+01], Loss = 0.2947\n",
      "Iteration 9783: Weights = [5.50000000e+01 3.14775741e+00 6.61821036e+00 2.18048599e-02\n",
      " 2.20350814e-01 1.24484741e+01], Loss = 0.2947\n",
      "Iteration 9784: Weights = [5.50000000e+01 3.14766705e+00 6.61802038e+00 2.18042339e-02\n",
      " 2.20344489e-01 1.24486748e+01], Loss = 0.2947\n",
      "Iteration 9785: Weights = [5.50000000e+01 3.14757670e+00 6.61783040e+00 2.18036080e-02\n",
      " 2.20338164e-01 1.24488755e+01], Loss = 0.2946\n",
      "Iteration 9786: Weights = [5.50000000e+01 3.14748634e+00 6.61764042e+00 2.18029821e-02\n",
      " 2.20331839e-01 1.24490762e+01], Loss = 0.2946\n",
      "Iteration 9787: Weights = [5.50000000e+01 3.14739599e+00 6.61745046e+00 2.18023562e-02\n",
      " 2.20325514e-01 1.24492769e+01], Loss = 0.2946\n",
      "Iteration 9788: Weights = [5.50000000e+01 3.14730564e+00 6.61726049e+00 2.18017304e-02\n",
      " 2.20319189e-01 1.24494776e+01], Loss = 0.2946\n",
      "Iteration 9789: Weights = [5.50000000e+01 3.14721529e+00 6.61707054e+00 2.18011045e-02\n",
      " 2.20312864e-01 1.24496783e+01], Loss = 0.2946\n",
      "Iteration 9790: Weights = [5.50000000e+01 3.14712494e+00 6.61688059e+00 2.18004787e-02\n",
      " 2.20306540e-01 1.24498790e+01], Loss = 0.2946\n",
      "Iteration 9791: Weights = [5.50000000e+01 3.14703460e+00 6.61669064e+00 2.17998529e-02\n",
      " 2.20300216e-01 1.24500797e+01], Loss = 0.2945\n",
      "Iteration 9792: Weights = [5.50000000e+01 3.14694426e+00 6.61650070e+00 2.17992271e-02\n",
      " 2.20293892e-01 1.24502803e+01], Loss = 0.2945\n",
      "Iteration 9793: Weights = [5.50000000e+01 3.14685393e+00 6.61631076e+00 2.17986013e-02\n",
      " 2.20287568e-01 1.24504810e+01], Loss = 0.2945\n",
      "Iteration 9794: Weights = [5.50000000e+01 3.14676359e+00 6.61612083e+00 2.17979756e-02\n",
      " 2.20281244e-01 1.24506817e+01], Loss = 0.2945\n",
      "Iteration 9795: Weights = [5.50000000e+01 3.14667326e+00 6.61593091e+00 2.17973498e-02\n",
      " 2.20274921e-01 1.24508823e+01], Loss = 0.2945\n",
      "Iteration 9796: Weights = [5.50000000e+01 3.14658293e+00 6.61574099e+00 2.17967241e-02\n",
      " 2.20268598e-01 1.24510830e+01], Loss = 0.2945\n",
      "Iteration 9797: Weights = [5.50000000e+01 3.14649260e+00 6.61555108e+00 2.17960984e-02\n",
      " 2.20262274e-01 1.24512836e+01], Loss = 0.2944\n",
      "Iteration 9798: Weights = [5.50000000e+01 3.14640228e+00 6.61536117e+00 2.17954727e-02\n",
      " 2.20255952e-01 1.24514842e+01], Loss = 0.2944\n",
      "Iteration 9799: Weights = [5.50000000e+01 3.14631196e+00 6.61517127e+00 2.17948470e-02\n",
      " 2.20249629e-01 1.24516849e+01], Loss = 0.2944\n",
      "Iteration 9800: Weights = [5.50000000e+01 3.14622164e+00 6.61498137e+00 2.17942214e-02\n",
      " 2.20243306e-01 1.24518855e+01], Loss = 0.2944\n",
      "Iteration 9801: Weights = [5.50000000e+01 3.14613132e+00 6.61479148e+00 2.17935958e-02\n",
      " 2.20236984e-01 1.24520861e+01], Loss = 0.2944\n",
      "Iteration 9802: Weights = [5.50000000e+01 3.14604101e+00 6.61460159e+00 2.17929701e-02\n",
      " 2.20230662e-01 1.24522867e+01], Loss = 0.2944\n",
      "Iteration 9803: Weights = [5.50000000e+01 3.14595070e+00 6.61441171e+00 2.17923446e-02\n",
      " 2.20224340e-01 1.24524873e+01], Loss = 0.2943\n",
      "Iteration 9804: Weights = [5.50000000e+01 3.14586039e+00 6.61422183e+00 2.17917190e-02\n",
      " 2.20218018e-01 1.24526879e+01], Loss = 0.2943\n",
      "Iteration 9805: Weights = [5.50000000e+01 3.14577008e+00 6.61403196e+00 2.17910934e-02\n",
      " 2.20211696e-01 1.24528885e+01], Loss = 0.2943\n",
      "Iteration 9806: Weights = [5.50000000e+01 3.14567978e+00 6.61384210e+00 2.17904679e-02\n",
      " 2.20205375e-01 1.24530891e+01], Loss = 0.2943\n",
      "Iteration 9807: Weights = [5.50000000e+01 3.14558948e+00 6.61365224e+00 2.17898423e-02\n",
      " 2.20199053e-01 1.24532897e+01], Loss = 0.2943\n",
      "Iteration 9808: Weights = [5.50000000e+01 3.14549918e+00 6.61346239e+00 2.17892168e-02\n",
      " 2.20192732e-01 1.24534903e+01], Loss = 0.2943\n",
      "Iteration 9809: Weights = [5.50000000e+01 3.14540888e+00 6.61327254e+00 2.17885914e-02\n",
      " 2.20186411e-01 1.24536908e+01], Loss = 0.2942\n",
      "Iteration 9810: Weights = [5.50000000e+01 3.14531859e+00 6.61308270e+00 2.17879659e-02\n",
      " 2.20180091e-01 1.24538914e+01], Loss = 0.2942\n",
      "Iteration 9811: Weights = [5.50000000e+01 3.14522830e+00 6.61289286e+00 2.17873404e-02\n",
      " 2.20173770e-01 1.24540920e+01], Loss = 0.2942\n",
      "Iteration 9812: Weights = [5.50000000e+01 3.14513801e+00 6.61270303e+00 2.17867150e-02\n",
      " 2.20167450e-01 1.24542925e+01], Loss = 0.2942\n",
      "Iteration 9813: Weights = [5.50000000e+01 3.14504773e+00 6.61251320e+00 2.17860896e-02\n",
      " 2.20161130e-01 1.24544931e+01], Loss = 0.2942\n",
      "Iteration 9814: Weights = [5.50000000e+01 3.14495744e+00 6.61232338e+00 2.17854642e-02\n",
      " 2.20154810e-01 1.24546936e+01], Loss = 0.2942\n",
      "Iteration 9815: Weights = [5.50000000e+01 3.14486716e+00 6.61213357e+00 2.17848388e-02\n",
      " 2.20148490e-01 1.24548941e+01], Loss = 0.2941\n",
      "Iteration 9816: Weights = [5.50000000e+01 3.14477689e+00 6.61194376e+00 2.17842134e-02\n",
      " 2.20142170e-01 1.24550947e+01], Loss = 0.2941\n",
      "Iteration 9817: Weights = [5.50000000e+01 3.14468661e+00 6.61175395e+00 2.17835881e-02\n",
      " 2.20135851e-01 1.24552952e+01], Loss = 0.2941\n",
      "Iteration 9818: Weights = [5.50000000e+01 3.14459634e+00 6.61156415e+00 2.17829628e-02\n",
      " 2.20129531e-01 1.24554957e+01], Loss = 0.2941\n",
      "Iteration 9819: Weights = [5.50000000e+01 3.14450607e+00 6.61137436e+00 2.17823375e-02\n",
      " 2.20123212e-01 1.24556962e+01], Loss = 0.2941\n",
      "Iteration 9820: Weights = [5.50000000e+01 3.14441580e+00 6.61118457e+00 2.17817122e-02\n",
      " 2.20116893e-01 1.24558967e+01], Loss = 0.2941\n",
      "Iteration 9821: Weights = [5.50000000e+01 3.14432554e+00 6.61099479e+00 2.17810869e-02\n",
      " 2.20110575e-01 1.24560972e+01], Loss = 0.2940\n",
      "Iteration 9822: Weights = [5.50000000e+01 3.14423528e+00 6.61080501e+00 2.17804616e-02\n",
      " 2.20104256e-01 1.24562977e+01], Loss = 0.2940\n",
      "Iteration 9823: Weights = [5.50000000e+01 3.14414502e+00 6.61061524e+00 2.17798364e-02\n",
      " 2.20097938e-01 1.24564982e+01], Loss = 0.2940\n",
      "Iteration 9824: Weights = [5.50000000e+01 3.14405476e+00 6.61042547e+00 2.17792112e-02\n",
      " 2.20091619e-01 1.24566987e+01], Loss = 0.2940\n",
      "Iteration 9825: Weights = [5.50000000e+01 3.14396451e+00 6.61023571e+00 2.17785860e-02\n",
      " 2.20085301e-01 1.24568992e+01], Loss = 0.2940\n",
      "Iteration 9826: Weights = [5.50000000e+01 3.14387425e+00 6.61004596e+00 2.17779608e-02\n",
      " 2.20078984e-01 1.24570997e+01], Loss = 0.2940\n",
      "Iteration 9827: Weights = [5.50000000e+01 3.14378400e+00 6.60985621e+00 2.17773356e-02\n",
      " 2.20072666e-01 1.24573001e+01], Loss = 0.2939\n",
      "Iteration 9828: Weights = [5.50000000e+01 3.14369376e+00 6.60966646e+00 2.17767105e-02\n",
      " 2.20066348e-01 1.24575006e+01], Loss = 0.2939\n",
      "Iteration 9829: Weights = [5.50000000e+01 3.14360351e+00 6.60947672e+00 2.17760854e-02\n",
      " 2.20060031e-01 1.24577011e+01], Loss = 0.2939\n",
      "Iteration 9830: Weights = [5.50000000e+01 3.14351327e+00 6.60928699e+00 2.17754603e-02\n",
      " 2.20053714e-01 1.24579015e+01], Loss = 0.2939\n",
      "Iteration 9831: Weights = [5.50000000e+01 3.14342303e+00 6.60909726e+00 2.17748352e-02\n",
      " 2.20047397e-01 1.24581020e+01], Loss = 0.2939\n",
      "Iteration 9832: Weights = [5.50000000e+01 3.14333280e+00 6.60890754e+00 2.17742101e-02\n",
      " 2.20041080e-01 1.24583024e+01], Loss = 0.2938\n",
      "Iteration 9833: Weights = [5.50000000e+01 3.14324257e+00 6.60871782e+00 2.17735850e-02\n",
      " 2.20034764e-01 1.24585028e+01], Loss = 0.2938\n",
      "Iteration 9834: Weights = [5.50000000e+01 3.14315233e+00 6.60852811e+00 2.17729600e-02\n",
      " 2.20028447e-01 1.24587033e+01], Loss = 0.2938\n",
      "Iteration 9835: Weights = [5.50000000e+01 3.14306211e+00 6.60833840e+00 2.17723350e-02\n",
      " 2.20022131e-01 1.24589037e+01], Loss = 0.2938\n",
      "Iteration 9836: Weights = [5.50000000e+01 3.14297188e+00 6.60814870e+00 2.17717100e-02\n",
      " 2.20015815e-01 1.24591041e+01], Loss = 0.2938\n",
      "Iteration 9837: Weights = [5.50000000e+01 3.14288166e+00 6.60795900e+00 2.17710850e-02\n",
      " 2.20009499e-01 1.24593045e+01], Loss = 0.2938\n",
      "Iteration 9838: Weights = [5.50000000e+01 3.14279144e+00 6.60776931e+00 2.17704600e-02\n",
      " 2.20003184e-01 1.24595049e+01], Loss = 0.2937\n",
      "Iteration 9839: Weights = [5.50000000e+01 3.14270122e+00 6.60757963e+00 2.17698351e-02\n",
      " 2.19996868e-01 1.24597053e+01], Loss = 0.2937\n",
      "Iteration 9840: Weights = [5.50000000e+01 3.14261100e+00 6.60738995e+00 2.17692101e-02\n",
      " 2.19990553e-01 1.24599057e+01], Loss = 0.2937\n",
      "Iteration 9841: Weights = [5.50000000e+01 3.14252079e+00 6.60720028e+00 2.17685852e-02\n",
      " 2.19984238e-01 1.24601061e+01], Loss = 0.2937\n",
      "Iteration 9842: Weights = [5.50000000e+01 3.14243058e+00 6.60701061e+00 2.17679603e-02\n",
      " 2.19977923e-01 1.24603065e+01], Loss = 0.2937\n",
      "Iteration 9843: Weights = [5.50000000e+01 3.14234037e+00 6.60682095e+00 2.17673354e-02\n",
      " 2.19971608e-01 1.24605068e+01], Loss = 0.2937\n",
      "Iteration 9844: Weights = [5.50000000e+01 3.14225017e+00 6.60663129e+00 2.17667106e-02\n",
      " 2.19965293e-01 1.24607072e+01], Loss = 0.2936\n",
      "Iteration 9845: Weights = [5.50000000e+01 3.14215997e+00 6.60644164e+00 2.17660857e-02\n",
      " 2.19958979e-01 1.24609076e+01], Loss = 0.2936\n",
      "Iteration 9846: Weights = [5.50000000e+01 3.14206977e+00 6.60625199e+00 2.17654609e-02\n",
      " 2.19952665e-01 1.24611079e+01], Loss = 0.2936\n",
      "Iteration 9847: Weights = [5.50000000e+01 3.14197957e+00 6.60606235e+00 2.17648361e-02\n",
      " 2.19946351e-01 1.24613083e+01], Loss = 0.2936\n",
      "Iteration 9848: Weights = [5.50000000e+01 3.14188937e+00 6.60587271e+00 2.17642113e-02\n",
      " 2.19940037e-01 1.24615086e+01], Loss = 0.2936\n",
      "Iteration 9849: Weights = [5.50000000e+01 3.14179918e+00 6.60568308e+00 2.17635866e-02\n",
      " 2.19933723e-01 1.24617090e+01], Loss = 0.2936\n",
      "Iteration 9850: Weights = [5.50000000e+01 3.14170899e+00 6.60549346e+00 2.17629618e-02\n",
      " 2.19927410e-01 1.24619093e+01], Loss = 0.2935\n",
      "Iteration 9851: Weights = [5.50000000e+01 3.14161881e+00 6.60530384e+00 2.17623371e-02\n",
      " 2.19921097e-01 1.24621096e+01], Loss = 0.2935\n",
      "Iteration 9852: Weights = [5.50000000e+01 3.14152862e+00 6.60511422e+00 2.17617123e-02\n",
      " 2.19914783e-01 1.24623100e+01], Loss = 0.2935\n",
      "Iteration 9853: Weights = [5.50000000e+01 3.14143844e+00 6.60492462e+00 2.17610877e-02\n",
      " 2.19908470e-01 1.24625103e+01], Loss = 0.2935\n",
      "Iteration 9854: Weights = [5.50000000e+01 3.14134826e+00 6.60473501e+00 2.17604630e-02\n",
      " 2.19902158e-01 1.24627106e+01], Loss = 0.2935\n",
      "Iteration 9855: Weights = [5.50000000e+01 3.14125808e+00 6.60454542e+00 2.17598383e-02\n",
      " 2.19895845e-01 1.24629109e+01], Loss = 0.2935\n",
      "Iteration 9856: Weights = [5.50000000e+01 3.14116791e+00 6.60435582e+00 2.17592137e-02\n",
      " 2.19889533e-01 1.24631112e+01], Loss = 0.2934\n",
      "Iteration 9857: Weights = [5.50000000e+01 3.14107774e+00 6.60416624e+00 2.17585890e-02\n",
      " 2.19883221e-01 1.24633115e+01], Loss = 0.2934\n",
      "Iteration 9858: Weights = [5.50000000e+01 3.14098757e+00 6.60397666e+00 2.17579644e-02\n",
      " 2.19876909e-01 1.24635118e+01], Loss = 0.2934\n",
      "Iteration 9859: Weights = [5.50000000e+01 3.14089740e+00 6.60378708e+00 2.17573398e-02\n",
      " 2.19870597e-01 1.24637121e+01], Loss = 0.2934\n",
      "Iteration 9860: Weights = [5.50000000e+01 3.14080724e+00 6.60359751e+00 2.17567153e-02\n",
      " 2.19864285e-01 1.24639123e+01], Loss = 0.2934\n",
      "Iteration 9861: Weights = [5.50000000e+01 3.14071708e+00 6.60340794e+00 2.17560907e-02\n",
      " 2.19857973e-01 1.24641126e+01], Loss = 0.2934\n",
      "Iteration 9862: Weights = [5.50000000e+01 3.14062692e+00 6.60321839e+00 2.17554662e-02\n",
      " 2.19851662e-01 1.24643129e+01], Loss = 0.2933\n",
      "Iteration 9863: Weights = [5.50000000e+01 3.14053676e+00 6.60302883e+00 2.17548417e-02\n",
      " 2.19845351e-01 1.24645131e+01], Loss = 0.2933\n",
      "Iteration 9864: Weights = [5.50000000e+01 3.14044661e+00 6.60283928e+00 2.17542172e-02\n",
      " 2.19839040e-01 1.24647134e+01], Loss = 0.2933\n",
      "Iteration 9865: Weights = [5.50000000e+01 3.14035646e+00 6.60264974e+00 2.17535927e-02\n",
      " 2.19832729e-01 1.24649137e+01], Loss = 0.2933\n",
      "Iteration 9866: Weights = [5.50000000e+01 3.14026631e+00 6.60246020e+00 2.17529682e-02\n",
      " 2.19826419e-01 1.24651139e+01], Loss = 0.2933\n",
      "Iteration 9867: Weights = [5.50000000e+01 3.14017617e+00 6.60227067e+00 2.17523438e-02\n",
      " 2.19820108e-01 1.24653141e+01], Loss = 0.2933\n",
      "Iteration 9868: Weights = [5.50000000e+01 3.14008602e+00 6.60208114e+00 2.17517193e-02\n",
      " 2.19813798e-01 1.24655144e+01], Loss = 0.2932\n",
      "Iteration 9869: Weights = [5.50000000e+01 3.13999588e+00 6.60189162e+00 2.17510949e-02\n",
      " 2.19807488e-01 1.24657146e+01], Loss = 0.2932\n",
      "Iteration 9870: Weights = [5.50000000e+01 3.13990575e+00 6.60170211e+00 2.17504705e-02\n",
      " 2.19801178e-01 1.24659148e+01], Loss = 0.2932\n",
      "Iteration 9871: Weights = [5.50000000e+01 3.13981561e+00 6.60151259e+00 2.17498461e-02\n",
      " 2.19794869e-01 1.24661150e+01], Loss = 0.2932\n",
      "Iteration 9872: Weights = [5.50000000e+01 3.13972548e+00 6.60132309e+00 2.17492218e-02\n",
      " 2.19788559e-01 1.24663152e+01], Loss = 0.2932\n",
      "Iteration 9873: Weights = [5.50000000e+01 3.13963535e+00 6.60113359e+00 2.17485974e-02\n",
      " 2.19782250e-01 1.24665154e+01], Loss = 0.2932\n",
      "Iteration 9874: Weights = [5.50000000e+01 3.13954522e+00 6.60094410e+00 2.17479731e-02\n",
      " 2.19775941e-01 1.24667156e+01], Loss = 0.2931\n",
      "Iteration 9875: Weights = [5.50000000e+01 3.13945510e+00 6.60075461e+00 2.17473488e-02\n",
      " 2.19769632e-01 1.24669158e+01], Loss = 0.2931\n",
      "Iteration 9876: Weights = [5.50000000e+01 3.13936497e+00 6.60056512e+00 2.17467245e-02\n",
      " 2.19763323e-01 1.24671160e+01], Loss = 0.2931\n",
      "Iteration 9877: Weights = [5.50000000e+01 3.13927486e+00 6.60037565e+00 2.17461003e-02\n",
      " 2.19757014e-01 1.24673162e+01], Loss = 0.2931\n",
      "Iteration 9878: Weights = [5.50000000e+01 3.13918474e+00 6.60018617e+00 2.17454760e-02\n",
      " 2.19750706e-01 1.24675164e+01], Loss = 0.2931\n",
      "Iteration 9879: Weights = [5.50000000e+01 3.13909462e+00 6.59999671e+00 2.17448518e-02\n",
      " 2.19744398e-01 1.24677165e+01], Loss = 0.2931\n",
      "Iteration 9880: Weights = [5.50000000e+01 3.13900451e+00 6.59980725e+00 2.17442276e-02\n",
      " 2.19738090e-01 1.24679167e+01], Loss = 0.2930\n",
      "Iteration 9881: Weights = [5.50000000e+01 3.13891440e+00 6.59961779e+00 2.17436034e-02\n",
      " 2.19731782e-01 1.24681169e+01], Loss = 0.2930\n",
      "Iteration 9882: Weights = [5.50000000e+01 3.13882430e+00 6.59942834e+00 2.17429792e-02\n",
      " 2.19725474e-01 1.24683170e+01], Loss = 0.2930\n",
      "Iteration 9883: Weights = [5.50000000e+01 3.13873419e+00 6.59923889e+00 2.17423550e-02\n",
      " 2.19719166e-01 1.24685172e+01], Loss = 0.2930\n",
      "Iteration 9884: Weights = [5.50000000e+01 3.13864409e+00 6.59904945e+00 2.17417309e-02\n",
      " 2.19712859e-01 1.24687173e+01], Loss = 0.2930\n",
      "Iteration 9885: Weights = [5.50000000e+01 3.13855399e+00 6.59886002e+00 2.17411068e-02\n",
      " 2.19706552e-01 1.24689174e+01], Loss = 0.2930\n",
      "Iteration 9886: Weights = [5.50000000e+01 3.13846390e+00 6.59867059e+00 2.17404827e-02\n",
      " 2.19700245e-01 1.24691176e+01], Loss = 0.2929\n",
      "Iteration 9887: Weights = [5.50000000e+01 3.13837380e+00 6.59848117e+00 2.17398586e-02\n",
      " 2.19693938e-01 1.24693177e+01], Loss = 0.2929\n",
      "Iteration 9888: Weights = [5.50000000e+01 3.13828371e+00 6.59829175e+00 2.17392345e-02\n",
      " 2.19687632e-01 1.24695178e+01], Loss = 0.2929\n",
      "Iteration 9889: Weights = [5.50000000e+01 3.13819362e+00 6.59810234e+00 2.17386104e-02\n",
      " 2.19681325e-01 1.24697179e+01], Loss = 0.2929\n",
      "Iteration 9890: Weights = [5.50000000e+01 3.13810354e+00 6.59791293e+00 2.17379864e-02\n",
      " 2.19675019e-01 1.24699180e+01], Loss = 0.2929\n",
      "Iteration 9891: Weights = [5.50000000e+01 3.13801345e+00 6.59772353e+00 2.17373624e-02\n",
      " 2.19668713e-01 1.24701181e+01], Loss = 0.2929\n",
      "Iteration 9892: Weights = [5.50000000e+01 3.13792337e+00 6.59753413e+00 2.17367384e-02\n",
      " 2.19662407e-01 1.24703182e+01], Loss = 0.2928\n",
      "Iteration 9893: Weights = [5.50000000e+01 3.13783329e+00 6.59734474e+00 2.17361144e-02\n",
      " 2.19656101e-01 1.24705183e+01], Loss = 0.2928\n",
      "Iteration 9894: Weights = [5.50000000e+01 3.13774322e+00 6.59715535e+00 2.17354904e-02\n",
      " 2.19649796e-01 1.24707184e+01], Loss = 0.2928\n",
      "Iteration 9895: Weights = [5.50000000e+01 3.13765315e+00 6.59696597e+00 2.17348665e-02\n",
      " 2.19643491e-01 1.24709185e+01], Loss = 0.2928\n",
      "Iteration 9896: Weights = [5.50000000e+01 3.13756307e+00 6.59677660e+00 2.17342426e-02\n",
      " 2.19637185e-01 1.24711185e+01], Loss = 0.2928\n",
      "Iteration 9897: Weights = [5.50000000e+01 3.13747301e+00 6.59658723e+00 2.17336187e-02\n",
      " 2.19630880e-01 1.24713186e+01], Loss = 0.2928\n",
      "Iteration 9898: Weights = [5.50000000e+01 3.13738294e+00 6.59639787e+00 2.17329948e-02\n",
      " 2.19624576e-01 1.24715187e+01], Loss = 0.2927\n",
      "Iteration 9899: Weights = [5.50000000e+01 3.13729288e+00 6.59620851e+00 2.17323709e-02\n",
      " 2.19618271e-01 1.24717187e+01], Loss = 0.2927\n",
      "Iteration 9900: Weights = [5.50000000e+01 3.13720282e+00 6.59601916e+00 2.17317470e-02\n",
      " 2.19611967e-01 1.24719188e+01], Loss = 0.2927\n",
      "Iteration 9901: Weights = [5.50000000e+01 3.13711276e+00 6.59582981e+00 2.17311232e-02\n",
      " 2.19605662e-01 1.24721188e+01], Loss = 0.2927\n",
      "Iteration 9902: Weights = [5.50000000e+01 3.13702271e+00 6.59564047e+00 2.17304994e-02\n",
      " 2.19599358e-01 1.24723188e+01], Loss = 0.2927\n",
      "Iteration 9903: Weights = [5.50000000e+01 3.13693265e+00 6.59545113e+00 2.17298756e-02\n",
      " 2.19593054e-01 1.24725189e+01], Loss = 0.2927\n",
      "Iteration 9904: Weights = [5.50000000e+01 3.13684260e+00 6.59526180e+00 2.17292518e-02\n",
      " 2.19586751e-01 1.24727189e+01], Loss = 0.2926\n",
      "Iteration 9905: Weights = [5.50000000e+01 3.13675256e+00 6.59507247e+00 2.17286280e-02\n",
      " 2.19580447e-01 1.24729189e+01], Loss = 0.2926\n",
      "Iteration 9906: Weights = [5.50000000e+01 3.13666251e+00 6.59488315e+00 2.17280043e-02\n",
      " 2.19574144e-01 1.24731189e+01], Loss = 0.2926\n",
      "Iteration 9907: Weights = [5.50000000e+01 3.13657247e+00 6.59469384e+00 2.17273806e-02\n",
      " 2.19567841e-01 1.24733189e+01], Loss = 0.2926\n",
      "Iteration 9908: Weights = [5.50000000e+01 3.13648243e+00 6.59450453e+00 2.17267568e-02\n",
      " 2.19561538e-01 1.24735189e+01], Loss = 0.2926\n",
      "Iteration 9909: Weights = [5.50000000e+01 3.13639239e+00 6.59431523e+00 2.17261331e-02\n",
      " 2.19555235e-01 1.24737189e+01], Loss = 0.2926\n",
      "Iteration 9910: Weights = [5.50000000e+01 3.13630236e+00 6.59412593e+00 2.17255095e-02\n",
      " 2.19548932e-01 1.24739189e+01], Loss = 0.2925\n",
      "Iteration 9911: Weights = [5.50000000e+01 3.13621233e+00 6.59393663e+00 2.17248858e-02\n",
      " 2.19542630e-01 1.24741189e+01], Loss = 0.2925\n",
      "Iteration 9912: Weights = [5.50000000e+01 3.13612230e+00 6.59374735e+00 2.17242622e-02\n",
      " 2.19536328e-01 1.24743189e+01], Loss = 0.2925\n",
      "Iteration 9913: Weights = [5.50000000e+01 3.13603227e+00 6.59355806e+00 2.17236385e-02\n",
      " 2.19530025e-01 1.24745189e+01], Loss = 0.2925\n",
      "Iteration 9914: Weights = [5.50000000e+01 3.13594225e+00 6.59336879e+00 2.17230149e-02\n",
      " 2.19523724e-01 1.24747188e+01], Loss = 0.2925\n",
      "Iteration 9915: Weights = [5.50000000e+01 3.13585223e+00 6.59317952e+00 2.17223914e-02\n",
      " 2.19517422e-01 1.24749188e+01], Loss = 0.2925\n",
      "Iteration 9916: Weights = [5.50000000e+01 3.13576221e+00 6.59299025e+00 2.17217678e-02\n",
      " 2.19511120e-01 1.24751187e+01], Loss = 0.2924\n",
      "Iteration 9917: Weights = [5.50000000e+01 3.13567219e+00 6.59280099e+00 2.17211442e-02\n",
      " 2.19504819e-01 1.24753187e+01], Loss = 0.2924\n",
      "Iteration 9918: Weights = [5.50000000e+01 3.13558218e+00 6.59261174e+00 2.17205207e-02\n",
      " 2.19498518e-01 1.24755186e+01], Loss = 0.2924\n",
      "Iteration 9919: Weights = [5.50000000e+01 3.13549217e+00 6.59242249e+00 2.17198972e-02\n",
      " 2.19492217e-01 1.24757186e+01], Loss = 0.2924\n",
      "Iteration 9920: Weights = [5.50000000e+01 3.13540216e+00 6.59223324e+00 2.17192737e-02\n",
      " 2.19485916e-01 1.24759185e+01], Loss = 0.2924\n",
      "Iteration 9921: Weights = [5.50000000e+01 3.13531215e+00 6.59204400e+00 2.17186502e-02\n",
      " 2.19479615e-01 1.24761184e+01], Loss = 0.2924\n",
      "Iteration 9922: Weights = [5.50000000e+01 3.13522215e+00 6.59185477e+00 2.17180267e-02\n",
      " 2.19473315e-01 1.24763184e+01], Loss = 0.2923\n",
      "Iteration 9923: Weights = [5.50000000e+01 3.13513215e+00 6.59166554e+00 2.17174033e-02\n",
      " 2.19467015e-01 1.24765183e+01], Loss = 0.2923\n",
      "Iteration 9924: Weights = [5.50000000e+01 3.13504215e+00 6.59147632e+00 2.17167799e-02\n",
      " 2.19460715e-01 1.24767182e+01], Loss = 0.2923\n",
      "Iteration 9925: Weights = [5.50000000e+01 3.13495216e+00 6.59128710e+00 2.17161565e-02\n",
      " 2.19454415e-01 1.24769181e+01], Loss = 0.2923\n",
      "Iteration 9926: Weights = [5.50000000e+01 3.13486216e+00 6.59109789e+00 2.17155331e-02\n",
      " 2.19448115e-01 1.24771180e+01], Loss = 0.2923\n",
      "Iteration 9927: Weights = [5.50000000e+01 3.13477217e+00 6.59090868e+00 2.17149097e-02\n",
      " 2.19441815e-01 1.24773179e+01], Loss = 0.2923\n",
      "Iteration 9928: Weights = [5.50000000e+01 3.13468219e+00 6.59071948e+00 2.17142863e-02\n",
      " 2.19435516e-01 1.24775178e+01], Loss = 0.2922\n",
      "Iteration 9929: Weights = [5.50000000e+01 3.13459220e+00 6.59053029e+00 2.17136630e-02\n",
      " 2.19429217e-01 1.24777177e+01], Loss = 0.2922\n",
      "Iteration 9930: Weights = [5.50000000e+01 3.13450222e+00 6.59034110e+00 2.17130397e-02\n",
      " 2.19422918e-01 1.24779175e+01], Loss = 0.2922\n",
      "Iteration 9931: Weights = [5.50000000e+01 3.13441224e+00 6.59015191e+00 2.17124164e-02\n",
      " 2.19416619e-01 1.24781174e+01], Loss = 0.2922\n",
      "Iteration 9932: Weights = [5.50000000e+01 3.13432226e+00 6.58996274e+00 2.17117931e-02\n",
      " 2.19410320e-01 1.24783173e+01], Loss = 0.2922\n",
      "Iteration 9933: Weights = [5.50000000e+01 3.13423229e+00 6.58977356e+00 2.17111698e-02\n",
      " 2.19404022e-01 1.24785171e+01], Loss = 0.2922\n",
      "Iteration 9934: Weights = [5.50000000e+01 3.13414231e+00 6.58958439e+00 2.17105466e-02\n",
      " 2.19397724e-01 1.24787170e+01], Loss = 0.2921\n",
      "Iteration 9935: Weights = [5.50000000e+01 3.13405234e+00 6.58939523e+00 2.17099234e-02\n",
      " 2.19391425e-01 1.24789168e+01], Loss = 0.2921\n",
      "Iteration 9936: Weights = [5.50000000e+01 3.13396238e+00 6.58920607e+00 2.17093001e-02\n",
      " 2.19385128e-01 1.24791167e+01], Loss = 0.2921\n",
      "Iteration 9937: Weights = [5.50000000e+01 3.13387241e+00 6.58901692e+00 2.17086770e-02\n",
      " 2.19378830e-01 1.24793165e+01], Loss = 0.2921\n",
      "Iteration 9938: Weights = [5.50000000e+01 3.13378245e+00 6.58882778e+00 2.17080538e-02\n",
      " 2.19372532e-01 1.24795163e+01], Loss = 0.2921\n",
      "Iteration 9939: Weights = [5.50000000e+01 3.13369249e+00 6.58863864e+00 2.17074306e-02\n",
      " 2.19366235e-01 1.24797162e+01], Loss = 0.2921\n",
      "Iteration 9940: Weights = [5.50000000e+01 3.13360253e+00 6.58844950e+00 2.17068075e-02\n",
      " 2.19359938e-01 1.24799160e+01], Loss = 0.2920\n",
      "Iteration 9941: Weights = [5.50000000e+01 3.13351258e+00 6.58826037e+00 2.17061844e-02\n",
      " 2.19353641e-01 1.24801158e+01], Loss = 0.2920\n",
      "Iteration 9942: Weights = [5.50000000e+01 3.13342263e+00 6.58807124e+00 2.17055613e-02\n",
      " 2.19347344e-01 1.24803156e+01], Loss = 0.2920\n",
      "Iteration 9943: Weights = [5.50000000e+01 3.13333268e+00 6.58788213e+00 2.17049382e-02\n",
      " 2.19341047e-01 1.24805154e+01], Loss = 0.2920\n",
      "Iteration 9944: Weights = [5.50000000e+01 3.13324273e+00 6.58769301e+00 2.17043151e-02\n",
      " 2.19334751e-01 1.24807152e+01], Loss = 0.2920\n",
      "Iteration 9945: Weights = [5.50000000e+01 3.13315279e+00 6.58750390e+00 2.17036920e-02\n",
      " 2.19328454e-01 1.24809150e+01], Loss = 0.2919\n",
      "Iteration 9946: Weights = [5.50000000e+01 3.13306285e+00 6.58731480e+00 2.17030690e-02\n",
      " 2.19322158e-01 1.24811148e+01], Loss = 0.2919\n",
      "Iteration 9947: Weights = [5.50000000e+01 3.13297291e+00 6.58712570e+00 2.17024460e-02\n",
      " 2.19315862e-01 1.24813145e+01], Loss = 0.2919\n",
      "Iteration 9948: Weights = [5.50000000e+01 3.13288297e+00 6.58693661e+00 2.17018230e-02\n",
      " 2.19309567e-01 1.24815143e+01], Loss = 0.2919\n",
      "Iteration 9949: Weights = [5.50000000e+01 3.13279304e+00 6.58674752e+00 2.17012000e-02\n",
      " 2.19303271e-01 1.24817141e+01], Loss = 0.2919\n",
      "Iteration 9950: Weights = [5.50000000e+01 3.13270311e+00 6.58655844e+00 2.17005771e-02\n",
      " 2.19296976e-01 1.24819138e+01], Loss = 0.2919\n",
      "Iteration 9951: Weights = [5.50000000e+01 3.13261318e+00 6.58636937e+00 2.16999541e-02\n",
      " 2.19290680e-01 1.24821136e+01], Loss = 0.2918\n",
      "Iteration 9952: Weights = [5.50000000e+01 3.13252325e+00 6.58618030e+00 2.16993312e-02\n",
      " 2.19284385e-01 1.24823134e+01], Loss = 0.2918\n",
      "Iteration 9953: Weights = [5.50000000e+01 3.13243333e+00 6.58599123e+00 2.16987083e-02\n",
      " 2.19278091e-01 1.24825131e+01], Loss = 0.2918\n",
      "Iteration 9954: Weights = [5.50000000e+01 3.13234341e+00 6.58580217e+00 2.16980854e-02\n",
      " 2.19271796e-01 1.24827128e+01], Loss = 0.2918\n",
      "Iteration 9955: Weights = [5.50000000e+01 3.13225349e+00 6.58561312e+00 2.16974625e-02\n",
      " 2.19265501e-01 1.24829126e+01], Loss = 0.2918\n",
      "Iteration 9956: Weights = [5.50000000e+01 3.13216358e+00 6.58542407e+00 2.16968397e-02\n",
      " 2.19259207e-01 1.24831123e+01], Loss = 0.2918\n",
      "Iteration 9957: Weights = [5.50000000e+01 3.13207366e+00 6.58523503e+00 2.16962168e-02\n",
      " 2.19252913e-01 1.24833120e+01], Loss = 0.2917\n",
      "Iteration 9958: Weights = [5.50000000e+01 3.13198375e+00 6.58504599e+00 2.16955940e-02\n",
      " 2.19246619e-01 1.24835117e+01], Loss = 0.2917\n",
      "Iteration 9959: Weights = [5.50000000e+01 3.13189385e+00 6.58485696e+00 2.16949712e-02\n",
      " 2.19240325e-01 1.24837114e+01], Loss = 0.2917\n",
      "Iteration 9960: Weights = [5.50000000e+01 3.13180394e+00 6.58466793e+00 2.16943484e-02\n",
      " 2.19234032e-01 1.24839111e+01], Loss = 0.2917\n",
      "Iteration 9961: Weights = [5.50000000e+01 3.13171404e+00 6.58447891e+00 2.16937257e-02\n",
      " 2.19227738e-01 1.24841108e+01], Loss = 0.2917\n",
      "Iteration 9962: Weights = [5.50000000e+01 3.13162414e+00 6.58428989e+00 2.16931029e-02\n",
      " 2.19221445e-01 1.24843105e+01], Loss = 0.2917\n",
      "Iteration 9963: Weights = [5.50000000e+01 3.13153424e+00 6.58410088e+00 2.16924802e-02\n",
      " 2.19215152e-01 1.24845102e+01], Loss = 0.2916\n",
      "Iteration 9964: Weights = [5.50000000e+01 3.13144435e+00 6.58391188e+00 2.16918575e-02\n",
      " 2.19208859e-01 1.24847099e+01], Loss = 0.2916\n",
      "Iteration 9965: Weights = [5.50000000e+01 3.13135445e+00 6.58372288e+00 2.16912348e-02\n",
      " 2.19202567e-01 1.24849096e+01], Loss = 0.2916\n",
      "Iteration 9966: Weights = [5.50000000e+01 3.13126456e+00 6.58353388e+00 2.16906121e-02\n",
      " 2.19196274e-01 1.24851093e+01], Loss = 0.2916\n",
      "Iteration 9967: Weights = [5.50000000e+01 3.13117468e+00 6.58334489e+00 2.16899895e-02\n",
      " 2.19189982e-01 1.24853089e+01], Loss = 0.2916\n",
      "Iteration 9968: Weights = [5.50000000e+01 3.13108479e+00 6.58315591e+00 2.16893668e-02\n",
      " 2.19183690e-01 1.24855086e+01], Loss = 0.2916\n",
      "Iteration 9969: Weights = [5.50000000e+01 3.13099491e+00 6.58296693e+00 2.16887442e-02\n",
      " 2.19177398e-01 1.24857082e+01], Loss = 0.2915\n",
      "Iteration 9970: Weights = [5.50000000e+01 3.13090503e+00 6.58277796e+00 2.16881216e-02\n",
      " 2.19171106e-01 1.24859079e+01], Loss = 0.2915\n",
      "Iteration 9971: Weights = [5.50000000e+01 3.13081516e+00 6.58258899e+00 2.16874990e-02\n",
      " 2.19164814e-01 1.24861075e+01], Loss = 0.2915\n",
      "Iteration 9972: Weights = [5.50000000e+01 3.13072528e+00 6.58240003e+00 2.16868764e-02\n",
      " 2.19158523e-01 1.24863071e+01], Loss = 0.2915\n",
      "Iteration 9973: Weights = [5.50000000e+01 3.13063541e+00 6.58221107e+00 2.16862539e-02\n",
      " 2.19152232e-01 1.24865068e+01], Loss = 0.2915\n",
      "Iteration 9974: Weights = [5.50000000e+01 3.13054554e+00 6.58202212e+00 2.16856313e-02\n",
      " 2.19145941e-01 1.24867064e+01], Loss = 0.2915\n",
      "Iteration 9975: Weights = [5.50000000e+01 3.13045567e+00 6.58183318e+00 2.16850088e-02\n",
      " 2.19139650e-01 1.24869060e+01], Loss = 0.2914\n",
      "Iteration 9976: Weights = [5.50000000e+01 3.13036581e+00 6.58164424e+00 2.16843863e-02\n",
      " 2.19133359e-01 1.24871056e+01], Loss = 0.2914\n",
      "Iteration 9977: Weights = [5.50000000e+01 3.13027595e+00 6.58145530e+00 2.16837639e-02\n",
      " 2.19127069e-01 1.24873052e+01], Loss = 0.2914\n",
      "Iteration 9978: Weights = [5.50000000e+01 3.13018609e+00 6.58126637e+00 2.16831414e-02\n",
      " 2.19120778e-01 1.24875048e+01], Loss = 0.2914\n",
      "Iteration 9979: Weights = [5.50000000e+01 3.13009623e+00 6.58107745e+00 2.16825190e-02\n",
      " 2.19114488e-01 1.24877044e+01], Loss = 0.2914\n",
      "Iteration 9980: Weights = [5.50000000e+01 3.13000638e+00 6.58088853e+00 2.16818965e-02\n",
      " 2.19108198e-01 1.24879040e+01], Loss = 0.2914\n",
      "Iteration 9981: Weights = [5.50000000e+01 3.12991653e+00 6.58069962e+00 2.16812741e-02\n",
      " 2.19101908e-01 1.24881036e+01], Loss = 0.2913\n",
      "Iteration 9982: Weights = [5.50000000e+01 3.12982668e+00 6.58051071e+00 2.16806517e-02\n",
      " 2.19095619e-01 1.24883032e+01], Loss = 0.2913\n",
      "Iteration 9983: Weights = [5.50000000e+01 3.12973684e+00 6.58032181e+00 2.16800294e-02\n",
      " 2.19089329e-01 1.24885028e+01], Loss = 0.2913\n",
      "Iteration 9984: Weights = [5.50000000e+01 3.12964699e+00 6.58013291e+00 2.16794070e-02\n",
      " 2.19083040e-01 1.24887023e+01], Loss = 0.2913\n",
      "Iteration 9985: Weights = [5.50000000e+01 3.12955715e+00 6.57994402e+00 2.16787847e-02\n",
      " 2.19076751e-01 1.24889019e+01], Loss = 0.2913\n",
      "Iteration 9986: Weights = [5.50000000e+01 3.12946731e+00 6.57975513e+00 2.16781624e-02\n",
      " 2.19070462e-01 1.24891014e+01], Loss = 0.2913\n",
      "Iteration 9987: Weights = [5.50000000e+01 3.12937748e+00 6.57956625e+00 2.16775401e-02\n",
      " 2.19064173e-01 1.24893010e+01], Loss = 0.2912\n",
      "Iteration 9988: Weights = [5.50000000e+01 3.12928765e+00 6.57937738e+00 2.16769178e-02\n",
      " 2.19057885e-01 1.24895005e+01], Loss = 0.2912\n",
      "Iteration 9989: Weights = [5.50000000e+01 3.12919782e+00 6.57918851e+00 2.16762955e-02\n",
      " 2.19051597e-01 1.24897001e+01], Loss = 0.2912\n",
      "Iteration 9990: Weights = [5.50000000e+01 3.12910799e+00 6.57899964e+00 2.16756733e-02\n",
      " 2.19045308e-01 1.24898996e+01], Loss = 0.2912\n",
      "Iteration 9991: Weights = [5.50000000e+01 3.12901816e+00 6.57881079e+00 2.16750510e-02\n",
      " 2.19039020e-01 1.24900991e+01], Loss = 0.2912\n",
      "Iteration 9992: Weights = [5.50000000e+01 3.12892834e+00 6.57862193e+00 2.16744288e-02\n",
      " 2.19032733e-01 1.24902986e+01], Loss = 0.2912\n",
      "Iteration 9993: Weights = [5.50000000e+01 3.12883852e+00 6.57843308e+00 2.16738066e-02\n",
      " 2.19026445e-01 1.24904982e+01], Loss = 0.2911\n",
      "Iteration 9994: Weights = [5.50000000e+01 3.12874870e+00 6.57824424e+00 2.16731845e-02\n",
      " 2.19020157e-01 1.24906977e+01], Loss = 0.2911\n",
      "Iteration 9995: Weights = [5.50000000e+01 3.12865889e+00 6.57805540e+00 2.16725623e-02\n",
      " 2.19013870e-01 1.24908972e+01], Loss = 0.2911\n",
      "Iteration 9996: Weights = [5.50000000e+01 3.12856908e+00 6.57786657e+00 2.16719402e-02\n",
      " 2.19007583e-01 1.24910967e+01], Loss = 0.2911\n",
      "Iteration 9997: Weights = [5.50000000e+01 3.12847927e+00 6.57767775e+00 2.16713180e-02\n",
      " 2.19001296e-01 1.24912962e+01], Loss = 0.2911\n",
      "Iteration 9998: Weights = [5.50000000e+01 3.12838946e+00 6.57748893e+00 2.16706959e-02\n",
      " 2.18995010e-01 1.24914957e+01], Loss = 0.2911\n",
      "Iteration 9999: Weights = [5.50000000e+01 3.12829965e+00 6.57730011e+00 2.16700738e-02\n",
      " 2.18988723e-01 1.24916951e+01], Loss = 0.2910\n",
      "Iteration 10000: Weights = [5.50000000e+01 3.12820985e+00 6.57711130e+00 2.16694518e-02\n",
      " 2.18982437e-01 1.24918946e+01], Loss = 0.2910\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 11. Using all 10,000 iterations ^^\n",
    "# =============================================================================\n",
    "\n",
    "final_weights, weight_history = gradient_descent(X_train_aug, y_train, \n",
    "                                                 initial_weights,\n",
    "                                                 learning_rate=0.01, \n",
    "                                                 iterations=10000)\n",
    "\n",
    "# Convert weight_history list to a NumPy array for plotting\n",
    "weight_history = np.array(weight_history)  # shape: (iterations, number_of_weights)\n",
    "\n",
    "# Define names for each weight: first weight is the Intercept, then the feature names\n",
    "weight_names = ['Bias'] + features\n",
    "\n",
    "# Create a 3x2 grid of subplots\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
    "axs = axs.flatten()  # Flatten the grid for easy indexing\n",
    "\n",
    "# Plot the evolution of each weight over iterations\n",
    "for j in range(weight_history.shape[1]):\n",
    "    axs[j].plot(range(1, len(weight_history) + 1), weight_history[:, j],\n",
    "                marker='o', linestyle='-')\n",
    "    axs[j].set_xlabel('Iteration')\n",
    "    axs[j].set_ylabel(weight_names[j])\n",
    "    axs[j].set_title(f'Weight Update for {weight_names[j]}')\n",
    "    axs[j].grid(True)\n",
    "\n",
    "# Hide any unused subplots (if any)\n",
    "for k in range(weight_history.shape[1], len(axs)):\n",
    "    axs[k].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Test Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([31.34141936, 35.3634258 , 36.63101421, 75.67624175, 34.52854598,\n",
       "       56.36490033, 85.54215198, 24.99713064, 29.70976574, 60.82407804,\n",
       "       75.4550396 , 21.20670121, 66.9488541 , 23.73435269, 75.06665059,\n",
       "       38.56006709, 16.82783704, 41.59232616, 48.62487649, 61.08979491,\n",
       "       85.82305418, 35.4959604 , 40.73333415, 61.7561761 , 52.37824021,\n",
       "       41.306885  , 48.53445959, 38.72767652, 53.34740399, 27.90091168])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict using the final weights for all test observations\n",
    "predictions = X_test_aug.dot(final_weights)\n",
    "\n",
    "# Show a few predictions alongside actual values\n",
    "predictions = X_test_aug.dot(final_weights)\n",
    "print(\"Predictions on Test Set:\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.6015\n",
      "Root Mean Squared Error on Test Set: 0.7756\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print(f\"Mean Squared Error on Test Set: {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error on Test Set: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
